{"py/object": "tensorboard_plugin_torch_profiler.run.Run", "name": "resnet50_newAPI_ddp", "run_dir": "./data/tracing\\resnet50_newAPI_ddp", "profiles": {"py/reduce": [{"py/type": "collections.OrderedDict"}, {"py/tuple": []}, null, null, {"py/tuple": [{"py/tuple": ["worker0_span1", {"py/object": "tensorboard_plugin_torch_profiler.run.RunProfile", "worker": "worker0_span1", "views": [{"py/object": "tensorboard_plugin_torch_profiler.consts.View", "py/newargs": {"py/tuple": [1, "overall", "Overview"]}, "py/seq": [1, "overall", "Overview"]}, {"py/object": "tensorboard_plugin_torch_profiler.consts.View", "py/newargs": {"py/tuple": [2, "operator", "Operator"]}, "py/seq": [2, "operator", "Operator"]}, {"py/object": "tensorboard_plugin_torch_profiler.consts.View", "py/newargs": {"py/tuple": [3, "kernel", "Kernel"]}, "py/seq": [3, "kernel", "Kernel"]}, {"py/object": "tensorboard_plugin_torch_profiler.consts.View", "py/newargs": {"py/tuple": [4, "trace", "Trace"]}, "py/seq": [4, "trace", "Trace"]}], "is_gpu_used": true, "overview": {"steps": {"columns": [{"type": "string", "name": "Step"}, {"type": "number", "name": "Kernel"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memcpy"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memset"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Runtime"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "DataLoader"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "CPU Exec"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Other"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}], "rows": [["5", 525069, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 1925746us<br><b>Kernel: 525069us</b><br>Percentage: 27.27%</div>", 1973, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 1925746us<br><b>Memcpy: 1973us</b><br>Percentage: 0.1%</div>", 1, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 1925746us<br><b>Memset: 1us</b><br>Percentage: 0.0%</div>", 10650, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 1925746us<br><b>Runtime: 10650us</b><br>Percentage: 0.55%</div>", 1170595, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 1925746us<br><b>DataLoader: 1170595us</b><br>Percentage: 60.79%</div>", 184623, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 1925746us<br><b>CPU Exec: 184623us</b><br>Percentage: 9.59%</div>", 32835, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 1925746us<br><b>Other: 32835us</b><br>Percentage: 1.71%</div>"], ["6", 1086995, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1826690us<br><b>Kernel: 1086995us</b><br>Percentage: 59.51%</div>", 1938, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1826690us<br><b>Memcpy: 1938us</b><br>Percentage: 0.11%</div>", 1, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1826690us<br><b>Memset: 1us</b><br>Percentage: 0.0%</div>", 10410, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1826690us<br><b>Runtime: 10410us</b><br>Percentage: 0.57%</div>", 543525, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1826690us<br><b>DataLoader: 543525us</b><br>Percentage: 29.75%</div>", 159334, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1826690us<br><b>CPU Exec: 159334us</b><br>Percentage: 8.72%</div>", 24487, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1826690us<br><b>Other: 24487us</b><br>Percentage: 1.34%</div>"], ["7", 1178195, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 1978892us<br><b>Kernel: 1178195us</b><br>Percentage: 59.54%</div>", 1973, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 1978892us<br><b>Memcpy: 1973us</b><br>Percentage: 0.1%</div>", 1, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 1978892us<br><b>Memset: 1us</b><br>Percentage: 0.0%</div>", 13847, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 1978892us<br><b>Runtime: 13847us</b><br>Percentage: 0.7%</div>", 558580, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 1978892us<br><b>DataLoader: 558580us</b><br>Percentage: 28.23%</div>", 187282, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 1978892us<br><b>CPU Exec: 187282us</b><br>Percentage: 9.46%</div>", 39014, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 1978892us<br><b>Other: 39014us</b><br>Percentage: 1.97%</div>"], ["8", 771109, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1849744us<br><b>Kernel: 771109us</b><br>Percentage: 41.69%</div>", 1938, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1849744us<br><b>Memcpy: 1938us</b><br>Percentage: 0.1%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1849744us<br><b>Memset: 0us</b><br>Percentage: 0.0%</div>", 5355, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1849744us<br><b>Runtime: 5355us</b><br>Percentage: 0.29%</div>", 544617, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1849744us<br><b>DataLoader: 544617us</b><br>Percentage: 29.44%</div>", 450575, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1849744us<br><b>CPU Exec: 450575us</b><br>Percentage: 24.36%</div>", 76150, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1849744us<br><b>Other: 76150us</b><br>Percentage: 4.12%</div>"]]}, "performance": [{"name": "Average Step Time", "description": "", "value": 1895268, "extra": 100, "children": [{"name": "Kernel", "description": "", "value": 890342, "extra": 46.98}, {"name": "Memcpy", "description": "", "value": 1956, "extra": 0.1}, {"name": "Memset", "description": "", "value": 1, "extra": 0.0}, {"name": "Runtime", "description": "", "value": 10066, "extra": 0.53}, {"name": "DataLoader", "description": "", "value": 704329, "extra": 37.16}, {"name": "CPU Exec", "description": "", "value": 245454, "extra": 12.95}, {"name": "Other", "description": "", "value": 43122, "extra": 2.28}]}], "recommendations": "<ul><li>This run has high time cost on input data loading. 37.2% of the step time is in DataLoader. You could try to set num_workers on DataLoader's construction and enable multi-processes on data loading. Reference: <a href =\"https://pytorch.org/docs/stable/data.html#single-and-multi-process-data-loading\" target=\"_blank\">Single- and Multi-process Data Loading</a></li></ul>"}, "operation_pie_by_name": {"device_total_time": {"title": "Device Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward", 147546], ["CudnnConvolutionBackward", 147546], ["aten::cudnn_convolution_backward_weight", 77413], ["aten::cudnn_convolution", 75413], ["aten::_convolution", 75413], ["aten::convolution", 75413], ["aten::conv2d", 75413], ["aten::cudnn_convolution_backward_input", 70133], ["aten::cudnn_batch_norm_backward", 29049], ["CudnnBatchNormBackward", 29049], ["aten::cudnn_batch_norm", 21031], ["aten::_batch_norm_impl_index", 21031], ["aten::batch_norm", 21031], ["aten::add_", 15027], ["aten::threshold_backward", 13643], ["ReluBackward1", 13643], ["aten::threshold_", 11158], ["aten::relu_", 11158], ["aten::copy_", 7349], ["aten::to", 6713], ["torch::autograd::AccumulateGrad", 3081], ["aten::max_pool2d_with_indices_backward", 2564], ["MaxPool2DWithIndicesBackward", 2564], ["aten::add", 1777], ["aten::fill_", 1215], ["aten::zero_", 1212], ["aten::mul_", 1173], ["aten::max_pool2d_with_indices", 891], ["aten::max_pool2d", 891], ["aten::zeros_like", 482], ["aten::_cat", 192], ["aten::cat", 192], ["aten::mm", 144], ["AddmmBackward", 144], ["aten::mean", 128], ["aten::adaptive_avg_pool2d", 128], ["aten::addmm", 97], ["aten::div", 87], ["MeanBackward1", 87], ["aten::_log_softmax_backward_data", 33], ["LogSoftmaxBackward", 33], ["aten::_log_softmax", 30], ["aten::log_softmax", 30], ["aten::nll_loss_forward", 12], ["aten::nll_loss", 12], ["aten::nll_loss_backward", 9], ["NllLossBackward", 9], ["aten::_local_scalar_dense", 3], ["aten::item", 3], ["aten::ones_like", 3]]}, "device_self_time": {"title": "Device Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward_weight", 77413], ["aten::cudnn_convolution", 75413], ["aten::cudnn_convolution_backward_input", 70133], ["aten::cudnn_batch_norm_backward", 29049], ["aten::cudnn_batch_norm", 21031], ["aten::add_", 15027], ["aten::threshold_backward", 13643], ["aten::threshold_", 11158], ["aten::copy_", 7349], ["aten::max_pool2d_with_indices_backward", 2082], ["aten::add", 1777], ["aten::fill_", 1215], ["aten::mul_", 1173], ["aten::max_pool2d_with_indices", 891], ["aten::_cat", 192], ["aten::mm", 144], ["aten::mean", 128], ["aten::addmm", 97], ["aten::div", 87], ["aten::_log_softmax_backward_data", 33], ["aten::_log_softmax", 30], ["aten::nll_loss_forward", 12], ["aten::nll_loss_backward", 9], ["aten::_local_scalar_dense", 3]]}, "host_total_time": {"title": "Host Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 2031774], ["aten::to", 1025097], ["aten::cat", 612492], ["aten::_cat", 610536], ["aten::stack", 604875], ["aten::clone", 523983], ["aten::contiguous", 521557], ["aten::div_", 495885], ["aten::div", 445543], ["aten::sub_", 409287], ["CudnnConvolutionBackward", 280330], ["aten::cudnn_convolution_backward", 262742], ["aten::empty", 205911], ["aten::add_", 203467], ["aten::batch_norm", 199524], ["aten::_batch_norm_impl_index", 189759], ["aten::conv2d", 182429], ["aten::convolution", 171985], ["aten::_convolution", 162628], ["aten::add", 160821], ["aten::cudnn_batch_norm", 153773], ["aten::cudnn_convolution", 140205], ["CudnnBatchNormBackward", 137733], ["aten::cudnn_convolution_backward_weight", 112384], ["aten::view", 112089], ["aten::cudnn_convolution_backward_input", 111884], ["aten::cudnn_batch_norm_backward", 110552], ["aten::eq", 89529], ["aten::zero_", 88626], ["aten::lt", 84744], ["torch::autograd::AccumulateGrad", 84524], ["aten::mul_", 75630], ["aten::narrow", 69542], ["aten::item", 66664], ["aten::exp", 53755], ["aten::slice", 50459], ["aten::pin_memory", 49716], ["ReluBackward1", 46361], ["aten::fill_", 41634], ["aten::select", 37077], ["aten::_local_scalar_dense", 36779], ["aten::relu_", 34905], ["aten::threshold_backward", 34320], ["aten::any", 33151], ["aten::uniform_", 29298], ["aten::randint", 28925], ["aten::empty_like", 28415], ["aten::resize_", 25020], ["aten::log", 21260], ["aten::stride", 20457], ["aten::as_strided", 20391], ["aten::empty_strided", 17016], ["aten::is_nonzero", 16639], ["aten::rand", 16262], ["aten::permute", 13976], ["aten::threshold_", 11579], ["aten::set_", 8897], ["aten::random_", 7918], ["aten::is_floating_point", 7147], ["aten::detach_", 6060], ["aten::unsqueeze", 5985], ["aten::addmm", 5088], ["AddmmBackward", 4140], ["MaxPool2DWithIndicesBackward", 2788], ["detach_", 2653], ["aten::zeros", 2521], ["aten::max_pool2d_with_indices_backward", 2463], ["aten::max_pool2d", 2413], ["aten::t", 2294], ["aten::max_pool2d_with_indices", 2197], ["aten::mm", 2022], ["MeanBackward1", 1765], ["AddBackward0", 1596], ["aten::nll_loss", 1569], ["aten::log_softmax", 1433], ["aten::expand", 1426], ["aten::nll_loss_forward", 1366], ["aten::ones_like", 1290], ["LogSoftmaxBackward", 1281], ["aten::_log_softmax", 1251], ["aten::adaptive_avg_pool2d", 1250], ["aten::mean", 1060], ["aten::_log_softmax_backward_data", 1027], ["NllLossBackward", 1013], ["aten::transpose", 979], ["aten::zeros_like", 927], ["aten::reshape", 923], ["aten::flatten", 735], ["aten::nll_loss_backward", 677], ["ViewBackward", 545], ["TBackward", 534], ["aten::is_pinned", 432], ["nccl:broadcast", 241], ["aten::resize_as_", 174], ["aten::conj", 151]]}, "host_self_time": {"title": "Host Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 2031774], ["aten::_cat", 606011], ["aten::div_", 495885], ["aten::div", 425536], ["aten::sub_", 409287], ["aten::empty", 205911], ["aten::add_", 203467], ["aten::add", 123747], ["aten::view", 112089], ["aten::cudnn_convolution", 108447], ["aten::cudnn_batch_norm", 104225], ["aten::cudnn_convolution_backward_weight", 81790], ["aten::cudnn_convolution_backward_input", 81100], ["aten::mul_", 75630], ["aten::cudnn_batch_norm_backward", 74031], ["aten::contiguous", 54385], ["aten::zero_", 49533], ["aten::to", 42633], ["aten::slice", 41829], ["aten::fill_", 41634], ["aten::_local_scalar_dense", 36779], ["aten::cudnn_convolution_backward", 36139], ["aten::exp", 34186], ["aten::select", 31688], ["aten::eq", 30095], ["aten::item", 29885], ["aten::uniform_", 29298], ["aten::lt", 26250], ["aten::threshold_backward", 26228], ["aten::_batch_norm_impl_index", 26137], ["torch::autograd::AccumulateGrad", 25378], ["aten::resize_", 25020], ["aten::any", 24450], ["CudnnBatchNormBackward", 23858], ["aten::relu_", 23326], ["aten::stride", 20457], ["aten::as_strided", 20391], ["aten::clone", 19700], ["aten::_convolution", 19668], ["aten::narrow", 19083], ["aten::log", 17617], ["CudnnConvolutionBackward", 17588], ["aten::empty_strided", 17016], ["aten::randint", 16300], ["aten::empty_like", 16137], ["ReluBackward1", 12041], ["aten::permute", 11866], ["aten::threshold_", 11579], ["aten::conv2d", 10444], ["aten::batch_norm", 9765], ["aten::convolution", 9357], ["aten::set_", 8897], ["aten::rand", 8790], ["aten::random_", 7918], ["aten::is_floating_point", 7147], ["aten::is_nonzero", 5465], ["aten::unsqueeze", 4334], ["aten::detach_", 3407], ["aten::addmm", 3278], ["detach_", 2653], ["aten::stack", 2431], ["aten::cat", 1956], ["AddBackward0", 1596], ["aten::max_pool2d_with_indices", 1574], ["aten::mm", 1523], ["aten::pin_memory", 1413], ["aten::zeros", 1376], ["aten::nll_loss_forward", 1366], ["aten::t", 1315], ["aten::max_pool2d_with_indices_backward", 1101], ["aten::expand", 1089], ["aten::mean", 899], ["aten::_log_softmax", 873], ["AddmmBackward", 696], ["aten::transpose", 679], ["aten::nll_loss_backward", 677], ["aten::_log_softmax_backward_data", 585], ["aten::ones_like", 450], ["aten::is_pinned", 432], ["NllLossBackward", 336], ["MeanBackward1", 330], ["MaxPool2DWithIndicesBackward", 325], ["LogSoftmaxBackward", 254], ["aten::reshape", 245], ["nccl:broadcast", 241], ["aten::max_pool2d", 216], ["aten::nll_loss", 203], ["aten::flatten", 196], ["aten::adaptive_avg_pool2d", 190], ["aten::log_softmax", 182], ["aten::zeros_like", 173], ["ViewBackward", 161], ["aten::conj", 151], ["aten::resize_as_", 138], ["TBackward", 134]]}}, "operation_table_by_name": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Device Self Duration (us)"}, {"type": "number", "name": "Device Total Duration (us)"}, {"type": "number", "name": "Host Self Duration (us)"}, {"type": "number", "name": "Host Total Duration (us)"}], "rows": [["aten::cudnn_convolution_backward_weight", 212, 77413, 77413, 81790, 112384], ["aten::cudnn_convolution", 212, 75413, 75413, 108447, 140205], ["aten::cudnn_convolution_backward_input", 208, 70133, 70133, 81100, 111884], ["aten::cudnn_batch_norm_backward", 212, 29049, 29049, 74031, 110552], ["aten::cudnn_batch_norm", 212, 21031, 21031, 104225, 153773], ["aten::add_", 1996, 15027, 15027, 203467, 203467], ["aten::threshold_backward", 196, 13643, 13643, 26228, 34320], ["aten::threshold_", 196, 11158, 11158, 11579, 11579], ["aten::copy_", 1420, 7349, 7349, 2031774, 2031774], ["aten::max_pool2d_with_indices_backward", 4, 2082, 2564, 1101, 2463], ["aten::add", 856, 1777, 1777, 123747, 160821], ["aten::fill_", 796, 1215, 1215, 41634, 41634], ["aten::mul_", 644, 1173, 1173, 75630, 75630], ["aten::max_pool2d_with_indices", 4, 891, 891, 1574, 2197], ["aten::_cat", 12, 192, 192, 606011, 610536], ["aten::mm", 8, 144, 144, 1523, 2022], ["aten::mean", 4, 128, 128, 899, 1060], ["aten::addmm", 4, 97, 97, 3278, 5088], ["aten::div", 132, 87, 87, 425536, 445543], ["aten::_log_softmax_backward_data", 4, 33, 33, 585, 1027], ["aten::_log_softmax", 4, 30, 30, 873, 1251], ["aten::nll_loss_forward", 4, 12, 12, 1366, 1366], ["aten::nll_loss_backward", 4, 9, 9, 677, 677], ["aten::_local_scalar_dense", 1512, 3, 3, 36779, 36779], ["aten::empty", 6653, 0, 0, 205911, 205911], ["aten::zero_", 664, 0, 1212, 49533, 88626], ["aten::zeros", 16, 0, 0, 1376, 2521], ["aten::uniform_", 498, 0, 0, 29298, 29298], ["aten::is_floating_point", 630, 0, 0, 7147, 7147], ["aten::item", 1512, 0, 3, 29885, 66664], ["aten::to", 973, 0, 6713, 42633, 1025097], ["detach_", 189, 0, 0, 2653, 2653], ["aten::detach_", 189, 0, 0, 3407, 6060], ["aten::log", 185, 0, 0, 17617, 21260], ["aten::as_strided", 1422, 0, 0, 20391, 20391], ["aten::select", 370, 0, 0, 31688, 37077], ["aten::resize_", 1861, 0, 0, 25020, 25020], ["aten::exp", 370, 0, 0, 34186, 53755], ["aten::random_", 256, 0, 0, 7918, 7918], ["aten::randint", 256, 0, 0, 16300, 28925], ["aten::rand", 128, 0, 0, 8790, 16262], ["aten::empty_strided", 652, 0, 0, 17016, 17016], ["aten::lt", 256, 0, 0, 26250, 84744], ["aten::is_nonzero", 256, 0, 0, 5465, 16639], ["aten::set_", 136, 0, 0, 8897, 8897], ["aten::view", 2088, 0, 0, 112089, 112089], ["aten::permute", 128, 0, 0, 11866, 13976], ["aten::empty_like", 356, 0, 0, 16137, 28415], ["aten::contiguous", 3960, 0, 0, 54385, 521557], ["aten::clone", 128, 0, 0, 19700, 523983], ["aten::eq", 256, 0, 0, 30095, 89529], ["aten::any", 128, 0, 0, 24450, 33151], ["aten::sub_", 128, 0, 0, 409287, 409287], ["aten::div_", 128, 0, 0, 495885, 495885], ["aten::unsqueeze", 128, 0, 0, 4334, 5985], ["aten::slice", 640, 0, 0, 41829, 50459], ["aten::narrow", 640, 0, 0, 19083, 69542], ["aten::stride", 3264, 0, 0, 20457, 20457], ["aten::cat", 12, 0, 192, 1956, 612492], ["aten::stack", 4, 0, 0, 2431, 604875], ["aten::is_pinned", 8, 0, 0, 432, 432], ["aten::pin_memory", 8, 0, 0, 1413, 49716], ["nccl:broadcast", 8, 0, 0, 241, 241], ["aten::_convolution", 212, 0, 75413, 19668, 162628], ["aten::convolution", 212, 0, 75413, 9357, 171985], ["aten::conv2d", 212, 0, 75413, 10444, 182429], ["aten::_batch_norm_impl_index", 212, 0, 21031, 26137, 189759], ["aten::batch_norm", 212, 0, 21031, 9765, 199524], ["aten::relu_", 196, 0, 11158, 23326, 34905], ["aten::max_pool2d", 4, 0, 891, 216, 2413], ["aten::adaptive_avg_pool2d", 4, 0, 128, 190, 1250], ["aten::reshape", 8, 0, 0, 245, 923], ["aten::flatten", 4, 0, 0, 196, 735], ["aten::transpose", 20, 0, 0, 679, 979], ["aten::t", 20, 0, 0, 1315, 2294], ["aten::expand", 8, 0, 0, 1089, 1426], ["aten::log_softmax", 4, 0, 30, 182, 1433], ["aten::nll_loss", 4, 0, 12, 203, 1569], ["aten::ones_like", 4, 0, 3, 450, 1290], ["NllLossBackward", 4, 0, 9, 336, 1013], ["LogSoftmaxBackward", 4, 0, 33, 254, 1281], ["aten::conj", 8, 0, 0, 151, 151], ["AddmmBackward", 4, 0, 144, 696, 4140], ["torch::autograd::AccumulateGrad", 644, 0, 3081, 25378, 84524], ["TBackward", 4, 0, 0, 134, 534], ["ViewBackward", 4, 0, 0, 161, 545], ["MeanBackward1", 4, 0, 87, 330, 1765], ["ReluBackward1", 196, 0, 13643, 12041, 46361], ["AddBackward0", 64, 0, 0, 1596, 1596], ["CudnnBatchNormBackward", 212, 0, 29049, 23858, 137733], ["aten::cudnn_convolution_backward", 212, 0, 147546, 36139, 262742], ["CudnnConvolutionBackward", 212, 0, 147546, 17588, 280330], ["aten::zeros_like", 4, 0, 482, 173, 927], ["aten::resize_as_", 4, 0, 0, 138, 174], ["MaxPool2DWithIndicesBackward", 4, 0, 2564, 325, 2788]]}}, "operation_pie_by_name_input": {"device_total_time": {"title": "Device Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["CudnnConvolutionBackward", 25974], ["CudnnConvolutionBackward", 19882], ["CudnnConvolutionBackward", 19163], ["CudnnConvolutionBackward", 17629], ["aten::cudnn_convolution_backward", 14985], ["CudnnConvolutionBackward", 14175], ["CudnnConvolutionBackward", 13542], ["CudnnConvolutionBackward", 12576], ["aten::cudnn_convolution_backward", 12210], ["aten::cudnn_convolution_backward", 11553], ["aten::cudnn_convolution_backward", 9364], ["CudnnConvolutionBackward", 9364], ["aten::cudnn_convolution_backward", 9316], ["aten::cudnn_convolution_backward", 9068], ["aten::cudnn_convolution_backward_weight", 8810], ["aten::cudnn_convolution_backward_input", 8195], ["aten::cudnn_batch_norm_backward", 7677], ["CudnnBatchNormBackward", 7677], ["aten::cudnn_convolution_backward", 7569], ["aten::cudnn_convolution_backward_input", 7261], ["aten::cudnn_convolution", 7103], ["aten::_convolution", 7103], ["aten::convolution", 7103], ["aten::conv2d", 7103], ["aten::cudnn_convolution_backward_weight", 6790], ["aten::copy_", 6701], ["aten::to", 6701], ["aten::cudnn_convolution_backward", 6565], ["aten::cudnn_convolution_backward", 6449], ["aten::cudnn_convolution_backward_input", 6373], ["aten::cudnn_batch_norm", 6370], ["aten::_batch_norm_impl_index", 6370], ["aten::batch_norm", 6370], ["aten::cudnn_convolution_backward_input", 6274], ["aten::cudnn_convolution", 5880], ["aten::_convolution", 5880], ["aten::convolution", 5880], ["aten::conv2d", 5880], ["aten::cudnn_convolution_backward_weight", 5837], ["aten::cudnn_convolution_backward_weight", 5810], ["aten::cudnn_convolution_backward", 5605], ["aten::cudnn_convolution_backward", 5575], ["aten::cudnn_convolution", 5022], ["aten::_convolution", 5022], ["aten::convolution", 5022], ["aten::conv2d", 5022], ["aten::cudnn_convolution_backward", 5007], ["aten::cudnn_batch_norm_backward", 4933], ["CudnnBatchNormBackward", 4933], ["aten::cudnn_convolution_backward", 4897], ["aten::cudnn_convolution_backward", 4875], ["aten::cudnn_convolution_backward_weight", 4873], ["aten::cudnn_convolution_backward", 4859], ["aten::cudnn_convolution_backward", 4854], ["aten::cudnn_convolution", 4825], ["aten::_convolution", 4825], ["aten::convolution", 4825], ["aten::conv2d", 4825], ["aten::cudnn_convolution_backward_input", 4737], ["aten::cudnn_convolution_backward", 4696], ["aten::cudnn_convolution_backward_weight", 4581], ["aten::cudnn_convolution_backward_weight", 4533], ["aten::cudnn_convolution", 4503], ["aten::_convolution", 4503], ["aten::convolution", 4503], ["aten::conv2d", 4503], ["aten::cudnn_convolution", 4463], ["aten::_convolution", 4463], ["aten::convolution", 4463], ["aten::conv2d", 4463], ["aten::cudnn_convolution_backward_input", 4443], ["aten::cudnn_convolution_backward_input", 4358], ["aten::add_", 4357], ["aten::cudnn_convolution", 4296], ["aten::_convolution", 4296], ["aten::convolution", 4296], ["aten::conv2d", 4296], ["aten::cudnn_convolution_backward", 4235], ["CudnnConvolutionBackward", 4235], ["aten::cudnn_convolution_backward", 4149], ["CudnnConvolutionBackward", 4149], ["aten::cudnn_batch_norm", 4119], ["aten::_batch_norm_impl_index", 4119], ["aten::batch_norm", 4119], ["aten::cudnn_convolution_backward", 3848], ["CudnnConvolutionBackward", 3848], ["aten::cudnn_convolution_backward", 3813], ["aten::cudnn_batch_norm_backward", 3786], ["CudnnBatchNormBackward", 3786], ["aten::cudnn_batch_norm_backward", 3776], ["CudnnBatchNormBackward", 3776], ["aten::cudnn_convolution", 3742], ["aten::_convolution", 3742], ["aten::convolution", 3742], ["aten::conv2d", 3742], ["aten::cudnn_convolution_backward_weight", 3678], ["aten::cudnn_convolution_backward_input", 3554], ["aten::cudnn_convolution", 3473], ["aten::_convolution", 3473], ["aten::convolution", 3473], ["aten::conv2d", 3473], ["aten::cudnn_convolution_backward_input", 3461], ["aten::cudnn_convolution", 3393], ["aten::_convolution", 3393], ["aten::convolution", 3393], ["aten::conv2d", 3393], ["aten::threshold_backward", 3298], ["ReluBackward1", 3298], ["aten::cudnn_convolution_backward_weight", 3211], ["aten::cudnn_convolution_backward_weight", 3009], ["aten::cudnn_convolution_backward", 3009], ["CudnnConvolutionBackward", 3009], ["aten::threshold_", 2997], ["aten::relu_", 2997], ["aten::add_", 2919], ["aten::cudnn_convolution", 2846], ["aten::_convolution", 2846], ["aten::convolution", 2846], ["aten::conv2d", 2846], ["aten::cudnn_convolution_backward_input", 2840], ["aten::cudnn_convolution_backward_weight", 2809], ["aten::cudnn_convolution_backward_input", 2771], ["aten::cudnn_convolution", 2738], ["aten::_convolution", 2738], ["aten::convolution", 2738], ["aten::conv2d", 2738], ["aten::cudnn_convolution_backward_input", 2731], ["aten::cudnn_convolution_backward_input", 2727], ["aten::cudnn_convolution", 2676], ["aten::_convolution", 2676], ["aten::convolution", 2676], ["aten::conv2d", 2676], ["aten::cudnn_batch_norm", 2656], ["aten::_batch_norm_impl_index", 2656], ["aten::batch_norm", 2656], ["aten::cudnn_convolution", 2565], ["aten::_convolution", 2565], ["aten::convolution", 2565], ["aten::conv2d", 2565], ["aten::max_pool2d_with_indices_backward", 2564], ["MaxPool2DWithIndicesBackward", 2564], ["aten::cudnn_convolution_backward_input", 2510], ["aten::cudnn_convolution_backward_weight", 2448], ["aten::cudnn_convolution", 2397], ["aten::_convolution", 2397], ["aten::convolution", 2397], ["aten::conv2d", 2397], ["aten::cudnn_batch_norm_backward", 2397], ["CudnnBatchNormBackward", 2397], ["aten::cudnn_convolution_backward_weight", 2349], ["aten::cudnn_convolution", 2271], ["aten::_convolution", 2271], ["aten::convolution", 2271], ["aten::conv2d", 2271], ["aten::cudnn_convolution", 2269], ["aten::_convolution", 2269], ["aten::convolution", 2269], ["aten::conv2d", 2269], ["aten::cudnn_convolution", 2264], ["aten::_convolution", 2264], ["aten::convolution", 2264], ["aten::conv2d", 2264], ["aten::cudnn_convolution_backward_input", 2254], ["aten::threshold_backward", 2229], ["ReluBackward1", 2229], ["aten::cudnn_convolution", 2223], ["aten::_convolution", 2223], ["aten::convolution", 2223], ["aten::conv2d", 2223], ["aten::cudnn_convolution_backward_weight", 2216], ["aten::cudnn_convolution", 2196], ["aten::_convolution", 2196], ["aten::convolution", 2196], ["aten::conv2d", 2196], ["aten::cudnn_convolution_backward_weight", 2170], ["aten::cudnn_convolution_backward_weight", 2167], ["aten::cudnn_convolution_backward_weight", 2144], ["aten::cudnn_convolution_backward_weight", 2097], ["aten::cudnn_convolution_backward_weight", 2055], ["aten::cudnn_convolution", 2041], ["aten::_convolution", 2041], ["aten::convolution", 2041], ["aten::conv2d", 2041], ["aten::threshold_", 2001], ["aten::relu_", 2001], ["aten::cudnn_convolution_backward_input", 1984], ["aten::cudnn_convolution_backward_weight", 1981], ["aten::cudnn_convolution_backward_weight", 1970], ["aten::cudnn_batch_norm_backward", 1906], ["CudnnBatchNormBackward", 1906], ["aten::cudnn_convolution_backward_weight", 1875], ["aten::cudnn_convolution", 1841], ["aten::_convolution", 1841], ["aten::convolution", 1841], ["aten::conv2d", 1841], ["aten::cudnn_batch_norm", 1785], ["aten::_batch_norm_impl_index", 1785], ["aten::batch_norm", 1785], ["aten::threshold_backward", 1719], ["ReluBackward1", 1719], ["aten::cudnn_convolution_backward_input", 1701], ["aten::cudnn_batch_norm", 1699], ["aten::_batch_norm_impl_index", 1699], ["aten::batch_norm", 1699], ["aten::threshold_backward", 1659], ["ReluBackward1", 1659], ["aten::add_", 1655], ["aten::cudnn_convolution_backward_input", 1632], ["aten::cudnn_batch_norm_backward", 1562], ["CudnnBatchNormBackward", 1562], ["aten::threshold_", 1521], ["aten::relu_", 1521], ["aten::cudnn_batch_norm", 1433], ["aten::_batch_norm_impl_index", 1433], ["aten::batch_norm", 1433], ["aten::threshold_", 1136], ["aten::relu_", 1136], ["aten::threshold_backward", 1104], ["ReluBackward1", 1104], ["aten::cudnn_convolution_backward", 1045], ["aten::threshold_backward", 1027], ["ReluBackward1", 1027], ["aten::cudnn_batch_norm_backward", 1026], ["CudnnBatchNormBackward", 1026], ["aten::threshold_", 997], ["aten::relu_", 997], ["aten::add_", 977], ["aten::threshold_backward", 915], ["ReluBackward1", 915], ["aten::threshold_", 896], ["aten::relu_", 896], ["aten::max_pool2d_with_indices", 891], ["aten::max_pool2d", 891], ["aten::cudnn_batch_norm_backward", 879], ["CudnnBatchNormBackward", 879], ["aten::cudnn_batch_norm", 794], ["aten::_batch_norm_impl_index", 794], ["aten::batch_norm", 794], ["aten::cudnn_batch_norm", 739], ["aten::_batch_norm_impl_index", 739], ["aten::batch_norm", 739], ["aten::cudnn_batch_norm", 668], ["aten::_batch_norm_impl_index", 668], ["aten::batch_norm", 668], ["aten::add_", 609], ["aten::threshold_backward", 551], ["ReluBackward1", 551], ["aten::threshold_", 501], ["aten::relu_", 501], ["aten::cudnn_batch_norm_backward", 491], ["CudnnBatchNormBackward", 491], ["aten::fill_", 482], ["aten::zero_", 482], ["aten::zeros_like", 482], ["aten::threshold_backward", 452], ["ReluBackward1", 452], ["aten::add_", 419], ["torch::autograd::AccumulateGrad", 417], ["aten::add_", 414], ["aten::cudnn_batch_norm", 412], ["aten::_batch_norm_impl_index", 412], ["aten::batch_norm", 412], ["aten::threshold_", 387], ["aten::relu_", 387], ["aten::cudnn_convolution", 386], ["aten::_convolution", 386], ["aten::convolution", 386], ["aten::conv2d", 386], ["aten::add_", 373], ["aten::add_", 369], ["torch::autograd::AccumulateGrad", 347], ["aten::cudnn_batch_norm_backward", 344], ["CudnnBatchNormBackward", 344], ["aten::cudnn_convolution_backward_input", 327], ["aten::add", 315], ["aten::add_", 303], ["aten::add_", 291], ["aten::threshold_", 289], ["aten::relu_", 289], ["torch::autograd::AccumulateGrad", 287], ["aten::threshold_backward", 286], ["ReluBackward1", 286], ["aten::add_", 274], ["aten::cudnn_batch_norm_backward", 272], ["CudnnBatchNormBackward", 272], ["aten::add_", 270], ["aten::add_", 265], ["aten::add_", 264], ["aten::threshold_", 252], ["aten::relu_", 252], ["aten::threshold_backward", 251], ["ReluBackward1", 251], ["aten::cudnn_batch_norm", 220], ["aten::_batch_norm_impl_index", 220], ["aten::batch_norm", 220], ["aten::mul_", 216], ["aten::copy_", 212], ["torch::autograd::AccumulateGrad", 207], ["aten::add_", 201], ["aten::add_", 199], ["aten::add", 193], ["aten::_cat", 192], ["aten::cat", 192], ["torch::autograd::AccumulateGrad", 186], ["aten::add", 182], ["torch::autograd::AccumulateGrad", 180], ["torch::autograd::AccumulateGrad", 171], ["aten::threshold_backward", 152], ["ReluBackward1", 152], ["aten::add_", 151], ["torch::autograd::AccumulateGrad", 149], ["aten::add", 146], ["AddmmBackward", 144], ["aten::cudnn_batch_norm", 136], ["aten::_batch_norm_impl_index", 136], ["aten::batch_norm", 136], ["aten::fill_", 135], ["aten::zero_", 135], ["aten::copy_", 128], ["aten::mean", 128], ["aten::adaptive_avg_pool2d", 128], ["torch::autograd::AccumulateGrad", 128], ["torch::autograd::AccumulateGrad", 125], ["aten::add_", 119], ["torch::autograd::AccumulateGrad", 116], ["aten::mul_", 108], ["torch::autograd::AccumulateGrad", 104], ["torch::autograd::AccumulateGrad", 103], ["aten::mul_", 100], ["aten::addmm", 97], ["aten::add", 96], ["aten::mul_", 96], ["aten::add", 96], ["aten::add", 93], ["aten::add", 93], ["aten::threshold_", 91], ["aten::relu_", 91], ["aten::threshold_", 90], ["aten::relu_", 90], ["torch::autograd::AccumulateGrad", 90], ["aten::add", 89], ["aten::copy_", 88], ["aten::add_", 87], ["aten::mm", 87], ["aten::div", 87], ["MeanBackward1", 87], ["aten::add_", 79], ["aten::fill_", 72], ["aten::zero_", 72], ["aten::add_", 72], ["torch::autograd::AccumulateGrad", 71], ["aten::add", 66], ["aten::mul_", 66], ["aten::add_", 66], ["aten::mul_", 66], ["aten::mul_", 65], ["aten::copy_", 64], ["aten::add", 64], ["aten::fill_", 63], ["aten::zero_", 63], ["aten::mul_", 63], ["torch::autograd::AccumulateGrad", 63], ["aten::add_", 62], ["aten::mul_", 62], ["aten::mm", 57], ["aten::copy_", 56], ["aten::copy_", 56], ["torch::autograd::AccumulateGrad", 55], ["torch::autograd::AccumulateGrad", 54], ["aten::add_", 53], ["aten::add", 48], ["aten::mul_", 48], ["aten::mul_", 46], ["aten::fill_", 45], ["aten::zero_", 45], ["torch::autograd::AccumulateGrad", 44], ["aten::fill_", 42], ["aten::zero_", 42], ["aten::add", 42], ["aten::mul_", 42], ["aten::add", 42], ["aten::mul_", 42], ["aten::add_", 41], ["aten::fill_", 39], ["aten::zero_", 39], ["aten::fill_", 39], ["aten::zero_", 39], ["torch::autograd::AccumulateGrad", 39], ["aten::fill_", 36], ["aten::zero_", 36], ["aten::fill_", 35], ["aten::zero_", 35], ["aten::add", 33], ["aten::add_", 33], ["aten::_log_softmax_backward_data", 33], ["LogSoftmaxBackward", 33], ["aten::copy_", 32], ["aten::add_", 32], ["aten::fill_", 31], ["aten::zero_", 31], ["aten::_log_softmax", 30], ["aten::log_softmax", 30], ["aten::fill_", 30], ["aten::zero_", 30], ["aten::fill_", 30], ["aten::zero_", 30], ["torch::autograd::AccumulateGrad", 29], ["aten::add", 27], ["aten::add", 27], ["torch::autograd::AccumulateGrad", 26], ["aten::add", 25], ["aten::mul_", 24], ["aten::add", 24], ["aten::mul_", 24], ["aten::add_", 23], ["aten::add_", 21], ["torch::autograd::AccumulateGrad", 21], ["aten::fill_", 20], ["aten::zero_", 20], ["aten::add_", 20], ["torch::autograd::AccumulateGrad", 20], ["aten::add", 18], ["torch::autograd::AccumulateGrad", 17], ["aten::mul_", 16], ["aten::mul_", 16], ["torch::autograd::AccumulateGrad", 15], ["torch::autograd::AccumulateGrad", 14], ["aten::copy_", 12], ["aten::to", 12], ["aten::nll_loss_forward", 12], ["aten::nll_loss", 12], ["aten::fill_", 12], ["aten::zero_", 12], ["aten::fill_", 12], ["aten::zero_", 12], ["aten::fill_", 12], ["aten::zero_", 12], ["aten::fill_", 12], ["aten::zero_", 12], ["aten::fill_", 12], ["aten::zero_", 12], ["aten::fill_", 12], ["aten::zero_", 12], ["aten::add", 12], ["aten::mul_", 12], ["aten::mul_", 12], ["aten::mul_", 10], ["aten::fill_", 9], ["aten::zero_", 9], ["aten::fill_", 9], ["aten::zero_", 9], ["aten::add", 9], ["aten::mul_", 9], ["aten::add", 9], ["aten::add", 9], ["aten::add_", 9], ["aten::nll_loss_backward", 9], ["NllLossBackward", 9], ["aten::fill_", 6], ["aten::zero_", 6], ["aten::add", 6], ["aten::mul_", 6], ["aten::mul_", 6], ["aten::mul_", 6], ["aten::add", 4], ["aten::_local_scalar_dense", 3], ["aten::item", 3], ["aten::fill_", 3], ["aten::zero_", 3], ["aten::fill_", 3], ["aten::zero_", 3], ["aten::fill_", 3], ["aten::zero_", 3], ["aten::fill_", 3], ["aten::zero_", 3], ["aten::fill_", 3], ["aten::zero_", 3], ["aten::fill_", 3], ["aten::ones_like", 3], ["aten::add", 3], ["aten::mul_", 3], ["aten::add", 3], ["aten::mul_", 3], ["aten::add", 3], ["aten::mul_", 3], ["aten::mul_", 3], ["torch::autograd::AccumulateGrad", 3], ["aten::fill_", 2], ["aten::zero_", 2]]}, "device_self_time": {"title": "Device Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward_weight", 8810], ["aten::cudnn_convolution_backward_input", 8195], ["aten::cudnn_batch_norm_backward", 7677], ["aten::cudnn_convolution_backward_input", 7261], ["aten::cudnn_convolution", 7103], ["aten::cudnn_convolution_backward_weight", 6790], ["aten::copy_", 6701], ["aten::cudnn_convolution_backward_input", 6373], ["aten::cudnn_batch_norm", 6370], ["aten::cudnn_convolution_backward_input", 6274], ["aten::cudnn_convolution", 5880], ["aten::cudnn_convolution_backward_weight", 5837], ["aten::cudnn_convolution_backward_weight", 5810], ["aten::cudnn_convolution", 5022], ["aten::cudnn_batch_norm_backward", 4933], ["aten::cudnn_convolution_backward_weight", 4873], ["aten::cudnn_convolution", 4825], ["aten::cudnn_convolution_backward_input", 4737], ["aten::cudnn_convolution_backward_weight", 4581], ["aten::cudnn_convolution_backward_weight", 4533], ["aten::cudnn_convolution", 4503], ["aten::cudnn_convolution", 4463], ["aten::cudnn_convolution_backward_input", 4443], ["aten::cudnn_convolution_backward_input", 4358], ["aten::add_", 4357], ["aten::cudnn_convolution", 4296], ["aten::cudnn_batch_norm", 4119], ["aten::cudnn_batch_norm_backward", 3786], ["aten::cudnn_batch_norm_backward", 3776], ["aten::cudnn_convolution", 3742], ["aten::cudnn_convolution_backward_weight", 3678], ["aten::cudnn_convolution_backward_input", 3554], ["aten::cudnn_convolution", 3473], ["aten::cudnn_convolution_backward_input", 3461], ["aten::cudnn_convolution", 3393], ["aten::threshold_backward", 3298], ["aten::cudnn_convolution_backward_weight", 3211], ["aten::cudnn_convolution_backward_weight", 3009], ["aten::threshold_", 2997], ["aten::add_", 2919], ["aten::cudnn_convolution", 2846], ["aten::cudnn_convolution_backward_input", 2840], ["aten::cudnn_convolution_backward_weight", 2809], ["aten::cudnn_convolution_backward_input", 2771], ["aten::cudnn_convolution", 2738], ["aten::cudnn_convolution_backward_input", 2731], ["aten::cudnn_convolution_backward_input", 2727], ["aten::cudnn_convolution", 2676], ["aten::cudnn_batch_norm", 2656], ["aten::cudnn_convolution", 2565], ["aten::cudnn_convolution_backward_input", 2510], ["aten::cudnn_convolution_backward_weight", 2448], ["aten::cudnn_convolution", 2397], ["aten::cudnn_batch_norm_backward", 2397], ["aten::cudnn_convolution_backward_weight", 2349], ["aten::cudnn_convolution", 2271], ["aten::cudnn_convolution", 2269], ["aten::cudnn_convolution", 2264], ["aten::cudnn_convolution_backward_input", 2254], ["aten::threshold_backward", 2229], ["aten::cudnn_convolution", 2223], ["aten::cudnn_convolution_backward_weight", 2216], ["aten::cudnn_convolution", 2196], ["aten::cudnn_convolution_backward_weight", 2170], ["aten::cudnn_convolution_backward_weight", 2167], ["aten::cudnn_convolution_backward_weight", 2144], ["aten::cudnn_convolution_backward_weight", 2097], ["aten::max_pool2d_with_indices_backward", 2082], ["aten::cudnn_convolution_backward_weight", 2055], ["aten::cudnn_convolution", 2041], ["aten::threshold_", 2001], ["aten::cudnn_convolution_backward_input", 1984], ["aten::cudnn_convolution_backward_weight", 1981], ["aten::cudnn_convolution_backward_weight", 1970], ["aten::cudnn_batch_norm_backward", 1906], ["aten::cudnn_convolution_backward_weight", 1875], ["aten::cudnn_convolution", 1841], ["aten::cudnn_batch_norm", 1785], ["aten::threshold_backward", 1719], ["aten::cudnn_convolution_backward_input", 1701], ["aten::cudnn_batch_norm", 1699], ["aten::threshold_backward", 1659], ["aten::add_", 1655], ["aten::cudnn_convolution_backward_input", 1632], ["aten::cudnn_batch_norm_backward", 1562], ["aten::threshold_", 1521], ["aten::cudnn_batch_norm", 1433], ["aten::threshold_", 1136], ["aten::threshold_backward", 1104], ["aten::threshold_backward", 1027], ["aten::cudnn_batch_norm_backward", 1026], ["aten::threshold_", 997], ["aten::add_", 977], ["aten::threshold_backward", 915], ["aten::threshold_", 896], ["aten::max_pool2d_with_indices", 891], ["aten::cudnn_batch_norm_backward", 879], ["aten::cudnn_batch_norm", 794], ["aten::cudnn_batch_norm", 739], ["aten::cudnn_batch_norm", 668], ["aten::add_", 609], ["aten::threshold_backward", 551], ["aten::threshold_", 501], ["aten::cudnn_batch_norm_backward", 491], ["aten::fill_", 482], ["aten::threshold_backward", 452], ["aten::add_", 419], ["aten::add_", 414], ["aten::cudnn_batch_norm", 412], ["aten::threshold_", 387], ["aten::cudnn_convolution", 386], ["aten::add_", 373], ["aten::add_", 369], ["aten::cudnn_batch_norm_backward", 344], ["aten::cudnn_convolution_backward_input", 327], ["aten::add", 315], ["aten::add_", 303], ["aten::add_", 291], ["aten::threshold_", 289], ["aten::threshold_backward", 286], ["aten::add_", 274], ["aten::cudnn_batch_norm_backward", 272], ["aten::add_", 270], ["aten::add_", 265], ["aten::add_", 264], ["aten::threshold_", 252], ["aten::threshold_backward", 251], ["aten::cudnn_batch_norm", 220], ["aten::mul_", 216], ["aten::copy_", 212], ["aten::add_", 201], ["aten::add_", 199], ["aten::add", 193], ["aten::_cat", 192], ["aten::add", 182], ["aten::threshold_backward", 152], ["aten::add_", 151], ["aten::add", 146], ["aten::cudnn_batch_norm", 136], ["aten::fill_", 135], ["aten::copy_", 128], ["aten::mean", 128], ["aten::add_", 119], ["aten::mul_", 108], ["aten::mul_", 100], ["aten::addmm", 97], ["aten::add", 96], ["aten::mul_", 96], ["aten::add", 96], ["aten::add", 93], ["aten::add", 93], ["aten::threshold_", 91], ["aten::threshold_", 90], ["aten::add", 89], ["aten::copy_", 88], ["aten::add_", 87], ["aten::mm", 87], ["aten::div", 87], ["aten::add_", 79], ["aten::fill_", 72], ["aten::add_", 72], ["aten::add", 66], ["aten::mul_", 66], ["aten::add_", 66], ["aten::mul_", 66], ["aten::mul_", 65], ["aten::copy_", 64], ["aten::add", 64], ["aten::fill_", 63], ["aten::mul_", 63], ["aten::add_", 62], ["aten::mul_", 62], ["aten::mm", 57], ["aten::copy_", 56], ["aten::copy_", 56], ["aten::add_", 53], ["aten::add", 48], ["aten::mul_", 48], ["aten::mul_", 46], ["aten::fill_", 45], ["aten::fill_", 42], ["aten::add", 42], ["aten::mul_", 42], ["aten::add", 42], ["aten::mul_", 42], ["aten::add_", 41], ["aten::fill_", 39], ["aten::fill_", 39], ["aten::fill_", 36], ["aten::fill_", 35], ["aten::add", 33], ["aten::add_", 33], ["aten::_log_softmax_backward_data", 33], ["aten::copy_", 32], ["aten::add_", 32], ["aten::fill_", 31], ["aten::_log_softmax", 30], ["aten::fill_", 30], ["aten::fill_", 30], ["aten::add", 27], ["aten::add", 27], ["aten::add", 25], ["aten::mul_", 24], ["aten::add", 24], ["aten::mul_", 24], ["aten::add_", 23], ["aten::add_", 21], ["aten::fill_", 20], ["aten::add_", 20], ["aten::add", 18], ["aten::mul_", 16], ["aten::mul_", 16], ["aten::copy_", 12], ["aten::nll_loss_forward", 12], ["aten::fill_", 12], ["aten::fill_", 12], ["aten::fill_", 12], ["aten::fill_", 12], ["aten::fill_", 12], ["aten::fill_", 12], ["aten::add", 12], ["aten::mul_", 12], ["aten::mul_", 12], ["aten::mul_", 10], ["aten::fill_", 9], ["aten::fill_", 9], ["aten::add", 9], ["aten::mul_", 9], ["aten::add", 9], ["aten::add", 9], ["aten::add_", 9], ["aten::nll_loss_backward", 9], ["aten::fill_", 6], ["aten::add", 6], ["aten::mul_", 6], ["aten::mul_", 6], ["aten::mul_", 6], ["aten::add", 4], ["aten::_local_scalar_dense", 3], ["aten::fill_", 3], ["aten::fill_", 3], ["aten::fill_", 3], ["aten::fill_", 3], ["aten::fill_", 3], ["aten::fill_", 3], ["aten::add", 3], ["aten::mul_", 3], ["aten::add", 3], ["aten::mul_", 3], ["aten::add", 3], ["aten::mul_", 3], ["aten::mul_", 3], ["aten::fill_", 2]]}, "host_total_time": {"title": "Host Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 1913708], ["aten::to", 967075], ["aten::cat", 612492], ["aten::_cat", 610536], ["aten::stack", 604875], ["aten::clone", 523983], ["aten::div_", 495885], ["aten::contiguous", 475443], ["aten::div", 444600], ["aten::sub_", 409287], ["aten::empty", 205911], ["CudnnConvolutionBackward", 57196], ["aten::eq", 54222], ["aten::lt", 50098], ["aten::to", 48976], ["aten::narrow", 48317], ["aten::pin_memory", 48239], ["aten::copy_", 47444], ["aten::batch_norm", 41758], ["aten::exp", 40631], ["aten::_batch_norm_impl_index", 39713], ["CudnnConvolutionBackward", 38967], ["aten::add_", 38654], ["aten::select", 37077], ["CudnnConvolutionBackward", 36960], ["aten::add", 36652], ["aten::item", 35916], ["aten::eq", 35307], ["aten::slice", 35036], ["aten::lt", 34646], ["aten::any", 33151], ["aten::copy_", 32597], ["aten::cudnn_batch_norm", 32295], ["CudnnConvolutionBackward", 31450], ["aten::item", 30748], ["aten::cudnn_convolution_backward", 29658], ["aten::uniform_", 29298], ["aten::randint", 28925], ["aten::batch_norm", 28917], ["CudnnBatchNormBackward", 28270], ["aten::add_", 27750], ["aten::_batch_norm_impl_index", 27570], ["CudnnConvolutionBackward", 26989], ["aten::batch_norm", 26567], ["aten::cudnn_convolution_backward", 25481], ["aten::_batch_norm_impl_index", 25278], ["CudnnConvolutionBackward", 24881], ["aten::add", 24056], ["aten::cudnn_convolution_backward", 23294], ["CudnnConvolutionBackward", 23177], ["aten::cudnn_batch_norm", 22737], ["aten::cudnn_batch_norm_backward", 22596], ["aten::batch_norm", 21816], ["aten::_local_scalar_dense", 21617], ["aten::log", 21260], ["CudnnConvolutionBackward", 20999], ["aten::narrow", 20912], ["aten::_batch_norm_impl_index", 20724], ["aten::cudnn_batch_norm", 20425], ["aten::cudnn_convolution_backward", 19674], ["aten::conv2d", 19169], ["CudnnBatchNormBackward", 18941], ["aten::cudnn_convolution_backward", 18527], ["aten::batch_norm", 18261], ["aten::batch_norm", 18232], ["aten::add_", 18154], ["aten::convolution", 18001], ["aten::view", 17963], ["aten::zero_", 17907], ["CudnnBatchNormBackward", 17853], ["aten::view", 17567], ["aten::add", 17512], ["aten::add_", 17451], ["aten::_batch_norm_impl_index", 17348], ["aten::_batch_norm_impl_index", 17326], ["aten::conv2d", 17066], ["aten::empty_strided", 17016], ["aten::_convolution", 16986], ["aten::cudnn_convolution_backward", 16796], ["torch::autograd::AccumulateGrad", 16751], ["aten::cudnn_batch_norm", 16705], ["aten::cudnn_convolution_backward", 16628], ["aten::conv2d", 16525], ["aten::rand", 16262], ["aten::convolution", 16093], ["aten::conv2d", 16000], ["aten::add_", 15914], ["aten::convolution", 15743], ["CudnnBatchNormBackward", 15543], ["aten::cudnn_batch_norm_backward", 15452], ["aten::_convolution", 15236], ["aten::slice", 15223], ["aten::_local_scalar_dense", 15162], ["aten::_convolution", 15071], ["aten::convolution", 15017], ["aten::cudnn_convolution_backward", 14807], ["aten::mul_", 14792], ["aten::batch_norm", 14665], ["aten::cudnn_convolution_backward", 14664], ["aten::batch_norm", 14473], ["aten::cudnn_convolution", 14432], ["aten::cudnn_batch_norm_backward", 14320], ["aten::view", 14258], ["aten::_convolution", 14156], ["aten::cudnn_batch_norm", 14013], ["aten::permute", 13976], ["aten::_batch_norm_impl_index", 13943], ["aten::cudnn_batch_norm", 13936], ["aten::_batch_norm_impl_index", 13752], ["aten::cudnn_convolution_backward_weight", 13656], ["aten::conv2d", 13579], ["aten::cudnn_convolution", 13353], ["aten::exp", 13124], ["aten::cudnn_convolution", 13107], ["CudnnBatchNormBackward", 13058], ["CudnnBatchNormBackward", 12975], ["aten::add", 12878], ["aten::convolution", 12768], ["aten::cudnn_convolution_backward_input", 12550], ["aten::cudnn_batch_norm_backward", 12489], ["aten::zero_", 12115], ["aten::_convolution", 12110], ["aten::view", 12021], ["aten::cudnn_convolution", 11999], ["aten::add", 11773], ["aten::cudnn_convolution_backward_input", 11660], ["torch::autograd::AccumulateGrad", 11442], ["aten::copy_", 11399], ["aten::resize_", 11338], ["aten::cudnn_convolution_backward_weight", 11262], ["aten::cudnn_batch_norm", 11215], ["aten::cudnn_batch_norm", 11127], ["aten::view", 10964], ["aten::mul_", 10859], ["CudnnBatchNormBackward", 10492], ["aten::cudnn_batch_norm_backward", 10423], ["aten::cudnn_convolution", 10415], ["aten::cudnn_batch_norm_backward", 10412], ["ReluBackward1", 10384], ["aten::cudnn_convolution_backward", 10379], ["CudnnBatchNormBackward", 10278], ["aten::conv2d", 10152], ["aten::conv2d", 10150], ["aten::cudnn_convolution_backward", 10054], ["aten::add_", 10037], ["aten::cudnn_convolution_backward_input", 9872], ["aten::cudnn_convolution_backward_weight", 9871], ["aten::cudnn_convolution_backward", 9831], ["aten::conv2d", 9685], ["aten::add", 9644], ["aten::convolution", 9565], ["aten::convolution", 9554], ["aten::conv2d", 9517], ["aten::convolution", 9107], ["aten::_convolution", 9076], ["aten::_convolution", 9033], ["aten::view", 9025], ["aten::convolution", 8934], ["aten::cudnn_convolution_backward_input", 8774], ["aten::view", 8606], ["aten::_convolution", 8580], ["aten::is_nonzero", 8530], ["aten::set_", 8459], ["aten::_convolution", 8438], ["aten::cudnn_batch_norm_backward", 8417], ["aten::cudnn_convolution_backward_input", 8320], ["aten::view", 8302], ["aten::cudnn_convolution_backward_input", 8272], ["torch::autograd::AccumulateGrad", 8209], ["aten::cudnn_batch_norm_backward", 8203], ["aten::is_nonzero", 8109], ["aten::view", 8081], ["aten::cudnn_convolution_backward_weight", 8024], ["aten::fill_", 7933], ["aten::zero_", 7924], ["aten::random_", 7918], ["aten::cudnn_convolution_backward_weight", 7908], ["aten::cudnn_convolution_backward_weight", 7849], ["aten::cudnn_convolution_backward_input", 7847], ["aten::cudnn_convolution", 7828], ["aten::empty_like", 7821], ["aten::relu_", 7818], ["aten::cudnn_convolution", 7798], ["aten::mul_", 7718], ["aten::add_", 7717], ["aten::threshold_backward", 7714], ["aten::copy_", 7702], ["aten::cudnn_convolution_backward_input", 7680], ["aten::zero_", 7585], ["torch::autograd::AccumulateGrad", 7515], ["aten::add_", 7492], ["aten::mul_", 7360], ["aten::cudnn_convolution", 7331], ["torch::autograd::AccumulateGrad", 7236], ["aten::conv2d", 7197], ["aten::cudnn_convolution", 7183], ["aten::is_floating_point", 7094], ["aten::cudnn_convolution_backward_weight", 6920], ["aten::conv2d", 6881], ["aten::convolution", 6810], ["aten::zero_", 6682], ["ReluBackward1", 6607], ["aten::convolution", 6491], ["aten::cudnn_convolution_backward_input", 6459], ["aten::conv2d", 6430], ["aten::cudnn_convolution_backward_weight", 6295], ["aten::cudnn_convolution_backward_input", 6234], ["aten::_convolution", 6158], ["aten::_convolution", 6132], ["aten::cudnn_convolution_backward_weight", 6027], ["aten::convolution", 6023], ["CudnnConvolutionBackward", 6023], ["aten::unsqueeze", 5985], ["aten::add", 5965], ["aten::mul_", 5956], ["aten::add_", 5944], ["aten::as_strided", 5938], ["aten::detach_", 5906], ["aten::cudnn_convolution_backward", 5688], ["ReluBackward1", 5671], ["aten::_convolution", 5653], ["CudnnConvolutionBackward", 5627], ["ReluBackward1", 5610], ["aten::as_strided", 5389], ["aten::copy_", 5370], ["aten::cudnn_convolution", 5308], ["aten::cudnn_convolution", 5305], ["aten::cudnn_convolution_backward", 5274], ["CudnnConvolutionBackward", 5259], ["aten::cudnn_convolution_backward", 5227], ["aten::copy_", 5225], ["aten::fill_", 5091], ["aten::addmm", 5088], ["aten::relu_", 5033], ["aten::cudnn_convolution_backward", 5032], ["aten::cudnn_convolution_backward", 4976], ["aten::zero_", 4968], ["aten::cudnn_convolution_backward", 4935], ["aten::cudnn_convolution_backward", 4916], ["aten::cudnn_convolution_backward", 4898], ["aten::threshold_backward", 4885], ["aten::cudnn_convolution_backward", 4840], ["aten::cudnn_convolution", 4831], ["aten::copy_", 4818], ["aten::add_", 4790], ["aten::add", 4712], ["ReluBackward1", 4694], ["aten::cudnn_convolution_backward", 4688], ["aten::add", 4652], ["aten::view", 4624], ["aten::add_", 4524], ["aten::conv2d", 4513], ["aten::cudnn_convolution_backward_weight", 4510], ["aten::contiguous", 4486], ["aten::add_", 4481], ["aten::cudnn_convolution_backward_input", 4408], ["aten::relu_", 4320], ["aten::cudnn_convolution_backward_weight", 4320], ["aten::convolution", 4284], ["aten::cudnn_convolution_backward_input", 4243], ["aten::threshold_backward", 4231], ["aten::conv2d", 4227], ["aten::relu_", 4225], ["aten::conv2d", 4224], ["aten::add_", 4214], ["aten::contiguous", 4164], ["AddmmBackward", 4140], ["torch::autograd::AccumulateGrad", 4140], ["aten::threshold_backward", 4120], ["aten::_convolution", 4102], ["aten::convolution", 4038], ["aten::convolution", 4035], ["aten::add", 4035], ["aten::empty_like", 4003], ["aten::cudnn_convolution_backward_weight", 3994], ["aten::conv2d", 3974], ["aten::to", 3925], ["aten::add_", 3900], ["aten::_convolution", 3877], ["aten::_convolution", 3871], ["aten::batch_norm", 3870], ["aten::convolution", 3782], ["ReluBackward1", 3770], ["aten::mul_", 3720], ["aten::batch_norm", 3686], ["aten::_batch_norm_impl_index", 3680], ["aten::batch_norm", 3649], ["aten::batch_norm", 3630], ["aten::zero_", 3617], ["aten::cudnn_convolution", 3605], ["aten::_convolution", 3600], ["aten::add_", 3555], ["aten::relu_", 3535], ["aten::fill_", 3516], ["aten::_batch_norm_impl_index", 3505], ["aten::conv2d", 3480], ["aten::cudnn_convolution", 3473], ["aten::_batch_norm_impl_index", 3470], ["aten::threshold_backward", 3468], ["aten::zero_", 3464], ["aten::cudnn_convolution", 3450], ["aten::_batch_norm_impl_index", 3450], ["aten::stride", 3428], ["aten::conv2d", 3413], ["aten::conv2d", 3389], ["aten::add_", 3379], ["aten::contiguous", 3348], ["aten::fill_", 3341], ["aten::add_", 3340], ["aten::conv2d", 3301], ["aten::convolution", 3271], ["aten::conv2d", 3206], ["aten::convolution", 3201], ["aten::convolution", 3196], ["aten::cudnn_convolution", 3191], ["aten::conv2d", 3176], ["aten::conv2d", 3175], ["torch::autograd::AccumulateGrad", 3135], ["aten::contiguous", 3132], ["aten::contiguous", 3114], ["torch::autograd::AccumulateGrad", 3111], ["aten::_convolution", 3107], ["aten::convolution", 3107], ["aten::fill_", 3086], ["aten::_convolution", 3033], ["aten::_convolution", 3031], ["aten::convolution", 3006], ["aten::convolution", 2981], ["aten::cudnn_convolution_backward_input", 2979], ["aten::convolution", 2978], ["aten::mul_", 2964], ["aten::cudnn_batch_norm", 2950], ["aten::_convolution", 2944], ["ReluBackward1", 2943], ["aten::add", 2929], ["aten::add", 2850], ["aten::contiguous", 2849], ["aten::to", 2839], ["aten::add", 2829], ["aten::_convolution", 2822], ["aten::copy_", 2821], ["aten::threshold_backward", 2818], ["aten::_convolution", 2813], ["aten::cudnn_batch_norm", 2811], ["CudnnConvolutionBackward", 2802], ["aten::_convolution", 2799], ["aten::relu_", 2788], ["MaxPool2DWithIndicesBackward", 2788], ["aten::zero_", 2787], ["aten::contiguous", 2785], ["ReluBackward1", 2785], ["aten::cudnn_batch_norm", 2784], ["aten::add", 2784], ["aten::cudnn_batch_norm", 2775], ["aten::cudnn_convolution", 2699], ["aten::mul_", 2680], ["aten::add", 2666], ["aten::as_strided", 2637], ["aten::add_", 2637], ["aten::cudnn_convolution", 2624], ["torch::autograd::AccumulateGrad", 2617], ["CudnnBatchNormBackward", 2608], ["CudnnBatchNormBackward", 2589], ["aten::cudnn_convolution", 2583], ["CudnnBatchNormBackward", 2583], ["aten::cudnn_convolution_backward_input", 2582], ["detach_", 2578], ["aten::empty_like", 2563], ["aten::threshold_", 2559], ["CudnnBatchNormBackward", 2543], ["aten::fill_", 2540], ["aten::cudnn_convolution", 2536], ["aten::stride", 2532], ["aten::zeros", 2521], ["aten::cudnn_convolution_backward_weight", 2503], ["aten::cudnn_convolution_backward", 2475], ["aten::empty_like", 2463], ["aten::max_pool2d_with_indices_backward", 2463], ["aten::fill_", 2444], ["aten::max_pool2d", 2413], ["aten::cudnn_convolution", 2394], ["aten::cudnn_convolution", 2388], ["aten::cudnn_convolution", 2372], ["aten::cudnn_convolution_backward_weight", 2344], ["aten::add_", 2312], ["aten::cudnn_convolution_backward_weight", 2275], ["aten::cudnn_convolution_backward_weight", 2255], ["aten::cudnn_convolution_backward_weight", 2224], ["aten::cudnn_convolution_backward_weight", 2223], ["aten::stride", 2219], ["aten::max_pool2d_with_indices", 2197], ["aten::add", 2194], ["aten::stride", 2188], ["aten::empty_like", 2167], ["aten::mul_", 2165], ["torch::autograd::AccumulateGrad", 2158], ["aten::cudnn_convolution_backward_input", 2152], ["aten::add_", 2139], ["aten::relu_", 2114], ["aten::as_strided", 2110], ["aten::zero_", 2109], ["aten::relu_", 2102], ["aten::threshold_backward", 2101], ["aten::contiguous", 2095], ["aten::cudnn_batch_norm_backward", 2089], ["aten::contiguous", 2078], ["torch::autograd::AccumulateGrad", 2075], ["aten::threshold_backward", 2072], ["aten::contiguous", 2069], ["torch::autograd::AccumulateGrad", 2068], ["aten::cudnn_batch_norm_backward", 2068], ["aten::cudnn_batch_norm_backward", 2067], ["aten::contiguous", 2058], ["aten::zero_", 2056], ["aten::add", 2046], ["aten::cudnn_batch_norm_backward", 2016], ["aten::cudnn_convolution_backward_weight", 2011], ["aten::cudnn_convolution_backward_weight", 2001], ["aten::cudnn_convolution_backward_input", 1990], ["aten::cudnn_convolution_backward_input", 1981], ["aten::as_strided", 1974], ["aten::cudnn_convolution_backward_weight", 1972], ["aten::cudnn_convolution_backward_input", 1942], ["aten::cudnn_convolution_backward_weight", 1940], ["aten::cudnn_convolution_backward_input", 1939], ["torch::autograd::AccumulateGrad", 1928], ["aten::contiguous", 1816], ["aten::mul_", 1806], ["aten::resize_", 1801], ["aten::empty_like", 1800], ["aten::zero_", 1774], ["MeanBackward1", 1765], ["aten::empty_like", 1752], ["aten::mul_", 1743], ["aten::zero_", 1726], ["aten::zero_", 1725], ["aten::mul_", 1685], ["aten::mul_", 1684], ["aten::threshold_", 1683], ["torch::autograd::AccumulateGrad", 1660], ["aten::as_strided", 1651], ["aten::add_", 1634], ["aten::add", 1632], ["aten::contiguous", 1631], ["aten::add_", 1630], ["aten::stride", 1596], ["torch::autograd::AccumulateGrad", 1582], ["aten::fill_", 1577], ["aten::nll_loss", 1569], ["torch::autograd::AccumulateGrad", 1564], ["aten::stride", 1545], ["aten::zero_", 1541], ["aten::mul_", 1517], ["aten::fill_", 1484], ["aten::pin_memory", 1477], ["aten::threshold_", 1475], ["aten::log_softmax", 1433], ["aten::empty_like", 1416], ["aten::empty_like", 1411], ["aten::add_", 1405], ["aten::add_", 1404], ["aten::threshold_", 1386], ["aten::contiguous", 1386], ["aten::add", 1385], ["aten::nll_loss_forward", 1366], ["aten::fill_", 1339], ["aten::zero_", 1308], ["aten::ones_like", 1290], ["LogSoftmaxBackward", 1281], ["aten::mul_", 1278], ["aten::mul_", 1271], ["aten::to", 1256], ["aten::_log_softmax", 1251], ["aten::adaptive_avg_pool2d", 1250], ["aten::zero_", 1250], ["aten::stride", 1242], ["aten::add_", 1193], ["aten::resize_", 1167], ["aten::resize_", 1150], ["aten::add_", 1147], ["aten::threshold_", 1146], ["aten::add_", 1145], ["aten::add_", 1120], ["aten::add_", 1110], ["ReluBackward1", 1108], ["aten::resize_", 1106], ["aten::add_", 1104], ["aten::add_", 1100], ["aten::add_", 1091], ["aten::mm", 1086], ["torch::autograd::AccumulateGrad", 1080], ["aten::t", 1062], ["aten::mean", 1060], ["aten::contiguous", 1053], ["aten::stride", 1052], ["aten::_log_softmax_backward_data", 1027], ["aten::fill_", 1026], ["torch::autograd::AccumulateGrad", 1021], ["NllLossBackward", 1013], ["aten::expand", 989], ["ReluBackward1", 957], ["aten::mul_", 949], ["aten::add", 947], ["aten::div", 943], ["aten::mm", 936], ["aten::threshold_", 931], ["aten::zeros_like", 927], ["ReluBackward1", 916], ["ReluBackward1", 916], ["aten::add", 902], ["aten::zero_", 893], ["aten::to", 879], ["aten::zero_", 868], ["aten::mul_", 866], ["aten::zero_", 852], ["aten::threshold_backward", 850], ["aten::add", 840], ["aten::resize_", 833], ["aten::t", 818], ["aten::resize_", 810], ["aten::relu_", 804], ["aten::fill_", 804], ["aten::fill_", 769], ["aten::fill_", 764], ["aten::add", 758], ["aten::zero_", 741], ["aten::flatten", 735], ["aten::relu_", 729], ["aten::relu_", 722], ["aten::contiguous", 715], ["aten::relu_", 715], ["aten::add", 713], ["aten::add", 710], ["aten::threshold_", 708], ["aten::add", 704], ["aten::contiguous", 699], ["aten::threshold_backward", 697], ["aten::empty_like", 691], ["aten::copy_", 690], ["aten::add", 687], ["aten::fill_", 686], ["aten::add", 686], ["aten::threshold_backward", 684], ["aten::threshold_", 683], ["aten::add", 680], ["aten::threshold_backward", 680], ["aten::zero_", 679], ["aten::zero_", 677], ["aten::zero_", 677], ["aten::nll_loss_backward", 677], ["aten::empty_like", 675], ["aten::resize_", 667], ["aten::mul_", 659], ["aten::fill_", 652], ["aten::stride", 633], ["aten::empty_like", 617], ["aten::stride", 611], ["aten::fill_", 596], ["AddBackward0", 588], ["torch::autograd::AccumulateGrad", 580], ["aten::contiguous", 572], ["aten::fill_", 569], ["aten::resize_", 561], ["aten::zero_", 557], ["aten::resize_", 553], ["ViewBackward", 545], ["aten::reshape", 539], ["aten::contiguous", 534], ["TBackward", 534], ["torch::autograd::AccumulateGrad", 532], ["torch::autograd::AccumulateGrad", 530], ["torch::autograd::AccumulateGrad", 525], ["torch::autograd::AccumulateGrad", 523], ["torch::autograd::AccumulateGrad", 515], ["torch::autograd::AccumulateGrad", 514], ["torch::autograd::AccumulateGrad", 514], ["aten::resize_", 508], ["torch::autograd::AccumulateGrad", 507], ["torch::autograd::AccumulateGrad", 492], ["aten::resize_", 491], ["aten::contiguous", 473], ["aten::mul_", 467], ["aten::mul_", 461], ["aten::mul_", 456], ["aten::contiguous", 453], ["aten::zero_", 449], ["aten::stride", 446], ["aten::mul_", 439], ["aten::set_", 438], ["aten::mul_", 437], ["aten::expand", 437], ["aten::mul_", 435], ["aten::zero_", 431], ["aten::zero_", 426], ["aten::mul_", 426], ["aten::contiguous", 425], ["aten::zero_", 424], ["aten::mul_", 419], ["aten::mul_", 418], ["aten::stride", 414], ["aten::view", 414], ["aten::t", 414], ["aten::zero_", 414], ["aten::fill_", 412], ["AddBackward0", 410], ["aten::contiguous", 403], ["aten::transpose", 400], ["aten::contiguous", 392], ["aten::fill_", 391], ["aten::transpose", 388], ["aten::reshape", 384], ["aten::fill_", 374], ["aten::resize_", 371], ["aten::resize_", 369], ["aten::contiguous", 369], ["aten::resize_", 363], ["aten::contiguous", 358], ["aten::contiguous", 357], ["aten::resize_", 350], ["aten::empty_like", 349], ["aten::contiguous", 348], ["aten::empty_like", 347], ["aten::stride", 346], ["aten::contiguous", 343], ["aten::fill_", 341], ["aten::empty_like", 340], ["aten::stride", 327], ["aten::stride", 317], ["aten::narrow", 313], ["AddBackward0", 305], ["aten::stride", 303], ["aten::stride", 302], ["AddBackward0", 293], ["aten::resize_", 290], ["aten::resize_", 290], ["aten::threshold_", 287], ["aten::resize_", 283], ["aten::as_strided", 265], ["aten::view", 264], ["aten::fill_", 262], ["aten::stride", 254], ["aten::fill_", 248], ["aten::threshold_", 247], ["aten::threshold_", 244], ["nccl:broadcast", 241], ["aten::threshold_", 230], ["aten::contiguous", 229], ["aten::is_pinned", 228], ["aten::contiguous", 226], ["aten::fill_", 223], ["aten::fill_", 209], ["aten::is_pinned", 204], ["aten::fill_", 202], ["aten::slice", 200], ["aten::fill_", 191], ["aten::transpose", 191], ["aten::fill_", 189], ["aten::fill_", 188], ["aten::fill_", 187], ["aten::resize_", 185], ["aten::resize_", 184], ["aten::resize_", 179], ["aten::stride", 177], ["aten::resize_as_", 174], ["aten::resize_", 162], ["aten::resize_", 159], ["aten::detach_", 154], ["aten::stride", 147], ["aten::contiguous", 145], ["aten::contiguous", 141], ["aten::as_strided", 129], ["aten::contiguous", 119], ["aten::contiguous", 118], ["aten::contiguous", 116], ["aten::contiguous", 116], ["aten::contiguous", 114], ["aten::contiguous", 114], ["aten::contiguous", 112], ["aten::as_strided", 111], ["aten::stride", 99], ["aten::resize_", 93], ["aten::resize_", 93], ["aten::to", 92], ["aten::resize_", 92], ["aten::resize_", 92], ["aten::resize_", 92], ["aten::resize_", 91], ["aten::resize_", 91], ["aten::resize_", 82], ["aten::conj", 76], ["detach_", 75], ["aten::resize_", 75], ["aten::conj", 75], ["aten::as_strided", 72], ["aten::stride", 69], ["aten::as_strided", 60], ["aten::contiguous", 59], ["aten::stride", 57], ["aten::as_strided", 55], ["aten::to", 55], ["aten::is_floating_point", 53], ["aten::resize_", 49], ["aten::stride", 44], ["aten::stride", 44], ["aten::stride", 42], ["aten::stride", 23]]}, "host_self_time": {"title": "Host Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 1913708], ["aten::_cat", 606011], ["aten::div_", 495885], ["aten::div", 424760], ["aten::sub_", 409287], ["aten::empty", 205911], ["aten::copy_", 47444], ["aten::add_", 38654], ["aten::copy_", 32597], ["aten::select", 31688], ["aten::uniform_", 29298], ["aten::slice", 29098], ["aten::add", 28555], ["aten::add_", 27750], ["aten::to", 25504], ["aten::any", 24450], ["aten::exp", 24091], ["aten::_local_scalar_dense", 21617], ["aten::cudnn_batch_norm", 21505], ["aten::clone", 19700], ["aten::add_", 18154], ["aten::add", 18108], ["aten::view", 17963], ["aten::log", 17617], ["aten::view", 17567], ["aten::add_", 17451], ["aten::empty_strided", 17016], ["aten::eq", 16936], ["aten::randint", 16300], ["aten::cudnn_batch_norm", 16153], ["aten::add_", 15914], ["aten::item", 15586], ["aten::cudnn_batch_norm_backward", 15181], ["aten::_local_scalar_dense", 15162], ["aten::mul_", 14792], ["aten::item", 14299], ["aten::view", 14258], ["aten::cudnn_batch_norm", 13625], ["aten::lt", 13487], ["aten::add", 13329], ["aten::narrow", 13281], ["aten::eq", 13159], ["aten::lt", 12763], ["aten::slice", 12586], ["aten::view", 12021], ["aten::permute", 11866], ["aten::copy_", 11399], ["aten::resize_", 11338], ["aten::cudnn_batch_norm", 11314], ["aten::cudnn_convolution", 11079], ["aten::view", 10964], ["aten::mul_", 10859], ["aten::cudnn_convolution", 10702], ["aten::cudnn_batch_norm_backward", 10308], ["aten::add", 10151], ["aten::exp", 10095], ["aten::cudnn_convolution_backward_weight", 10051], ["aten::add_", 10037], ["aten::cudnn_convolution", 10025], ["aten::zero_", 9974], ["aten::cudnn_batch_norm_backward", 9630], ["aten::to", 9501], ["aten::cudnn_batch_norm", 9421], ["aten::cudnn_batch_norm", 9380], ["aten::cudnn_convolution", 9181], ["aten::add", 9147], ["aten::view", 9025], ["aten::cudnn_convolution_backward_input", 8967], ["aten::rand", 8790], ["aten::view", 8606], ["aten::set_", 8459], ["aten::cudnn_batch_norm_backward", 8387], ["aten::cudnn_convolution_backward_weight", 8323], ["aten::view", 8302], ["aten::cudnn_convolution_backward_input", 8300], ["aten::contiguous", 8271], ["aten::view", 8081], ["aten::cudnn_convolution", 7998], ["aten::fill_", 7933], ["aten::random_", 7918], ["aten::mul_", 7718], ["aten::add_", 7717], ["aten::copy_", 7702], ["aten::cudnn_batch_norm", 7570], ["aten::cudnn_batch_norm", 7533], ["aten::add_", 7492], ["aten::add", 7445], ["aten::mul_", 7360], ["aten::cudnn_convolution_backward_weight", 7131], ["aten::is_floating_point", 7094], ["aten::cudnn_convolution_backward_input", 7043], ["aten::zero_", 7024], ["aten::cudnn_batch_norm_backward", 6947], ["aten::cudnn_batch_norm_backward", 6941], ["aten::cudnn_convolution_backward_input", 6325], ["aten::cudnn_convolution_backward_input", 6186], ["aten::cudnn_convolution", 6002], ["aten::cudnn_convolution", 5989], ["aten::cudnn_convolution_backward_input", 5959], ["aten::mul_", 5956], ["aten::add_", 5944], ["aten::as_strided", 5938], ["aten::threshold_backward", 5909], ["aten::cudnn_convolution_backward_input", 5897], ["aten::cudnn_convolution_backward_weight", 5802], ["aten::narrow", 5689], ["aten::cudnn_convolution_backward_weight", 5675], ["aten::cudnn_batch_norm_backward", 5649], ["aten::cudnn_convolution_backward_weight", 5648], ["aten::cudnn_convolution", 5577], ["aten::cudnn_convolution_backward_input", 5535], ["aten::cudnn_batch_norm_backward", 5503], ["aten::cudnn_convolution", 5492], ["aten::_batch_norm_impl_index", 5395], ["aten::as_strided", 5389], ["aten::copy_", 5370], ["aten::relu_", 5259], ["aten::empty_like", 5252], ["aten::copy_", 5225], ["aten::cudnn_convolution_backward_weight", 5116], ["aten::fill_", 5091], ["torch::autograd::AccumulateGrad", 5077], ["CudnnBatchNormBackward", 4999], ["aten::copy_", 4818], ["aten::add_", 4790], ["aten::add", 4659], ["aten::view", 4624], ["aten::cudnn_convolution_backward_input", 4571], ["aten::add_", 4524], ["aten::cudnn_convolution_backward_weight", 4523], ["aten::contiguous", 4486], ["aten::add_", 4481], ["aten::cudnn_convolution_backward_input", 4478], ["aten::zero_", 4408], ["aten::cudnn_convolution_backward_weight", 4388], ["aten::unsqueeze", 4334], ["aten::zero_", 4244], ["aten::add_", 4214], ["aten::contiguous", 4164], ["aten::cudnn_convolution", 4081], ["aten::cudnn_convolution_backward", 4073], ["aten::cudnn_convolution", 4051], ["aten::to", 3925], ["aten::add_", 3900], ["aten::threshold_backward", 3736], ["aten::mul_", 3720], ["aten::cudnn_convolution", 3697], ["aten::add", 3636], ["aten::zero_", 3596], ["CudnnConvolutionBackward", 3581], ["aten::add_", 3555], ["aten::_batch_norm_impl_index", 3521], ["aten::_batch_norm_impl_index", 3517], ["aten::fill_", 3516], ["aten::add", 3497], ["aten::stride", 3428], ["torch::autograd::AccumulateGrad", 3424], ["aten::add_", 3379], ["aten::cudnn_convolution_backward", 3366], ["aten::relu_", 3350], ["aten::contiguous", 3348], ["aten::fill_", 3341], ["aten::add_", 3340], ["aten::cudnn_convolution_backward", 3331], ["aten::detach_", 3328], ["aten::cudnn_convolution_backward_weight", 3301], ["aten::addmm", 3278], ["aten::add", 3209], ["aten::threshold_backward", 3207], ["aten::cudnn_convolution_backward_input", 3195], ["aten::cudnn_convolution_backward_input", 3154], ["aten::threshold_backward", 3138], ["aten::contiguous", 3132], ["aten::contiguous", 3114], ["aten::cudnn_convolution_backward_weight", 3112], ["CudnnBatchNormBackward", 3108], ["aten::fill_", 3086], ["CudnnBatchNormBackward", 3064], ["aten::mul_", 2964], ["aten::_batch_norm_impl_index", 2926], ["aten::cudnn_convolution_backward_weight", 2903], ["aten::contiguous", 2849], ["aten::relu_", 2845], ["aten::cudnn_convolution", 2842], ["aten::to", 2839], ["aten::relu_", 2839], ["aten::is_nonzero", 2835], ["aten::cudnn_convolution", 2834], ["aten::copy_", 2821], ["aten::cudnn_convolution_backward", 2819], ["aten::cudnn_convolution", 2801], ["aten::contiguous", 2785], ["CudnnBatchNormBackward", 2690], ["aten::mul_", 2680], ["ReluBackward1", 2670], ["aten::threshold_backward", 2658], ["aten::cudnn_convolution_backward", 2657], ["aten::as_strided", 2637], ["aten::add_", 2637], ["aten::is_nonzero", 2630], ["aten::cudnn_convolution", 2584], ["detach_", 2578], ["aten::threshold_", 2559], ["aten::fill_", 2540], ["aten::stride", 2532], ["aten::zero_", 2524], ["aten::_batch_norm_impl_index", 2448], ["aten::fill_", 2444], ["aten::stack", 2431], ["aten::_batch_norm_impl_index", 2419], ["torch::autograd::AccumulateGrad", 2413], ["aten::relu_", 2389], ["CudnnConvolutionBackward", 2386], ["aten::cudnn_convolution_backward_input", 2362], ["CudnnBatchNormBackward", 2323], ["aten::add_", 2312], ["CudnnConvolutionBackward", 2305], ["aten::add", 2304], ["aten::_convolution", 2239], ["aten::add", 2237], ["CudnnBatchNormBackward", 2229], ["aten::stride", 2219], ["aten::stride", 2188], ["aten::mul_", 2165], ["aten::empty_like", 2151], ["aten::add", 2151], ["torch::autograd::AccumulateGrad", 2147], ["aten::cudnn_convolution_backward", 2146], ["aten::add_", 2139], ["aten::threshold_backward", 2130], ["torch::autograd::AccumulateGrad", 2120], ["aten::as_strided", 2110], ["aten::add", 2100], ["aten::contiguous", 2095], ["aten::cudnn_convolution", 2089], ["aten::contiguous", 2078], ["aten::cudnn_convolution_backward", 2070], ["aten::contiguous", 2069], ["aten::add", 2068], ["aten::cudnn_batch_norm", 2059], ["aten::contiguous", 2058], ["aten::cudnn_convolution_backward", 2051], ["aten::batch_norm", 2045], ["aten::cudnn_convolution_backward", 2044], ["aten::zero_", 2040], ["aten::cudnn_convolution_backward_input", 1981], ["aten::zero_", 1980], ["CudnnConvolutionBackward", 1979], ["aten::cudnn_convolution", 1977], ["aten::as_strided", 1974], ["aten::cudnn_convolution", 1974], ["aten::cudnn_convolution", 1973], ["aten::_batch_norm_impl_index", 1973], ["aten::cat", 1956], ["aten::cudnn_batch_norm", 1907], ["aten::_batch_norm_impl_index", 1901], ["aten::cudnn_batch_norm", 1898], ["aten::_convolution", 1897], ["aten::_convolution", 1875], ["aten::cudnn_batch_norm", 1860], ["aten::relu_", 1857], ["aten::cudnn_convolution", 1841], ["aten::cudnn_convolution", 1839], ["CudnnBatchNormBackward", 1828], ["aten::cudnn_convolution", 1819], ["aten::cudnn_convolution_backward_weight", 1819], ["aten::contiguous", 1816], ["aten::mul_", 1806], ["CudnnBatchNormBackward", 1803], ["aten::resize_", 1801], ["aten::mul_", 1743], ["aten::cudnn_convolution_backward_weight", 1731], ["ReluBackward1", 1722], ["aten::mul_", 1685], ["aten::mul_", 1684], ["aten::threshold_", 1683], ["aten::cudnn_convolution_backward_weight", 1671], ["CudnnConvolutionBackward", 1666], ["CudnnConvolutionBackward", 1658], ["aten::as_strided", 1651], ["aten::cudnn_convolution_backward_weight", 1649], ["aten::add_", 1634], ["aten::add", 1634], ["aten::contiguous", 1631], ["aten::threshold_backward", 1631], ["aten::add_", 1630], ["aten::cudnn_convolution_backward_weight", 1627], ["aten::cudnn_convolution_backward_weight", 1615], ["aten::stride", 1596], ["aten::threshold_backward", 1596], ["aten::fill_", 1577], ["aten::max_pool2d_with_indices", 1574], ["aten::add", 1554], ["aten::cudnn_convolution_backward_input", 1548], ["aten::stride", 1545], ["aten::cudnn_convolution_backward", 1541], ["aten::mul_", 1517], ["aten::_convolution", 1512], ["ReluBackward1", 1490], ["aten::fill_", 1484], ["aten::threshold_", 1475], ["aten::_convolution", 1465], ["aten::cudnn_convolution_backward_weight", 1458], ["aten::zero_", 1448], ["ReluBackward1", 1440], ["aten::cudnn_convolution_backward_weight", 1438], ["aten::relu_", 1431], ["aten::cudnn_convolution_backward_input", 1425], ["aten::cudnn_convolution_backward_input", 1414], ["aten::cudnn_convolution_backward_weight", 1407], ["aten::add_", 1405], ["aten::add_", 1404], ["aten::cudnn_convolution_backward_weight", 1402], ["aten::cudnn_convolution_backward_input", 1400], ["aten::relu_", 1394], ["aten::cudnn_batch_norm_backward", 1393], ["aten::threshold_", 1386], ["aten::contiguous", 1386], ["aten::cudnn_batch_norm_backward", 1386], ["aten::zeros", 1376], ["aten::zero_", 1370], ["aten::cudnn_batch_norm_backward", 1367], ["aten::nll_loss_forward", 1366], ["aten::cudnn_convolution_backward_input", 1360], ["aten::cudnn_convolution_backward", 1357], ["CudnnConvolutionBackward", 1349], ["aten::batch_norm", 1347], ["aten::cudnn_convolution_backward", 1344], ["aten::fill_", 1339], ["aten::cudnn_batch_norm_backward", 1339], ["aten::empty_like", 1338], ["CudnnConvolutionBackward", 1325], ["aten::empty_like", 1291], ["aten::batch_norm", 1289], ["aten::mul_", 1278], ["aten::mul_", 1271], ["aten::stride", 1242], ["ReluBackward1", 1226], ["torch::autograd::AccumulateGrad", 1202], ["aten::add_", 1193], ["aten::conv2d", 1168], ["aten::resize_", 1167], ["aten::resize_", 1150], ["aten::add_", 1147], ["aten::add", 1147], ["aten::threshold_", 1146], ["aten::add_", 1145], ["aten::empty_like", 1125], ["aten::zero_", 1122], ["aten::add_", 1120], ["aten::add_", 1110], ["aten::resize_", 1106], ["aten::add_", 1104], ["aten::_convolution", 1102], ["aten::max_pool2d_with_indices_backward", 1101], ["aten::_convolution", 1100], ["aten::add_", 1100], ["aten::batch_norm", 1092], ["aten::add_", 1091], ["aten::_convolution", 1086], ["aten::_convolution", 1085], ["aten::zero_", 1083], ["aten::contiguous", 1053], ["aten::stride", 1052], ["aten::add", 1050], ["aten::fill_", 1026], ["aten::convolution", 1015], ["aten::empty_like", 997], ["aten::conv2d", 983], ["aten::conv2d", 973], ["aten::zero_", 962], ["aten::zero_", 956], ["ReluBackward1", 952], ["aten::mul_", 949], ["aten::threshold_", 931], ["aten::empty_like", 928], ["torch::autograd::AccumulateGrad", 927], ["torch::autograd::AccumulateGrad", 927], ["aten::batch_norm", 913], ["aten::batch_norm", 906], ["aten::mean", 899], ["aten::_log_softmax", 873], ["aten::mul_", 866], ["aten::convolution", 861], ["aten::convolution", 857], ["ReluBackward1", 842], ["aten::mm", 840], ["aten::resize_", 833], ["torch::autograd::AccumulateGrad", 818], ["aten::conv2d", 811], ["aten::resize_", 810], ["torch::autograd::AccumulateGrad", 807], ["aten::fill_", 804], ["aten::conv2d", 782], ["aten::div", 776], ["aten::fill_", 769], ["aten::cudnn_convolution_backward", 766], ["aten::fill_", 764], ["aten::pin_memory", 756], ["aten::empty_like", 754], ["aten::empty_like", 751], ["aten::cudnn_convolution_backward", 751], ["aten::zero_", 739], ["aten::add", 739], ["aten::zero_", 737], ["aten::_convolution", 735], ["aten::_convolution", 731], ["aten::_convolution", 725], ["aten::expand", 724], ["aten::batch_norm", 722], ["aten::batch_norm", 721], ["aten::contiguous", 715], ["ReluBackward1", 713], ["aten::threshold_", 708], ["aten::contiguous", 699], ["AddmmBackward", 696], ["aten::cudnn_convolution_backward", 691], ["aten::copy_", 690], ["aten::fill_", 686], ["aten::cudnn_convolution_backward", 685], ["aten::threshold_", 683], ["aten::mm", 683], ["aten::convolution", 678], ["aten::nll_loss_backward", 677], ["torch::autograd::AccumulateGrad", 673], ["aten::convolution", 672], ["aten::resize_", 667], ["aten::cudnn_convolution_backward", 667], ["aten::add", 665], ["aten::cudnn_convolution_backward", 663], ["aten::t", 662], ["aten::cudnn_convolution_backward", 661], ["aten::mul_", 659], ["aten::convolution", 658], ["aten::cudnn_convolution_backward", 658], ["aten::pin_memory", 657], ["aten::cudnn_convolution_backward", 656], ["aten::zero_", 654], ["aten::cudnn_convolution_backward", 653], ["aten::fill_", 652], ["aten::zero_", 643], ["aten::threshold_backward", 642], ["aten::stride", 633], ["torch::autograd::AccumulateGrad", 619], ["aten::add", 616], ["aten::stride", 611], ["torch::autograd::AccumulateGrad", 601], ["aten::conv2d", 598], ["aten::fill_", 596], ["AddBackward0", 588], ["aten::conv2d", 585], ["aten::_log_softmax_backward_data", 585], ["aten::conv2d", 583], ["aten::add", 581], ["aten::conv2d", 578], ["aten::contiguous", 572], ["aten::fill_", 569], ["aten::resize_", 561], ["aten::resize_", 553], ["aten::_batch_norm_impl_index", 547], ["aten::add", 540], ["aten::threshold_backward", 539], ["aten::add", 536], ["aten::contiguous", 534], ["aten::add", 531], ["aten::convolution", 527], ["aten::threshold_backward", 525], ["aten::convolution", 521], ["aten::add", 521], ["aten::add", 520], ["aten::zero_", 519], ["aten::zero_", 519], ["aten::relu_", 517], ["aten::add", 517], ["aten::threshold_backward", 517], ["aten::_batch_norm_impl_index", 509], ["aten::resize_", 508], ["aten::_batch_norm_impl_index", 501], ["aten::convolution", 496], ["aten::resize_", 491], ["aten::convolution", 489], ["aten::cudnn_convolution_backward", 489], ["aten::relu_", 485], ["aten::relu_", 485], ["aten::_batch_norm_impl_index", 480], ["aten::zero_", 477], ["aten::zero_", 477], ["torch::autograd::AccumulateGrad", 476], ["aten::relu_", 475], ["aten::contiguous", 473], ["torch::autograd::AccumulateGrad", 468], ["aten::mul_", 467], ["aten::mul_", 461], ["CudnnBatchNormBackward", 459], ["torch::autograd::AccumulateGrad", 457], ["aten::mul_", 456], ["CudnnBatchNormBackward", 455], ["aten::contiguous", 453], ["CudnnBatchNormBackward", 452], ["aten::ones_like", 450], ["CudnnBatchNormBackward", 448], ["aten::stride", 446], ["aten::_convolution", 441], ["aten::mul_", 439], ["aten::set_", 438], ["aten::mul_", 437], ["aten::mul_", 435], ["aten::t", 430], ["aten::to", 429], ["aten::mul_", 426], ["aten::contiguous", 425], ["aten::mul_", 419], ["aten::mul_", 418], ["aten::stride", 414], ["aten::view", 414], ["aten::fill_", 412], ["AddBackward0", 410], ["aten::conv2d", 407], ["aten::contiguous", 403], ["aten::_convolution", 399], ["aten::_convolution", 398], ["aten::contiguous", 392], ["aten::fill_", 391], ["aten::conv2d", 390], ["aten::conv2d", 387], ["aten::fill_", 374], ["aten::_convolution", 372], ["aten::resize_", 371], ["aten::convolution", 370], ["aten::resize_", 369], ["aten::contiguous", 369], ["aten::empty_like", 368], ["aten::empty_like", 365], ["aten::expand", 365], ["aten::resize_", 363], ["aten::_convolution", 360], ["aten::_convolution", 360], ["aten::_convolution", 360], ["aten::contiguous", 358], ["aten::_convolution", 358], ["aten::contiguous", 357], ["aten::_convolution", 357], ["aten::_convolution", 356], ["aten::_convolution", 355], ["CudnnConvolutionBackward", 353], ["aten::resize_", 350], ["aten::contiguous", 348], ["aten::stride", 346], ["aten::contiguous", 343], ["aten::fill_", 341], ["aten::zero_", 336], ["NllLossBackward", 336], ["CudnnConvolutionBackward", 335], ["aten::convolution", 333], ["MeanBackward1", 330], ["torch::autograd::AccumulateGrad", 328], ["aten::stride", 327], ["CudnnConvolutionBackward", 327], ["MaxPool2DWithIndicesBackward", 325], ["CudnnConvolutionBackward", 324], ["aten::stride", 317], ["torch::autograd::AccumulateGrad", 311], ["aten::zero_", 309], ["AddBackward0", 305], ["aten::stride", 303], ["aten::stride", 302], ["AddBackward0", 293], ["aten::resize_", 290], ["aten::resize_", 290], ["aten::to", 288], ["aten::threshold_", 287], ["aten::resize_", 283], ["aten::transpose", 277], ["aten::transpose", 271], ["aten::empty_like", 267], ["aten::as_strided", 265], ["aten::zero_", 265], ["aten::view", 264], ["aten::fill_", 262], ["ReluBackward1", 260], ["aten::zero_", 258], ["ReluBackward1", 258], ["aten::stride", 254], ["LogSoftmaxBackward", 254], ["aten::fill_", 248], ["aten::threshold_", 247], ["aten::threshold_", 244], ["aten::zero_", 242], ["nccl:broadcast", 241], ["aten::zero_", 238], ["aten::zero_", 237], ["ReluBackward1", 236], ["ReluBackward1", 232], ["aten::threshold_", 230], ["aten::conv2d", 229], ["aten::contiguous", 229], ["aten::is_pinned", 228], ["aten::contiguous", 226], ["aten::fill_", 223], ["aten::t", 223], ["aten::max_pool2d", 216], ["aten::conv2d", 212], ["aten::conv2d", 209], ["aten::fill_", 209], ["aten::is_pinned", 204], ["aten::nll_loss", 203], ["aten::fill_", 202], ["aten::conv2d", 200], ["aten::conv2d", 197], ["aten::flatten", 196], ["aten::conv2d", 195], ["aten::conv2d", 194], ["aten::conv2d", 193], ["aten::conv2d", 192], ["aten::fill_", 191], ["aten::batch_norm", 190], ["aten::adaptive_avg_pool2d", 190], ["aten::conv2d", 189], ["aten::conv2d", 189], ["aten::fill_", 189], ["aten::fill_", 188], ["aten::fill_", 187], ["aten::resize_", 185], ["aten::empty_like", 184], ["aten::convolution", 184], ["aten::resize_", 184], ["aten::empty_like", 183], ["aten::empty_like", 183], ["aten::convolution", 182], ["aten::convolution", 182], ["aten::convolution", 182], ["aten::log_softmax", 182], ["aten::batch_norm", 181], ["aten::batch_norm", 180], ["aten::batch_norm", 179], ["aten::resize_", 179], ["torch::autograd::AccumulateGrad", 179], ["aten::stride", 177], ["aten::zeros_like", 173], ["aten::convolution", 168], ["torch::autograd::AccumulateGrad", 168], ["torch::autograd::AccumulateGrad", 166], ["aten::convolution", 165], ["aten::convolution", 165], ["aten::convolution", 164], ["aten::convolution", 164], ["aten::convolution", 163], ["aten::resize_", 162], ["aten::convolution", 161], ["torch::autograd::AccumulateGrad", 161], ["ViewBackward", 161], ["aten::resize_", 159], ["torch::autograd::AccumulateGrad", 158], ["torch::autograd::AccumulateGrad", 155], ["torch::autograd::AccumulateGrad", 153], ["torch::autograd::AccumulateGrad", 152], ["torch::autograd::AccumulateGrad", 152], ["aten::zero_", 152], ["aten::stride", 147], ["aten::slice", 145], ["aten::contiguous", 145], ["aten::contiguous", 141], ["torch::autograd::AccumulateGrad", 139], ["aten::resize_as_", 138], ["TBackward", 134], ["aten::transpose", 131], ["aten::as_strided", 129], ["aten::reshape", 125], ["aten::reshape", 120], ["aten::contiguous", 119], ["aten::contiguous", 118], ["aten::contiguous", 116], ["aten::contiguous", 116], ["aten::contiguous", 114], ["aten::contiguous", 114], ["aten::narrow", 113], ["aten::contiguous", 112], ["aten::as_strided", 111], ["aten::stride", 99], ["aten::resize_", 93], ["aten::resize_", 93], ["aten::to", 92], ["aten::resize_", 92], ["aten::resize_", 92], ["aten::resize_", 92], ["aten::resize_", 91], ["aten::resize_", 91], ["aten::resize_", 82], ["aten::detach_", 79], ["aten::conj", 76], ["detach_", 75], ["aten::resize_", 75], ["aten::conj", 75], ["aten::as_strided", 72], ["aten::stride", 69], ["aten::as_strided", 60], ["aten::contiguous", 59], ["aten::stride", 57], ["aten::as_strided", 55], ["aten::to", 55], ["aten::is_floating_point", 53], ["aten::resize_", 49], ["aten::stride", 44], ["aten::stride", 44], ["aten::stride", 42], ["aten::stride", 23]]}}, "operation_table_by_name_input": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "string", "name": "Input Shape"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Device Self Duration (us)"}, {"type": "number", "name": "Device Total Duration (us)"}, {"type": "number", "name": "Host Self Duration (us)"}, {"type": "number", "name": "Host Total Duration (us)"}], "rows": [["aten::cudnn_convolution_backward_weight", "[[], [32, 64, 56, 56], [32, 64, 56, 56], [], [], [], [], [], [], []]", 16, 8810, 8810, 5802, 8024], ["aten::cudnn_convolution_backward_input", "[[], [32, 1024, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], []]", 24, 8195, 8195, 8300, 11660], ["aten::cudnn_batch_norm_backward", "[[32, 256, 56, 56], [32, 256, 56, 56], [256], [256], [256], [256], [256], [], [0]]", 16, 7677, 7677, 5503, 8203], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], []]", 24, 7261, 7261, 8967, 12550], ["aten::cudnn_convolution", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], []]", 24, 7103, 7103, 11079, 14432], ["aten::cudnn_convolution_backward_weight", "[[], [32, 1024, 14, 14], [32, 256, 14, 14], [], [], [], [], [], [], []]", 24, 6790, 6790, 10051, 13656], ["aten::copy_", "[[32, 3, 224, 224], [32, 3, 224, 224], []]", 8, 6701, 6701, 47444, 47444], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], []]", 20, 6373, 6373, 7043, 9872], ["aten::cudnn_batch_norm", "[[32, 256, 56, 56], [256], [256], [256], [256], [], [], []]", 16, 6370, 6370, 7533, 11127], ["aten::cudnn_convolution_backward_input", "[[], [32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], []]", 16, 6274, 6274, 5897, 8272], ["aten::cudnn_convolution", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], []]", 20, 5880, 5880, 9181, 11999], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 14, 14], [32, 1024, 14, 14], [], [], [], [], [], [], []]", 20, 5837, 5837, 7131, 9871], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 56, 56], [32, 64, 56, 56], [], [], [], [], [], [], []]", 16, 5810, 5810, 5675, 7908], ["aten::cudnn_convolution", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], []]", 12, 5022, 5022, 6002, 7828], ["aten::cudnn_batch_norm_backward", "[[32, 512, 28, 28], [32, 512, 28, 28], [512], [512], [512], [512], [512], [], [0]]", 20, 4933, 4933, 6941, 10423], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 28, 28], [32, 128, 28, 28], [], [], [], [], [], [], []]", 16, 4873, 4873, 5648, 7849], ["aten::cudnn_convolution", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], []]", 16, 4825, 4825, 7998, 10415], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], []]", 12, 4737, 4737, 4478, 6234], ["aten::cudnn_convolution_backward_weight", "[[], [32, 64, 56, 56], [32, 256, 56, 56], [], [], [], [], [], [], []]", 8, 4581, 4581, 2903, 3994], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 14, 14], [32, 256, 14, 14], [], [], [], [], [], [], []]", 20, 4533, 4533, 8323, 11262], ["aten::cudnn_convolution", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], []]", 16, 4503, 4503, 10702, 13353], ["aten::cudnn_convolution", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], []]", 12, 4463, 4463, 5577, 7331], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], []]", 16, 4443, 4443, 5535, 7847], ["aten::cudnn_convolution_backward_input", "[[], [32, 2048, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], []]", 12, 4358, 4358, 5959, 7680], ["aten::add_", "[[32, 256, 56, 56], [32, 256, 56, 56], []]", 12, 4357, 4357, 1630, 1630], ["aten::cudnn_convolution", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], []]", 20, 4296, 4296, 10025, 13107], ["aten::cudnn_batch_norm", "[[32, 512, 28, 28], [512], [512], [512], [512], [], [], []]", 20, 4119, 4119, 9421, 13936], ["aten::cudnn_batch_norm_backward", "[[32, 1024, 14, 14], [32, 1024, 14, 14], [1024], [1024], [1024], [1024], [1024], [], [0]]", 28, 3786, 3786, 10308, 15452], ["aten::cudnn_batch_norm_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], [64], [64], [64], [64], [64], [], [0]]", 24, 3776, 3776, 8387, 12489], ["aten::cudnn_convolution", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], []]", 12, 3742, 3742, 5492, 7183], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 28, 28], [32, 512, 28, 28], [], [], [], [], [], [], []]", 12, 3678, 3678, 4388, 6027], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], []]", 16, 3554, 3554, 6325, 8774], ["aten::cudnn_convolution", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], []]", 12, 3473, 3473, 5989, 7798], ["aten::cudnn_convolution_backward_input", "[[], [32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], []]", 12, 3461, 3461, 4571, 6459], ["aten::cudnn_convolution", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], [], [], []]", 4, 3393, 3393, 1841, 2394], ["aten::threshold_backward", "[[32, 256, 56, 56], [32, 256, 56, 56], []]", 12, 3298, 3298, 1596, 2072], ["aten::cudnn_convolution_backward_weight", "[[], [32, 2048, 7, 7], [32, 512, 7, 7], [], [], [], [], [], [], []]", 12, 3211, 3211, 5116, 6920], ["aten::cudnn_convolution_backward_weight", "[[], [32, 64, 112, 112], [32, 3, 224, 224], [], [], [], [], [], [], []]", 4, 3009, 3009, 1402, 1940], ["aten::threshold_", "[[32, 256, 56, 56], [], []]", 12, 2997, 2997, 708, 708], ["aten::add_", "[[32, 512, 28, 28], [32, 512, 28, 28], []]", 16, 2919, 2919, 2139, 2139], ["aten::cudnn_convolution", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], []]", 4, 2846, 2846, 1974, 2536], ["aten::cudnn_convolution_backward_input", "[[], [32, 2048, 7, 7], [2048, 1024, 1, 1], [], [], [], [], [], [], []]", 4, 2840, 2840, 1425, 1990], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 28, 28], [32, 128, 28, 28], [], [], [], [], [], [], []]", 12, 2809, 2809, 4523, 6295], ["aten::cudnn_convolution_backward_input", "[[], [32, 128, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], []]", 12, 2771, 2771, 6186, 8320], ["aten::cudnn_convolution", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], [], [], []]", 4, 2738, 2738, 1977, 2624], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], []]", 8, 2731, 2731, 3154, 4243], ["aten::cudnn_convolution_backward_input", "[[], [32, 1024, 14, 14], [1024, 512, 1, 1], [], [], [], [], [], [], []]", 4, 2727, 2727, 1400, 1942], ["aten::cudnn_convolution", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], []]", 8, 2676, 2676, 3697, 4831], ["aten::cudnn_batch_norm", "[[32, 64, 56, 56], [64], [64], [64], [64], [], [], []]", 24, 2656, 2656, 11314, 16705], ["aten::cudnn_convolution", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], []]", 4, 2565, 2565, 2801, 3605], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 28, 28], [512, 256, 1, 1], [], [], [], [], [], [], []]", 4, 2510, 2510, 1360, 1939], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 56, 56], [32, 256, 56, 56], [], [], [], [], [], [], []]", 4, 2448, 2448, 1407, 1972], ["aten::cudnn_convolution", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], [], [], []]", 4, 2397, 2397, 2834, 3473], ["aten::cudnn_batch_norm_backward", "[[32, 64, 112, 112], [32, 64, 112, 112], [64], [64], [64], [64], [64], [], [0]]", 4, 2397, 2397, 1386, 2068], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 28, 28], [32, 256, 56, 56], [], [], [], [], [], [], []]", 4, 2349, 2349, 1458, 2011], ["aten::cudnn_convolution", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], []]", 8, 2271, 2271, 4051, 5305], ["aten::cudnn_convolution", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], []]", 4, 2269, 2269, 1973, 2583], ["aten::cudnn_convolution", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], [], [], []]", 4, 2264, 2264, 1819, 2372], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], []]", 4, 2254, 2254, 1414, 1981], ["aten::threshold_backward", "[[32, 512, 28, 28], [32, 512, 28, 28], []]", 16, 2229, 2229, 2130, 2818], ["aten::cudnn_convolution", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], [], [], []]", 4, 2223, 2223, 2584, 3191], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 28, 28], [32, 512, 28, 28], [], [], [], [], [], [], []]", 4, 2216, 2216, 1438, 2001], ["aten::cudnn_convolution", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], [], [], []]", 4, 2196, 2196, 1839, 2388], ["aten::cudnn_convolution_backward_weight", "[[], [32, 1024, 14, 14], [32, 512, 28, 28], [], [], [], [], [], [], []]", 4, 2170, 2170, 1671, 2275], ["aten::cudnn_convolution_backward_weight", "[[], [32, 2048, 7, 7], [32, 1024, 14, 14], [], [], [], [], [], [], []]", 4, 2167, 2167, 1731, 2344], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 7, 7], [32, 2048, 7, 7], [], [], [], [], [], [], []]", 8, 2144, 2144, 3301, 4510], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 28, 28], [32, 128, 56, 56], [], [], [], [], [], [], []]", 4, 2097, 2097, 1819, 2503], ["aten::max_pool2d_with_indices_backward", "[[32, 64, 56, 56], [32, 64, 112, 112], [], [], [], [], [], [32, 64, 56, 56]]", 4, 2082, 2564, 1101, 2463], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 7, 7], [32, 512, 14, 14], [], [], [], [], [], [], []]", 4, 2055, 2055, 1649, 2255], ["aten::cudnn_convolution", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], []]", 4, 2041, 2041, 2842, 3450], ["aten::threshold_", "[[32, 512, 28, 28], [], []]", 16, 2001, 2001, 931, 931], ["aten::cudnn_convolution_backward_input", "[[], [32, 64, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], []]", 8, 1984, 1984, 3195, 4408], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 14, 14], [32, 1024, 14, 14], [], [], [], [], [], [], []]", 4, 1981, 1981, 1615, 2224], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 14, 14], [32, 256, 28, 28], [], [], [], [], [], [], []]", 4, 1970, 1970, 1627, 2223], ["aten::cudnn_batch_norm_backward", "[[32, 128, 28, 28], [32, 128, 28, 28], [128], [128], [128], [128], [128], [], [0]]", 28, 1906, 1906, 9630, 14320], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 7, 7], [32, 512, 7, 7], [], [], [], [], [], [], []]", 8, 1875, 1875, 3112, 4320], ["aten::cudnn_convolution", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], []]", 8, 1841, 1841, 4081, 5308], ["aten::cudnn_batch_norm", "[[32, 1024, 14, 14], [1024], [1024], [1024], [1024], [], [], []]", 28, 1785, 1785, 16153, 22737], ["aten::threshold_backward", "[[32, 1024, 14, 14], [32, 1024, 14, 14], []]", 24, 1719, 1719, 3138, 4120], ["aten::cudnn_convolution_backward_input", "[[], [32, 128, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], []]", 4, 1701, 1701, 1981, 2582], ["aten::cudnn_batch_norm", "[[32, 64, 112, 112], [64], [64], [64], [64], [], [], []]", 4, 1699, 1699, 2059, 2950], ["aten::threshold_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], []]", 24, 1659, 1659, 3207, 4231], ["aten::add_", "[[32, 1024, 14, 14], [32, 1024, 14, 14], []]", 24, 1655, 1655, 3340, 3340], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], []]", 4, 1632, 1632, 2362, 2979], ["aten::cudnn_batch_norm_backward", "[[32, 256, 14, 14], [32, 256, 14, 14], [256], [256], [256], [256], [256], [], [0]]", 44, 1562, 1562, 15181, 22596], ["aten::threshold_", "[[32, 64, 56, 56], [], []]", 24, 1521, 1521, 1475, 1475], ["aten::cudnn_batch_norm", "[[32, 128, 28, 28], [128], [128], [128], [128], [], [], []]", 28, 1433, 1433, 13625, 20425], ["aten::threshold_", "[[32, 1024, 14, 14], [], []]", 24, 1136, 1136, 1386, 1386], ["aten::threshold_backward", "[[32, 64, 112, 112], [32, 64, 112, 112], []]", 4, 1104, 1104, 525, 684], ["aten::threshold_backward", "[[32, 128, 28, 28], [32, 128, 28, 28], []]", 28, 1027, 1027, 3736, 4885], ["aten::cudnn_batch_norm_backward", "[[32, 128, 56, 56], [32, 128, 56, 56], [128], [128], [128], [128], [128], [], [0]]", 4, 1026, 1026, 1339, 2016], ["aten::threshold_", "[[32, 64, 112, 112], [], []]", 4, 997, 997, 287, 287], ["aten::add_", "[[512, 512, 3, 3], [512, 512, 3, 3], []]", 36, 977, 977, 4214, 4214], ["aten::threshold_backward", "[[32, 256, 14, 14], [32, 256, 14, 14], []]", 44, 915, 915, 5909, 7714], ["aten::threshold_", "[[32, 128, 28, 28], [], []]", 28, 896, 896, 1683, 1683], ["aten::max_pool2d_with_indices", "[[32, 64, 112, 112], [], [], [], [], []]", 4, 891, 891, 1574, 2197], ["aten::cudnn_batch_norm_backward", "[[32, 2048, 7, 7], [32, 2048, 7, 7], [2048], [2048], [2048], [2048], [2048], [], [0]]", 16, 879, 879, 5649, 8417], ["aten::cudnn_batch_norm", "[[32, 128, 56, 56], [128], [128], [128], [128], [], [], []]", 4, 794, 794, 1898, 2775], ["aten::cudnn_batch_norm", "[[32, 256, 14, 14], [256], [256], [256], [256], [], [], []]", 44, 739, 739, 21505, 32295], ["aten::cudnn_batch_norm", "[[32, 2048, 7, 7], [2048], [2048], [2048], [2048], [], [], []]", 16, 668, 668, 7570, 11215], ["aten::add_", "[[256], [256], []]", 384, 609, 609, 38654, 38654], ["aten::threshold_backward", "[[32, 128, 56, 56], [32, 128, 56, 56], []]", 4, 551, 551, 539, 697], ["aten::threshold_", "[[32, 128, 56, 56], [], []]", 4, 501, 501, 244, 244], ["aten::cudnn_batch_norm_backward", "[[32, 256, 28, 28], [32, 256, 28, 28], [256], [256], [256], [256], [256], [], [0]]", 4, 491, 491, 1393, 2089], ["aten::fill_", "[[32, 64, 112, 112], []]", 4, 482, 482, 262, 262], ["aten::threshold_backward", "[[32, 2048, 7, 7], [32, 2048, 7, 7], []]", 12, 452, 452, 1631, 2101], ["aten::add_", "[[512], [512], []]", 264, 419, 419, 27750, 27750], ["aten::add_", "[[32, 2048, 7, 7], [32, 2048, 7, 7], []]", 12, 414, 414, 1634, 1634], ["aten::cudnn_batch_norm", "[[32, 256, 28, 28], [256], [256], [256], [256], [], [], []]", 4, 412, 412, 1907, 2811], ["aten::threshold_", "[[32, 256, 14, 14], [], []]", 44, 387, 387, 2559, 2559], ["aten::cudnn_convolution", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], []]", 4, 386, 386, 2089, 2699], ["aten::add_", "[[2048, 512, 1, 1], [2048, 512, 1, 1], []]", 36, 373, 373, 3900, 3900], ["aten::add_", "[[256, 256, 3, 3], [256, 256, 3, 3], []]", 72, 369, 369, 7492, 7492], ["aten::cudnn_batch_norm_backward", "[[32, 512, 7, 7], [32, 512, 7, 7], [512], [512], [512], [512], [512], [], [0]]", 20, 344, 344, 6947, 10412], ["aten::cudnn_convolution_backward_input", "[[], [32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], []]", 4, 327, 327, 1548, 2152], ["aten::add", "[[512, 512, 3, 3], [512, 512, 3, 3], []]", 12, 315, 315, 2304, 2850], ["aten::add_", "[[128], [128], []]", 192, 303, 303, 18154, 18154], ["aten::add_", "[[2048, 1024, 1, 1], [2048, 1024, 1, 1], []]", 12, 291, 291, 1110, 1110], ["aten::threshold_", "[[32, 2048, 7, 7], [], []]", 12, 289, 289, 683, 683], ["aten::threshold_backward", "[[32, 256, 28, 28], [32, 256, 28, 28], []]", 4, 286, 286, 517, 680], ["aten::add_", "[[1000, 2048], [1000, 2048], []]", 12, 274, 274, 1405, 1405], ["aten::cudnn_batch_norm_backward", "[[32, 512, 14, 14], [32, 512, 14, 14], [512], [512], [512], [512], [512], [], [0]]", 4, 272, 272, 1367, 2067], ["aten::add_", "[[1024], [1024], []]", 168, 270, 270, 17451, 17451], ["aten::add_", "[[512, 2048, 1, 1], [512, 2048, 1, 1], []]", 24, 265, 265, 2637, 2637], ["aten::add_", "[[64], [64], []]", 168, 264, 264, 15914, 15914], ["aten::threshold_", "[[32, 256, 28, 28], [], []]", 4, 252, 252, 247, 247], ["aten::threshold_backward", "[[32, 512, 7, 7], [32, 512, 7, 7], []]", 20, 251, 251, 2658, 3468], ["aten::cudnn_batch_norm", "[[32, 512, 7, 7], [512], [512], [512], [512], [], [], []]", 20, 220, 220, 9380, 14013], ["aten::mul_", "[[512, 512, 3, 3], []]", 12, 216, 216, 1517, 1517], ["aten::copy_", "[[], [], []]", 596, 212, 212, 32597, 32597], ["aten::add_", "[[1024, 256, 1, 1], [1024, 256, 1, 1], []]", 72, 201, 201, 7717, 7717], ["aten::add_", "[[256, 1024, 1, 1], [256, 1024, 1, 1], []]", 60, 199, 199, 5944, 5944], ["aten::add", "[[], [], []]", 212, 193, 193, 28555, 36652], ["aten::_cat", "[[], []]", 12, 192, 192, 606011, 610536], ["aten::add", "[[256, 256, 3, 3], [256, 256, 3, 3], []]", 24, 182, 182, 3636, 4712], ["aten::threshold_backward", "[[32, 512, 14, 14], [32, 512, 14, 14], []]", 4, 152, 152, 642, 850], ["aten::add_", "[[2048], [2048], []]", 96, 151, 151, 10037, 10037], ["aten::add", "[[2048, 512, 1, 1], [2048, 512, 1, 1], []]", 12, 146, 146, 2068, 2666], ["aten::cudnn_batch_norm", "[[32, 512, 14, 14], [512], [512], [512], [512], [], [], []]", 4, 136, 136, 1860, 2784], ["aten::fill_", "[[512, 512, 3, 3], []]", 12, 135, 135, 804, 804], ["aten::copy_", "[[256], [256], []]", 128, 128, 128, 11399, 11399], ["aten::mean", "[[32, 2048, 7, 7], [], [], []]", 4, 128, 128, 899, 1060], ["aten::add_", "[[128, 128, 3, 3], [128, 128, 3, 3], []]", 48, 119, 119, 4524, 4524], ["aten::mul_", "[[256, 256, 3, 3], []]", 24, 108, 108, 2680, 2680], ["aten::mul_", "[[2048, 512, 1, 1], []]", 12, 100, 100, 1684, 1684], ["aten::addmm", "[[1000], [32, 2048], [2048, 1000], [], []]", 4, 97, 97, 3278, 5088], ["aten::add", "[[256], [256], []]", 128, 96, 96, 18108, 24056], ["aten::mul_", "[[256], []]", 128, 96, 96, 14792, 14792], ["aten::add", "[[512, 2048, 1, 1], [512, 2048, 1, 1], []]", 8, 96, 96, 1147, 1632], ["aten::add", "[[2048, 1024, 1, 1], [2048, 1024, 1, 1], []]", 4, 93, 93, 531, 710], ["aten::add", "[[1000, 2048], [1000, 2048], []]", 4, 93, 93, 616, 947], ["aten::threshold_", "[[32, 512, 14, 14], [], []]", 4, 91, 91, 230, 230], ["aten::threshold_", "[[32, 512, 7, 7], [], []]", 20, 90, 90, 1146, 1146], ["aten::add", "[[1024, 256, 1, 1], [1024, 256, 1, 1], []]", 24, 89, 89, 3497, 4652], ["aten::copy_", "[[512], [512], []]", 88, 88, 88, 7702, 7702], ["aten::add_", "[[512, 128, 1, 1], [512, 128, 1, 1], []]", 48, 87, 87, 4790, 4790], ["aten::mm", "[[32, 1000], [1000, 2048]]", 4, 87, 87, 840, 1086], ["aten::div", "[[32, 2048, 7, 7], []]", 4, 87, 87, 776, 943], ["aten::add_", "[[256, 64, 1, 1], [256, 64, 1, 1], []]", 48, 79, 79, 4481, 4481], ["aten::fill_", "[[256, 256, 3, 3], []]", 24, 72, 72, 1577, 1577], ["aten::add_", "[[128, 512, 1, 1], [128, 512, 1, 1], []]", 36, 72, 72, 3379, 3379], ["aten::add", "[[512], [512], []]", 88, 66, 66, 13329, 17512], ["aten::mul_", "[[512], []]", 88, 66, 66, 10859, 10859], ["aten::add_", "[[512, 1024, 1, 1], [512, 1024, 1, 1], []]", 12, 66, 66, 1147, 1147], ["aten::mul_", "[[512, 2048, 1, 1], []]", 8, 66, 66, 949, 949], ["aten::mul_", "[[2048, 1024, 1, 1], []]", 4, 65, 65, 419, 419], ["aten::copy_", "[[128], [128], []]", 64, 64, 64, 5370, 5370], ["aten::add", "[[256, 1024, 1, 1], [256, 1024, 1, 1], []]", 20, 64, 64, 3209, 4035], ["aten::fill_", "[[2048, 512, 1, 1], []]", 12, 63, 63, 686, 686], ["aten::mul_", "[[1000, 2048], []]", 4, 63, 63, 456, 456], ["aten::add_", "[[64, 64, 3, 3], [64, 64, 3, 3], []]", 36, 62, 62, 3555, 3555], ["aten::mul_", "[[1024, 256, 1, 1], []]", 24, 62, 62, 2964, 2964], ["aten::mm", "[[1000, 32], [32, 2048]]", 4, 57, 57, 683, 936], ["aten::copy_", "[[64], [64], []]", 56, 56, 56, 5225, 5225], ["aten::copy_", "[[1024], [1024], []]", 56, 56, 56, 4818, 4818], ["aten::add_", "[[1024, 512, 1, 1], [1024, 512, 1, 1], []]", 12, 53, 53, 1193, 1193], ["aten::add", "[[128], [128], []]", 64, 48, 48, 9147, 11773], ["aten::mul_", "[[128], []]", 64, 48, 48, 7360, 7360], ["aten::mul_", "[[256, 1024, 1, 1], []]", 20, 46, 46, 2165, 2165], ["aten::fill_", "[[512], []]", 88, 45, 45, 5091, 5091], ["aten::fill_", "[[512, 2048, 1, 1], []]", 8, 42, 42, 391, 391], ["aten::add", "[[64], [64], []]", 56, 42, 42, 7445, 9644], ["aten::mul_", "[[64], []]", 56, 42, 42, 5956, 5956], ["aten::add", "[[1024], [1024], []]", 56, 42, 42, 10151, 12878], ["aten::mul_", "[[1024], []]", 56, 42, 42, 7718, 7718], ["aten::add_", "[[64, 256, 1, 1], [64, 256, 1, 1], []]", 24, 41, 41, 2312, 2312], ["aten::fill_", "[[2048, 1024, 1, 1], []]", 4, 39, 39, 202, 202], ["aten::fill_", "[[1000, 2048], []]", 4, 39, 39, 209, 209], ["aten::fill_", "[[1024, 256, 1, 1], []]", 24, 36, 36, 1484, 1484], ["aten::fill_", "[[1024], []]", 56, 35, 35, 3516, 3516], ["aten::add", "[[128, 128, 3, 3], [128, 128, 3, 3], []]", 16, 33, 33, 2237, 2929], ["aten::add_", "[[256, 512, 1, 1], [256, 512, 1, 1], []]", 12, 33, 33, 1100, 1100], ["aten::_log_softmax_backward_data", "[[32, 1000], [32, 1000], [], [32, 1000]]", 4, 33, 33, 585, 1027], ["aten::copy_", "[[2048], [2048], []]", 32, 32, 32, 2821, 2821], ["aten::add_", "[[512, 256, 1, 1], [512, 256, 1, 1], []]", 12, 32, 32, 1145, 1145], ["aten::fill_", "[[256], []]", 128, 31, 31, 7933, 7933], ["aten::_log_softmax", "[[32, 1000], [], []]", 4, 30, 30, 873, 1251], ["aten::fill_", "[[128], []]", 64, 30, 30, 3341, 3341], ["aten::fill_", "[[256, 1024, 1, 1], []]", 20, 30, 30, 1339, 1339], ["aten::add", "[[1024, 512, 1, 1], [1024, 512, 1, 1], []]", 4, 27, 27, 521, 686], ["aten::add", "[[512, 1024, 1, 1], [512, 1024, 1, 1], []]", 4, 27, 27, 517, 680], ["aten::add", "[[512, 128, 1, 1], [512, 128, 1, 1], []]", 16, 25, 25, 2151, 2829], ["aten::mul_", "[[128, 128, 3, 3], []]", 16, 24, 24, 1685, 1685], ["aten::add", "[[2048], [2048], []]", 32, 24, 24, 4659, 5965], ["aten::mul_", "[[2048], []]", 32, 24, 24, 3720, 3720], ["aten::add_", "[[128, 256, 1, 1], [128, 256, 1, 1], []]", 12, 23, 23, 1120, 1120], ["aten::add_", "[[64, 3, 7, 7], [64, 3, 7, 7], []]", 12, 21, 21, 1104, 1104], ["aten::fill_", "[[64], []]", 56, 20, 20, 3086, 3086], ["aten::add_", "[[64, 64, 1, 1], [64, 64, 1, 1], []]", 12, 20, 20, 1091, 1091], ["aten::add", "[[128, 512, 1, 1], [128, 512, 1, 1], []]", 12, 18, 18, 1634, 2194], ["aten::mul_", "[[1024, 512, 1, 1], []]", 4, 16, 16, 426, 426], ["aten::mul_", "[[512, 1024, 1, 1], []]", 4, 16, 16, 435, 435], ["aten::copy_", "[[32], [32], []]", 8, 12, 12, 690, 690], ["aten::nll_loss_forward", "[[32, 1000], [32], [], [], []]", 4, 12, 12, 1366, 1366], ["aten::fill_", "[[256, 64, 1, 1], []]", 16, 12, 12, 764, 764], ["aten::fill_", "[[128, 128, 3, 3], []]", 16, 12, 12, 769, 769], ["aten::fill_", "[[512, 128, 1, 1], []]", 16, 12, 12, 1026, 1026], ["aten::fill_", "[[1024, 512, 1, 1], []]", 4, 12, 12, 189, 189], ["aten::fill_", "[[512, 1024, 1, 1], []]", 4, 12, 12, 341, 341], ["aten::fill_", "[[2048], []]", 32, 12, 12, 2444, 2444], ["aten::add", "[[256, 64, 1, 1], [256, 64, 1, 1], []]", 16, 12, 12, 2100, 2784], ["aten::mul_", "[[256, 64, 1, 1], []]", 16, 12, 12, 1743, 1743], ["aten::mul_", "[[512, 128, 1, 1], []]", 16, 12, 12, 1806, 1806], ["aten::mul_", "[[128, 512, 1, 1], []]", 12, 10, 10, 1271, 1271], ["aten::fill_", "[[64, 64, 3, 3], []]", 12, 9, 9, 652, 652], ["aten::fill_", "[[128, 512, 1, 1], []]", 12, 9, 9, 569, 569], ["aten::add", "[[64, 64, 3, 3], [64, 64, 3, 3], []]", 12, 9, 9, 1554, 2046], ["aten::mul_", "[[64, 64, 3, 3], []]", 12, 9, 9, 1278, 1278], ["aten::add", "[[512, 256, 1, 1], [512, 256, 1, 1], []]", 4, 9, 9, 540, 713], ["aten::add", "[[256, 512, 1, 1], [256, 512, 1, 1], []]", 4, 9, 9, 739, 902], ["aten::add_", "[[1000], [1000], []]", 12, 9, 9, 1404, 1404], ["aten::nll_loss_backward", "[[], [32, 1000], [32], [], [], [], []]", 4, 9, 9, 677, 677], ["aten::fill_", "[[64, 256, 1, 1], []]", 8, 6, 6, 374, 374], ["aten::add", "[[64, 256, 1, 1], [64, 256, 1, 1], []]", 8, 6, 6, 1050, 1385], ["aten::mul_", "[[64, 256, 1, 1], []]", 8, 6, 6, 866, 866], ["aten::mul_", "[[512, 256, 1, 1], []]", 4, 6, 6, 439, 439], ["aten::mul_", "[[256, 512, 1, 1], []]", 4, 6, 6, 461, 461], ["aten::add", "[[1000], [1000], []]", 4, 4, 4, 665, 840], ["aten::_local_scalar_dense", "[[]]", 758, 3, 3, 15162, 15162], ["aten::fill_", "[[64, 3, 7, 7], []]", 4, 3, 3, 248, 248], ["aten::fill_", "[[128, 256, 1, 1], []]", 4, 3, 3, 596, 596], ["aten::fill_", "[[512, 256, 1, 1], []]", 4, 3, 3, 188, 188], ["aten::fill_", "[[256, 512, 1, 1], []]", 4, 3, 3, 187, 187], ["aten::fill_", "[[1000], []]", 4, 3, 3, 412, 412], ["aten::fill_", "[[], []]", 4, 3, 3, 223, 223], ["aten::add", "[[64, 3, 7, 7], [64, 3, 7, 7], []]", 4, 3, 3, 581, 758], ["aten::mul_", "[[64, 3, 7, 7], []]", 4, 3, 3, 467, 467], ["aten::add", "[[64, 64, 1, 1], [64, 64, 1, 1], []]", 4, 3, 3, 520, 687], ["aten::mul_", "[[64, 64, 1, 1], []]", 4, 3, 3, 437, 437], ["aten::add", "[[128, 256, 1, 1], [128, 256, 1, 1], []]", 4, 3, 3, 536, 704], ["aten::mul_", "[[128, 256, 1, 1], []]", 4, 3, 3, 418, 418], ["aten::mul_", "[[1000], []]", 4, 3, 3, 659, 659], ["aten::fill_", "[[64, 64, 1, 1], []]", 4, 2, 2, 191, 191], ["aten::empty", "[[], [], [], [], [], []]", 6653, 0, 0, 205911, 205911], ["aten::fill_", "[[1], []]", 144, 0, 0, 2540, 2540], ["aten::zero_", "[[1]]", 16, 0, 0, 519, 741], ["aten::zeros", "[[], [], [], [], []]", 16, 0, 0, 1376, 2521], ["aten::uniform_", "[[1], [], [], []]", 498, 0, 0, 29298, 29298], ["aten::is_floating_point", "[[1]]", 626, 0, 0, 7094, 7094], ["aten::_local_scalar_dense", "[[1]]", 754, 0, 0, 21617, 21617], ["aten::item", "[[1]]", 754, 0, 0, 14299, 35916], ["aten::to", "[[2], [], [], [], [], []]", 185, 0, 0, 2839, 2839], ["detach_", "[[2]]", 185, 0, 0, 2578, 2578], ["aten::detach_", "[[2]]", 185, 0, 0, 3328, 5906], ["aten::log", "[[2]]", 185, 0, 0, 17617, 21260], ["aten::as_strided", "[[2], [], [], []]", 370, 0, 0, 5389, 5389], ["aten::select", "[[2], [], []]", 370, 0, 0, 31688, 37077], ["aten::item", "[[]]", 758, 0, 3, 15586, 30748], ["aten::resize_", "[[0], [], []]", 593, 0, 0, 11338, 11338], ["aten::exp", "[[0], [1]]", 185, 0, 0, 10095, 13124], ["aten::exp", "[[1]]", 185, 0, 0, 24091, 40631], ["aten::random_", "[[1], [], [], []]", 256, 0, 0, 7918, 7918], ["aten::randint", "[[], [], [], [], [], [], [], []]", 256, 0, 0, 16300, 28925], ["aten::rand", "[[], [], [], [], []]", 128, 0, 0, 8790, 16262], ["aten::empty_strided", "[[], [], [], [], [], []]", 652, 0, 0, 17016, 17016], ["aten::to", "[[], [], [], [], []]", 384, 0, 0, 25504, 48976], ["aten::lt", "[[0], [1], []]", 128, 0, 0, 12763, 34646], ["aten::lt", "[[1], []]", 128, 0, 0, 13487, 50098], ["aten::is_nonzero", "[[1]]", 128, 0, 0, 2835, 8530], ["aten::set_", "[[], []]", 128, 0, 0, 8459, 8459], ["aten::view", "[[150528], []]", 128, 0, 0, 8606, 8606], ["aten::as_strided", "[[224, 224, 3], [], [], []]", 128, 0, 0, 2110, 2110], ["aten::permute", "[[224, 224, 3], []]", 128, 0, 0, 11866, 13976], ["aten::empty_like", "[[3, 224, 224], [], [], [], [], []]", 128, 0, 0, 5252, 7821], ["aten::copy_", "[[3, 224, 224], [3, 224, 224], []]", 384, 0, 0, 1913708, 1913708], ["aten::contiguous", "[[3, 224, 224], []]", 128, 0, 0, 8271, 475443], ["aten::to", "[[3, 224, 224], [], [], [], []]", 128, 0, 0, 9501, 967075], ["aten::div", "[[3, 224, 224], []]", 128, 0, 0, 424760, 444600], ["aten::clone", "[[3, 224, 224], []]", 128, 0, 0, 19700, 523983], ["aten::to", "[[3], [], [], [], [], []]", 256, 0, 0, 3925, 3925], ["aten::eq", "[[0], [3], []]", 128, 0, 0, 13159, 35307], ["aten::eq", "[[3], []]", 128, 0, 0, 16936, 54222], ["aten::as_strided", "[[], [], [], []]", 128, 0, 0, 1974, 1974], ["aten::any", "[[3]]", 128, 0, 0, 24450, 33151], ["aten::is_nonzero", "[[]]", 128, 0, 0, 2630, 8109], ["aten::view", "[[3], []]", 256, 0, 0, 17963, 17963], ["aten::sub_", "[[3, 224, 224], [3, 1, 1], []]", 128, 0, 0, 409287, 409287], ["aten::div_", "[[3, 224, 224], [3, 1, 1]]", 128, 0, 0, 495885, 495885], ["aten::as_strided", "[[3, 224, 224], [], [], []]", 128, 0, 0, 1651, 1651], ["aten::unsqueeze", "[[3, 224, 224], []]", 128, 0, 0, 4334, 5985], ["aten::as_strided", "[[32, 3, 224, 224], [], [], []]", 4, 0, 0, 55, 55], ["aten::slice", "[[32, 3, 224, 224], [], [], [], []]", 4, 0, 0, 145, 200], ["aten::narrow", "[[32, 3, 224, 224], [], [], []]", 4, 0, 0, 113, 313], ["aten::stride", "[[32, 3, 224, 224], []]", 36, 0, 0, 254, 254], ["aten::cat", "[[], []]", 12, 0, 192, 1956, 612492], ["aten::stack", "[[], []]", 4, 0, 0, 2431, 604875], ["aten::to", "[[32], [], [], [], [], []]", 4, 0, 0, 92, 92], ["detach_", "[[32]]", 4, 0, 0, 75, 75], ["aten::detach_", "[[32]]", 4, 0, 0, 79, 154], ["aten::is_pinned", "[[32, 3, 224, 224]]", 4, 0, 0, 228, 228], ["aten::set_", "[[0], [], [], [], []]", 8, 0, 0, 438, 438], ["aten::pin_memory", "[[32, 3, 224, 224]]", 4, 0, 0, 756, 48239], ["aten::is_pinned", "[[32]]", 4, 0, 0, 204, 204], ["aten::pin_memory", "[[32]]", 4, 0, 0, 657, 1477], ["aten::to", "[[32, 3, 224, 224], [], [], [], [], [], [], []]", 8, 0, 6701, 429, 1256], ["aten::to", "[[32], [], [], [], [], [], [], []]", 4, 0, 12, 288, 879], ["aten::contiguous", "[[64], []]", 168, 0, 0, 1816, 1816], ["aten::view", "[[64], []]", 168, 0, 0, 8302, 8302], ["aten::contiguous", "[[256], []]", 384, 0, 0, 4164, 4164], ["aten::view", "[[256], []]", 384, 0, 0, 17567, 17567], ["aten::contiguous", "[[128], []]", 192, 0, 0, 2069, 2069], ["aten::view", "[[128], []]", 192, 0, 0, 9025, 9025], ["aten::contiguous", "[[512], []]", 264, 0, 0, 3114, 3114], ["aten::view", "[[512], []]", 264, 0, 0, 12021, 12021], ["aten::contiguous", "[[1024], []]", 168, 0, 0, 2095, 2095], ["aten::view", "[[1024], []]", 168, 0, 0, 8081, 8081], ["aten::contiguous", "[[2048], []]", 96, 0, 0, 1053, 1053], ["aten::view", "[[2048], []]", 96, 0, 0, 4624, 4624], ["aten::stride", "[[64], []]", 56, 0, 0, 446, 446], ["aten::stride", "[[256], []]", 128, 0, 0, 633, 633], ["aten::stride", "[[128], []]", 64, 0, 0, 303, 303], ["aten::stride", "[[512], []]", 88, 0, 0, 414, 414], ["aten::stride", "[[1024], []]", 56, 0, 0, 346, 346], ["aten::stride", "[[2048], []]", 32, 0, 0, 147, 147], ["aten::stride", "[[53120], []]", 8, 0, 0, 42, 42], ["nccl:broadcast", "[]", 8, 0, 0, 241, 241], ["aten::contiguous", "[[], []]", 212, 0, 0, 3348, 3348], ["aten::view", "[[], []]", 212, 0, 0, 14258, 14258], ["aten::stride", "[[1], []]", 212, 0, 0, 1052, 1052], ["aten::stride", "[[53], []]", 8, 0, 0, 44, 44], ["aten::as_strided", "[[53120], [], [], []]", 424, 0, 0, 5938, 5938], ["aten::slice", "[[53120], [], [], [], []]", 424, 0, 0, 29098, 35036], ["aten::narrow", "[[53120], [], [], []]", 424, 0, 0, 13281, 48317], ["aten::as_strided", "[[53], [], [], []]", 212, 0, 0, 2637, 2637], ["aten::slice", "[[53], [], [], [], []]", 212, 0, 0, 12586, 15223], ["aten::narrow", "[[53], [], [], []]", 212, 0, 0, 5689, 20912], ["aten::view", "[[1], []]", 212, 0, 0, 10964, 10964], ["aten::contiguous", "[[32, 3, 224, 224], []]", 12, 0, 0, 141, 141], ["aten::contiguous", "[[64, 3, 7, 7], []]", 4, 0, 0, 59, 59], ["aten::resize_", "[[64, 3, 7, 7], [], []]", 4, 0, 0, 49, 49], ["aten::resize_", "[[32, 3, 224, 224], [], []]", 8, 0, 0, 75, 75], ["aten::_convolution", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], [], [], [], [], []]", 4, 0, 2565, 441, 4102], ["aten::convolution", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], []]", 4, 0, 2565, 182, 4284], ["aten::conv2d", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], []]", 4, 0, 2565, 229, 4513], ["aten::contiguous", "[[32, 64, 112, 112], []]", 28, 0, 0, 358, 358], ["aten::empty_like", "[[32, 64, 112, 112], [], [], [], [], []]", 8, 0, 0, 368, 691], ["aten::_batch_norm_impl_index", "[[32, 64, 112, 112], [64], [64], [64], [64], [], [], [], []]", 4, 0, 1699, 547, 3680], ["aten::batch_norm", "[[32, 64, 112, 112], [64], [64], [64], [64], [], [], [], []]", 4, 0, 1699, 190, 3870], ["aten::relu_", "[[32, 64, 112, 112]]", 4, 0, 997, 517, 804], ["aten::stride", "[[32, 64, 112, 112], []]", 32, 0, 0, 177, 177], ["aten::max_pool2d", "[[32, 64, 112, 112], [], [], [], [], []]", 4, 0, 891, 216, 2413], ["aten::contiguous", "[[32, 64, 56, 56], []]", 244, 0, 0, 2785, 2785], ["aten::contiguous", "[[64, 64, 1, 1], []]", 8, 0, 0, 114, 114], ["aten::resize_", "[[64, 64, 1, 1], [], []]", 8, 0, 0, 92, 92], ["aten::resize_", "[[32, 64, 56, 56], [], []]", 112, 0, 0, 1167, 1167], ["aten::stride", "[[32, 64, 56, 56], []]", 396, 0, 0, 2532, 2532], ["aten::_convolution", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 4, 0, 386, 360, 3107], ["aten::convolution", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], []]", 4, 0, 386, 164, 3271], ["aten::conv2d", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], []]", 4, 0, 386, 209, 3480], ["aten::empty_like", "[[32, 64, 56, 56], [], [], [], [], []]", 24, 0, 0, 1125, 2167], ["aten::_batch_norm_impl_index", "[[32, 64, 56, 56], [64], [64], [64], [64], [], [], [], []]", 24, 0, 2656, 2926, 20724], ["aten::batch_norm", "[[32, 64, 56, 56], [64], [64], [64], [64], [], [], [], []]", 24, 0, 2656, 1092, 21816], ["aten::relu_", "[[32, 64, 56, 56]]", 24, 0, 1521, 2845, 4320], ["aten::contiguous", "[[64, 64, 3, 3], []]", 24, 0, 0, 357, 357], ["aten::resize_", "[[64, 64, 3, 3], [], []]", 24, 0, 0, 283, 283], ["aten::_convolution", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 12, 0, 5022, 1086, 9076], ["aten::convolution", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], []]", 12, 0, 5022, 489, 9565], ["aten::conv2d", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], []]", 12, 0, 5022, 585, 10150], ["aten::contiguous", "[[256, 64, 1, 1], []]", 32, 0, 0, 453, 453], ["aten::resize_", "[[256, 64, 1, 1], [], []]", 32, 0, 0, 369, 369], ["aten::_convolution", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 16, 0, 4825, 1465, 12110], ["aten::convolution", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], []]", 16, 0, 4825, 658, 12768], ["aten::conv2d", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], []]", 16, 0, 4825, 811, 13579], ["aten::contiguous", "[[32, 256, 56, 56], []]", 144, 0, 0, 1631, 1631], ["aten::empty_like", "[[32, 256, 56, 56], [], [], [], [], []]", 16, 0, 0, 751, 1416], ["aten::_batch_norm_impl_index", "[[32, 256, 56, 56], [256], [256], [256], [256], [], [], [], []]", 16, 0, 6370, 1901, 13752], ["aten::batch_norm", "[[32, 256, 56, 56], [256], [256], [256], [256], [], [], [], []]", 16, 0, 6370, 721, 14473], ["aten::relu_", "[[32, 256, 56, 56]]", 12, 0, 2997, 1394, 2102], ["aten::contiguous", "[[64, 256, 1, 1], []]", 16, 0, 0, 229, 229], ["aten::resize_", "[[64, 256, 1, 1], [], []]", 16, 0, 0, 185, 185], ["aten::resize_", "[[32, 256, 56, 56], [], []]", 64, 0, 0, 667, 667], ["aten::stride", "[[32, 256, 56, 56], []]", 192, 0, 0, 1242, 1242], ["aten::_convolution", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 2271, 731, 6132], ["aten::convolution", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], []]", 8, 0, 2271, 678, 6810], ["aten::conv2d", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], []]", 8, 0, 2271, 387, 7197], ["aten::contiguous", "[[128, 256, 1, 1], []]", 8, 0, 0, 114, 114], ["aten::resize_", "[[128, 256, 1, 1], [], []]", 8, 0, 0, 91, 91], ["aten::_convolution", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 4, 0, 2041, 372, 3871], ["aten::convolution", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], []]", 4, 0, 2041, 164, 4035], ["aten::conv2d", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], []]", 4, 0, 2041, 189, 4224], ["aten::contiguous", "[[32, 128, 56, 56], []]", 36, 0, 0, 425, 425], ["aten::empty_like", "[[32, 128, 56, 56], [], [], [], [], []]", 4, 0, 0, 183, 340], ["aten::_batch_norm_impl_index", "[[32, 128, 56, 56], [128], [128], [128], [128], [], [], [], []]", 4, 0, 794, 501, 3470], ["aten::batch_norm", "[[32, 128, 56, 56], [128], [128], [128], [128], [], [], [], []]", 4, 0, 794, 179, 3649], ["aten::relu_", "[[32, 128, 56, 56]]", 4, 0, 501, 485, 729], ["aten::contiguous", "[[128, 128, 3, 3], []]", 32, 0, 0, 473, 473], ["aten::resize_", "[[128, 128, 3, 3], [], []]", 32, 0, 0, 363, 363], ["aten::resize_", "[[32, 128, 56, 56], [], []]", 16, 0, 0, 179, 179], ["aten::stride", "[[32, 128, 56, 56], []]", 48, 0, 0, 327, 327], ["aten::_convolution", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 4, 0, 2397, 355, 3877], ["aten::convolution", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], [], [], []]", 4, 0, 2397, 161, 4038], ["aten::conv2d", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], []]", 4, 0, 2397, 189, 4227], ["aten::contiguous", "[[32, 128, 28, 28], []]", 252, 0, 0, 3132, 3132], ["aten::empty_like", "[[32, 128, 28, 28], [], [], [], [], []]", 28, 0, 0, 1338, 2563], ["aten::_batch_norm_impl_index", "[[32, 128, 28, 28], [128], [128], [128], [128], [], [], [], []]", 28, 0, 1433, 3521, 25278], ["aten::batch_norm", "[[32, 128, 28, 28], [128], [128], [128], [128], [], [], [], []]", 28, 0, 1433, 1289, 26567], ["aten::relu_", "[[32, 128, 28, 28]]", 28, 0, 896, 3350, 5033], ["aten::contiguous", "[[512, 128, 1, 1], []]", 32, 0, 0, 534, 534], ["aten::resize_", "[[512, 128, 1, 1], [], []]", 32, 0, 0, 371, 371], ["aten::resize_", "[[32, 128, 28, 28], [], []]", 112, 0, 0, 1150, 1150], ["aten::stride", "[[32, 128, 28, 28], []]", 336, 0, 0, 2219, 2219], ["aten::_convolution", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 16, 0, 4503, 1512, 15071], ["aten::convolution", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], []]", 16, 0, 4503, 672, 15743], ["aten::conv2d", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], []]", 16, 0, 4503, 782, 16525], ["aten::contiguous", "[[32, 512, 28, 28], []]", 180, 0, 0, 2078, 2078], ["aten::empty_like", "[[32, 512, 28, 28], [], [], [], [], []]", 20, 0, 0, 928, 1752], ["aten::_batch_norm_impl_index", "[[32, 512, 28, 28], [512], [512], [512], [512], [], [], [], []]", 20, 0, 4119, 2448, 17326], ["aten::batch_norm", "[[32, 512, 28, 28], [512], [512], [512], [512], [], [], [], []]", 20, 0, 4119, 906, 18232], ["aten::contiguous", "[[512, 256, 1, 1], []]", 8, 0, 0, 112, 112], ["aten::resize_", "[[512, 256, 1, 1], [], []]", 8, 0, 0, 93, 93], ["aten::_convolution", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 4, 0, 2223, 360, 3600], ["aten::convolution", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], [], [], []]", 4, 0, 2223, 182, 3782], ["aten::conv2d", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], []]", 4, 0, 2223, 192, 3974], ["aten::relu_", "[[32, 512, 28, 28]]", 16, 0, 2001, 1857, 2788], ["aten::contiguous", "[[128, 512, 1, 1], []]", 24, 0, 0, 369, 369], ["aten::resize_", "[[128, 512, 1, 1], [], []]", 24, 0, 0, 350, 350], ["aten::resize_", "[[32, 512, 28, 28], [], []]", 80, 0, 0, 833, 833], ["aten::stride", "[[32, 512, 28, 28], []]", 240, 0, 0, 1545, 1545], ["aten::_convolution", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 12, 0, 4463, 1100, 8580], ["aten::convolution", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], []]", 12, 0, 4463, 527, 9107], ["aten::conv2d", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], []]", 12, 0, 4463, 578, 9685], ["aten::_convolution", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 12, 0, 3473, 1085, 9033], ["aten::convolution", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], []]", 12, 0, 3473, 521, 9554], ["aten::conv2d", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], []]", 12, 0, 3473, 598, 10152], ["aten::contiguous", "[[256, 512, 1, 1], []]", 8, 0, 0, 116, 116], ["aten::resize_", "[[256, 512, 1, 1], [], []]", 8, 0, 0, 91, 91], ["aten::_convolution", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 4, 0, 2846, 358, 2944], ["aten::convolution", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], []]", 4, 0, 2846, 163, 3107], ["aten::conv2d", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], []]", 4, 0, 2846, 194, 3301], ["aten::contiguous", "[[32, 256, 28, 28], []]", 36, 0, 0, 392, 392], ["aten::empty_like", "[[32, 256, 28, 28], [], [], [], [], []]", 4, 0, 0, 184, 349], ["aten::_batch_norm_impl_index", "[[32, 256, 28, 28], [256], [256], [256], [256], [], [], [], []]", 4, 0, 412, 509, 3505], ["aten::batch_norm", "[[32, 256, 28, 28], [256], [256], [256], [256], [], [], [], []]", 4, 0, 412, 181, 3686], ["aten::relu_", "[[32, 256, 28, 28]]", 4, 0, 252, 475, 722], ["aten::contiguous", "[[256, 256, 3, 3], []]", 48, 0, 0, 715, 715], ["aten::resize_", "[[256, 256, 3, 3], [], []]", 48, 0, 0, 553, 553], ["aten::resize_", "[[32, 256, 28, 28], [], []]", 16, 0, 0, 159, 159], ["aten::stride", "[[32, 256, 28, 28], []]", 48, 0, 0, 302, 302], ["aten::_convolution", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 4, 0, 3393, 356, 2799], ["aten::convolution", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], [], [], []]", 4, 0, 3393, 182, 2981], ["aten::conv2d", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], []]", 4, 0, 3393, 195, 3176], ["aten::contiguous", "[[32, 256, 14, 14], []]", 396, 0, 0, 4486, 4486], ["aten::empty_like", "[[32, 256, 14, 14], [], [], [], [], []]", 44, 0, 0, 2151, 4003], ["aten::_batch_norm_impl_index", "[[32, 256, 14, 14], [256], [256], [256], [256], [], [], [], []]", 44, 0, 739, 5395, 39713], ["aten::batch_norm", "[[32, 256, 14, 14], [256], [256], [256], [256], [], [], [], []]", 44, 0, 739, 2045, 41758], ["aten::relu_", "[[32, 256, 14, 14]]", 44, 0, 387, 5259, 7818], ["aten::contiguous", "[[1024, 256, 1, 1], []]", 48, 0, 0, 699, 699], ["aten::resize_", "[[1024, 256, 1, 1], [], []]", 48, 0, 0, 561, 561], ["aten::resize_", "[[32, 256, 14, 14], [], []]", 176, 0, 0, 1801, 1801], ["aten::stride", "[[32, 256, 14, 14], []]", 528, 0, 0, 3428, 3428], ["aten::_convolution", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 24, 0, 7103, 2239, 16986], ["aten::convolution", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], []]", 24, 0, 7103, 1015, 18001], ["aten::conv2d", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], []]", 24, 0, 7103, 1168, 19169], ["aten::contiguous", "[[32, 1024, 14, 14], []]", 252, 0, 0, 2849, 2849], ["aten::empty_like", "[[32, 1024, 14, 14], [], [], [], [], []]", 28, 0, 0, 1291, 2463], ["aten::_batch_norm_impl_index", "[[32, 1024, 14, 14], [1024], [1024], [1024], [1024], [], [], [], []]", 28, 0, 1785, 3517, 27570], ["aten::batch_norm", "[[32, 1024, 14, 14], [1024], [1024], [1024], [1024], [], [], [], []]", 28, 0, 1785, 1347, 28917], ["aten::contiguous", "[[1024, 512, 1, 1], []]", 8, 0, 0, 116, 116], ["aten::resize_", "[[1024, 512, 1, 1], [], []]", 8, 0, 0, 92, 92], ["aten::_convolution", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 4, 0, 2264, 398, 2822], ["aten::convolution", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], [], [], []]", 4, 0, 2264, 184, 3006], ["aten::conv2d", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], []]", 4, 0, 2264, 200, 3206], ["aten::relu_", "[[32, 1024, 14, 14]]", 24, 0, 1136, 2839, 4225], ["aten::contiguous", "[[256, 1024, 1, 1], []]", 40, 0, 0, 572, 572], ["aten::resize_", "[[256, 1024, 1, 1], [], []]", 40, 0, 0, 491, 491], ["aten::resize_", "[[32, 1024, 14, 14], [], []]", 112, 0, 0, 1106, 1106], ["aten::stride", "[[32, 1024, 14, 14], []]", 336, 0, 0, 2188, 2188], ["aten::_convolution", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 20, 0, 5880, 1897, 14156], ["aten::convolution", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], []]", 20, 0, 5880, 861, 15017], ["aten::conv2d", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], []]", 20, 0, 5880, 983, 16000], ["aten::_convolution", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 20, 0, 4296, 1875, 15236], ["aten::convolution", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], []]", 20, 0, 4296, 857, 16093], ["aten::conv2d", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], []]", 20, 0, 4296, 973, 17066], ["aten::contiguous", "[[512, 1024, 1, 1], []]", 8, 0, 0, 119, 119], ["aten::resize_", "[[512, 1024, 1, 1], [], []]", 8, 0, 0, 92, 92], ["aten::_convolution", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 4, 0, 2269, 399, 3033], ["aten::convolution", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], []]", 4, 0, 2269, 168, 3201], ["aten::conv2d", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], []]", 4, 0, 2269, 212, 3413], ["aten::contiguous", "[[32, 512, 14, 14], []]", 36, 0, 0, 403, 403], ["aten::empty_like", "[[32, 512, 14, 14], [], [], [], [], []]", 4, 0, 0, 183, 347], ["aten::_batch_norm_impl_index", "[[32, 512, 14, 14], [512], [512], [512], [512], [], [], [], []]", 4, 0, 136, 480, 3450], ["aten::batch_norm", "[[32, 512, 14, 14], [512], [512], [512], [512], [], [], [], []]", 4, 0, 136, 180, 3630], ["aten::relu_", "[[32, 512, 14, 14]]", 4, 0, 91, 485, 715], ["aten::contiguous", "[[512, 512, 3, 3], []]", 24, 0, 0, 348, 348], ["aten::resize_", "[[512, 512, 3, 3], [], []]", 24, 0, 0, 290, 290], ["aten::resize_", "[[32, 512, 14, 14], [], []]", 16, 0, 0, 162, 162], ["aten::stride", "[[32, 512, 14, 14], []]", 48, 0, 0, 317, 317], ["aten::_convolution", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 4, 0, 2738, 357, 3031], ["aten::convolution", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], [], [], []]", 4, 0, 2738, 165, 3196], ["aten::conv2d", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], []]", 4, 0, 2738, 193, 3389], ["aten::contiguous", "[[32, 512, 7, 7], []]", 180, 0, 0, 2058, 2058], ["aten::empty_like", "[[32, 512, 7, 7], [], [], [], [], []]", 20, 0, 0, 997, 1800], ["aten::_batch_norm_impl_index", "[[32, 512, 7, 7], [512], [512], [512], [512], [], [], [], []]", 20, 0, 220, 2419, 17348], ["aten::batch_norm", "[[32, 512, 7, 7], [512], [512], [512], [512], [], [], [], []]", 20, 0, 220, 913, 18261], ["aten::relu_", "[[32, 512, 7, 7]]", 20, 0, 90, 2389, 3535], ["aten::contiguous", "[[2048, 512, 1, 1], []]", 24, 0, 0, 343, 343], ["aten::resize_", "[[2048, 512, 1, 1], [], []]", 24, 0, 0, 290, 290], ["aten::resize_", "[[32, 512, 7, 7], [], []]", 80, 0, 0, 810, 810], ["aten::stride", "[[32, 512, 7, 7], []]", 240, 0, 0, 1596, 1596], ["aten::_convolution", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 12, 0, 3742, 1102, 8438], ["aten::convolution", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], []]", 12, 0, 3742, 496, 8934], ["aten::conv2d", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], []]", 12, 0, 3742, 583, 9517], ["aten::contiguous", "[[32, 2048, 7, 7], []]", 120, 0, 0, 1386, 1386], ["aten::empty_like", "[[32, 2048, 7, 7], [], [], [], [], []]", 16, 0, 0, 754, 1411], ["aten::_batch_norm_impl_index", "[[32, 2048, 7, 7], [2048], [2048], [2048], [2048], [], [], [], []]", 16, 0, 668, 1973, 13943], ["aten::batch_norm", "[[32, 2048, 7, 7], [2048], [2048], [2048], [2048], [], [], [], []]", 16, 0, 668, 722, 14665], ["aten::contiguous", "[[2048, 1024, 1, 1], []]", 8, 0, 0, 118, 118], ["aten::resize_", "[[2048, 1024, 1, 1], [], []]", 8, 0, 0, 93, 93], ["aten::_convolution", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 4, 0, 2196, 360, 2813], ["aten::convolution", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], [], [], []]", 4, 0, 2196, 165, 2978], ["aten::conv2d", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], []]", 4, 0, 2196, 197, 3175], ["aten::relu_", "[[32, 2048, 7, 7]]", 12, 0, 289, 1431, 2114], ["aten::contiguous", "[[512, 2048, 1, 1], []]", 16, 0, 0, 226, 226], ["aten::resize_", "[[512, 2048, 1, 1], [], []]", 16, 0, 0, 184, 184], ["aten::resize_", "[[32, 2048, 7, 7], [], []]", 48, 0, 0, 508, 508], ["aten::stride", "[[32, 2048, 7, 7], []]", 96, 0, 0, 611, 611], ["aten::_convolution", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 2676, 725, 5653], ["aten::convolution", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], []]", 8, 0, 2676, 370, 6023], ["aten::conv2d", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], []]", 8, 0, 2676, 407, 6430], ["aten::_convolution", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 1841, 735, 6158], ["aten::convolution", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], []]", 8, 0, 1841, 333, 6491], ["aten::conv2d", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], []]", 8, 0, 1841, 390, 6881], ["aten::adaptive_avg_pool2d", "[[32, 2048, 7, 7], []]", 4, 0, 128, 190, 1250], ["aten::view", "[[32, 2048, 1, 1], []]", 4, 0, 0, 414, 414], ["aten::reshape", "[[32, 2048, 1, 1], []]", 4, 0, 0, 125, 539], ["aten::flatten", "[[32, 2048, 1, 1], [], []]", 4, 0, 0, 196, 735], ["aten::as_strided", "[[1000, 2048], [], [], []]", 8, 0, 0, 129, 129], ["aten::transpose", "[[1000, 2048], [], []]", 8, 0, 0, 271, 400], ["aten::t", "[[1000, 2048]]", 8, 0, 0, 662, 1062], ["aten::as_strided", "[[1000], [], [], []]", 4, 0, 0, 265, 265], ["aten::expand", "[[1000], [], []]", 4, 0, 0, 724, 989], ["aten::stride", "[[2048, 1000], []]", 4, 0, 0, 57, 57], ["aten::stride", "[[32, 2048], []]", 12, 0, 0, 99, 99], ["aten::stride", "[[32, 1000], []]", 8, 0, 0, 44, 44], ["aten::contiguous", "[[32, 1000], []]", 12, 0, 0, 145, 145], ["aten::empty_like", "[[32, 1000], [], [], [], [], []]", 8, 0, 0, 365, 675], ["aten::log_softmax", "[[32, 1000], [], []]", 4, 0, 30, 182, 1433], ["aten::nll_loss", "[[32, 1000], [32], [], [], []]", 4, 0, 12, 203, 1569], ["aten::is_floating_point", "[[]]", 4, 0, 0, 53, 53], ["aten::zero_", "[[64, 3, 7, 7]]", 4, 0, 3, 309, 557], ["aten::zero_", "[[64]]", 56, 0, 20, 3596, 6682], ["aten::zero_", "[[64, 64, 1, 1]]", 4, 0, 2, 258, 449], ["aten::zero_", "[[64, 64, 3, 3]]", 12, 0, 9, 1122, 1774], ["aten::zero_", "[[256, 64, 1, 1]]", 16, 0, 12, 962, 1726], ["aten::zero_", "[[256]]", 128, 0, 31, 9974, 17907], ["aten::zero_", "[[64, 256, 1, 1]]", 8, 0, 6, 519, 893], ["aten::zero_", "[[128, 256, 1, 1]]", 4, 0, 3, 654, 1250], ["aten::zero_", "[[128]]", 64, 0, 30, 4244, 7585], ["aten::zero_", "[[128, 128, 3, 3]]", 16, 0, 12, 956, 1725], ["aten::zero_", "[[512, 128, 1, 1]]", 16, 0, 12, 1083, 2109], ["aten::zero_", "[[512]]", 88, 0, 45, 7024, 12115], ["aten::zero_", "[[512, 256, 1, 1]]", 4, 0, 3, 238, 426], ["aten::zero_", "[[128, 512, 1, 1]]", 12, 0, 9, 739, 1308], ["aten::zero_", "[[256, 512, 1, 1]]", 4, 0, 3, 237, 424], ["aten::zero_", "[[256, 256, 3, 3]]", 24, 0, 72, 2040, 3617], ["aten::zero_", "[[1024, 256, 1, 1]]", 24, 0, 36, 1980, 3464], ["aten::zero_", "[[1024]]", 56, 0, 35, 4408, 7924], ["aten::zero_", "[[1024, 512, 1, 1]]", 4, 0, 12, 242, 431], ["aten::zero_", "[[256, 1024, 1, 1]]", 20, 0, 30, 1448, 2787], ["aten::zero_", "[[512, 1024, 1, 1]]", 4, 0, 12, 336, 677], ["aten::zero_", "[[512, 512, 3, 3]]", 12, 0, 135, 737, 1541], ["aten::zero_", "[[2048, 512, 1, 1]]", 12, 0, 63, 1370, 2056], ["aten::zero_", "[[2048]]", 32, 0, 12, 2524, 4968], ["aten::zero_", "[[2048, 1024, 1, 1]]", 4, 0, 39, 477, 679], ["aten::zero_", "[[512, 2048, 1, 1]]", 8, 0, 42, 477, 868], ["aten::zero_", "[[1000, 2048]]", 4, 0, 39, 643, 852], ["aten::zero_", "[[1000]]", 4, 0, 3, 265, 677], ["aten::empty_like", "[[], [], [], [], [], []]", 4, 0, 0, 267, 617], ["aten::ones_like", "[[], [], [], [], [], []]", 4, 0, 3, 450, 1290], ["NllLossBackward", "[[]]", 4, 0, 9, 336, 1013], ["LogSoftmaxBackward", "[[32, 1000]]", 4, 0, 33, 254, 1281], ["aten::as_strided", "[[2048, 1000], [], [], []]", 8, 0, 0, 111, 111], ["aten::transpose", "[[2048, 1000], [], []]", 8, 0, 0, 277, 388], ["aten::t", "[[2048, 1000]]", 8, 0, 0, 430, 818], ["aten::conj", "[[1000, 2048]]", 4, 0, 0, 76, 76], ["aten::stride", "[[1000, 2048], []]", 8, 0, 0, 69, 69], ["aten::as_strided", "[[32, 1000], [], [], []]", 4, 0, 0, 60, 60], ["aten::transpose", "[[32, 1000], [], []]", 4, 0, 0, 131, 191], ["aten::t", "[[32, 1000]]", 4, 0, 0, 223, 414], ["aten::conj", "[[32, 2048]]", 4, 0, 0, 75, 75], ["aten::stride", "[[1000, 32], []]", 4, 0, 0, 23, 23], ["AddmmBackward", "[[32, 1000]]", 4, 0, 144, 696, 4140], ["torch::autograd::AccumulateGrad", "[[1000]]", 4, 0, 3, 161, 530], ["TBackward", "[[2048, 1000]]", 4, 0, 0, 134, 534], ["torch::autograd::AccumulateGrad", "[[1000, 2048]]", 4, 0, 90, 139, 492], ["aten::view", "[[32, 2048], []]", 4, 0, 0, 264, 264], ["aten::reshape", "[[32, 2048], []]", 4, 0, 0, 120, 384], ["ViewBackward", "[[32, 2048]]", 4, 0, 0, 161, 545], ["aten::as_strided", "[[32, 2048, 1, 1], [], [], []]", 4, 0, 0, 72, 72], ["aten::expand", "[[32, 2048, 1, 1], [], []]", 4, 0, 0, 365, 437], ["aten::to", "[[32, 2048, 7, 7], [], [], [], []]", 4, 0, 0, 55, 55], ["MeanBackward1", "[[32, 2048, 1, 1]]", 4, 0, 87, 330, 1765], ["ReluBackward1", "[[32, 2048, 7, 7]]", 12, 0, 452, 842, 2943], ["AddBackward0", "[[32, 2048, 7, 7]]", 12, 0, 0, 293, 293], ["CudnnBatchNormBackward", "[[32, 2048, 7, 7]]", 16, 0, 879, 1803, 10492], ["torch::autograd::AccumulateGrad", "[[2048]]", 32, 0, 103, 1202, 4140], ["aten::cudnn_convolution_backward", "[[32, 512, 7, 7], [32, 2048, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], [], []]", 12, 0, 7569, 2051, 16796], ["CudnnConvolutionBackward", "[[32, 2048, 7, 7]]", 16, 0, 12576, 1349, 23177], ["torch::autograd::AccumulateGrad", "[[2048, 512, 1, 1]]", 12, 0, 149, 468, 1564], ["ReluBackward1", "[[32, 512, 7, 7]]", 20, 0, 251, 1226, 4694], ["CudnnBatchNormBackward", "[[32, 512, 7, 7]]", 20, 0, 344, 2323, 13058], ["torch::autograd::AccumulateGrad", "[[512]]", 88, 0, 287, 3424, 11442], ["aten::cudnn_convolution_backward", "[[32, 512, 7, 7], [32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], [], []]", 8, 0, 3813, 1357, 10054], ["CudnnConvolutionBackward", "[[32, 512, 7, 7]]", 20, 0, 13542, 1658, 26989], ["torch::autograd::AccumulateGrad", "[[512, 512, 3, 3]]", 12, 0, 347, 476, 1582], ["aten::cudnn_convolution_backward", "[[32, 2048, 7, 7], [32, 512, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 4875, 1541, 10379], ["torch::autograd::AccumulateGrad", "[[512, 2048, 1, 1]]", 8, 0, 116, 311, 1021], ["aten::cudnn_convolution_backward", "[[32, 1024, 14, 14], [32, 2048, 7, 7], [2048, 1024, 1, 1], [], [], [], [], [], [], [], []]", 4, 0, 5007, 653, 5032], ["torch::autograd::AccumulateGrad", "[[2048, 1024, 1, 1]]", 4, 0, 104, 152, 515], ["aten::cudnn_convolution_backward", "[[32, 512, 14, 14], [32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], [], []]", 4, 0, 4854, 658, 4898], ["ReluBackward1", "[[32, 512, 14, 14]]", 4, 0, 152, 258, 1108], ["CudnnBatchNormBackward", "[[32, 512, 14, 14]]", 4, 0, 272, 455, 2583], ["aten::cudnn_convolution_backward", "[[32, 1024, 14, 14], [32, 512, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], [], []]", 4, 0, 4235, 685, 4935], ["CudnnConvolutionBackward", "[[32, 512, 14, 14]]", 4, 0, 4235, 324, 5259], ["torch::autograd::AccumulateGrad", "[[512, 1024, 1, 1]]", 4, 0, 39, 179, 580], ["ReluBackward1", "[[32, 1024, 14, 14]]", 24, 0, 1719, 1490, 5610], ["AddBackward0", "[[32, 1024, 14, 14]]", 24, 0, 0, 588, 588], ["CudnnBatchNormBackward", "[[32, 1024, 14, 14]]", 28, 0, 3786, 3064, 18941], ["torch::autograd::AccumulateGrad", "[[1024]]", 56, 0, 186, 2120, 7236], ["aten::cudnn_convolution_backward", "[[32, 256, 14, 14], [32, 1024, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], [], []]", 24, 0, 14985, 4073, 29658], ["CudnnConvolutionBackward", "[[32, 1024, 14, 14]]", 28, 0, 19882, 2386, 36960], ["torch::autograd::AccumulateGrad", "[[1024, 256, 1, 1]]", 24, 0, 125, 927, 3135], ["ReluBackward1", "[[32, 256, 14, 14]]", 44, 0, 915, 2670, 10384], ["CudnnBatchNormBackward", "[[32, 256, 14, 14]]", 44, 0, 1562, 4999, 28270], ["torch::autograd::AccumulateGrad", "[[256]]", 128, 0, 417, 5077, 16751], ["aten::cudnn_convolution_backward", "[[32, 256, 14, 14], [32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], [], []]", 20, 0, 9068, 3366, 25481], ["CudnnConvolutionBackward", "[[32, 256, 14, 14]]", 44, 0, 25974, 3581, 57196], ["torch::autograd::AccumulateGrad", "[[256, 256, 3, 3]]", 24, 0, 171, 927, 3111], ["aten::cudnn_convolution_backward", "[[32, 1024, 14, 14], [32, 256, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], [], []]", 20, 0, 12210, 3331, 23294], ["torch::autograd::AccumulateGrad", "[[256, 1024, 1, 1]]", 20, 0, 128, 807, 2617], ["aten::cudnn_convolution_backward", "[[32, 512, 28, 28], [32, 1024, 14, 14], [1024, 512, 1, 1], [], [], [], [], [], [], [], []]", 4, 0, 4897, 656, 4916], ["torch::autograd::AccumulateGrad", "[[1024, 512, 1, 1]]", 4, 0, 26, 158, 532], ["aten::cudnn_convolution_backward", "[[32, 256, 28, 28], [32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], [], []]", 4, 0, 4696, 661, 4840], ["ReluBackward1", "[[32, 256, 28, 28]]", 4, 0, 286, 236, 916], ["CudnnBatchNormBackward", "[[32, 256, 28, 28]]", 4, 0, 491, 459, 2608], ["aten::cudnn_convolution_backward", "[[32, 512, 28, 28], [32, 256, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], [], []]", 4, 0, 3848, 663, 5688], ["CudnnConvolutionBackward", "[[32, 256, 28, 28]]", 4, 0, 3848, 335, 6023], ["torch::autograd::AccumulateGrad", "[[256, 512, 1, 1]]", 4, 0, 21, 155, 514], ["ReluBackward1", "[[32, 512, 28, 28]]", 16, 0, 2229, 952, 3770], ["AddBackward0", "[[32, 512, 28, 28]]", 16, 0, 0, 410, 410], ["CudnnBatchNormBackward", "[[32, 512, 28, 28]]", 20, 0, 4933, 2229, 12975], ["aten::cudnn_convolution_backward", "[[32, 128, 28, 28], [32, 512, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], [], []]", 16, 0, 9316, 2657, 18527], ["CudnnConvolutionBackward", "[[32, 512, 28, 28]]", 20, 0, 14175, 1666, 24881], ["torch::autograd::AccumulateGrad", "[[512, 128, 1, 1]]", 16, 0, 63, 673, 2158], ["ReluBackward1", "[[32, 128, 28, 28]]", 28, 0, 1027, 1722, 6607], ["CudnnBatchNormBackward", "[[32, 128, 28, 28]]", 28, 0, 1906, 3108, 17853], ["torch::autograd::AccumulateGrad", "[[128]]", 64, 0, 207, 2413, 8209], ["aten::cudnn_convolution_backward", "[[32, 128, 28, 28], [32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], [], []]", 12, 0, 5575, 2044, 14807], ["CudnnConvolutionBackward", "[[32, 128, 28, 28]]", 28, 0, 17629, 2305, 38967], ["torch::autograd::AccumulateGrad", "[[128, 128, 3, 3]]", 16, 0, 71, 619, 2075], ["aten::cudnn_convolution_backward", "[[32, 512, 28, 28], [32, 128, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], [], []]", 12, 0, 6449, 2146, 16628], ["torch::autograd::AccumulateGrad", "[[128, 512, 1, 1]]", 12, 0, 54, 818, 1928], ["aten::cudnn_convolution_backward", "[[32, 256, 56, 56], [32, 512, 28, 28], [512, 256, 1, 1], [], [], [], [], [], [], [], []]", 4, 0, 4859, 691, 4688], ["torch::autograd::AccumulateGrad", "[[512, 256, 1, 1]]", 4, 0, 20, 152, 514], ["aten::cudnn_convolution_backward", "[[32, 128, 56, 56], [32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], [], []]", 4, 0, 5605, 751, 5227], ["ReluBackward1", "[[32, 128, 56, 56]]", 4, 0, 551, 260, 957], ["CudnnBatchNormBackward", "[[32, 128, 56, 56]]", 4, 0, 1026, 452, 2543], ["aten::cudnn_convolution_backward", "[[32, 256, 56, 56], [32, 128, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], [], []]", 4, 0, 4149, 667, 5274], ["CudnnConvolutionBackward", "[[32, 128, 56, 56]]", 4, 0, 4149, 353, 5627], ["torch::autograd::AccumulateGrad", "[[128, 256, 1, 1]]", 4, 0, 17, 153, 507], ["ReluBackward1", "[[32, 256, 56, 56]]", 12, 0, 3298, 713, 2785], ["AddBackward0", "[[32, 256, 56, 56]]", 12, 0, 0, 305, 305], ["CudnnBatchNormBackward", "[[32, 256, 56, 56]]", 16, 0, 7677, 1828, 10278], ["aten::cudnn_convolution_backward", "[[32, 64, 56, 56], [32, 256, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], [], []]", 16, 0, 9364, 2819, 19674], ["CudnnConvolutionBackward", "[[32, 256, 56, 56]]", 16, 0, 9364, 1325, 20999], ["torch::autograd::AccumulateGrad", "[[256, 64, 1, 1]]", 16, 0, 55, 601, 2068], ["ReluBackward1", "[[32, 64, 56, 56]]", 24, 0, 1659, 1440, 5671], ["CudnnBatchNormBackward", "[[32, 64, 56, 56]]", 24, 0, 3776, 2690, 15543], ["torch::autograd::AccumulateGrad", "[[64]]", 56, 0, 180, 2147, 7515], ["aten::cudnn_convolution_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], [], []]", 12, 0, 11553, 2070, 14664], ["CudnnConvolutionBackward", "[[32, 64, 56, 56]]", 24, 0, 19163, 1979, 31450], ["torch::autograd::AccumulateGrad", "[[64, 64, 3, 3]]", 12, 0, 44, 457, 1660], ["aten::cudnn_convolution_backward", "[[32, 256, 56, 56], [32, 64, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 6565, 1344, 9831], ["torch::autograd::AccumulateGrad", "[[64, 256, 1, 1]]", 8, 0, 29, 328, 1080], ["aten::cudnn_convolution_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], [], []]", 4, 0, 1045, 766, 4976], ["torch::autograd::AccumulateGrad", "[[64, 64, 1, 1]]", 4, 0, 14, 168, 523], ["aten::zero_", "[[32, 64, 112, 112]]", 4, 0, 482, 152, 414], ["aten::zeros_like", "[[32, 64, 112, 112], [], [], [], [], []]", 4, 0, 482, 173, 927], ["aten::resize_", "[[32, 64, 112, 112], [], []]", 8, 0, 0, 82, 82], ["aten::resize_as_", "[[32, 64, 112, 112], [32, 64, 112, 112], []]", 4, 0, 0, 138, 174], ["MaxPool2DWithIndicesBackward", "[[32, 64, 56, 56]]", 4, 0, 2564, 325, 2788], ["ReluBackward1", "[[32, 64, 112, 112]]", 4, 0, 1104, 232, 916], ["CudnnBatchNormBackward", "[[32, 64, 112, 112]]", 4, 0, 2397, 448, 2589], ["aten::cudnn_convolution_backward", "[[32, 3, 224, 224], [32, 64, 112, 112], [64, 3, 7, 7], [], [], [], [], [], [], [], []]", 4, 0, 3009, 489, 2475], ["CudnnConvolutionBackward", "[[32, 64, 112, 112]]", 4, 0, 3009, 327, 2802], ["torch::autograd::AccumulateGrad", "[[64, 3, 7, 7]]", 4, 0, 15, 166, 525]]}}, "kernel_op_table": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "string", "name": "Operator"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Total Duration (us)"}, {"type": "number", "name": "Mean Duration (us)"}, {"type": "number", "name": "Max Duration (us)"}, {"type": "number", "name": "Min Duration (us)"}], "rows": [["ncclAllReduceRingLLKernel_sum_f32(ncclColl)", "CallTreeRoot", 15, 3237283, 215818.86666666667, 17608, 892991], ["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", "aten::cudnn_convolution_backward_input", 81, 42585, 525.7407407407408, 341, 1089], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 60, 29369, 489.48333333333335, 384, 821], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", "aten::cudnn_batch_norm_backward", 132, 27826, 210.8030303030303, 46, 799], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", "aten::cudnn_batch_norm", 100, 17483, 174.83, 50, 426], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 34, 15932, 468.5882352941176, 362, 851], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", "aten::add_", 1504, 15027, 9.991356382978724, 1, 364], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", "aten::threshold_backward", 147, 13643, 92.80952380952381, 16, 368], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 30, 13109, 436.96666666666664, 386, 759], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", "aten::cudnn_convolution_backward_weight", 24, 11183, 465.9583333333333, 336, 715], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", "aten::threshold_", 170, 11158, 65.63529411764706, 6, 250], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", "aten::cudnn_convolution_backward_weight", 21, 8706, 414.57142857142856, 361, 765], ["volta_sgemm_128x64_nn", "aten::cudnn_convolution", 45, 8213, 182.51111111111112, 157, 207], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 9, 8081, 897.8888888888889, 888, 906], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", "CallTreeRoot", 48, 7757, 161.60416666666666, 49, 365], ["volta_scudnn_128x64_relu_interior_nn_v1", "aten::cudnn_convolution", 24, 7203, 300.125, 92, 511], ["volta_sgemm_128x64_nt", "aten::cudnn_convolution_backward_weight", 30, 5837, 194.56666666666666, 175, 207], ["volta_sgemm_128x64_nt", "aten::cudnn_convolution_backward_input", 30, 5826, 194.2, 160, 209], ["volta_scudnn_128x64_stridedB_interior_nn_v1", "aten::cudnn_convolution_backward_input", 15, 5038, 335.8666666666667, 264, 542], ["volta_scudnn_128x128_relu_medium_nn_v1", "aten::cudnn_convolution", 16, 4459, 278.6875, 272, 294], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", "aten::cudnn_convolution_backward_weight", 6, 4079, 679.8333333333334, 672, 688], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 6, 3721, 620.1666666666666, 230, 1006], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", "aten::cudnn_batch_norm", 84, 3548, 42.23809523809524, 14, 87], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", "aten::cudnn_convolution_backward_input", 9, 3393, 377.0, 368, 384], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", "aten::cudnn_convolution", 45, 2917, 64.82222222222222, 17, 140], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", "aten::cudnn_convolution_backward_input", 81, 2879, 35.54320987654321, 9, 162], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 4, 2846, 711.5, 663, 773], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", "aten::cudnn_convolution", 45, 2781, 61.8, 19, 113], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 6, 2676, 446.0, 444, 447], ["volta_scudnn_128x128_stridedB_interior_nn_v1", "aten::cudnn_convolution_backward_input", 9, 2662, 295.77777777777777, 291, 303], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", "CallTreeRoot", 483, 2585, 5.351966873706004, 1, 29], ["volta_scudnn_128x64_relu_medium_nn_v1", "aten::cudnn_convolution", 4, 2549, 637.25, 635, 639], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", "aten::cudnn_convolution", 3, 2443, 814.3333333333334, 813, 816], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", "aten::cudnn_convolution", 4, 2389, 597.25, 571, 673], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 3, 2345, 781.6666666666666, 753, 803], ["volta_scudnn_128x64_relu_small_nn_v1", "aten::cudnn_convolution", 8, 2255, 281.875, 270, 292], ["volta_scudnn_128x128_relu_interior_nn_v1", "aten::cudnn_convolution", 4, 2215, 553.75, 551, 557], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", "aten::max_pool2d_with_indices_backward", 3, 2082, 694.0, 693, 695], ["volta_scudnn_128x128_stridedB_medium_nn_v1", "aten::cudnn_convolution_backward_input", 6, 1921, 320.1666666666667, 308, 332], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", "aten::cudnn_convolution", 3, 1723, 574.3333333333334, 573, 575], ["volta_scudnn_128x128_stridedB_small_nn_v1", "aten::cudnn_convolution_backward_input", 3, 1668, 556.0, 553, 559], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", "aten::add", 483, 1584, 3.279503105590062, 1, 35], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", "aten::cudnn_convolution_backward_input", 30, 1376, 45.86666666666667, 24, 71], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", "aten::cudnn_convolution_backward_weight", 30, 1326, 44.2, 23, 64], ["ncclBroadcastRingLLKernel_copy_i8(ncclColl)", "CallTreeRoot", 8, 1277, 159.625, 72, 247], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", "aten::cudnn_convolution_backward_weight", 30, 1268, 42.266666666666666, 21, 64], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", "aten::cudnn_convolution_backward_input", 30, 1265, 42.166666666666664, 22, 65], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", "aten::cudnn_batch_norm_backward", 27, 1223, 45.2962962962963, 22, 76], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", "aten::fill_", 489, 1215, 2.4846625766871164, 0, 161], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", "aten::mul_", 483, 1173, 2.4285714285714284, 1, 25], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", "aten::max_pool2d_with_indices", 4, 891, 222.75, 222, 223], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", "aten::cudnn_convolution", 6, 841, 140.16666666666666, 98, 183], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", "aten::cudnn_convolution_backward_weight", 30, 786, 26.2, 9, 70], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", "aten::cudnn_convolution_backward_input", 30, 772, 25.733333333333334, 8, 71], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", "aten::cudnn_convolution", 45, 721, 16.022222222222222, 4, 64], ["volta_scudnn_128x64_stridedB_small_nn_v1", "aten::cudnn_convolution_backward_input", 3, 296, 98.66666666666667, 98, 99], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", "aten::cudnn_convolution_backward_weight", 51, 250, 4.901960784313726, 3, 6], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", "aten::cudnn_convolution_backward_weight", 51, 241, 4.7254901960784315, 3, 6], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", "aten::cudnn_convolution_backward_input", 36, 229, 6.361111111111111, 4, 8], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", "aten::add", 185, 193, 1.0432432432432432, 1, 5], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", "aten::cudnn_convolution_backward_input", 36, 155, 4.305555555555555, 2, 6], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", "aten::cudnn_convolution", 60, 141, 2.35, 2, 4], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<float, unsigned int, 1, 128, 1>(float*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<float, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", "aten::_cat", 4, 128, 32.0, 32, 32], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", "aten::mean", 3, 128, 42.666666666666664, 42, 43], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", "aten::div", 3, 87, 29.0, 29, 29], ["volta_sgemm_64x32_sliced1x4_nn", "aten::mm", 3, 81, 27.0, 27, 27], ["volta_sgemm_64x32_sliced1x4_tn", "aten::addmm", 3, 73, 24.333333333333332, 24, 25], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", "aten::cudnn_convolution_backward_input", 9, 68, 7.555555555555555, 7, 8], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<long, unsigned int, 1, 128, 1>(long*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<long, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", "aten::_cat", 4, 64, 16.0, 16, 16], ["volta_sgemm_128x32_nt", "aten::mm", 3, 57, 19.0, 19, 19], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", "aten::_log_softmax_backward_data", 3, 33, 11.0, 11, 11], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", "aten::_log_softmax", 3, 30, 10.0, 10, 10], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", "CallTreeRoot", 3, 26, 8.666666666666666, 8, 9], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", "aten::addmm", 3, 15, 5.0, 5, 5], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", "aten::nll_loss_forward", 3, 12, 4.0, 4, 4], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", "aten::addmm", 3, 9, 3.0, 3, 3], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", "aten::nll_loss_backward", 3, 6, 2.0, 2, 2], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", "aten::mm", 3, 6, 2.0, 2, 2]]}}, "kernel_pie": {"total": {"columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["ncclAllReduceRingLLKernel_sum_f32(ncclColl)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3434430.0}], ["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 42585.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 29369.0}], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 27826.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 25768.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 24801.0}], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 17483.0}], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 15932.0}], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 13109.0}], ["volta_sgemm_128x64_nt", {"py/object": "numpy.float64", "dtype": "float64", "value": 11663.0}], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 11183.0}], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 8706.0}], ["volta_sgemm_128x64_nn", {"py/object": "numpy.float64", "dtype": "float64", "value": 8213.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 8081.0}], ["volta_scudnn_128x64_relu_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 7203.0}], ["volta_scudnn_128x64_stridedB_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 5038.0}], ["volta_scudnn_128x128_relu_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 4459.0}], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 4182.0}], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 4157.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 4146.0}], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 4079.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3721.0}], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3548.0}], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 3393.0}], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2879.0}], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2846.0}], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2676.0}], ["volta_scudnn_128x128_stridedB_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 2662.0}], ["volta_scudnn_128x64_relu_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 2549.0}], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2443.0}], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 2389.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2345.0}], ["volta_scudnn_128x64_relu_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 2255.0}], ["volta_scudnn_128x128_relu_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 2215.0}], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2082.0}], ["volta_scudnn_128x128_stridedB_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 1921.0}], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1723.0}], ["volta_scudnn_128x128_stridedB_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 1668.0}], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1493.0}], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1326.0}], ["ncclBroadcastRingLLKernel_copy_i8(ncclColl)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1277.0}], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1268.0}], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1223.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1215.0}], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 891.0}], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 841.0}], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 786.0}], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 370.0}], ["volta_scudnn_128x64_stridedB_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 296.0}], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 250.0}], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 241.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 193.0}], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 155.0}], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 128.0}], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<float, unsigned int, 1, 128, 1>(float*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<float, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 128.0}], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", {"py/object": "numpy.float64", "dtype": "float64", "value": 87.0}], ["volta_sgemm_64x32_sliced1x4_nn", {"py/object": "numpy.float64", "dtype": "float64", "value": 81.0}], ["volta_sgemm_64x32_sliced1x4_tn", {"py/object": "numpy.float64", "dtype": "float64", "value": 73.0}], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 68.0}], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<long, unsigned int, 1, 128, 1>(long*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<long, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 64.0}], ["volta_sgemm_128x32_nt", {"py/object": "numpy.float64", "dtype": "float64", "value": 57.0}], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 33.0}], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 30.0}], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 26.0}], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 15.0}], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", {"py/object": "numpy.float64", "dtype": "float64", "value": 15.0}], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", {"py/object": "numpy.float64", "dtype": "float64", "value": 12.0}], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", {"py/object": "numpy.float64", "dtype": "float64", "value": 6.0}]]}}, "kernel_table": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Total Duration (us)"}, {"type": "number", "name": "Mean Duration (us)"}, {"type": "number", "name": "Max Duration (us)"}, {"type": "number", "name": "Min Duration (us)"}], "rows": [["ncclAllReduceRingLLKernel_sum_f32(ncclColl)", 19, 3434430, 180759, 892991, 17608], ["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", 81, 42585, 526, 1089, 341], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 60, 29369, 489, 821, 384], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", 132, 27826, 211, 799, 46], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", 2518, 25768, 10, 365, 1], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", 317, 24801, 78, 368, 6], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", 100, 17483, 175, 426, 50], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 34, 15932, 469, 851, 362], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 30, 13109, 437, 759, 386], ["volta_sgemm_128x64_nt", 60, 11663, 194, 209, 160], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", 24, 11183, 466, 715, 336], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", 21, 8706, 415, 765, 361], ["volta_sgemm_128x64_nn", 45, 8213, 183, 207, 157], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 9, 8081, 898, 906, 888], ["volta_scudnn_128x64_relu_interior_nn_v1", 24, 7203, 300, 511, 92], ["volta_scudnn_128x64_stridedB_interior_nn_v1", 15, 5038, 336, 542, 264], ["volta_scudnn_128x128_relu_medium_nn_v1", 16, 4459, 279, 294, 272], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 75, 4182, 56, 140, 17], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", 75, 4157, 55, 113, 19], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", 1127, 4146, 4, 29, 1], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", 6, 4079, 680, 688, 672], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 6, 3721, 620, 1006, 230], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", 84, 3548, 42, 87, 14], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", 9, 3393, 377, 384, 368], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", 81, 2879, 36, 162, 9], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 4, 2846, 712, 773, 663], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 6, 2676, 446, 447, 444], ["volta_scudnn_128x128_stridedB_interior_nn_v1", 9, 2662, 296, 303, 291], ["volta_scudnn_128x64_relu_medium_nn_v1", 4, 2549, 637, 639, 635], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 3, 2443, 814, 816, 813], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", 4, 2389, 597, 673, 571], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 3, 2345, 782, 803, 753], ["volta_scudnn_128x64_relu_small_nn_v1", 8, 2255, 282, 292, 270], ["volta_scudnn_128x128_relu_interior_nn_v1", 4, 2215, 554, 557, 551], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", 3, 2082, 694, 695, 693], ["volta_scudnn_128x128_stridedB_medium_nn_v1", 6, 1921, 320, 332, 308], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 3, 1723, 574, 575, 573], ["volta_scudnn_128x128_stridedB_small_nn_v1", 3, 1668, 556, 559, 553], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", 75, 1493, 20, 71, 4], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 30, 1326, 44, 64, 23], ["ncclBroadcastRingLLKernel_copy_i8(ncclColl)", 8, 1277, 160, 247, 72], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", 30, 1268, 42, 64, 21], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", 27, 1223, 45, 76, 22], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", 489, 1215, 2, 161, 0], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", 4, 891, 223, 223, 222], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", 6, 841, 140, 183, 98], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", 30, 786, 26, 70, 9], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", 96, 370, 4, 8, 2], ["volta_scudnn_128x64_stridedB_small_nn_v1", 3, 296, 99, 99, 98], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", 51, 250, 5, 6, 3], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", 51, 241, 5, 6, 3], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", 185, 193, 1, 5, 1], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", 36, 155, 4, 6, 2], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", 3, 128, 43, 43, 42], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<float, unsigned int, 1, 128, 1>(float*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<float, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", 4, 128, 32, 32, 32], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", 3, 87, 29, 29, 29], ["volta_sgemm_64x32_sliced1x4_nn", 3, 81, 27, 27, 27], ["volta_sgemm_64x32_sliced1x4_tn", 3, 73, 24, 25, 24], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", 9, 68, 8, 8, 7], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<long, unsigned int, 1, 128, 1>(long*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<long, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", 4, 64, 16, 16, 16], ["volta_sgemm_128x32_nt", 3, 57, 19, 19, 19], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", 3, 33, 11, 11, 11], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", 3, 30, 10, 10, 10], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", 3, 26, 9, 9, 8], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", 6, 15, 2, 3, 2], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", 3, 15, 5, 5, 5], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", 3, 12, 4, 4, 4], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", 3, 6, 2, 2, 2]]}}, "trace_file_path": "./data/tracing\\resnet50_newAPI_ddp\\worker0_span1.pt.trace.json.gz"}]}, {"py/tuple": ["worker1_span1", {"py/object": "tensorboard_plugin_torch_profiler.run.RunProfile", "worker": "worker1_span1", "views": [{"py/id": 4}, {"py/id": 5}, {"py/id": 6}, {"py/id": 7}], "is_gpu_used": true, "overview": {"steps": {"columns": [{"type": "string", "name": "Step"}, {"type": "number", "name": "Kernel"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memcpy"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memset"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Runtime"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "DataLoader"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "CPU Exec"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Other"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}], "rows": [["5", 267456, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 2155463us<br><b>Kernel: 267456us</b><br>Percentage: 12.41%</div>", 2123, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 2155463us<br><b>Memcpy: 2123us</b><br>Percentage: 0.1%</div>", 1, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 2155463us<br><b>Memset: 1us</b><br>Percentage: 0.0%</div>", 20203, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 2155463us<br><b>Runtime: 20203us</b><br>Percentage: 0.94%</div>", 1586072, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 2155463us<br><b>DataLoader: 1586072us</b><br>Percentage: 73.58%</div>", 253795, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 2155463us<br><b>CPU Exec: 253795us</b><br>Percentage: 11.77%</div>", 25813, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 2155463us<br><b>Other: 25813us</b><br>Percentage: 1.2%</div>"], ["6", 254116, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1907247us<br><b>Kernel: 254116us</b><br>Percentage: 13.32%</div>", 2040, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1907247us<br><b>Memcpy: 2040us</b><br>Percentage: 0.11%</div>", 10, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1907247us<br><b>Memset: 10us</b><br>Percentage: 0.0%</div>", 25632, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1907247us<br><b>Runtime: 25632us</b><br>Percentage: 1.34%</div>", 1310762, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1907247us<br><b>DataLoader: 1310762us</b><br>Percentage: 68.73%</div>", 284181, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1907247us<br><b>CPU Exec: 284181us</b><br>Percentage: 14.9%</div>", 30506, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1907247us<br><b>Other: 30506us</b><br>Percentage: 1.6%</div>"], ["7", 256154, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 1895223us<br><b>Kernel: 256154us</b><br>Percentage: 13.52%</div>", 2073, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 1895223us<br><b>Memcpy: 2073us</b><br>Percentage: 0.11%</div>", 12, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 1895223us<br><b>Memset: 12us</b><br>Percentage: 0.0%</div>", 22340, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 1895223us<br><b>Runtime: 22340us</b><br>Percentage: 1.18%</div>", 1311239, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 1895223us<br><b>DataLoader: 1311239us</b><br>Percentage: 69.19%</div>", 261948, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 1895223us<br><b>CPU Exec: 261948us</b><br>Percentage: 13.82%</div>", 41457, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 1895223us<br><b>Other: 41457us</b><br>Percentage: 2.19%</div>"], ["8", 247972, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1786944us<br><b>Kernel: 247972us</b><br>Percentage: 13.88%</div>", 2048, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1786944us<br><b>Memcpy: 2048us</b><br>Percentage: 0.11%</div>", 1, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1786944us<br><b>Memset: 1us</b><br>Percentage: 0.0%</div>", 20901, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1786944us<br><b>Runtime: 20901us</b><br>Percentage: 1.17%</div>", 1247261, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1786944us<br><b>DataLoader: 1247261us</b><br>Percentage: 69.8%</div>", 243495, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1786944us<br><b>CPU Exec: 243495us</b><br>Percentage: 13.63%</div>", 25266, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1786944us<br><b>Other: 25266us</b><br>Percentage: 1.41%</div>"]]}, "performance": [{"name": "Average Step Time", "description": "", "value": 1936219, "extra": 100, "children": [{"name": "Kernel", "description": "", "value": 256424, "extra": 13.24}, {"name": "Memcpy", "description": "", "value": 2071, "extra": 0.11}, {"name": "Memset", "description": "", "value": 6, "extra": 0.0}, {"name": "Runtime", "description": "", "value": 22269, "extra": 1.15}, {"name": "DataLoader", "description": "", "value": 1363834, "extra": 70.44}, {"name": "CPU Exec", "description": "", "value": 260855, "extra": 13.47}, {"name": "Other", "description": "", "value": 30760, "extra": 1.59}]}], "recommendations": "<ul><li>This run has high time cost on input data loading. 70.4% of the step time is in DataLoader. You could try to set num_workers on DataLoader's construction and enable multi-processes on data loading. Reference: <a href =\"https://pytorch.org/docs/stable/data.html#single-and-multi-process-data-loading\" target=\"_blank\">Single- and Multi-process Data Loading</a></li></ul>"}, "operation_pie_by_name": {"device_total_time": {"title": "Device Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward", 195206], ["CudnnConvolutionBackward", 195206], ["aten::cudnn_convolution_backward_weight", 104474], ["aten::cudnn_convolution_backward_input", 90732], ["aten::cudnn_convolution", 87826], ["aten::_convolution", 87826], ["aten::convolution", 87826], ["aten::conv2d", 87826], ["aten::cudnn_batch_norm_backward", 38851], ["CudnnBatchNormBackward", 38851], ["aten::cudnn_batch_norm", 22223], ["aten::_batch_norm_impl_index", 22223], ["aten::batch_norm", 22223], ["aten::threshold_backward", 18168], ["ReluBackward1", 18168], ["aten::add_", 17488], ["aten::threshold_", 11821], ["aten::relu_", 11821], ["aten::copy_", 7770], ["aten::to", 7134], ["torch::autograd::AccumulateGrad", 3973], ["aten::max_pool2d_with_indices_backward", 3394], ["MaxPool2DWithIndicesBackward", 3394], ["aten::add", 2325], ["aten::fill_", 1619], ["aten::zero_", 1615], ["aten::mul_", 1557], ["aten::max_pool2d_with_indices", 896], ["aten::max_pool2d", 896], ["aten::zeros_like", 637], ["aten::_cat", 192], ["aten::cat", 192], ["aten::mm", 191], ["AddmmBackward", 191], ["aten::mean", 172], ["aten::adaptive_avg_pool2d", 172], ["aten::addmm", 133], ["aten::div", 116], ["MeanBackward1", 116], ["aten::_log_softmax_backward_data", 42], ["LogSoftmaxBackward", 42], ["aten::_log_softmax", 40], ["aten::log_softmax", 40], ["aten::nll_loss_forward", 16], ["aten::nll_loss", 16], ["aten::nll_loss_backward", 12], ["NllLossBackward", 12], ["aten::_local_scalar_dense", 4], ["aten::item", 4], ["aten::ones_like", 4]]}, "device_self_time": {"title": "Device Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward_weight", 104474], ["aten::cudnn_convolution_backward_input", 90732], ["aten::cudnn_convolution", 87826], ["aten::cudnn_batch_norm_backward", 38851], ["aten::cudnn_batch_norm", 22223], ["aten::threshold_backward", 18168], ["aten::add_", 17488], ["aten::threshold_", 11821], ["aten::copy_", 7770], ["aten::max_pool2d_with_indices_backward", 2757], ["aten::add", 2325], ["aten::fill_", 1619], ["aten::mul_", 1557], ["aten::max_pool2d_with_indices", 896], ["aten::_cat", 192], ["aten::mm", 191], ["aten::mean", 172], ["aten::addmm", 133], ["aten::div", 116], ["aten::_log_softmax_backward_data", 42], ["aten::_log_softmax", 40], ["aten::nll_loss_forward", 16], ["aten::nll_loss_backward", 12], ["aten::_local_scalar_dense", 4]]}, "host_total_time": {"title": "Host Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 2026472], ["aten::to", 1001741], ["aten::contiguous", 561311], ["aten::clone", 492156], ["aten::div_", 476251], ["aten::cat", 463896], ["aten::div", 463552], ["aten::_cat", 462387], ["aten::stack", 460236], ["aten::sub_", 386589], ["CudnnConvolutionBackward", 321218], ["aten::cudnn_convolution_backward", 301463], ["aten::empty", 215172], ["aten::batch_norm", 205257], ["aten::add_", 200560], ["aten::_batch_norm_impl_index", 195255], ["aten::conv2d", 185950], ["aten::convolution", 174614], ["aten::_convolution", 165306], ["CudnnBatchNormBackward", 159218], ["aten::cudnn_batch_norm", 158764], ["aten::add", 151319], ["aten::cudnn_convolution", 143066], ["aten::cudnn_convolution_backward_input", 130333], ["aten::cudnn_batch_norm_backward", 127340], ["aten::cudnn_convolution_backward_weight", 127107], ["aten::view", 109645], ["torch::autograd::AccumulateGrad", 97289], ["aten::eq", 87392], ["aten::lt", 85366], ["aten::zero_", 72293], ["aten::item", 68570], ["aten::mul_", 68009], ["aten::narrow", 65279], ["aten::pin_memory", 52613], ["ReluBackward1", 52602], ["aten::slice", 47852], ["aten::exp", 46528], ["aten::threshold_backward", 39079], ["aten::select", 38073], ["aten::_local_scalar_dense", 37815], ["aten::relu_", 37193], ["aten::fill_", 34161], ["aten::any", 31678], ["aten::randint", 29450], ["aten::uniform_", 29025], ["aten::empty_like", 28166], ["aten::resize_", 26704], ["aten::stride", 23199], ["aten::as_strided", 21563], ["aten::log", 21098], ["aten::permute", 18737], ["aten::is_nonzero", 18169], ["aten::empty_strided", 15907], ["aten::rand", 15682], ["aten::set_", 15084], ["aten::threshold_", 12226], ["aten::unsqueeze", 8803], ["aten::random_", 8052], ["aten::is_floating_point", 6972], ["aten::detach_", 5953], ["AddmmBackward", 4874], ["MaxPool2DWithIndicesBackward", 3376], ["aten::max_pool2d_with_indices_backward", 3011], ["aten::max_pool2d", 2837], ["aten::t", 2677], ["aten::max_pool2d_with_indices", 2613], ["aten::addmm", 2565], ["detach_", 2513], ["aten::mm", 2305], ["aten::zeros", 2178], ["MeanBackward1", 2018], ["AddBackward0", 1799], ["LogSoftmaxBackward", 1530], ["aten::log_softmax", 1393], ["aten::_log_softmax_backward_data", 1245], ["aten::adaptive_avg_pool2d", 1231], ["aten::transpose", 1228], ["aten::_log_softmax", 1208], ["NllLossBackward", 1181], ["aten::nll_loss", 1156], ["aten::zeros_like", 1128], ["aten::mean", 1044], ["aten::reshape", 981], ["aten::nll_loss_forward", 940], ["aten::ones_like", 925], ["aten::nll_loss_backward", 788], ["aten::flatten", 758], ["aten::expand", 746], ["TBackward", 621], ["ViewBackward", 593], ["aten::is_pinned", 406], ["nccl:broadcast", 241], ["aten::resize_as_", 212], ["aten::conj", 177]]}, "host_self_time": {"title": "Host Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 2026472], ["aten::div_", 476251], ["aten::_cat", 457630], ["aten::div", 443730], ["aten::sub_", 386589], ["aten::empty", 215172], ["aten::add_", 200560], ["aten::add", 115280], ["aten::cudnn_convolution", 109880], ["aten::view", 109645], ["aten::cudnn_batch_norm", 108643], ["aten::cudnn_convolution_backward_input", 94588], ["aten::cudnn_convolution_backward_weight", 91133], ["aten::cudnn_batch_norm_backward", 85444], ["aten::mul_", 68009], ["aten::contiguous", 58201], ["aten::to", 42719], ["aten::cudnn_convolution_backward", 41084], ["aten::zero_", 40682], ["aten::slice", 39708], ["aten::_local_scalar_dense", 37815], ["aten::fill_", 34161], ["aten::select", 32471], ["aten::item", 30755], ["aten::threshold_backward", 29791], ["aten::eq", 29349], ["aten::uniform_", 29025], ["torch::autograd::AccumulateGrad", 28540], ["CudnnBatchNormBackward", 27992], ["aten::resize_", 26704], ["aten::exp", 26680], ["aten::_batch_norm_impl_index", 26411], ["aten::lt", 26221], ["aten::relu_", 24967], ["aten::any", 23283], ["aten::stride", 23199], ["aten::as_strided", 21563], ["CudnnConvolutionBackward", 19755], ["aten::_convolution", 19588], ["aten::clone", 18601], ["aten::log", 17507], ["aten::narrow", 17427], ["aten::permute", 16740], ["aten::randint", 16393], ["aten::empty_like", 16172], ["aten::empty_strided", 15907], ["aten::set_", 15084], ["ReluBackward1", 13523], ["aten::threshold_", 12226], ["aten::conv2d", 11336], ["aten::batch_norm", 10002], ["aten::convolution", 9308], ["aten::rand", 8414], ["aten::random_", 8052], ["aten::is_floating_point", 6972], ["aten::is_nonzero", 5525], ["aten::unsqueeze", 5432], ["aten::detach_", 3440], ["detach_", 2513], ["aten::stack", 2343], ["aten::max_pool2d_with_indices", 1968], ["aten::addmm", 1940], ["AddBackward0", 1799], ["aten::mm", 1721], ["aten::cat", 1509], ["aten::t", 1449], ["aten::pin_memory", 1301], ["aten::max_pool2d_with_indices_backward", 1300], ["aten::zeros", 1167], ["aten::nll_loss_forward", 940], ["aten::transpose", 891], ["aten::mean", 883], ["aten::_log_softmax", 837], ["AddmmBackward", 794], ["aten::nll_loss_backward", 788], ["aten::_log_softmax_backward_data", 716], ["aten::expand", 589], ["MeanBackward1", 420], ["aten::is_pinned", 406], ["NllLossBackward", 393], ["MaxPool2DWithIndicesBackward", 365], ["LogSoftmaxBackward", 285], ["aten::reshape", 266], ["aten::ones_like", 264], ["nccl:broadcast", 241], ["aten::max_pool2d", 224], ["aten::nll_loss", 216], ["aten::zeros_like", 207], ["aten::flatten", 195], ["aten::adaptive_avg_pool2d", 187], ["aten::log_softmax", 185], ["aten::conj", 177], ["ViewBackward", 175], ["aten::resize_as_", 158], ["TBackward", 153]]}}, "operation_table_by_name": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Device Self Duration (us)"}, {"type": "number", "name": "Device Total Duration (us)"}, {"type": "number", "name": "Host Self Duration (us)"}, {"type": "number", "name": "Host Total Duration (us)"}], "rows": [["aten::cudnn_convolution_backward_weight", 212, 104474, 104474, 91133, 127107], ["aten::cudnn_convolution_backward_input", 208, 90732, 90732, 94588, 130333], ["aten::cudnn_convolution", 212, 87826, 87826, 109880, 143066], ["aten::cudnn_batch_norm_backward", 212, 38851, 38851, 85444, 127340], ["aten::cudnn_batch_norm", 212, 22223, 22223, 108643, 158764], ["aten::threshold_backward", 196, 18168, 18168, 29791, 39079], ["aten::add_", 1996, 17488, 17488, 200560, 200560], ["aten::threshold_", 196, 11821, 11821, 12226, 12226], ["aten::copy_", 1420, 7770, 7770, 2026472, 2026472], ["aten::max_pool2d_with_indices_backward", 4, 2757, 3394, 1300, 3011], ["aten::add", 856, 2325, 2325, 115280, 151319], ["aten::fill_", 796, 1619, 1619, 34161, 34161], ["aten::mul_", 644, 1557, 1557, 68009, 68009], ["aten::max_pool2d_with_indices", 4, 896, 896, 1968, 2613], ["aten::_cat", 12, 192, 192, 457630, 462387], ["aten::mm", 8, 191, 191, 1721, 2305], ["aten::mean", 4, 172, 172, 883, 1044], ["aten::addmm", 4, 133, 133, 1940, 2565], ["aten::div", 132, 116, 116, 443730, 463552], ["aten::_log_softmax_backward_data", 4, 42, 42, 716, 1245], ["aten::_log_softmax", 4, 40, 40, 837, 1208], ["aten::nll_loss_forward", 4, 16, 16, 940, 940], ["aten::nll_loss_backward", 4, 12, 12, 788, 788], ["aten::_local_scalar_dense", 1524, 4, 4, 37815, 37815], ["aten::empty", 6668, 0, 0, 215172, 215172], ["aten::zero_", 664, 0, 1615, 40682, 72293], ["aten::zeros", 16, 0, 0, 1167, 2178], ["aten::uniform_", 504, 0, 0, 29025, 29025], ["aten::is_floating_point", 636, 0, 0, 6972, 6972], ["aten::item", 1524, 0, 4, 30755, 68570], ["aten::to", 976, 0, 7134, 42719, 1001741], ["detach_", 192, 0, 0, 2513, 2513], ["aten::detach_", 192, 0, 0, 3440, 5953], ["aten::log", 188, 0, 0, 17507, 21098], ["aten::as_strided", 1428, 0, 0, 21563, 21563], ["aten::select", 376, 0, 0, 32471, 38073], ["aten::resize_", 1864, 0, 0, 26704, 26704], ["aten::exp", 376, 0, 0, 26680, 46528], ["aten::random_", 256, 0, 0, 8052, 8052], ["aten::randint", 256, 0, 0, 16393, 29450], ["aten::rand", 128, 0, 0, 8414, 15682], ["aten::empty_strided", 652, 0, 0, 15907, 15907], ["aten::lt", 256, 0, 0, 26221, 85366], ["aten::is_nonzero", 256, 0, 0, 5525, 18169], ["aten::set_", 136, 0, 0, 15084, 15084], ["aten::view", 2088, 0, 0, 109645, 109645], ["aten::permute", 128, 0, 0, 16740, 18737], ["aten::empty_like", 356, 0, 0, 16172, 28166], ["aten::contiguous", 3960, 0, 0, 58201, 561311], ["aten::clone", 128, 0, 0, 18601, 492156], ["aten::eq", 256, 0, 0, 29349, 87392], ["aten::any", 128, 0, 0, 23283, 31678], ["aten::sub_", 128, 0, 0, 386589, 386589], ["aten::div_", 128, 0, 0, 476251, 476251], ["aten::unsqueeze", 128, 0, 0, 5432, 8803], ["aten::slice", 640, 0, 0, 39708, 47852], ["aten::narrow", 640, 0, 0, 17427, 65279], ["aten::stride", 3264, 0, 0, 23199, 23199], ["aten::cat", 12, 0, 192, 1509, 463896], ["aten::stack", 4, 0, 0, 2343, 460236], ["aten::is_pinned", 8, 0, 0, 406, 406], ["aten::pin_memory", 8, 0, 0, 1301, 52613], ["nccl:broadcast", 8, 0, 0, 241, 241], ["aten::_convolution", 212, 0, 87826, 19588, 165306], ["aten::convolution", 212, 0, 87826, 9308, 174614], ["aten::conv2d", 212, 0, 87826, 11336, 185950], ["aten::_batch_norm_impl_index", 212, 0, 22223, 26411, 195255], ["aten::batch_norm", 212, 0, 22223, 10002, 205257], ["aten::relu_", 196, 0, 11821, 24967, 37193], ["aten::max_pool2d", 4, 0, 896, 224, 2837], ["aten::adaptive_avg_pool2d", 4, 0, 172, 187, 1231], ["aten::reshape", 8, 0, 0, 266, 981], ["aten::flatten", 4, 0, 0, 195, 758], ["aten::transpose", 20, 0, 0, 891, 1228], ["aten::t", 20, 0, 0, 1449, 2677], ["aten::expand", 8, 0, 0, 589, 746], ["aten::log_softmax", 4, 0, 40, 185, 1393], ["aten::nll_loss", 4, 0, 16, 216, 1156], ["aten::ones_like", 4, 0, 4, 264, 925], ["NllLossBackward", 4, 0, 12, 393, 1181], ["LogSoftmaxBackward", 4, 0, 42, 285, 1530], ["aten::conj", 8, 0, 0, 177, 177], ["AddmmBackward", 4, 0, 191, 794, 4874], ["torch::autograd::AccumulateGrad", 644, 0, 3973, 28540, 97289], ["TBackward", 4, 0, 0, 153, 621], ["ViewBackward", 4, 0, 0, 175, 593], ["MeanBackward1", 4, 0, 116, 420, 2018], ["ReluBackward1", 196, 0, 18168, 13523, 52602], ["AddBackward0", 64, 0, 0, 1799, 1799], ["CudnnBatchNormBackward", 212, 0, 38851, 27992, 159218], ["aten::cudnn_convolution_backward", 212, 0, 195206, 41084, 301463], ["CudnnConvolutionBackward", 212, 0, 195206, 19755, 321218], ["aten::zeros_like", 4, 0, 637, 207, 1128], ["aten::resize_as_", 4, 0, 0, 158, 212], ["MaxPool2DWithIndicesBackward", 4, 0, 3394, 365, 3376]]}}, "operation_pie_by_name_input": {"device_total_time": {"title": "Device Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["CudnnConvolutionBackward", 34769], ["CudnnConvolutionBackward", 25503], ["CudnnConvolutionBackward", 24483], ["CudnnConvolutionBackward", 23389], ["CudnnConvolutionBackward", 18877], ["CudnnConvolutionBackward", 17970], ["aten::cudnn_convolution_backward", 17023], ["CudnnConvolutionBackward", 16681], ["aten::cudnn_convolution_backward", 16331], ["aten::cudnn_convolution_backward", 15411], ["aten::cudnn_convolution_backward", 12468], ["CudnnConvolutionBackward", 12468], ["aten::cudnn_convolution_backward", 12405], ["aten::cudnn_convolution_backward", 12144], ["aten::cudnn_convolution_backward_weight", 11748], ["aten::cudnn_batch_norm_backward", 10250], ["CudnnBatchNormBackward", 10250], ["aten::cudnn_convolution_backward", 10027], ["aten::cudnn_convolution_backward_input", 9710], ["aten::cudnn_convolution", 9411], ["aten::_convolution", 9411], ["aten::convolution", 9411], ["aten::conv2d", 9411], ["aten::cudnn_convolution_backward_weight", 9408], ["aten::cudnn_convolution_backward", 8749], ["aten::cudnn_convolution_backward", 8616], ["aten::cudnn_convolution_backward_input", 8545], ["aten::cudnn_convolution_backward_input", 8383], ["aten::cudnn_convolution_backward", 8317], ["aten::cudnn_convolution", 7886], ["aten::_convolution", 7886], ["aten::convolution", 7886], ["aten::conv2d", 7886], ["aten::cudnn_convolution_backward_weight", 7802], ["aten::cudnn_convolution_backward_weight", 7786], ["aten::cudnn_convolution_backward_input", 7615], ["aten::cudnn_convolution_backward", 7550], ["aten::copy_", 7122], ["aten::to", 7122], ["aten::cudnn_batch_norm_backward", 6656], ["CudnnBatchNormBackward", 6656], ["aten::cudnn_convolution_backward", 6654], ["aten::cudnn_convolution_backward", 6543], ["aten::cudnn_convolution_backward_weight", 6486], ["aten::cudnn_convolution_backward", 6472], ["aten::cudnn_convolution_backward", 6470], ["aten::cudnn_convolution_backward", 6366], ["aten::cudnn_batch_norm", 6356], ["aten::_batch_norm_impl_index", 6356], ["aten::batch_norm", 6356], ["aten::cudnn_convolution_backward", 6294], ["aten::cudnn_convolution_backward_input", 6257], ["aten::cudnn_convolution_backward_weight", 6092], ["aten::cudnn_convolution_backward_weight", 6068], ["aten::cudnn_convolution_backward_input", 5919], ["aten::cudnn_convolution_backward", 5860], ["CudnnConvolutionBackward", 5860], ["aten::cudnn_convolution_backward_input", 5762], ["aten::cudnn_convolution", 5720], ["aten::_convolution", 5720], ["aten::convolution", 5720], ["aten::conv2d", 5720], ["aten::cudnn_convolution_backward", 5695], ["CudnnConvolutionBackward", 5695], ["aten::cudnn_convolution_backward", 5521], ["CudnnConvolutionBackward", 5521], ["aten::cudnn_batch_norm_backward", 5040], ["CudnnBatchNormBackward", 5040], ["aten::cudnn_batch_norm_backward", 5036], ["CudnnBatchNormBackward", 5036], ["aten::cudnn_convolution", 5020], ["aten::_convolution", 5020], ["aten::convolution", 5020], ["aten::conv2d", 5020], ["aten::cudnn_convolution_backward", 4957], ["aten::cudnn_convolution_backward_weight", 4905], ["aten::cudnn_convolution", 4806], ["aten::_convolution", 4806], ["aten::convolution", 4806], ["aten::conv2d", 4806], ["aten::cudnn_convolution_backward_input", 4666], ["aten::cudnn_convolution_backward_weight", 4618], ["aten::cudnn_convolution", 4605], ["aten::_convolution", 4605], ["aten::convolution", 4605], ["aten::conv2d", 4605], ["aten::cudnn_convolution_backward_input", 4584], ["aten::cudnn_convolution", 4451], ["aten::_convolution", 4451], ["aten::convolution", 4451], ["aten::conv2d", 4451], ["aten::cudnn_convolution", 4444], ["aten::_convolution", 4444], ["aten::convolution", 4444], ["aten::conv2d", 4444], ["aten::threshold_backward", 4388], ["ReluBackward1", 4388], ["aten::add_", 4359], ["aten::cudnn_convolution_backward_weight", 4265], ["aten::cudnn_batch_norm", 4119], ["aten::_batch_norm_impl_index", 4119], ["aten::batch_norm", 4119], ["aten::cudnn_convolution_backward_weight", 3990], ["aten::cudnn_convolution_backward", 3990], ["CudnnConvolutionBackward", 3990], ["aten::cudnn_convolution_backward_input", 3745], ["aten::cudnn_convolution_backward_input", 3711], ["aten::cudnn_convolution_backward_input", 3656], ["aten::cudnn_convolution", 3655], ["aten::_convolution", 3655], ["aten::convolution", 3655], ["aten::conv2d", 3655], ["aten::cudnn_convolution_backward_input", 3585], ["aten::cudnn_convolution", 3570], ["aten::_convolution", 3570], ["aten::convolution", 3570], ["aten::conv2d", 3570], ["aten::cudnn_convolution", 3475], ["aten::_convolution", 3475], ["aten::convolution", 3475], ["aten::conv2d", 3475], ["aten::cudnn_convolution", 3407], ["aten::_convolution", 3407], ["aten::convolution", 3407], ["aten::conv2d", 3407], ["aten::max_pool2d_with_indices_backward", 3394], ["MaxPool2DWithIndicesBackward", 3394], ["aten::cudnn_convolution_backward_input", 3335], ["aten::cudnn_convolution_backward_weight", 3262], ["aten::cudnn_convolution", 3250], ["aten::_convolution", 3250], ["aten::convolution", 3250], ["aten::conv2d", 3250], ["aten::cudnn_batch_norm_backward", 3220], ["CudnnBatchNormBackward", 3220], ["aten::cudnn_convolution_backward_weight", 3137], ["aten::cudnn_convolution", 3108], ["aten::_convolution", 3108], ["aten::convolution", 3108], ["aten::conv2d", 3108], ["aten::cudnn_convolution", 3072], ["aten::_convolution", 3072], ["aten::convolution", 3072], ["aten::conv2d", 3072], ["aten::cudnn_convolution", 3051], ["aten::_convolution", 3051], ["aten::convolution", 3051], ["aten::conv2d", 3051], ["aten::cudnn_convolution_backward_input", 3021], ["aten::threshold_", 2995], ["aten::relu_", 2995], ["aten::threshold_backward", 2973], ["ReluBackward1", 2973], ["aten::cudnn_convolution_backward_weight", 2960], ["aten::add_", 2922], ["aten::cudnn_convolution_backward_weight", 2909], ["aten::cudnn_convolution_backward_input", 2900], ["aten::cudnn_convolution_backward_weight", 2887], ["aten::cudnn_convolution_backward_weight", 2866], ["aten::cudnn_convolution_backward_weight", 2781], ["aten::cudnn_convolution", 2752], ["aten::_convolution", 2752], ["aten::convolution", 2752], ["aten::conv2d", 2752], ["aten::cudnn_convolution_backward_weight", 2749], ["aten::cudnn_convolution_backward_weight", 2674], ["aten::cudnn_convolution_backward_weight", 2660], ["aten::cudnn_batch_norm", 2658], ["aten::_batch_norm_impl_index", 2658], ["aten::batch_norm", 2658], ["aten::cudnn_convolution_backward_input", 2657], ["aten::cudnn_convolution", 2571], ["aten::_convolution", 2571], ["aten::convolution", 2571], ["aten::conv2d", 2571], ["aten::cudnn_batch_norm_backward", 2565], ["CudnnBatchNormBackward", 2565], ["aten::cudnn_convolution", 2469], ["aten::_convolution", 2469], ["aten::convolution", 2469], ["aten::conv2d", 2469], ["aten::cudnn_convolution_backward_weight", 2421], ["aten::cudnn_convolution", 2398], ["aten::_convolution", 2398], ["aten::convolution", 2398], ["aten::conv2d", 2398], ["aten::cudnn_batch_norm", 2371], ["aten::_batch_norm_impl_index", 2371], ["aten::batch_norm", 2371], ["aten::threshold_backward", 2299], ["ReluBackward1", 2299], ["aten::cudnn_convolution_backward_input", 2259], ["aten::cudnn_convolution", 2244], ["aten::_convolution", 2244], ["aten::convolution", 2244], ["aten::conv2d", 2244], ["aten::add_", 2210], ["aten::threshold_backward", 2207], ["ReluBackward1", 2207], ["aten::cudnn_batch_norm_backward", 2086], ["CudnnBatchNormBackward", 2086], ["aten::cudnn_convolution", 2079], ["aten::_convolution", 2079], ["aten::convolution", 2079], ["aten::conv2d", 2079], ["aten::threshold_", 2004], ["aten::relu_", 2004], ["aten::cudnn_batch_norm", 1707], ["aten::_batch_norm_impl_index", 1707], ["aten::batch_norm", 1707], ["aten::threshold_", 1515], ["aten::relu_", 1515], ["aten::threshold_", 1513], ["aten::relu_", 1513], ["aten::threshold_backward", 1459], ["ReluBackward1", 1459], ["aten::cudnn_batch_norm", 1426], ["aten::_batch_norm_impl_index", 1426], ["aten::batch_norm", 1426], ["aten::cudnn_batch_norm_backward", 1389], ["CudnnBatchNormBackward", 1389], ["aten::threshold_backward", 1382], ["ReluBackward1", 1382], ["aten::cudnn_convolution_backward", 1343], ["aten::add_", 1282], ["aten::threshold_backward", 1207], ["ReluBackward1", 1207], ["aten::cudnn_batch_norm_backward", 1140], ["CudnnBatchNormBackward", 1140], ["aten::threshold_", 999], ["aten::relu_", 999], ["aten::cudnn_batch_norm", 995], ["aten::_batch_norm_impl_index", 995], ["aten::batch_norm", 995], ["aten::cudnn_batch_norm", 902], ["aten::_batch_norm_impl_index", 902], ["aten::batch_norm", 902], ["aten::threshold_", 897], ["aten::relu_", 897], ["aten::max_pool2d_with_indices", 896], ["aten::max_pool2d", 896], ["aten::add_", 808], ["aten::cudnn_batch_norm", 796], ["aten::_batch_norm_impl_index", 796], ["aten::batch_norm", 796], ["aten::threshold_backward", 741], ["ReluBackward1", 741], ["aten::cudnn_batch_norm_backward", 662], ["CudnnBatchNormBackward", 662], ["aten::fill_", 637], ["aten::zero_", 637], ["aten::zeros_like", 637], ["aten::threshold_backward", 606], ["ReluBackward1", 606], ["aten::add_", 553], ["aten::add_", 553], ["torch::autograd::AccumulateGrad", 552], ["aten::threshold_", 517], ["aten::relu_", 517], ["aten::threshold_", 502], ["aten::relu_", 502], ["aten::add_", 495], ["aten::add_", 489], ["aten::cudnn_batch_norm_backward", 444], ["CudnnBatchNormBackward", 444], ["torch::autograd::AccumulateGrad", 440], ["aten::add_", 428], ["aten::cudnn_convolution_backward_input", 422], ["aten::add", 421], ["aten::cudnn_batch_norm", 412], ["aten::_batch_norm_impl_index", 412], ["aten::batch_norm", 412], ["aten::add_", 389], ["aten::threshold_", 385], ["aten::relu_", 385], ["aten::cudnn_convolution", 382], ["aten::_convolution", 382], ["aten::convolution", 382], ["aten::conv2d", 382], ["aten::threshold_backward", 382], ["ReluBackward1", 382], ["torch::autograd::AccumulateGrad", 377], ["aten::add_", 368], ["aten::add_", 367], ["aten::cudnn_batch_norm_backward", 363], ["CudnnBatchNormBackward", 363], ["aten::add_", 361], ["aten::threshold_backward", 320], ["ReluBackward1", 320], ["aten::cudnn_batch_norm", 300], ["aten::_batch_norm_impl_index", 300], ["aten::batch_norm", 300], ["torch::autograd::AccumulateGrad", 300], ["aten::add_", 296], ["aten::mul_", 287], ["aten::add_", 265], ["aten::add_", 259], ["torch::autograd::AccumulateGrad", 255], ["aten::threshold_", 252], ["aten::relu_", 252], ["aten::add", 242], ["torch::autograd::AccumulateGrad", 231], ["aten::add", 217], ["aten::copy_", 212], ["aten::threshold_backward", 204], ["ReluBackward1", 204], ["aten::add_", 203], ["aten::_cat", 192], ["aten::cat", 192], ["aten::add", 192], ["torch::autograd::AccumulateGrad", 192], ["AddmmBackward", 191], ["torch::autograd::AccumulateGrad", 184], ["aten::cudnn_batch_norm", 181], ["aten::_batch_norm_impl_index", 181], ["aten::batch_norm", 181], ["aten::fill_", 180], ["aten::zero_", 180], ["aten::mean", 172], ["aten::adaptive_avg_pool2d", 172], ["torch::autograd::AccumulateGrad", 169], ["torch::autograd::AccumulateGrad", 163], ["torch::autograd::AccumulateGrad", 157], ["aten::add_", 156], ["aten::mul_", 145], ["torch::autograd::AccumulateGrad", 139], ["torch::autograd::AccumulateGrad", 139], ["aten::addmm", 133], ["aten::mul_", 133], ["aten::copy_", 128], ["aten::add", 128], ["aten::mul_", 128], ["aten::add", 128], ["aten::add", 124], ["torch::autograd::AccumulateGrad", 124], ["aten::threshold_", 122], ["aten::relu_", 122], ["aten::add", 122], ["aten::threshold_", 120], ["aten::relu_", 120], ["aten::add", 119], ["aten::add_", 117], ["aten::div", 116], ["MeanBackward1", 116], ["aten::mm", 115], ["aten::fill_", 96], ["aten::zero_", 96], ["aten::add_", 93], ["aten::add_", 92], ["torch::autograd::AccumulateGrad", 92], ["aten::copy_", 88], ["aten::add", 88], ["aten::mul_", 88], ["aten::add", 88], ["aten::mul_", 87], ["aten::add_", 85], ["aten::mul_", 85], ["torch::autograd::AccumulateGrad", 85], ["aten::fill_", 84], ["aten::zero_", 84], ["aten::mul_", 84], ["aten::mm", 76], ["aten::mul_", 75], ["aten::add_", 74], ["aten::add_", 71], ["aten::copy_", 64], ["aten::add", 64], ["aten::mul_", 64], ["aten::mul_", 61], ["torch::autograd::AccumulateGrad", 61], ["torch::autograd::AccumulateGrad", 60], ["torch::autograd::AccumulateGrad", 57], ["aten::copy_", 56], ["aten::copy_", 56], ["aten::fill_", 56], ["aten::zero_", 56], ["aten::add", 56], ["aten::mul_", 56], ["aten::add", 56], ["aten::mul_", 56], ["aten::fill_", 54], ["aten::zero_", 54], ["aten::fill_", 52], ["aten::zero_", 52], ["aten::fill_", 52], ["aten::zero_", 52], ["aten::fill_", 51], ["aten::zero_", 51], ["aten::fill_", 48], ["aten::zero_", 48], ["torch::autograd::AccumulateGrad", 47], ["aten::fill_", 46], ["aten::zero_", 46], ["aten::add_", 46], ["aten::fill_", 44], ["aten::zero_", 44], ["aten::add", 44], ["aten::_log_softmax_backward_data", 42], ["LogSoftmaxBackward", 42], ["aten::_log_softmax", 40], ["aten::log_softmax", 40], ["aten::fill_", 40], ["aten::zero_", 40], ["aten::add_", 39], ["aten::add", 36], ["torch::autograd::AccumulateGrad", 36], ["aten::add_", 35], ["aten::add", 35], ["aten::mul_", 34], ["aten::add", 33], ["aten::copy_", 32], ["aten::add", 32], ["aten::mul_", 32], ["torch::autograd::AccumulateGrad", 30], ["aten::fill_", 27], ["aten::zero_", 27], ["aten::add", 24], ["aten::mul_", 24], ["torch::autograd::AccumulateGrad", 23], ["aten::add_", 21], ["aten::mul_", 21], ["aten::add_", 20], ["aten::add_", 20], ["torch::autograd::AccumulateGrad", 19], ["aten::nll_loss_forward", 16], ["aten::nll_loss", 16], ["aten::fill_", 16], ["aten::zero_", 16], ["aten::fill_", 16], ["aten::zero_", 16], ["aten::fill_", 16], ["aten::zero_", 16], ["aten::fill_", 16], ["aten::zero_", 16], ["aten::fill_", 16], ["aten::zero_", 16], ["aten::add", 16], ["aten::mul_", 16], ["aten::mul_", 16], ["aten::fill_", 15], ["aten::zero_", 15], ["torch::autograd::AccumulateGrad", 13], ["aten::copy_", 12], ["aten::to", 12], ["aten::fill_", 12], ["aten::zero_", 12], ["aten::fill_", 12], ["aten::zero_", 12], ["aten::add", 12], ["aten::mul_", 12], ["aten::add", 12], ["aten::mul_", 12], ["aten::add", 12], ["aten::add_", 12], ["aten::nll_loss_backward", 12], ["NllLossBackward", 12], ["torch::autograd::AccumulateGrad", 12], ["torch::autograd::AccumulateGrad", 12], ["aten::mul_", 9], ["aten::fill_", 8], ["aten::zero_", 8], ["aten::add", 8], ["aten::mul_", 8], ["aten::mul_", 8], ["aten::_local_scalar_dense", 4], ["aten::item", 4], ["aten::fill_", 4], ["aten::zero_", 4], ["aten::fill_", 4], ["aten::zero_", 4], ["aten::fill_", 4], ["aten::zero_", 4], ["aten::fill_", 4], ["aten::zero_", 4], ["aten::fill_", 4], ["aten::zero_", 4], ["aten::fill_", 4], ["aten::ones_like", 4], ["aten::add", 4], ["aten::mul_", 4], ["aten::add", 4], ["aten::mul_", 4], ["aten::add", 4], ["aten::mul_", 4], ["aten::add", 4], ["aten::mul_", 4], ["torch::autograd::AccumulateGrad", 4], ["aten::fill_", 1], ["aten::zero_", 1]]}, "device_self_time": {"title": "Device Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward_weight", 11748], ["aten::cudnn_batch_norm_backward", 10250], ["aten::cudnn_convolution_backward_input", 9710], ["aten::cudnn_convolution", 9411], ["aten::cudnn_convolution_backward_weight", 9408], ["aten::cudnn_convolution_backward_input", 8545], ["aten::cudnn_convolution_backward_input", 8383], ["aten::cudnn_convolution", 7886], ["aten::cudnn_convolution_backward_weight", 7802], ["aten::cudnn_convolution_backward_weight", 7786], ["aten::cudnn_convolution_backward_input", 7615], ["aten::copy_", 7122], ["aten::cudnn_batch_norm_backward", 6656], ["aten::cudnn_convolution_backward_weight", 6486], ["aten::cudnn_batch_norm", 6356], ["aten::cudnn_convolution_backward_input", 6257], ["aten::cudnn_convolution_backward_weight", 6092], ["aten::cudnn_convolution_backward_weight", 6068], ["aten::cudnn_convolution_backward_input", 5919], ["aten::cudnn_convolution_backward_input", 5762], ["aten::cudnn_convolution", 5720], ["aten::cudnn_batch_norm_backward", 5040], ["aten::cudnn_batch_norm_backward", 5036], ["aten::cudnn_convolution", 5020], ["aten::cudnn_convolution_backward_weight", 4905], ["aten::cudnn_convolution", 4806], ["aten::cudnn_convolution_backward_input", 4666], ["aten::cudnn_convolution_backward_weight", 4618], ["aten::cudnn_convolution", 4605], ["aten::cudnn_convolution_backward_input", 4584], ["aten::cudnn_convolution", 4451], ["aten::cudnn_convolution", 4444], ["aten::threshold_backward", 4388], ["aten::add_", 4359], ["aten::cudnn_convolution_backward_weight", 4265], ["aten::cudnn_batch_norm", 4119], ["aten::cudnn_convolution_backward_weight", 3990], ["aten::cudnn_convolution_backward_input", 3745], ["aten::cudnn_convolution_backward_input", 3711], ["aten::cudnn_convolution_backward_input", 3656], ["aten::cudnn_convolution", 3655], ["aten::cudnn_convolution_backward_input", 3585], ["aten::cudnn_convolution", 3570], ["aten::cudnn_convolution", 3475], ["aten::cudnn_convolution", 3407], ["aten::cudnn_convolution_backward_input", 3335], ["aten::cudnn_convolution_backward_weight", 3262], ["aten::cudnn_convolution", 3250], ["aten::cudnn_batch_norm_backward", 3220], ["aten::cudnn_convolution_backward_weight", 3137], ["aten::cudnn_convolution", 3108], ["aten::cudnn_convolution", 3072], ["aten::cudnn_convolution", 3051], ["aten::cudnn_convolution_backward_input", 3021], ["aten::threshold_", 2995], ["aten::threshold_backward", 2973], ["aten::cudnn_convolution_backward_weight", 2960], ["aten::add_", 2922], ["aten::cudnn_convolution_backward_weight", 2909], ["aten::cudnn_convolution_backward_input", 2900], ["aten::cudnn_convolution_backward_weight", 2887], ["aten::cudnn_convolution_backward_weight", 2866], ["aten::cudnn_convolution_backward_weight", 2781], ["aten::max_pool2d_with_indices_backward", 2757], ["aten::cudnn_convolution", 2752], ["aten::cudnn_convolution_backward_weight", 2749], ["aten::cudnn_convolution_backward_weight", 2674], ["aten::cudnn_convolution_backward_weight", 2660], ["aten::cudnn_batch_norm", 2658], ["aten::cudnn_convolution_backward_input", 2657], ["aten::cudnn_convolution", 2571], ["aten::cudnn_batch_norm_backward", 2565], ["aten::cudnn_convolution", 2469], ["aten::cudnn_convolution_backward_weight", 2421], ["aten::cudnn_convolution", 2398], ["aten::cudnn_batch_norm", 2371], ["aten::threshold_backward", 2299], ["aten::cudnn_convolution_backward_input", 2259], ["aten::cudnn_convolution", 2244], ["aten::add_", 2210], ["aten::threshold_backward", 2207], ["aten::cudnn_batch_norm_backward", 2086], ["aten::cudnn_convolution", 2079], ["aten::threshold_", 2004], ["aten::cudnn_batch_norm", 1707], ["aten::threshold_", 1515], ["aten::threshold_", 1513], ["aten::threshold_backward", 1459], ["aten::cudnn_batch_norm", 1426], ["aten::cudnn_batch_norm_backward", 1389], ["aten::threshold_backward", 1382], ["aten::add_", 1282], ["aten::threshold_backward", 1207], ["aten::cudnn_batch_norm_backward", 1140], ["aten::threshold_", 999], ["aten::cudnn_batch_norm", 995], ["aten::cudnn_batch_norm", 902], ["aten::threshold_", 897], ["aten::max_pool2d_with_indices", 896], ["aten::add_", 808], ["aten::cudnn_batch_norm", 796], ["aten::threshold_backward", 741], ["aten::cudnn_batch_norm_backward", 662], ["aten::fill_", 637], ["aten::threshold_backward", 606], ["aten::add_", 553], ["aten::add_", 553], ["aten::threshold_", 517], ["aten::threshold_", 502], ["aten::add_", 495], ["aten::add_", 489], ["aten::cudnn_batch_norm_backward", 444], ["aten::add_", 428], ["aten::cudnn_convolution_backward_input", 422], ["aten::add", 421], ["aten::cudnn_batch_norm", 412], ["aten::add_", 389], ["aten::threshold_", 385], ["aten::cudnn_convolution", 382], ["aten::threshold_backward", 382], ["aten::add_", 368], ["aten::add_", 367], ["aten::cudnn_batch_norm_backward", 363], ["aten::add_", 361], ["aten::threshold_backward", 320], ["aten::cudnn_batch_norm", 300], ["aten::add_", 296], ["aten::mul_", 287], ["aten::add_", 265], ["aten::add_", 259], ["aten::threshold_", 252], ["aten::add", 242], ["aten::add", 217], ["aten::copy_", 212], ["aten::threshold_backward", 204], ["aten::add_", 203], ["aten::_cat", 192], ["aten::add", 192], ["aten::cudnn_batch_norm", 181], ["aten::fill_", 180], ["aten::mean", 172], ["aten::add_", 156], ["aten::mul_", 145], ["aten::addmm", 133], ["aten::mul_", 133], ["aten::copy_", 128], ["aten::add", 128], ["aten::mul_", 128], ["aten::add", 128], ["aten::add", 124], ["aten::threshold_", 122], ["aten::add", 122], ["aten::threshold_", 120], ["aten::add", 119], ["aten::add_", 117], ["aten::div", 116], ["aten::mm", 115], ["aten::fill_", 96], ["aten::add_", 93], ["aten::add_", 92], ["aten::copy_", 88], ["aten::add", 88], ["aten::mul_", 88], ["aten::add", 88], ["aten::mul_", 87], ["aten::add_", 85], ["aten::mul_", 85], ["aten::fill_", 84], ["aten::mul_", 84], ["aten::mm", 76], ["aten::mul_", 75], ["aten::add_", 74], ["aten::add_", 71], ["aten::copy_", 64], ["aten::add", 64], ["aten::mul_", 64], ["aten::mul_", 61], ["aten::copy_", 56], ["aten::copy_", 56], ["aten::fill_", 56], ["aten::add", 56], ["aten::mul_", 56], ["aten::add", 56], ["aten::mul_", 56], ["aten::fill_", 54], ["aten::fill_", 52], ["aten::fill_", 52], ["aten::fill_", 51], ["aten::fill_", 48], ["aten::fill_", 46], ["aten::add_", 46], ["aten::fill_", 44], ["aten::add", 44], ["aten::_log_softmax_backward_data", 42], ["aten::_log_softmax", 40], ["aten::fill_", 40], ["aten::add_", 39], ["aten::add", 36], ["aten::add_", 35], ["aten::add", 35], ["aten::mul_", 34], ["aten::add", 33], ["aten::copy_", 32], ["aten::add", 32], ["aten::mul_", 32], ["aten::fill_", 27], ["aten::add", 24], ["aten::mul_", 24], ["aten::add_", 21], ["aten::mul_", 21], ["aten::add_", 20], ["aten::add_", 20], ["aten::nll_loss_forward", 16], ["aten::fill_", 16], ["aten::fill_", 16], ["aten::fill_", 16], ["aten::fill_", 16], ["aten::fill_", 16], ["aten::add", 16], ["aten::mul_", 16], ["aten::mul_", 16], ["aten::fill_", 15], ["aten::copy_", 12], ["aten::fill_", 12], ["aten::fill_", 12], ["aten::add", 12], ["aten::mul_", 12], ["aten::add", 12], ["aten::mul_", 12], ["aten::add", 12], ["aten::add_", 12], ["aten::nll_loss_backward", 12], ["aten::mul_", 9], ["aten::fill_", 8], ["aten::add", 8], ["aten::mul_", 8], ["aten::mul_", 8], ["aten::_local_scalar_dense", 4], ["aten::fill_", 4], ["aten::fill_", 4], ["aten::fill_", 4], ["aten::fill_", 4], ["aten::fill_", 4], ["aten::fill_", 4], ["aten::add", 4], ["aten::mul_", 4], ["aten::add", 4], ["aten::mul_", 4], ["aten::add", 4], ["aten::mul_", 4], ["aten::add", 4], ["aten::mul_", 4], ["aten::fill_", 1]]}, "host_total_time": {"title": "Host Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 1896653], ["aten::to", 944044], ["aten::contiguous", 511262], ["aten::clone", 492156], ["aten::div_", 476251], ["aten::cat", 463896], ["aten::div", 462502], ["aten::_cat", 462387], ["aten::stack", 460236], ["aten::sub_", 386589], ["aten::empty", 215172], ["CudnnConvolutionBackward", 68808], ["aten::eq", 52817], ["aten::pin_memory", 51166], ["aten::copy_", 50472], ["aten::lt", 50465], ["aten::to", 48595], ["CudnnConvolutionBackward", 47580], ["aten::narrow", 42281], ["CudnnConvolutionBackward", 41979], ["aten::batch_norm", 41294], ["aten::_batch_norm_impl_index", 39223], ["aten::add_", 39041], ["aten::add", 38471], ["aten::cudnn_convolution_backward", 38428], ["aten::select", 38073], ["aten::item", 36979], ["CudnnConvolutionBackward", 35570], ["aten::copy_", 35301], ["aten::lt", 34901], ["CudnnBatchNormBackward", 34678], ["aten::eq", 34575], ["aten::exp", 33186], ["aten::cudnn_batch_norm", 31828], ["aten::any", 31678], ["aten::item", 31591], ["aten::slice", 31348], ["CudnnConvolutionBackward", 31227], ["aten::cudnn_convolution_backward", 29734], ["aten::randint", 29450], ["aten::cudnn_convolution_backward", 29274], ["aten::uniform_", 29025], ["aten::batch_norm", 28998], ["aten::_batch_norm_impl_index", 27686], ["aten::cudnn_batch_norm_backward", 27672], ["CudnnConvolutionBackward", 27210], ["aten::add_", 25929], ["aten::batch_norm", 25925], ["aten::_batch_norm_impl_index", 24622], ["CudnnConvolutionBackward", 24301], ["aten::batch_norm", 23849], ["CudnnConvolutionBackward", 22994], ["aten::cudnn_batch_norm", 22928], ["aten::_batch_norm_impl_index", 22723], ["aten::narrow", 22701], ["aten::add", 22465], ["aten::_local_scalar_dense", 22108], ["CudnnBatchNormBackward", 21723], ["aten::cudnn_convolution_backward", 21525], ["aten::log", 21098], ["torch::autograd::AccumulateGrad", 20970], ["aten::cudnn_convolution_backward", 20429], ["aten::cudnn_batch_norm", 19812], ["CudnnBatchNormBackward", 19729], ["aten::conv2d", 19129], ["aten::cudnn_convolution_backward_input", 19044], ["aten::permute", 18737], ["aten::batch_norm", 18708], ["aten::batch_norm", 18611], ["aten::add_", 18469], ["aten::cudnn_batch_norm", 18226], ["aten::convolution", 17944], ["aten::view", 17814], ["aten::_batch_norm_impl_index", 17764], ["aten::_batch_norm_impl_index", 17688], ["aten::cudnn_convolution_backward", 17663], ["CudnnBatchNormBackward", 17635], ["aten::conv2d", 17528], ["aten::cudnn_batch_norm_backward", 17235], ["aten::batch_norm", 17204], ["aten::_convolution", 16957], ["aten::cudnn_convolution_backward", 16907], ["aten::view", 16875], ["aten::add_", 16635], ["aten::add_", 16596], ["aten::cudnn_convolution_backward", 16557], ["aten::convolution", 16451], ["aten::_batch_norm_impl_index", 16427], ["aten::cudnn_convolution_backward", 16378], ["aten::slice", 16308], ["aten::conv2d", 16107], ["aten::conv2d", 16101], ["aten::conv2d", 16084], ["aten::empty_strided", 15907], ["aten::cudnn_batch_norm_backward", 15711], ["aten::_local_scalar_dense", 15707], ["aten::rand", 15682], ["aten::_convolution", 15617], ["aten::batch_norm", 15408], ["aten::convolution", 15271], ["aten::add", 15177], ["aten::convolution", 15090], ["aten::convolution", 15052], ["aten::cudnn_convolution_backward_input", 14765], ["aten::set_", 14662], ["aten::_batch_norm_impl_index", 14649], ["aten::_convolution", 14576], ["CudnnBatchNormBackward", 14512], ["aten::cudnn_convolution", 14510], ["aten::cudnn_convolution_backward_weight", 14396], ["aten::cudnn_batch_norm", 14361], ["aten::cudnn_batch_norm", 14273], ["aten::_convolution", 14226], ["aten::_convolution", 14167], ["CudnnBatchNormBackward", 14156], ["aten::cudnn_batch_norm_backward", 14050], ["aten::zero_", 13969], ["aten::cudnn_batch_norm", 13701], ["aten::cudnn_convolution", 13556], ["aten::exp", 13342], ["aten::copy_", 13314], ["aten::mul_", 13197], ["aten::cudnn_convolution_backward_weight", 12937], ["aten::cudnn_convolution", 12892], ["aten::view", 12848], ["torch::autograd::AccumulateGrad", 12799], ["CudnnBatchNormBackward", 12623], ["aten::cudnn_convolution_backward_input", 12506], ["ReluBackward1", 12379], ["aten::cudnn_convolution", 12332], ["aten::cudnn_convolution_backward", 12311], ["aten::cudnn_convolution_backward_weight", 12274], ["aten::cudnn_convolution", 12112], ["aten::cudnn_batch_norm", 11903], ["aten::view", 11730], ["aten::cudnn_convolution_backward", 11660], ["aten::cudnn_batch_norm_backward", 11559], ["CudnnBatchNormBackward", 11410], ["aten::view", 11383], ["aten::cudnn_batch_norm_backward", 11317], ["aten::resize_", 11198], ["aten::cudnn_convolution_backward", 11035], ["aten::add", 11025], ["aten::conv2d", 10707], ["aten::conv2d", 10226], ["aten::view", 10223], ["aten::cudnn_batch_norm_backward", 10215], ["aten::convolution", 10119], ["aten::is_nonzero", 9942], ["aten::add", 9816], ["aten::zero_", 9693], ["aten::convolution", 9632], ["aten::_convolution", 9609], ["aten::conv2d", 9608], ["aten::cudnn_convolution_backward_input", 9600], ["aten::add", 9543], ["aten::conv2d", 9486], ["aten::add_", 9268], ["aten::cudnn_convolution_backward_weight", 9227], ["aten::cudnn_batch_norm_backward", 9206], ["aten::threshold_backward", 9187], ["aten::cudnn_convolution_backward_input", 9112], ["aten::_convolution", 9111], ["aten::mul_", 9053], ["torch::autograd::AccumulateGrad", 9050], ["aten::convolution", 8927], ["aten::convolution", 8902], ["aten::unsqueeze", 8803], ["aten::cudnn_convolution_backward_input", 8774], ["aten::cudnn_convolution_backward_weight", 8708], ["torch::autograd::AccumulateGrad", 8704], ["aten::cudnn_convolution_backward_weight", 8691], ["aten::cudnn_convolution_backward_input", 8585], ["torch::autograd::AccumulateGrad", 8579], ["aten::view", 8557], ["aten::_convolution", 8427], ["aten::_convolution", 8409], ["aten::cudnn_convolution", 8364], ["aten::copy_", 8315], ["aten::relu_", 8271], ["aten::is_nonzero", 8227], ["aten::random_", 8052], ["aten::cudnn_convolution", 7863], ["aten::empty_like", 7777], ["aten::view", 7761], ["aten::cudnn_convolution_backward_weight", 7685], ["aten::view", 7398], ["ReluBackward1", 7278], ["aten::cudnn_convolution", 7216], ["aten::cudnn_convolution_backward_input", 7215], ["aten::cudnn_convolution_backward_input", 7200], ["aten::cudnn_convolution", 7193], ["aten::add_", 7158], ["aten::cudnn_convolution_backward_weight", 7047], ["aten::conv2d", 7034], ["aten::add_", 6937], ["aten::copy_", 6926], ["aten::is_floating_point", 6917], ["aten::zero_", 6909], ["ReluBackward1", 6799], ["aten::mul_", 6790], ["aten::cudnn_convolution_backward_input", 6758], ["aten::convolution", 6643], ["aten::cudnn_convolution_backward_weight", 6534], ["ReluBackward1", 6532], ["aten::cudnn_convolution_backward", 6528], ["aten::conv2d", 6342], ["aten::conv2d", 6337], ["aten::zero_", 6330], ["CudnnConvolutionBackward", 6296], ["aten::_convolution", 6293], ["aten::fill_", 6108], ["aten::zero_", 6045], ["aten::mul_", 6014], ["aten::add_", 5970], ["aten::convolution", 5945], ["aten::convolution", 5934], ["aten::cudnn_convolution_backward", 5933], ["aten::copy_", 5924], ["aten::cudnn_convolution_backward", 5878], ["CudnnConvolutionBackward", 5798], ["aten::detach_", 5787], ["aten::cudnn_convolution_backward", 5780], ["aten::mul_", 5777], ["CudnnConvolutionBackward", 5725], ["aten::cudnn_convolution_backward_weight", 5714], ["aten::add", 5637], ["aten::as_strided", 5602], ["aten::_convolution", 5587], ["aten::_convolution", 5571], ["aten::cudnn_convolution_backward", 5501], ["aten::copy_", 5495], ["aten::threshold_backward", 5458], ["aten::cudnn_convolution", 5450], ["aten::cudnn_convolution_backward", 5439], ["aten::cudnn_convolution_backward", 5438], ["aten::cudnn_convolution_backward", 5384], ["aten::cudnn_convolution_backward", 5364], ["aten::contiguous", 5308], ["ReluBackward1", 5281], ["aten::as_strided", 5269], ["aten::relu_", 5186], ["aten::threshold_backward", 5160], ["aten::relu_", 5152], ["aten::add_", 5127], ["aten::cudnn_convolution_backward", 4973], ["aten::cudnn_convolution_backward_input", 4945], ["aten::cudnn_convolution_backward_weight", 4908], ["AddmmBackward", 4874], ["aten::cudnn_convolution_backward_input", 4861], ["aten::conv2d", 4800], ["aten::cudnn_convolution", 4755], ["aten::cudnn_convolution", 4751], ["aten::threshold_backward", 4701], ["aten::add_", 4683], ["torch::autograd::AccumulateGrad", 4619], ["aten::conv2d", 4569], ["aten::cudnn_convolution_backward_weight", 4509], ["aten::add_", 4493], ["aten::convolution", 4356], ["aten::relu_", 4348], ["aten::view", 4341], ["aten::contiguous", 4324], ["aten::convolution", 4286], ["aten::conv2d", 4252], ["aten::add", 4223], ["aten::batch_norm", 4218], ["aten::add", 4195], ["aten::fill_", 4185], ["aten::_convolution", 4142], ["aten::_convolution", 4103], ["aten::stride", 4084], ["aten::convolution", 4059], ["ReluBackward1", 4048], ["aten::conv2d", 4022], ["aten::_batch_norm_impl_index", 4010], ["aten::threshold_backward", 3929], ["aten::conv2d", 3926], ["aten::_convolution", 3894], ["aten::empty_like", 3864], ["aten::to", 3845], ["aten::convolution", 3826], ["torch::autograd::AccumulateGrad", 3818], ["CudnnConvolutionBackward", 3730], ["aten::zero_", 3728], ["aten::convolution", 3724], ["aten::batch_norm", 3682], ["aten::relu_", 3682], ["aten::batch_norm", 3681], ["aten::batch_norm", 3679], ["aten::_convolution", 3659], ["aten::cudnn_convolution", 3654], ["aten::cudnn_convolution", 3643], ["torch::autograd::AccumulateGrad", 3579], ["aten::add_", 3572], ["aten::_convolution", 3562], ["aten::add_", 3527], ["aten::_batch_norm_impl_index", 3493], ["aten::_batch_norm_impl_index", 3491], ["aten::cudnn_convolution", 3489], ["aten::add", 3484], ["aten::_batch_norm_impl_index", 3479], ["aten::contiguous", 3465], ["aten::add_", 3460], ["CudnnBatchNormBackward", 3446], ["aten::contiguous", 3433], ["aten::add_", 3418], ["aten::add_", 3396], ["MaxPool2DWithIndicesBackward", 3376], ["aten::as_strided", 3371], ["aten::conv2d", 3355], ["aten::conv2d", 3345], ["aten::cudnn_convolution_backward", 3344], ["aten::copy_", 3318], ["aten::conv2d", 3310], ["CudnnBatchNormBackward", 3302], ["aten::cudnn_batch_norm", 3291], ["aten::mul_", 3284], ["aten::conv2d", 3272], ["aten::cudnn_convolution", 3240], ["aten::conv2d", 3213], ["aten::conv2d", 3197], ["aten::convolution", 3156], ["aten::cudnn_convolution", 3150], ["aten::convolution", 3135], ["aten::contiguous", 3123], ["aten::contiguous", 3114], ["torch::autograd::AccumulateGrad", 3102], ["aten::convolution", 3097], ["aten::convolution", 3073], ["ReluBackward1", 3073], ["ReluBackward1", 3072], ["CudnnBatchNormBackward", 3064], ["aten::convolution", 3016], ["aten::fill_", 3013], ["aten::max_pool2d_with_indices_backward", 3011], ["aten::threshold_backward", 3001], ["aten::stride", 2995], ["aten::convolution", 2976], ["aten::_convolution", 2973], ["aten::_convolution", 2970], ["aten::add", 2947], ["CudnnBatchNormBackward", 2940], ["aten::contiguous", 2939], ["aten::to", 2934], ["aten::_convolution", 2928], ["aten::relu_", 2925], ["aten::cudnn_convolution_backward_input", 2923], ["aten::cudnn_convolution_backward_weight", 2893], ["aten::_convolution", 2873], ["aten::cudnn_batch_norm_backward", 2866], ["aten::add", 2865], ["aten::_convolution", 2845], ["aten::add", 2840], ["aten::max_pool2d", 2837], ["aten::cudnn_batch_norm", 2825], ["aten::cudnn_batch_norm", 2821], ["aten::as_strided", 2808], ["aten::_convolution", 2807], ["aten::cudnn_batch_norm", 2795], ["aten::stride", 2769], ["aten::fill_", 2767], ["aten::cudnn_batch_norm_backward", 2747], ["aten::cudnn_convolution_backward_weight", 2705], ["aten::mul_", 2689], ["aten::zero_", 2675], ["aten::threshold_", 2654], ["aten::zero_", 2647], ["aten::fill_", 2643], ["aten::mul_", 2629], ["aten::cudnn_convolution_backward_input", 2620], ["aten::max_pool2d_with_indices", 2613], ["aten::addmm", 2565], ["aten::cudnn_convolution", 2552], ["aten::cudnn_convolution", 2550], ["aten::fill_", 2549], ["aten::cudnn_convolution_backward_input", 2540], ["aten::cudnn_convolution", 2528], ["aten::cudnn_convolution_backward_weight", 2514], ["aten::empty_like", 2506], ["aten::cudnn_convolution_backward_weight", 2499], ["aten::empty_like", 2495], ["aten::cudnn_convolution_backward_weight", 2479], ["aten::cudnn_convolution", 2464], ["aten::cudnn_convolution_backward_weight", 2454], ["detach_", 2421], ["aten::cudnn_convolution", 2415], ["aten::stride", 2411], ["aten::cudnn_batch_norm_backward", 2411], ["aten::cudnn_convolution_backward_weight", 2399], ["aten::cudnn_convolution", 2387], ["aten::add_", 2375], ["aten::cudnn_batch_norm_backward", 2351], ["torch::autograd::AccumulateGrad", 2346], ["aten::add_", 2334], ["torch::autograd::AccumulateGrad", 2302], ["aten::contiguous", 2298], ["aten::threshold_backward", 2286], ["aten::cudnn_convolution_backward_input", 2273], ["aten::add", 2266], ["aten::threshold_backward", 2264], ["aten::cudnn_convolution_backward_input", 2251], ["torch::autograd::AccumulateGrad", 2249], ["aten::cudnn_convolution_backward_input", 2247], ["aten::contiguous", 2243], ["aten::zero_", 2242], ["aten::resize_", 2233], ["aten::cudnn_convolution_backward_weight", 2220], ["aten::cudnn_convolution_backward_weight", 2217], ["aten::relu_", 2188], ["aten::zeros", 2178], ["aten::relu_", 2177], ["aten::add_", 2173], ["aten::contiguous", 2169], ["aten::empty_like", 2143], ["aten::mul_", 2140], ["aten::add", 2131], ["aten::add", 2123], ["aten::cudnn_convolution_backward_input", 2114], ["aten::cudnn_convolution_backward_weight", 2097], ["aten::add_", 2090], ["aten::add", 2068], ["aten::contiguous", 2026], ["MeanBackward1", 2018], ["aten::as_strided", 1997], ["aten::contiguous", 1975], ["aten::as_strided", 1955], ["aten::threshold_", 1944], ["aten::stride", 1918], ["aten::contiguous", 1871], ["aten::stride", 1829], ["torch::autograd::AccumulateGrad", 1804], ["aten::empty_like", 1797], ["aten::contiguous", 1785], ["aten::zero_", 1773], ["aten::fill_", 1772], ["aten::zero_", 1762], ["aten::empty_like", 1759], ["torch::autograd::AccumulateGrad", 1756], ["aten::mul_", 1754], ["aten::mul_", 1752], ["aten::zero_", 1731], ["torch::autograd::AccumulateGrad", 1726], ["aten::add_", 1716], ["aten::mul_", 1704], ["torch::autograd::AccumulateGrad", 1694], ["aten::threshold_", 1665], ["aten::add_", 1614], ["LogSoftmaxBackward", 1530], ["aten::add", 1486], ["aten::pin_memory", 1447], ["aten::empty_like", 1429], ["aten::empty_like", 1421], ["aten::threshold_", 1398], ["aten::add", 1394], ["aten::log_softmax", 1393], ["aten::stride", 1373], ["aten::zero_", 1346], ["aten::resize_", 1337], ["aten::mul_", 1337], ["aten::add_", 1336], ["aten::zero_", 1334], ["aten::zero_", 1333], ["aten::zero_", 1311], ["aten::resize_", 1297], ["aten::resize_", 1291], ["aten::mul_", 1287], ["aten::to", 1281], ["aten::mul_", 1276], ["aten::mul_", 1274], ["aten::_log_softmax_backward_data", 1245], ["aten::mm", 1239], ["aten::adaptive_avg_pool2d", 1231], ["aten::add_", 1223], ["aten::_log_softmax", 1208], ["torch::autograd::AccumulateGrad", 1197], ["aten::t", 1189], ["aten::threshold_", 1184], ["NllLossBackward", 1181], ["aten::add_", 1166], ["aten::add_", 1166], ["aten::nll_loss", 1156], ["aten::add_", 1156], ["aten::fill_", 1154], ["aten::fill_", 1153], ["aten::add_", 1152], ["aten::add_", 1129], ["aten::zeros_like", 1128], ["aten::add_", 1127], ["aten::add_", 1124], ["torch::autograd::AccumulateGrad", 1107], ["aten::contiguous", 1090], ["ReluBackward1", 1089], ["aten::mm", 1066], ["aten::stride", 1065], ["aten::div", 1050], ["aten::relu_", 1049], ["aten::mean", 1044], ["ReluBackward1", 1036], ["ReluBackward1", 1032], ["ReluBackward1", 983], ["aten::fill_", 978], ["aten::t", 972], ["aten::threshold_", 948], ["aten::nll_loss_forward", 940], ["aten::ones_like", 925], ["aten::resize_", 899], ["aten::to", 887], ["aten::resize_", 872], ["aten::zero_", 866], ["aten::mul_", 865], ["aten::zero_", 862], ["aten::mul_", 858], ["aten::add", 829], ["aten::threshold_backward", 815], ["aten::add", 800], ["aten::nll_loss_backward", 788], ["aten::contiguous", 782], ["aten::threshold_backward", 782], ["aten::threshold_backward", 768], ["aten::empty_like", 765], ["aten::stride", 764], ["aten::contiguous", 763], ["aten::resize_", 758], ["aten::flatten", 758], ["aten::copy_", 754], ["aten::fill_", 747], ["aten::fill_", 747], ["aten::relu_", 746], ["aten::fill_", 746], ["AddBackward0", 743], ["aten::empty_like", 740], ["aten::resize_", 736], ["aten::relu_", 735], ["aten::relu_", 734], ["aten::threshold_", 728], ["aten::threshold_backward", 728], ["aten::threshold_", 708], ["aten::add", 707], ["aten::add", 703], ["aten::add", 701], ["aten::add", 694], ["aten::add", 692], ["aten::add", 682], ["aten::add", 681], ["aten::add", 674], ["torch::autograd::AccumulateGrad", 650], ["aten::zero_", 645], ["aten::contiguous", 643], ["aten::resize_", 640], ["TBackward", 621], ["torch::autograd::AccumulateGrad", 611], ["aten::stride", 604], ["torch::autograd::AccumulateGrad", 601], ["torch::autograd::AccumulateGrad", 599], ["aten::fill_", 596], ["torch::autograd::AccumulateGrad", 596], ["ViewBackward", 593], ["aten::resize_", 586], ["aten::zero_", 586], ["aten::fill_", 584], ["torch::autograd::AccumulateGrad", 583], ["torch::autograd::AccumulateGrad", 579], ["aten::fill_", 578], ["aten::fill_", 570], ["torch::autograd::AccumulateGrad", 568], ["aten::reshape", 563], ["torch::autograd::AccumulateGrad", 556], ["torch::autograd::AccumulateGrad", 545], ["aten::contiguous", 536], ["aten::transpose", 521], ["aten::t", 516], ["aten::zero_", 513], ["aten::contiguous", 508], ["aten::resize_", 502], ["aten::zero_", 496], ["aten::contiguous", 488], ["aten::expand", 484], ["aten::contiguous", 483], ["aten::zero_", 459], ["aten::transpose", 459], ["aten::contiguous", 457], ["aten::contiguous", 455], ["aten::zero_", 453], ["aten::mul_", 451], ["aten::contiguous", 449], ["aten::zero_", 448], ["aten::empty_like", 443], ["aten::mul_", 443], ["aten::mul_", 443], ["aten::mul_", 441], ["aten::view", 438], ["aten::mul_", 435], ["aten::mul_", 433], ["aten::stride", 430], ["aten::zero_", 429], ["aten::zero_", 429], ["aten::zero_", 428], ["aten::zero_", 427], ["aten::mul_", 425], ["aten::zero_", 424], ["aten::mul_", 424], ["aten::set_", 422], ["aten::contiguous", 421], ["aten::mul_", 419], ["aten::reshape", 418], ["aten::mul_", 415], ["AddBackward0", 414], ["aten::contiguous", 402], ["aten::resize_", 397], ["aten::resize_", 397], ["aten::resize_", 388], ["aten::contiguous", 381], ["aten::fill_", 375], ["aten::fill_", 375], ["aten::contiguous", 374], ["aten::stride", 347], ["aten::empty_like", 345], ["aten::stride", 344], ["aten::empty_like", 342], ["aten::empty_like", 340], ["aten::stride", 328], ["aten::resize_", 323], ["AddBackward0", 323], ["AddBackward0", 319], ["aten::fill_", 311], ["aten::resize_", 308], ["aten::stride", 305], ["aten::narrow", 297], ["aten::stride", 294], ["aten::resize_", 294], ["aten::threshold_", 292], ["aten::resize_", 291], ["aten::stride", 284], ["aten::view", 277], ["aten::stride", 264], ["aten::expand", 262], ["aten::fill_", 252], ["aten::transpose", 248], ["aten::contiguous", 246], ["nccl:broadcast", 241], ["aten::contiguous", 241], ["aten::stride", 237], ["aten::threshold_", 236], ["aten::threshold_", 235], ["aten::threshold_", 234], ["aten::fill_", 234], ["aten::resize_", 221], ["aten::fill_", 218], ["aten::is_pinned", 214], ["aten::resize_as_", 212], ["aten::resize_", 205], ["aten::resize_", 197], ["aten::slice", 196], ["aten::is_pinned", 192], ["aten::fill_", 191], ["aten::fill_", 190], ["aten::fill_", 189], ["aten::fill_", 189], ["aten::fill_", 187], ["aten::fill_", 187], ["aten::fill_", 187], ["aten::fill_", 186], ["aten::resize_", 175], ["aten::resize_", 175], ["aten::detach_", 166], ["aten::contiguous", 160], ["aten::stride", 157], ["aten::contiguous", 155], ["aten::contiguous", 135], ["aten::as_strided", 135], ["aten::as_strided", 132], ["aten::contiguous", 127], ["aten::contiguous", 126], ["aten::contiguous", 123], ["aten::contiguous", 123], ["aten::contiguous", 123], ["aten::contiguous", 122], ["aten::resize_", 121], ["aten::resize_", 114], ["aten::resize_", 113], ["aten::resize_", 104], ["aten::resize_", 103], ["aten::resize_", 101], ["aten::resize_", 98], ["aten::resize_", 97], ["aten::stride", 96], ["detach_", 92], ["aten::to", 91], ["aten::conj", 90], ["aten::stride", 87], ["aten::conj", 87], ["aten::as_strided", 81], ["aten::resize_", 80], ["aten::as_strided", 76], ["aten::as_strided", 70], ["aten::as_strided", 67], ["aten::to", 64], ["aten::contiguous", 63], ["aten::is_floating_point", 55], ["aten::resize_", 53], ["aten::stride", 53], ["aten::stride", 48], ["aten::stride", 43], ["aten::stride", 42], ["aten::stride", 28]]}, "host_self_time": {"title": "Host Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 1896653], ["aten::div_", 476251], ["aten::_cat", 457630], ["aten::div", 442862], ["aten::sub_", 386589], ["aten::empty", 215172], ["aten::copy_", 50472], ["aten::add_", 39041], ["aten::copy_", 35301], ["aten::select", 32471], ["aten::add", 29327], ["aten::uniform_", 29025], ["aten::slice", 26079], ["aten::add_", 25929], ["aten::to", 25615], ["aten::any", 23283], ["aten::_local_scalar_dense", 22108], ["aten::cudnn_batch_norm", 21351], ["aten::clone", 18601], ["aten::cudnn_batch_norm_backward", 18531], ["aten::add_", 18469], ["aten::view", 17814], ["aten::log", 17507], ["aten::add", 16877], ["aten::view", 16875], ["aten::permute", 16740], ["aten::add_", 16635], ["aten::add_", 16596], ["aten::eq", 16455], ["aten::cudnn_batch_norm", 16422], ["aten::exp", 16399], ["aten::randint", 16393], ["aten::empty_strided", 15907], ["aten::item", 15884], ["aten::_local_scalar_dense", 15707], ["aten::item", 14871], ["aten::cudnn_convolution_backward_input", 14756], ["aten::set_", 14662], ["aten::lt", 13590], ["aten::slice", 13500], ["aten::copy_", 13314], ["aten::cudnn_batch_norm", 13302], ["aten::mul_", 13197], ["aten::eq", 12894], ["aten::view", 12848], ["aten::lt", 12631], ["aten::cudnn_batch_norm", 12310], ["aten::view", 11730], ["aten::add", 11689], ["aten::cudnn_batch_norm_backward", 11479], ["aten::view", 11383], ["aten::resize_", 11198], ["aten::cudnn_convolution", 11076], ["aten::narrow", 10933], ["aten::cudnn_convolution_backward_input", 10537], ["aten::cudnn_batch_norm_backward", 10523], ["aten::cudnn_convolution", 10445], ["aten::cudnn_convolution_backward_weight", 10298], ["aten::cudnn_convolution", 10296], ["aten::exp", 10281], ["aten::view", 10223], ["aten::cudnn_batch_norm", 9898], ["aten::cudnn_batch_norm", 9636], ["aten::cudnn_batch_norm", 9617], ["aten::to", 9455], ["aten::cudnn_batch_norm_backward", 9281], ["aten::add_", 9268], ["aten::cudnn_convolution", 9217], ["aten::cudnn_convolution_backward_weight", 9159], ["aten::mul_", 9053], ["aten::cudnn_convolution", 9033], ["aten::cudnn_convolution_backward_weight", 8711], ["aten::cudnn_convolution_backward_input", 8673], ["aten::view", 8557], ["aten::add", 8447], ["aten::rand", 8414], ["aten::copy_", 8315], ["aten::contiguous", 8152], ["aten::random_", 8052], ["aten::cudnn_batch_norm", 7999], ["aten::zero_", 7861], ["aten::cudnn_batch_norm_backward", 7786], ["aten::view", 7761], ["aten::add", 7540], ["aten::cudnn_batch_norm_backward", 7521], ["aten::view", 7398], ["aten::add", 7331], ["aten::add_", 7158], ["aten::threshold_backward", 6968], ["aten::add_", 6937], ["aten::copy_", 6926], ["aten::is_floating_point", 6917], ["aten::cudnn_convolution_backward_input", 6878], ["aten::cudnn_batch_norm_backward", 6850], ["aten::cudnn_convolution_backward_input", 6802], ["aten::mul_", 6790], ["aten::cudnn_convolution_backward_weight", 6674], ["aten::cudnn_convolution_backward_input", 6464], ["aten::cudnn_convolution", 6408], ["aten::narrow", 6393], ["aten::cudnn_convolution_backward_weight", 6268], ["aten::cudnn_batch_norm_backward", 6215], ["aten::cudnn_convolution_backward_weight", 6208], ["CudnnBatchNormBackward", 6198], ["aten::fill_", 6108], ["aten::cudnn_convolution_backward_input", 6103], ["aten::cudnn_convolution", 6033], ["aten::mul_", 6014], ["aten::add_", 5970], ["torch::autograd::AccumulateGrad", 5970], ["aten::copy_", 5924], ["aten::mul_", 5777], ["aten::cudnn_convolution_backward_weight", 5622], ["aten::relu_", 5617], ["aten::as_strided", 5602], ["aten::cudnn_convolution", 5552], ["aten::zero_", 5508], ["aten::copy_", 5495], ["aten::cudnn_convolution", 5495], ["aten::unsqueeze", 5432], ["aten::empty_like", 5357], ["aten::_batch_norm_impl_index", 5311], ["aten::contiguous", 5308], ["aten::as_strided", 5269], ["aten::cudnn_convolution_backward_input", 5186], ["aten::add_", 5127], ["aten::cudnn_convolution_backward_input", 5061], ["aten::cudnn_convolution_backward_weight", 5050], ["aten::cudnn_convolution_backward_input", 4826], ["aten::cudnn_convolution_backward_weight", 4739], ["aten::add_", 4683], ["aten::cudnn_convolution_backward", 4670], ["aten::add_", 4493], ["aten::view", 4341], ["aten::contiguous", 4324], ["CudnnConvolutionBackward", 4299], ["aten::add", 4281], ["aten::cudnn_convolution_backward", 4219], ["aten::fill_", 4185], ["aten::cudnn_convolution", 4182], ["aten::threshold_backward", 4120], ["aten::stride", 4084], ["aten::threshold_backward", 4065], ["CudnnBatchNormBackward", 3975], ["aten::cudnn_convolution_backward_weight", 3972], ["aten::cudnn_convolution_backward", 3955], ["aten::zero_", 3896], ["aten::to", 3845], ["torch::autograd::AccumulateGrad", 3665], ["aten::cudnn_convolution", 3646], ["aten::cudnn_convolution", 3642], ["aten::cudnn_convolution_backward_input", 3620], ["aten::add_", 3572], ["aten::zero_", 3563], ["aten::threshold_backward", 3560], ["aten::add_", 3527], ["aten::cudnn_convolution_backward_weight", 3521], ["aten::cudnn_convolution_backward_input", 3507], ["CudnnBatchNormBackward", 3496], ["aten::relu_", 3487], ["aten::_batch_norm_impl_index", 3472], ["aten::contiguous", 3465], ["aten::add_", 3460], ["aten::_batch_norm_impl_index", 3445], ["aten::contiguous", 3433], ["aten::add_", 3418], ["aten::zero_", 3402], ["aten::add_", 3396], ["aten::as_strided", 3371], ["aten::detach_", 3366], ["aten::copy_", 3318], ["aten::_batch_norm_impl_index", 3290], ["aten::mul_", 3284], ["aten::cudnn_convolution_backward_weight", 3259], ["aten::relu_", 3242], ["ReluBackward1", 3192], ["aten::add", 3185], ["aten::add", 3173], ["CudnnBatchNormBackward", 3140], ["aten::contiguous", 3123], ["aten::contiguous", 3114], ["aten::cudnn_convolution_backward", 3039], ["aten::fill_", 3013], ["aten::cudnn_convolution", 2998], ["aten::stride", 2995], ["aten::threshold_backward", 2979], ["aten::relu_", 2950], ["aten::contiguous", 2939], ["aten::to", 2934], ["aten::cudnn_convolution_backward", 2905], ["aten::cudnn_convolution", 2874], ["aten::is_nonzero", 2857], ["aten::as_strided", 2808], ["aten::cudnn_convolution", 2802], ["aten::stride", 2769], ["aten::fill_", 2767], ["aten::mul_", 2689], ["torch::autograd::AccumulateGrad", 2685], ["torch::autograd::AccumulateGrad", 2682], ["aten::is_nonzero", 2668], ["aten::threshold_", 2654], ["aten::add", 2652], ["aten::fill_", 2643], ["aten::mul_", 2629], ["aten::cudnn_convolution", 2626], ["CudnnConvolutionBackward", 2624], ["CudnnBatchNormBackward", 2592], ["CudnnConvolutionBackward", 2554], ["aten::fill_", 2549], ["aten::relu_", 2498], ["CudnnBatchNormBackward", 2495], ["aten::_batch_norm_impl_index", 2491], ["aten::_batch_norm_impl_index", 2466], ["torch::autograd::AccumulateGrad", 2428], ["detach_", 2421], ["aten::stride", 2411], ["aten::add_", 2375], ["aten::cudnn_batch_norm", 2350], ["aten::stack", 2343], ["aten::add_", 2334], ["aten::cudnn_convolution_backward", 2312], ["aten::cudnn_convolution_backward", 2307], ["aten::contiguous", 2298], ["aten::add", 2264], ["aten::threshold_backward", 2260], ["aten::contiguous", 2243], ["aten::resize_", 2233], ["aten::cudnn_convolution_backward", 2216], ["CudnnConvolutionBackward", 2198], ["aten::cudnn_convolution_backward", 2195], ["aten::add", 2192], ["aten::cudnn_convolution", 2183], ["aten::add_", 2173], ["aten::contiguous", 2169], ["aten::cudnn_convolution_backward_input", 2160], ["aten::add", 2148], ["aten::_convolution", 2144], ["aten::mul_", 2140], ["CudnnBatchNormBackward", 2117], ["aten::add_", 2090], ["aten::batch_norm", 2071], ["aten::empty_like", 2063], ["aten::cudnn_convolution_backward_weight", 2050], ["aten::cudnn_batch_norm_backward", 2038], ["aten::contiguous", 2026], ["aten::cudnn_batch_norm_backward", 2025], ["aten::as_strided", 1997], ["aten::relu_", 1977], ["aten::contiguous", 1975], ["aten::max_pool2d_with_indices", 1968], ["aten::_batch_norm_impl_index", 1966], ["aten::_batch_norm_impl_index", 1966], ["aten::cudnn_convolution", 1961], ["aten::zero_", 1956], ["aten::as_strided", 1955], ["aten::threshold_", 1944], ["aten::addmm", 1940], ["aten::cudnn_batch_norm", 1933], ["aten::cudnn_batch_norm", 1931], ["CudnnBatchNormBackward", 1926], ["aten::stride", 1918], ["aten::cudnn_convolution", 1914], ["aten::cudnn_convolution", 1907], ["aten::cudnn_convolution_backward_weight", 1900], ["aten::cudnn_convolution", 1896], ["aten::cudnn_batch_norm", 1894], ["aten::contiguous", 1871], ["aten::cudnn_convolution", 1861], ["aten::_convolution", 1859], ["aten::cudnn_convolution_backward_input", 1840], ["aten::cudnn_convolution", 1833], ["ReluBackward1", 1831], ["aten::stride", 1829], ["aten::cudnn_convolution_backward_weight", 1824], ["aten::_convolution", 1822], ["aten::cudnn_convolution_backward_input", 1822], ["ReluBackward1", 1820], ["CudnnConvolutionBackward", 1817], ["aten::cudnn_convolution_backward_weight", 1809], ["aten::cudnn_convolution_backward_weight", 1808], ["CudnnConvolutionBackward", 1808], ["aten::cudnn_convolution_backward_weight", 1787], ["aten::contiguous", 1785], ["aten::fill_", 1772], ["aten::mul_", 1754], ["aten::mul_", 1752], ["aten::threshold_backward", 1750], ["aten::threshold_backward", 1742], ["aten::cudnn_convolution_backward_weight", 1736], ["aten::add", 1732], ["aten::add_", 1716], ["aten::mul_", 1704], ["aten::threshold_", 1665], ["ReluBackward1", 1639], ["aten::_convolution", 1632], ["aten::add", 1630], ["aten::cudnn_convolution_backward_input", 1630], ["aten::cudnn_convolution_backward_input", 1623], ["aten::add_", 1614], ["aten::cudnn_convolution_backward_weight", 1613], ["aten::cudnn_batch_norm_backward", 1608], ["aten::add", 1607], ["aten::cudnn_convolution_backward_input", 1605], ["aten::cudnn_convolution_backward_weight", 1604], ["aten::cudnn_convolution_backward", 1588], ["aten::cudnn_batch_norm_backward", 1587], ["aten::add", 1570], ["aten::cudnn_convolution_backward", 1566], ["aten::cudnn_convolution_backward", 1546], ["aten::zero_", 1521], ["aten::cudnn_convolution_backward_weight", 1521], ["CudnnConvolutionBackward", 1516], ["aten::cat", 1509], ["aten::cudnn_convolution_backward_input", 1495], ["aten::zero_", 1494], ["aten::_convolution", 1471], ["aten::relu_", 1469], ["CudnnConvolutionBackward", 1469], ["aten::relu_", 1460], ["aten::threshold_", 1398], ["torch::autograd::AccumulateGrad", 1391], ["aten::stride", 1373], ["ReluBackward1", 1352], ["aten::resize_", 1337], ["aten::mul_", 1337], ["aten::add_", 1336], ["aten::empty_like", 1332], ["aten::empty_like", 1329], ["aten::batch_norm", 1312], ["aten::batch_norm", 1303], ["aten::max_pool2d_with_indices_backward", 1300], ["aten::resize_", 1297], ["aten::resize_", 1291], ["aten::mul_", 1287], ["aten::mul_", 1276], ["aten::mul_", 1274], ["aten::zero_", 1264], ["aten::add_", 1223], ["aten::conv2d", 1185], ["aten::threshold_", 1184], ["aten::zeros", 1167], ["aten::add_", 1166], ["aten::add_", 1166], ["aten::add_", 1156], ["aten::fill_", 1154], ["aten::fill_", 1153], ["aten::add_", 1152], ["aten::empty_like", 1144], ["torch::autograd::AccumulateGrad", 1133], ["aten::add_", 1129], ["aten::add_", 1127], ["aten::batch_norm", 1126], ["aten::add", 1126], ["aten::add_", 1124], ["torch::autograd::AccumulateGrad", 1101], ["aten::_convolution", 1100], ["aten::_convolution", 1095], ["aten::contiguous", 1090], ["aten::conv2d", 1077], ["aten::_convolution", 1070], ["aten::stride", 1065], ["aten::_convolution", 1064], ["aten::add", 1051], ["aten::conv2d", 1049], ["ReluBackward1", 1047], ["aten::zero_", 1027], ["aten::conv2d", 1017], ["aten::zero_", 1015], ["aten::convolution", 987], ["aten::zero_", 984], ["aten::fill_", 978], ["aten::empty_like", 964], ["aten::cudnn_convolution_backward", 962], ["aten::mm", 955], ["aten::threshold_", 948], ["aten::batch_norm", 944], ["aten::nll_loss_forward", 940], ["aten::batch_norm", 923], ["aten::empty_like", 918], ["aten::cudnn_convolution_backward", 918], ["aten::resize_", 899], ["aten::convolution", 885], ["aten::mean", 883], ["aten::resize_", 872], ["aten::div", 868], ["torch::autograd::AccumulateGrad", 866], ["aten::mul_", 865], ["aten::convolution", 864], ["aten::mul_", 858], ["aten::cudnn_convolution_backward", 847], ["aten::_log_softmax", 837], ["aten::convolution", 834], ["aten::cudnn_convolution_backward", 819], ["aten::conv2d", 813], ["ReluBackward1", 808], ["AddmmBackward", 794], ["aten::nll_loss_backward", 788], ["ReluBackward1", 787], ["aten::contiguous", 782], ["aten::batch_norm", 777], ["aten::cudnn_convolution_backward", 769], ["aten::mm", 766], ["aten::stride", 764], ["aten::contiguous", 763], ["aten::zero_", 763], ["aten::batch_norm", 759], ["aten::resize_", 758], ["aten::relu_", 757], ["aten::copy_", 754], ["aten::cudnn_convolution_backward", 754], ["aten::zero_", 750], ["aten::zero_", 750], ["aten::empty_like", 749], ["aten::fill_", 747], ["aten::fill_", 747], ["aten::_convolution", 746], ["aten::fill_", 746], ["aten::empty_like", 745], ["aten::cudnn_convolution_backward", 745], ["AddBackward0", 743], ["aten::cudnn_convolution_backward", 738], ["aten::resize_", 736], ["aten::cudnn_convolution_backward", 736], ["aten::_convolution", 733], ["aten::zero_", 733], ["aten::threshold_", 728], ["aten::_convolution", 718], ["aten::_log_softmax_backward_data", 716], ["aten::cudnn_convolution_backward", 711], ["aten::threshold_", 708], ["torch::autograd::AccumulateGrad", 707], ["torch::autograd::AccumulateGrad", 696], ["aten::convolution", 695], ["aten::pin_memory", 693], ["aten::conv2d", 681], ["aten::t", 668], ["torch::autograd::AccumulateGrad", 668], ["aten::contiguous", 643], ["aten::resize_", 640], ["aten::add", 620], ["aten::add", 616], ["aten::pin_memory", 608], ["aten::threshold_backward", 605], ["aten::stride", 604], ["aten::fill_", 596], ["aten::conv2d", 594], ["aten::threshold_backward", 593], ["aten::threshold_backward", 591], ["aten::conv2d", 588], ["aten::resize_", 586], ["aten::conv2d", 584], ["aten::fill_", 584], ["aten::fill_", 578], ["aten::fill_", 570], ["aten::cudnn_convolution_backward", 567], ["aten::threshold_backward", 558], ["CudnnBatchNormBackward", 548], ["torch::autograd::AccumulateGrad", 543], ["aten::add", 540], ["aten::add", 537], ["aten::contiguous", 536], ["aten::_batch_norm_impl_index", 533], ["aten::add", 533], ["aten::add", 531], ["torch::autograd::AccumulateGrad", 525], ["aten::add", 523], ["aten::convolution", 521], ["aten::add", 520], ["aten::add", 520], ["torch::autograd::AccumulateGrad", 519], ["CudnnBatchNormBackward", 519], ["aten::add", 518], ["aten::conv2d", 514], ["aten::t", 513], ["aten::convolution", 510], ["aten::relu_", 510], ["aten::contiguous", 508], ["CudnnBatchNormBackward", 507], ["torch::autograd::AccumulateGrad", 506], ["aten::resize_", 502], ["aten::relu_", 501], ["aten::convolution", 500], ["aten::_batch_norm_impl_index", 500], ["aten::relu_", 499], ["aten::convolution", 493], ["aten::zero_", 491], ["aten::contiguous", 488], ["aten::zero_", 487], ["aten::_batch_norm_impl_index", 486], ["aten::_batch_norm_impl_index", 485], ["aten::contiguous", 483], ["CudnnBatchNormBackward", 479], ["aten::contiguous", 457], ["aten::contiguous", 455], ["aten::mul_", 451], ["aten::contiguous", 449], ["aten::mul_", 443], ["aten::mul_", 443], ["aten::mul_", 441], ["aten::view", 438], ["aten::mul_", 435], ["aten::_convolution", 434], ["aten::mul_", 433], ["aten::stride", 430], ["aten::empty_like", 430], ["aten::to", 429], ["aten::zero_", 428], ["aten::mul_", 425], ["aten::mul_", 424], ["aten::set_", 422], ["aten::contiguous", 421], ["MeanBackward1", 420], ["aten::mul_", 419], ["aten::mul_", 415], ["AddBackward0", 414], ["aten::_convolution", 409], ["aten::conv2d", 408], ["aten::expand", 403], ["aten::contiguous", 402], ["aten::empty_like", 402], ["aten::resize_", 397], ["aten::resize_", 397], ["NllLossBackward", 393], ["aten::conv2d", 392], ["aten::conv2d", 391], ["torch::autograd::AccumulateGrad", 389], ["aten::resize_", 388], ["aten::transpose", 386], ["CudnnConvolutionBackward", 386], ["aten::contiguous", 381], ["aten::_convolution", 381], ["aten::fill_", 375], ["aten::fill_", 375], ["aten::contiguous", 374], ["aten::convolution", 374], ["aten::_convolution", 372], ["aten::_convolution", 372], ["aten::_convolution", 370], ["aten::_convolution", 369], ["MaxPool2DWithIndicesBackward", 365], ["CudnnConvolutionBackward", 363], ["aten::_convolution", 362], ["aten::_convolution", 361], ["CudnnConvolutionBackward", 361], ["CudnnConvolutionBackward", 360], ["aten::_convolution", 354], ["aten::_convolution", 350], ["aten::convolution", 350], ["aten::convolution", 347], ["aten::stride", 347], ["aten::stride", 344], ["aten::zero_", 334], ["aten::stride", 328], ["torch::autograd::AccumulateGrad", 328], ["aten::transpose", 327], ["aten::resize_", 323], ["AddBackward0", 323], ["AddBackward0", 319], ["aten::fill_", 311], ["aten::resize_", 308], ["aten::stride", 305], ["aten::stride", 294], ["aten::resize_", 294], ["aten::threshold_", 292], ["aten::resize_", 291], ["aten::to", 286], ["LogSoftmaxBackward", 285], ["aten::stride", 284], ["aten::view", 277], ["ReluBackward1", 274], ["aten::zero_", 272], ["aten::t", 268], ["aten::stride", 264], ["aten::ones_like", 264], ["ReluBackward1", 264], ["aten::zero_", 262], ["aten::zero_", 262], ["aten::zero_", 261], ["ReluBackward1", 255], ["ReluBackward1", 254], ["aten::fill_", 252], ["aten::contiguous", 246], ["nccl:broadcast", 241], ["aten::contiguous", 241], ["aten::zero_", 240], ["aten::zero_", 240], ["aten::zero_", 239], ["aten::zero_", 239], ["aten::zero_", 238], ["aten::stride", 237], ["aten::threshold_", 236], ["aten::threshold_", 235], ["aten::threshold_", 234], ["aten::fill_", 234], ["aten::max_pool2d", 224], ["aten::conv2d", 221], ["aten::resize_", 221], ["aten::fill_", 218], ["aten::nll_loss", 216], ["aten::is_pinned", 214], ["aten::convolution", 214], ["aten::conv2d", 213], ["aten::conv2d", 213], ["aten::conv2d", 210], ["aten::batch_norm", 208], ["aten::zeros_like", 207], ["aten::resize_", 205], ["aten::batch_norm", 203], ["aten::conv2d", 202], ["aten::zero_", 202], ["aten::convolution", 200], ["aten::conv2d", 199], ["aten::conv2d", 199], ["aten::conv2d", 197], ["aten::resize_", 197], ["aten::empty_like", 197], ["aten::conv2d", 196], ["aten::flatten", 195], ["aten::conv2d", 193], ["aten::is_pinned", 192], ["aten::fill_", 191], ["aten::fill_", 190], ["aten::fill_", 189], ["aten::fill_", 189], ["aten::batch_norm", 188], ["aten::batch_norm", 188], ["torch::autograd::AccumulateGrad", 188], ["aten::adaptive_avg_pool2d", 187], ["aten::fill_", 187], ["aten::fill_", 187], ["aten::fill_", 187], ["aten::expand", 186], ["aten::fill_", 186], ["aten::log_softmax", 185], ["aten::convolution", 183], ["aten::convolution", 183], ["torch::autograd::AccumulateGrad", 183], ["aten::empty_like", 181], ["aten::empty_like", 181], ["torch::autograd::AccumulateGrad", 181], ["aten::empty_like", 180], ["aten::transpose", 178], ["aten::resize_", 175], ["aten::resize_", 175], ["ViewBackward", 175], ["torch::autograd::AccumulateGrad", 174], ["torch::autograd::AccumulateGrad", 174], ["torch::autograd::AccumulateGrad", 174], ["torch::autograd::AccumulateGrad", 172], ["aten::convolution", 171], ["aten::convolution", 169], ["aten::convolution", 169], ["aten::convolution", 167], ["aten::convolution", 165], ["aten::convolution", 165], ["torch::autograd::AccumulateGrad", 165], ["torch::autograd::AccumulateGrad", 165], ["aten::convolution", 162], ["torch::autograd::AccumulateGrad", 162], ["aten::contiguous", 160], ["aten::resize_as_", 158], ["aten::stride", 157], ["aten::contiguous", 155], ["TBackward", 153], ["aten::reshape", 141], ["aten::contiguous", 135], ["aten::as_strided", 135], ["aten::as_strided", 132], ["aten::slice", 129], ["aten::contiguous", 127], ["aten::contiguous", 126], ["aten::reshape", 125], ["aten::contiguous", 123], ["aten::contiguous", 123], ["aten::contiguous", 123], ["aten::contiguous", 122], ["aten::resize_", 121], ["aten::resize_", 114], ["aten::resize_", 113], ["aten::resize_", 104], ["aten::resize_", 103], ["aten::narrow", 101], ["aten::resize_", 101], ["aten::resize_", 98], ["aten::resize_", 97], ["aten::stride", 96], ["detach_", 92], ["aten::to", 91], ["aten::conj", 90], ["aten::stride", 87], ["aten::conj", 87], ["aten::as_strided", 81], ["aten::resize_", 80], ["aten::as_strided", 76], ["aten::detach_", 74], ["aten::as_strided", 70], ["aten::as_strided", 67], ["aten::to", 64], ["aten::contiguous", 63], ["aten::is_floating_point", 55], ["aten::resize_", 53], ["aten::stride", 53], ["aten::stride", 48], ["aten::stride", 43], ["aten::stride", 42], ["aten::stride", 28]]}}, "operation_table_by_name_input": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "string", "name": "Input Shape"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Device Self Duration (us)"}, {"type": "number", "name": "Device Total Duration (us)"}, {"type": "number", "name": "Host Self Duration (us)"}, {"type": "number", "name": "Host Total Duration (us)"}], "rows": [["aten::cudnn_convolution_backward_weight", "[[], [32, 64, 56, 56], [32, 64, 56, 56], [], [], [], [], [], [], []]", 16, 11748, 11748, 6674, 9227], ["aten::cudnn_batch_norm_backward", "[[32, 256, 56, 56], [32, 256, 56, 56], [256], [256], [256], [256], [256], [], [0]]", 16, 10250, 10250, 6215, 9206], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], []]", 24, 9710, 9710, 10537, 14765], ["aten::cudnn_convolution", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], []]", 24, 9411, 9411, 11076, 14510], ["aten::cudnn_convolution_backward_weight", "[[], [32, 1024, 14, 14], [32, 256, 14, 14], [], [], [], [], [], [], []]", 24, 9408, 9408, 10298, 14396], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], []]", 20, 8545, 8545, 8673, 12506], ["aten::cudnn_convolution_backward_input", "[[], [32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], []]", 16, 8383, 8383, 6464, 9112], ["aten::cudnn_convolution", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], []]", 20, 7886, 7886, 9217, 12112], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 56, 56], [32, 64, 56, 56], [], [], [], [], [], [], []]", 16, 7802, 7802, 6208, 8691], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 14, 14], [32, 1024, 14, 14], [], [], [], [], [], [], []]", 20, 7786, 7786, 8711, 12274], ["aten::cudnn_convolution_backward_input", "[[], [32, 1024, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], []]", 24, 7615, 7615, 14756, 19044], ["aten::copy_", "[[32, 3, 224, 224], [32, 3, 224, 224], []]", 8, 7122, 7122, 50472, 50472], ["aten::cudnn_batch_norm_backward", "[[32, 512, 28, 28], [32, 512, 28, 28], [512], [512], [512], [512], [512], [], [0]]", 20, 6656, 6656, 7521, 11317], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 28, 28], [32, 128, 28, 28], [], [], [], [], [], [], []]", 16, 6486, 6486, 6268, 8708], ["aten::cudnn_batch_norm", "[[32, 256, 56, 56], [256], [256], [256], [256], [], [], []]", 16, 6356, 6356, 7999, 11903], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], []]", 12, 6257, 6257, 5186, 7215], ["aten::cudnn_convolution_backward_weight", "[[], [32, 64, 56, 56], [32, 256, 56, 56], [], [], [], [], [], [], []]", 8, 6092, 6092, 3259, 4509], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 14, 14], [32, 256, 14, 14], [], [], [], [], [], [], []]", 20, 6068, 6068, 9159, 12937], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], []]", 16, 5919, 5919, 6103, 8585], ["aten::cudnn_convolution_backward_input", "[[], [32, 2048, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], []]", 12, 5762, 5762, 4826, 6758], ["aten::cudnn_convolution", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], []]", 20, 5720, 5720, 10296, 13556], ["aten::cudnn_batch_norm_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], [64], [64], [64], [64], [64], [], [0]]", 24, 5040, 5040, 9281, 14050], ["aten::cudnn_batch_norm_backward", "[[32, 1024, 14, 14], [32, 1024, 14, 14], [1024], [1024], [1024], [1024], [1024], [], [0]]", 28, 5036, 5036, 11479, 17235], ["aten::cudnn_convolution", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], []]", 12, 5020, 5020, 5495, 7193], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 28, 28], [32, 512, 28, 28], [], [], [], [], [], [], []]", 12, 4905, 4905, 4739, 6534], ["aten::cudnn_convolution", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], []]", 16, 4806, 4806, 9033, 12332], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], []]", 16, 4666, 4666, 6878, 9600], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 28, 28], [32, 128, 28, 28], [], [], [], [], [], [], []]", 12, 4618, 4618, 5050, 7047], ["aten::cudnn_convolution", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], []]", 12, 4605, 4605, 5552, 7216], ["aten::cudnn_convolution_backward_input", "[[], [32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], []]", 12, 4584, 4584, 5061, 7200], ["aten::cudnn_convolution", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], []]", 16, 4451, 4451, 10445, 12892], ["aten::cudnn_convolution", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], []]", 12, 4444, 4444, 6408, 8364], ["aten::threshold_backward", "[[32, 256, 56, 56], [32, 256, 56, 56], []]", 12, 4388, 4388, 1742, 2286], ["aten::add_", "[[32, 256, 56, 56], [32, 256, 56, 56], []]", 12, 4359, 4359, 1716, 1716], ["aten::cudnn_convolution_backward_weight", "[[], [32, 2048, 7, 7], [32, 512, 7, 7], [], [], [], [], [], [], []]", 12, 4265, 4265, 5622, 7685], ["aten::cudnn_batch_norm", "[[32, 512, 28, 28], [512], [512], [512], [512], [], [], []]", 20, 4119, 4119, 9617, 14273], ["aten::cudnn_convolution_backward_weight", "[[], [32, 64, 112, 112], [32, 3, 224, 224], [], [], [], [], [], [], []]", 4, 3990, 3990, 1900, 2705], ["aten::cudnn_convolution_backward_input", "[[], [32, 2048, 7, 7], [2048, 1024, 1, 1], [], [], [], [], [], [], []]", 4, 3745, 3745, 1630, 2251], ["aten::cudnn_convolution_backward_input", "[[], [32, 128, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], []]", 12, 3711, 3711, 6802, 8774], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], []]", 8, 3656, 3656, 3620, 4945], ["aten::cudnn_convolution", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], [], [], []]", 4, 3655, 3655, 1896, 2528], ["aten::cudnn_convolution_backward_input", "[[], [32, 1024, 14, 14], [1024, 512, 1, 1], [], [], [], [], [], [], []]", 4, 3585, 3585, 1840, 2620], ["aten::cudnn_convolution", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], []]", 8, 3570, 3570, 3646, 4755], ["aten::cudnn_convolution", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], []]", 12, 3475, 3475, 6033, 7863], ["aten::cudnn_convolution", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], [], [], []]", 4, 3407, 3407, 1833, 2387], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 28, 28], [512, 256, 1, 1], [], [], [], [], [], [], []]", 4, 3335, 3335, 1495, 2114], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 56, 56], [32, 256, 56, 56], [], [], [], [], [], [], []]", 4, 3262, 3262, 1604, 2217], ["aten::cudnn_convolution", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], []]", 8, 3250, 3250, 3642, 4751], ["aten::cudnn_batch_norm_backward", "[[32, 64, 112, 112], [32, 64, 112, 112], [64], [64], [64], [64], [64], [], [0]]", 4, 3220, 3220, 1608, 2411], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 28, 28], [32, 256, 56, 56], [], [], [], [], [], [], []]", 4, 3137, 3137, 1521, 2097], ["aten::cudnn_convolution", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], []]", 4, 3108, 3108, 1914, 2550], ["aten::cudnn_convolution", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], [], [], []]", 4, 3072, 3072, 1961, 2552], ["aten::cudnn_convolution", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], [], [], []]", 4, 3051, 3051, 1907, 2464], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], []]", 4, 3021, 3021, 1605, 2247], ["aten::threshold_", "[[32, 256, 56, 56], [], []]", 12, 2995, 2995, 728, 728], ["aten::threshold_backward", "[[32, 512, 28, 28], [32, 512, 28, 28], []]", 16, 2973, 2973, 2260, 3001], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 28, 28], [32, 512, 28, 28], [], [], [], [], [], [], []]", 4, 2960, 2960, 1613, 2220], ["aten::add_", "[[32, 512, 28, 28], [32, 512, 28, 28], []]", 16, 2922, 2922, 2173, 2173], ["aten::cudnn_convolution_backward_weight", "[[], [32, 2048, 7, 7], [32, 1024, 14, 14], [], [], [], [], [], [], []]", 4, 2909, 2909, 1808, 2514], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], []]", 4, 2900, 2900, 1623, 2273], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 7, 7], [32, 2048, 7, 7], [], [], [], [], [], [], []]", 8, 2887, 2887, 3972, 5714], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 28, 28], [32, 128, 56, 56], [], [], [], [], [], [], []]", 4, 2866, 2866, 1824, 2454], ["aten::cudnn_convolution_backward_weight", "[[], [32, 1024, 14, 14], [32, 512, 28, 28], [], [], [], [], [], [], []]", 4, 2781, 2781, 2050, 2893], ["aten::max_pool2d_with_indices_backward", "[[32, 64, 56, 56], [32, 64, 112, 112], [], [], [], [], [], [32, 64, 56, 56]]", 4, 2757, 3394, 1300, 3011], ["aten::cudnn_convolution", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], []]", 4, 2752, 2752, 1861, 2415], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 7, 7], [32, 512, 14, 14], [], [], [], [], [], [], []]", 4, 2749, 2749, 1787, 2479], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 14, 14], [32, 1024, 14, 14], [], [], [], [], [], [], []]", 4, 2674, 2674, 1736, 2399], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 14, 14], [32, 256, 28, 28], [], [], [], [], [], [], []]", 4, 2660, 2660, 1809, 2499], ["aten::cudnn_batch_norm", "[[32, 64, 56, 56], [64], [64], [64], [64], [], [], []]", 24, 2658, 2658, 12310, 18226], ["aten::cudnn_convolution_backward_input", "[[], [32, 64, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], []]", 8, 2657, 2657, 3507, 4861], ["aten::cudnn_convolution", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], []]", 4, 2571, 2571, 2802, 3654], ["aten::cudnn_batch_norm_backward", "[[32, 128, 28, 28], [32, 128, 28, 28], [128], [128], [128], [128], [128], [], [0]]", 28, 2565, 2565, 10523, 15711], ["aten::cudnn_convolution", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], []]", 8, 2469, 2469, 4182, 5450], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 7, 7], [32, 512, 7, 7], [], [], [], [], [], [], []]", 8, 2421, 2421, 3521, 4908], ["aten::cudnn_convolution", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], [], [], []]", 4, 2398, 2398, 2874, 3489], ["aten::cudnn_batch_norm", "[[32, 1024, 14, 14], [1024], [1024], [1024], [1024], [], [], []]", 28, 2371, 2371, 16422, 22928], ["aten::threshold_backward", "[[32, 1024, 14, 14], [32, 1024, 14, 14], []]", 24, 2299, 2299, 4065, 5160], ["aten::cudnn_convolution_backward_input", "[[], [32, 128, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], []]", 4, 2259, 2259, 2160, 2923], ["aten::cudnn_convolution", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], [], [], []]", 4, 2244, 2244, 2626, 3240], ["aten::add_", "[[32, 1024, 14, 14], [32, 1024, 14, 14], []]", 24, 2210, 2210, 3418, 3418], ["aten::threshold_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], []]", 24, 2207, 2207, 3560, 4701], ["aten::cudnn_batch_norm_backward", "[[32, 256, 14, 14], [32, 256, 14, 14], [256], [256], [256], [256], [256], [], [0]]", 44, 2086, 2086, 18531, 27672], ["aten::cudnn_convolution", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], []]", 4, 2079, 2079, 2998, 3643], ["aten::threshold_", "[[32, 512, 28, 28], [], []]", 16, 2004, 2004, 948, 948], ["aten::cudnn_batch_norm", "[[32, 64, 112, 112], [64], [64], [64], [64], [], [], []]", 4, 1707, 1707, 2350, 3291], ["aten::threshold_", "[[32, 64, 56, 56], [], []]", 24, 1515, 1515, 1944, 1944], ["aten::threshold_", "[[32, 1024, 14, 14], [], []]", 24, 1513, 1513, 1398, 1398], ["aten::threshold_backward", "[[32, 64, 112, 112], [32, 64, 112, 112], []]", 4, 1459, 1459, 605, 815], ["aten::cudnn_batch_norm", "[[32, 128, 28, 28], [128], [128], [128], [128], [], [], []]", 28, 1426, 1426, 13302, 19812], ["aten::cudnn_batch_norm_backward", "[[32, 128, 56, 56], [32, 128, 56, 56], [128], [128], [128], [128], [128], [], [0]]", 4, 1389, 1389, 2025, 2747], ["aten::threshold_backward", "[[32, 128, 28, 28], [32, 128, 28, 28], []]", 28, 1382, 1382, 4120, 5458], ["aten::add_", "[[512, 512, 3, 3], [512, 512, 3, 3], []]", 36, 1282, 1282, 3527, 3527], ["aten::threshold_backward", "[[32, 256, 14, 14], [32, 256, 14, 14], []]", 44, 1207, 1207, 6968, 9187], ["aten::cudnn_batch_norm_backward", "[[32, 2048, 7, 7], [32, 2048, 7, 7], [2048], [2048], [2048], [2048], [2048], [], [0]]", 16, 1140, 1140, 6850, 10215], ["aten::threshold_", "[[32, 64, 112, 112], [], []]", 4, 999, 999, 292, 292], ["aten::cudnn_batch_norm", "[[32, 256, 14, 14], [256], [256], [256], [256], [], [], []]", 44, 995, 995, 21351, 31828], ["aten::cudnn_batch_norm", "[[32, 2048, 7, 7], [2048], [2048], [2048], [2048], [], [], []]", 16, 902, 902, 9898, 13701], ["aten::threshold_", "[[32, 128, 28, 28], [], []]", 28, 897, 897, 1665, 1665], ["aten::max_pool2d_with_indices", "[[32, 64, 112, 112], [], [], [], [], []]", 4, 896, 896, 1968, 2613], ["aten::add_", "[[256], [256], []]", 384, 808, 808, 39041, 39041], ["aten::cudnn_batch_norm", "[[32, 128, 56, 56], [128], [128], [128], [128], [], [], []]", 4, 796, 796, 1933, 2821], ["aten::threshold_backward", "[[32, 128, 56, 56], [32, 128, 56, 56], []]", 4, 741, 741, 558, 728], ["aten::cudnn_batch_norm_backward", "[[32, 256, 28, 28], [32, 256, 28, 28], [256], [256], [256], [256], [256], [], [0]]", 4, 662, 662, 1587, 2351], ["aten::fill_", "[[32, 64, 112, 112], []]", 4, 637, 637, 311, 311], ["aten::threshold_backward", "[[32, 2048, 7, 7], [32, 2048, 7, 7], []]", 12, 606, 606, 1750, 2264], ["aten::add_", "[[32, 2048, 7, 7], [32, 2048, 7, 7], []]", 12, 553, 553, 1614, 1614], ["aten::add_", "[[512], [512], []]", 264, 553, 553, 25929, 25929], ["aten::threshold_", "[[32, 256, 14, 14], [], []]", 44, 517, 517, 2654, 2654], ["aten::threshold_", "[[32, 128, 56, 56], [], []]", 4, 502, 502, 236, 236], ["aten::add_", "[[256, 256, 3, 3], [256, 256, 3, 3], []]", 72, 495, 495, 6937, 6937], ["aten::add_", "[[2048, 512, 1, 1], [2048, 512, 1, 1], []]", 36, 489, 489, 3396, 3396], ["aten::cudnn_batch_norm_backward", "[[32, 512, 7, 7], [32, 512, 7, 7], [512], [512], [512], [512], [512], [], [0]]", 20, 444, 444, 7786, 11559], ["aten::add_", "[[128], [128], []]", 192, 428, 428, 18469, 18469], ["aten::cudnn_convolution_backward_input", "[[], [32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], []]", 4, 422, 422, 1822, 2540], ["aten::add", "[[512, 512, 3, 3], [512, 512, 3, 3], []]", 12, 421, 421, 1607, 2131], ["aten::cudnn_batch_norm", "[[32, 256, 28, 28], [256], [256], [256], [256], [], [], []]", 4, 412, 412, 1894, 2795], ["aten::add_", "[[2048, 1024, 1, 1], [2048, 1024, 1, 1], []]", 12, 389, 389, 1127, 1127], ["aten::threshold_", "[[32, 2048, 7, 7], [], []]", 12, 385, 385, 708, 708], ["aten::cudnn_convolution", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], []]", 4, 382, 382, 2183, 3150], ["aten::threshold_backward", "[[32, 256, 28, 28], [32, 256, 28, 28], []]", 4, 382, 382, 593, 782], ["aten::add_", "[[1000, 2048], [1000, 2048], []]", 12, 368, 368, 1152, 1152], ["aten::add_", "[[1024], [1024], []]", 168, 367, 367, 16596, 16596], ["aten::cudnn_batch_norm_backward", "[[32, 512, 14, 14], [32, 512, 14, 14], [512], [512], [512], [512], [512], [], [0]]", 4, 363, 363, 2038, 2866], ["aten::add_", "[[512, 2048, 1, 1], [512, 2048, 1, 1], []]", 24, 361, 361, 2334, 2334], ["aten::threshold_backward", "[[32, 512, 7, 7], [32, 512, 7, 7], []]", 20, 320, 320, 2979, 3929], ["aten::cudnn_batch_norm", "[[32, 512, 7, 7], [512], [512], [512], [512], [], [], []]", 20, 300, 300, 9636, 14361], ["aten::add_", "[[64], [64], []]", 168, 296, 296, 16635, 16635], ["aten::mul_", "[[512, 512, 3, 3], []]", 12, 287, 287, 1274, 1274], ["aten::add_", "[[1024, 256, 1, 1], [1024, 256, 1, 1], []]", 72, 265, 265, 7158, 7158], ["aten::add_", "[[256, 1024, 1, 1], [256, 1024, 1, 1], []]", 60, 259, 259, 5970, 5970], ["aten::threshold_", "[[32, 256, 28, 28], [], []]", 4, 252, 252, 234, 234], ["aten::add", "[[256, 256, 3, 3], [256, 256, 3, 3], []]", 24, 242, 242, 3185, 4223], ["aten::add", "[[], [], []]", 212, 217, 217, 29327, 38471], ["aten::copy_", "[[], [], []]", 596, 212, 212, 35301, 35301], ["aten::threshold_backward", "[[32, 512, 14, 14], [32, 512, 14, 14], []]", 4, 204, 204, 591, 768], ["aten::add_", "[[2048], [2048], []]", 96, 203, 203, 9268, 9268], ["aten::_cat", "[[], []]", 12, 192, 192, 457630, 462387], ["aten::add", "[[2048, 512, 1, 1], [2048, 512, 1, 1], []]", 12, 192, 192, 1630, 2123], ["aten::cudnn_batch_norm", "[[32, 512, 14, 14], [512], [512], [512], [512], [], [], []]", 4, 181, 181, 1931, 2825], ["aten::fill_", "[[512, 512, 3, 3], []]", 12, 180, 180, 578, 578], ["aten::mean", "[[32, 2048, 7, 7], [], [], []]", 4, 172, 172, 883, 1044], ["aten::add_", "[[128, 128, 3, 3], [128, 128, 3, 3], []]", 48, 156, 156, 4493, 4493], ["aten::mul_", "[[256, 256, 3, 3], []]", 24, 145, 145, 2689, 2689], ["aten::addmm", "[[1000], [32, 2048], [2048, 1000], [], []]", 4, 133, 133, 1940, 2565], ["aten::mul_", "[[2048, 512, 1, 1], []]", 12, 133, 133, 1287, 1287], ["aten::copy_", "[[256], [256], []]", 128, 128, 128, 13314, 13314], ["aten::add", "[[256], [256], []]", 128, 128, 128, 16877, 22465], ["aten::mul_", "[[256], []]", 128, 128, 128, 13197, 13197], ["aten::add", "[[512, 2048, 1, 1], [512, 2048, 1, 1], []]", 8, 128, 128, 1051, 1394], ["aten::add", "[[2048, 1024, 1, 1], [2048, 1024, 1, 1], []]", 4, 124, 124, 533, 703], ["aten::threshold_", "[[32, 512, 14, 14], [], []]", 4, 122, 122, 235, 235], ["aten::add", "[[1000, 2048], [1000, 2048], []]", 4, 122, 122, 616, 829], ["aten::threshold_", "[[32, 512, 7, 7], [], []]", 20, 120, 120, 1184, 1184], ["aten::add", "[[1024, 256, 1, 1], [1024, 256, 1, 1], []]", 24, 119, 119, 3173, 4195], ["aten::add_", "[[512, 128, 1, 1], [512, 128, 1, 1], []]", 48, 117, 117, 5127, 5127], ["aten::div", "[[32, 2048, 7, 7], []]", 4, 116, 116, 868, 1050], ["aten::mm", "[[32, 1000], [1000, 2048]]", 4, 115, 115, 955, 1239], ["aten::fill_", "[[256, 256, 3, 3], []]", 24, 96, 96, 1154, 1154], ["aten::add_", "[[512, 1024, 1, 1], [512, 1024, 1, 1], []]", 12, 93, 93, 1124, 1124], ["aten::add_", "[[256, 64, 1, 1], [256, 64, 1, 1], []]", 48, 92, 92, 4683, 4683], ["aten::copy_", "[[512], [512], []]", 88, 88, 88, 8315, 8315], ["aten::add", "[[512], [512], []]", 88, 88, 88, 11689, 15177], ["aten::mul_", "[[512], []]", 88, 88, 88, 9053, 9053], ["aten::add", "[[256, 1024, 1, 1], [256, 1024, 1, 1], []]", 20, 88, 88, 2652, 3484], ["aten::mul_", "[[512, 2048, 1, 1], []]", 8, 87, 87, 858, 858], ["aten::add_", "[[128, 512, 1, 1], [128, 512, 1, 1], []]", 36, 85, 85, 3572, 3572], ["aten::mul_", "[[2048, 1024, 1, 1], []]", 4, 85, 85, 433, 433], ["aten::fill_", "[[2048, 512, 1, 1], []]", 12, 84, 84, 570, 570], ["aten::mul_", "[[1000, 2048], []]", 4, 84, 84, 419, 419], ["aten::mm", "[[1000, 32], [32, 2048]]", 4, 76, 76, 766, 1066], ["aten::mul_", "[[1024, 256, 1, 1], []]", 24, 75, 75, 2629, 2629], ["aten::add_", "[[1024, 512, 1, 1], [1024, 512, 1, 1], []]", 12, 74, 74, 1166, 1166], ["aten::add_", "[[64, 64, 3, 3], [64, 64, 3, 3], []]", 36, 71, 71, 3460, 3460], ["aten::copy_", "[[128], [128], []]", 64, 64, 64, 5924, 5924], ["aten::add", "[[128], [128], []]", 64, 64, 64, 8447, 11025], ["aten::mul_", "[[128], []]", 64, 64, 64, 6790, 6790], ["aten::mul_", "[[256, 1024, 1, 1], []]", 20, 61, 61, 2140, 2140], ["aten::copy_", "[[64], [64], []]", 56, 56, 56, 6926, 6926], ["aten::copy_", "[[1024], [1024], []]", 56, 56, 56, 5495, 5495], ["aten::fill_", "[[512, 2048, 1, 1], []]", 8, 56, 56, 375, 375], ["aten::add", "[[64], [64], []]", 56, 56, 56, 7540, 9816], ["aten::mul_", "[[64], []]", 56, 56, 56, 6014, 6014], ["aten::add", "[[1024], [1024], []]", 56, 56, 56, 7331, 9543], ["aten::mul_", "[[1024], []]", 56, 56, 56, 5777, 5777], ["aten::fill_", "[[512], []]", 88, 54, 54, 4185, 4185], ["aten::fill_", "[[2048, 1024, 1, 1], []]", 4, 52, 52, 187, 187], ["aten::fill_", "[[1000, 2048], []]", 4, 52, 52, 189, 189], ["aten::fill_", "[[128], []]", 64, 51, 51, 3013, 3013], ["aten::fill_", "[[1024, 256, 1, 1], []]", 24, 48, 48, 1153, 1153], ["aten::fill_", "[[256], []]", 128, 46, 46, 6108, 6108], ["aten::add_", "[[64, 256, 1, 1], [64, 256, 1, 1], []]", 24, 46, 46, 2375, 2375], ["aten::fill_", "[[1024], []]", 56, 44, 44, 2767, 2767], ["aten::add", "[[128, 128, 3, 3], [128, 128, 3, 3], []]", 16, 44, 44, 2192, 2865], ["aten::_log_softmax_backward_data", "[[32, 1000], [32, 1000], [], [32, 1000]]", 4, 42, 42, 716, 1245], ["aten::_log_softmax", "[[32, 1000], [], []]", 4, 40, 40, 837, 1208], ["aten::fill_", "[[256, 1024, 1, 1], []]", 20, 40, 40, 978, 978], ["aten::add_", "[[256, 512, 1, 1], [256, 512, 1, 1], []]", 12, 39, 39, 1166, 1166], ["aten::add", "[[512, 1024, 1, 1], [512, 1024, 1, 1], []]", 4, 36, 36, 520, 681], ["aten::add_", "[[512, 256, 1, 1], [512, 256, 1, 1], []]", 12, 35, 35, 1129, 1129], ["aten::add", "[[1024, 512, 1, 1], [1024, 512, 1, 1], []]", 4, 35, 35, 520, 682], ["aten::mul_", "[[128, 128, 3, 3], []]", 16, 34, 34, 1704, 1704], ["aten::add", "[[512, 128, 1, 1], [512, 128, 1, 1], []]", 16, 33, 33, 2264, 2947], ["aten::copy_", "[[2048], [2048], []]", 32, 32, 32, 3318, 3318], ["aten::add", "[[2048], [2048], []]", 32, 32, 32, 4281, 5637], ["aten::mul_", "[[2048], []]", 32, 32, 32, 3284, 3284], ["aten::fill_", "[[64], []]", 56, 27, 27, 2643, 2643], ["aten::add", "[[128, 512, 1, 1], [128, 512, 1, 1], []]", 12, 24, 24, 1732, 2266], ["aten::mul_", "[[1024, 512, 1, 1], []]", 4, 24, 24, 451, 451], ["aten::add_", "[[128, 256, 1, 1], [128, 256, 1, 1], []]", 12, 21, 21, 1156, 1156], ["aten::mul_", "[[512, 1024, 1, 1], []]", 4, 21, 21, 424, 424], ["aten::add_", "[[64, 3, 7, 7], [64, 3, 7, 7], []]", 12, 20, 20, 1336, 1336], ["aten::add_", "[[64, 64, 1, 1], [64, 64, 1, 1], []]", 12, 20, 20, 1223, 1223], ["aten::nll_loss_forward", "[[32, 1000], [32], [], [], []]", 4, 16, 16, 940, 940], ["aten::fill_", "[[256, 64, 1, 1], []]", 16, 16, 16, 746, 746], ["aten::fill_", "[[128, 128, 3, 3], []]", 16, 16, 16, 747, 747], ["aten::fill_", "[[512, 128, 1, 1], []]", 16, 16, 16, 747, 747], ["aten::fill_", "[[1024, 512, 1, 1], []]", 4, 16, 16, 252, 252], ["aten::fill_", "[[512, 1024, 1, 1], []]", 4, 16, 16, 191, 191], ["aten::add", "[[256, 64, 1, 1], [256, 64, 1, 1], []]", 16, 16, 16, 2148, 2840], ["aten::mul_", "[[256, 64, 1, 1], []]", 16, 16, 16, 1754, 1754], ["aten::mul_", "[[512, 128, 1, 1], []]", 16, 16, 16, 1752, 1752], ["aten::fill_", "[[2048], []]", 32, 15, 15, 1772, 1772], ["aten::copy_", "[[32], [32], []]", 8, 12, 12, 754, 754], ["aten::fill_", "[[64, 64, 3, 3], []]", 12, 12, 12, 596, 596], ["aten::fill_", "[[128, 512, 1, 1], []]", 12, 12, 12, 584, 584], ["aten::add", "[[64, 64, 3, 3], [64, 64, 3, 3], []]", 12, 12, 12, 1570, 2068], ["aten::mul_", "[[64, 64, 3, 3], []]", 12, 12, 12, 1276, 1276], ["aten::add", "[[512, 256, 1, 1], [512, 256, 1, 1], []]", 4, 12, 12, 537, 701], ["aten::mul_", "[[128, 512, 1, 1], []]", 12, 12, 12, 1337, 1337], ["aten::add", "[[256, 512, 1, 1], [256, 512, 1, 1], []]", 4, 12, 12, 531, 692], ["aten::add_", "[[1000], [1000], []]", 12, 12, 12, 2090, 2090], ["aten::nll_loss_backward", "[[], [32, 1000], [32], [], [], [], []]", 4, 12, 12, 788, 788], ["aten::mul_", "[[256, 512, 1, 1], []]", 4, 9, 9, 441, 441], ["aten::fill_", "[[64, 256, 1, 1], []]", 8, 8, 8, 375, 375], ["aten::add", "[[64, 256, 1, 1], [64, 256, 1, 1], []]", 8, 8, 8, 1126, 1486], ["aten::mul_", "[[64, 256, 1, 1], []]", 8, 8, 8, 865, 865], ["aten::mul_", "[[512, 256, 1, 1], []]", 4, 8, 8, 435, 435], ["aten::_local_scalar_dense", "[[]]", 764, 4, 4, 15707, 15707], ["aten::fill_", "[[64, 3, 7, 7], []]", 4, 4, 4, 234, 234], ["aten::fill_", "[[128, 256, 1, 1], []]", 4, 4, 4, 187, 187], ["aten::fill_", "[[512, 256, 1, 1], []]", 4, 4, 4, 190, 190], ["aten::fill_", "[[256, 512, 1, 1], []]", 4, 4, 4, 186, 186], ["aten::fill_", "[[1000], []]", 4, 4, 4, 189, 189], ["aten::fill_", "[[], []]", 4, 4, 4, 218, 218], ["aten::add", "[[64, 3, 7, 7], [64, 3, 7, 7], []]", 4, 4, 4, 620, 800], ["aten::mul_", "[[64, 3, 7, 7], []]", 4, 4, 4, 443, 443], ["aten::add", "[[64, 64, 1, 1], [64, 64, 1, 1], []]", 4, 4, 4, 523, 694], ["aten::mul_", "[[64, 64, 1, 1], []]", 4, 4, 4, 425, 425], ["aten::add", "[[128, 256, 1, 1], [128, 256, 1, 1], []]", 4, 4, 4, 540, 707], ["aten::mul_", "[[128, 256, 1, 1], []]", 4, 4, 4, 443, 443], ["aten::add", "[[1000], [1000], []]", 4, 4, 4, 518, 674], ["aten::mul_", "[[1000], []]", 4, 4, 4, 415, 415], ["aten::fill_", "[[64, 64, 1, 1], []]", 4, 1, 1, 187, 187], ["aten::empty", "[[], [], [], [], [], []]", 6668, 0, 0, 215172, 215172], ["aten::fill_", "[[1], []]", 144, 0, 0, 2549, 2549], ["aten::zero_", "[[1]]", 16, 0, 0, 428, 645], ["aten::zeros", "[[], [], [], [], []]", 16, 0, 0, 1167, 2178], ["aten::uniform_", "[[1], [], [], []]", 504, 0, 0, 29025, 29025], ["aten::is_floating_point", "[[1]]", 632, 0, 0, 6917, 6917], ["aten::_local_scalar_dense", "[[1]]", 760, 0, 0, 22108, 22108], ["aten::item", "[[1]]", 760, 0, 0, 14871, 36979], ["aten::to", "[[2], [], [], [], [], []]", 188, 0, 0, 2934, 2934], ["detach_", "[[2]]", 188, 0, 0, 2421, 2421], ["aten::detach_", "[[2]]", 188, 0, 0, 3366, 5787], ["aten::log", "[[2]]", 188, 0, 0, 17507, 21098], ["aten::as_strided", "[[2], [], [], []]", 376, 0, 0, 5602, 5602], ["aten::select", "[[2], [], []]", 376, 0, 0, 32471, 38073], ["aten::item", "[[]]", 764, 0, 4, 15884, 31591], ["aten::resize_", "[[0], [], []]", 596, 0, 0, 11198, 11198], ["aten::exp", "[[0], [1]]", 188, 0, 0, 10281, 13342], ["aten::exp", "[[1]]", 188, 0, 0, 16399, 33186], ["aten::random_", "[[1], [], [], []]", 256, 0, 0, 8052, 8052], ["aten::randint", "[[], [], [], [], [], [], [], []]", 256, 0, 0, 16393, 29450], ["aten::rand", "[[], [], [], [], []]", 128, 0, 0, 8414, 15682], ["aten::empty_strided", "[[], [], [], [], [], []]", 652, 0, 0, 15907, 15907], ["aten::to", "[[], [], [], [], []]", 384, 0, 0, 25615, 48595], ["aten::lt", "[[0], [1], []]", 128, 0, 0, 12631, 34901], ["aten::lt", "[[1], []]", 128, 0, 0, 13590, 50465], ["aten::is_nonzero", "[[1]]", 128, 0, 0, 2857, 9942], ["aten::set_", "[[], []]", 128, 0, 0, 14662, 14662], ["aten::view", "[[150528], []]", 128, 0, 0, 8557, 8557], ["aten::as_strided", "[[224, 224, 3], [], [], []]", 128, 0, 0, 1997, 1997], ["aten::permute", "[[224, 224, 3], []]", 128, 0, 0, 16740, 18737], ["aten::empty_like", "[[3, 224, 224], [], [], [], [], []]", 128, 0, 0, 5357, 7777], ["aten::copy_", "[[3, 224, 224], [3, 224, 224], []]", 384, 0, 0, 1896653, 1896653], ["aten::contiguous", "[[3, 224, 224], []]", 128, 0, 0, 8152, 511262], ["aten::to", "[[3, 224, 224], [], [], [], []]", 128, 0, 0, 9455, 944044], ["aten::div", "[[3, 224, 224], []]", 128, 0, 0, 442862, 462502], ["aten::clone", "[[3, 224, 224], []]", 128, 0, 0, 18601, 492156], ["aten::to", "[[3], [], [], [], [], []]", 256, 0, 0, 3845, 3845], ["aten::eq", "[[0], [3], []]", 128, 0, 0, 12894, 34575], ["aten::eq", "[[3], []]", 128, 0, 0, 16455, 52817], ["aten::as_strided", "[[], [], [], []]", 128, 0, 0, 1955, 1955], ["aten::any", "[[3]]", 128, 0, 0, 23283, 31678], ["aten::is_nonzero", "[[]]", 128, 0, 0, 2668, 8227], ["aten::view", "[[3], []]", 256, 0, 0, 16875, 16875], ["aten::sub_", "[[3, 224, 224], [3, 1, 1], []]", 128, 0, 0, 386589, 386589], ["aten::div_", "[[3, 224, 224], [3, 1, 1]]", 128, 0, 0, 476251, 476251], ["aten::as_strided", "[[3, 224, 224], [], [], []]", 128, 0, 0, 3371, 3371], ["aten::unsqueeze", "[[3, 224, 224], []]", 128, 0, 0, 5432, 8803], ["aten::as_strided", "[[32, 3, 224, 224], [], [], []]", 4, 0, 0, 67, 67], ["aten::slice", "[[32, 3, 224, 224], [], [], [], []]", 4, 0, 0, 129, 196], ["aten::narrow", "[[32, 3, 224, 224], [], [], []]", 4, 0, 0, 101, 297], ["aten::stride", "[[32, 3, 224, 224], []]", 36, 0, 0, 284, 284], ["aten::cat", "[[], []]", 12, 0, 192, 1509, 463896], ["aten::stack", "[[], []]", 4, 0, 0, 2343, 460236], ["aten::to", "[[32], [], [], [], [], []]", 4, 0, 0, 91, 91], ["detach_", "[[32]]", 4, 0, 0, 92, 92], ["aten::detach_", "[[32]]", 4, 0, 0, 74, 166], ["aten::is_pinned", "[[32, 3, 224, 224]]", 4, 0, 0, 214, 214], ["aten::set_", "[[0], [], [], [], []]", 8, 0, 0, 422, 422], ["aten::pin_memory", "[[32, 3, 224, 224]]", 4, 0, 0, 693, 51166], ["aten::is_pinned", "[[32]]", 4, 0, 0, 192, 192], ["aten::pin_memory", "[[32]]", 4, 0, 0, 608, 1447], ["aten::to", "[[32, 3, 224, 224], [], [], [], [], [], [], []]", 8, 0, 7122, 429, 1281], ["aten::to", "[[32], [], [], [], [], [], [], []]", 4, 0, 12, 286, 887], ["aten::contiguous", "[[64], []]", 168, 0, 0, 1975, 1975], ["aten::view", "[[64], []]", 168, 0, 0, 7761, 7761], ["aten::contiguous", "[[256], []]", 384, 0, 0, 4324, 4324], ["aten::view", "[[256], []]", 384, 0, 0, 17814, 17814], ["aten::contiguous", "[[128], []]", 192, 0, 0, 2169, 2169], ["aten::view", "[[128], []]", 192, 0, 0, 10223, 10223], ["aten::contiguous", "[[512], []]", 264, 0, 0, 2939, 2939], ["aten::view", "[[512], []]", 264, 0, 0, 11730, 11730], ["aten::contiguous", "[[1024], []]", 168, 0, 0, 1871, 1871], ["aten::view", "[[1024], []]", 168, 0, 0, 7398, 7398], ["aten::contiguous", "[[2048], []]", 96, 0, 0, 1090, 1090], ["aten::view", "[[2048], []]", 96, 0, 0, 4341, 4341], ["aten::stride", "[[64], []]", 56, 0, 0, 294, 294], ["aten::stride", "[[256], []]", 128, 0, 0, 604, 604], ["aten::stride", "[[128], []]", 64, 0, 0, 305, 305], ["aten::stride", "[[512], []]", 88, 0, 0, 430, 430], ["aten::stride", "[[1024], []]", 56, 0, 0, 264, 264], ["aten::stride", "[[2048], []]", 32, 0, 0, 157, 157], ["aten::stride", "[[53120], []]", 8, 0, 0, 43, 43], ["nccl:broadcast", "[]", 8, 0, 0, 241, 241], ["aten::contiguous", "[[], []]", 212, 0, 0, 3114, 3114], ["aten::view", "[[], []]", 212, 0, 0, 11383, 11383], ["aten::stride", "[[1], []]", 212, 0, 0, 1065, 1065], ["aten::stride", "[[53], []]", 8, 0, 0, 42, 42], ["aten::as_strided", "[[53120], [], [], []]", 424, 0, 0, 5269, 5269], ["aten::slice", "[[53120], [], [], [], []]", 424, 0, 0, 26079, 31348], ["aten::narrow", "[[53120], [], [], []]", 424, 0, 0, 10933, 42281], ["aten::as_strided", "[[53], [], [], []]", 212, 0, 0, 2808, 2808], ["aten::slice", "[[53], [], [], [], []]", 212, 0, 0, 13500, 16308], ["aten::narrow", "[[53], [], [], []]", 212, 0, 0, 6393, 22701], ["aten::view", "[[1], []]", 212, 0, 0, 12848, 12848], ["aten::contiguous", "[[32, 3, 224, 224], []]", 12, 0, 0, 155, 155], ["aten::contiguous", "[[64, 3, 7, 7], []]", 4, 0, 0, 63, 63], ["aten::resize_", "[[64, 3, 7, 7], [], []]", 4, 0, 0, 53, 53], ["aten::resize_", "[[32, 3, 224, 224], [], []]", 8, 0, 0, 80, 80], ["aten::_convolution", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], [], [], [], [], []]", 4, 0, 2571, 434, 4142], ["aten::convolution", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], []]", 4, 0, 2571, 214, 4356], ["aten::conv2d", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], []]", 4, 0, 2571, 213, 4569], ["aten::contiguous", "[[32, 64, 112, 112], []]", 28, 0, 0, 455, 455], ["aten::empty_like", "[[32, 64, 112, 112], [], [], [], [], []]", 8, 0, 0, 430, 765], ["aten::_batch_norm_impl_index", "[[32, 64, 112, 112], [64], [64], [64], [64], [], [], [], []]", 4, 0, 1707, 533, 4010], ["aten::batch_norm", "[[32, 64, 112, 112], [64], [64], [64], [64], [], [], [], []]", 4, 0, 1707, 208, 4218], ["aten::relu_", "[[32, 64, 112, 112]]", 4, 0, 999, 757, 1049], ["aten::stride", "[[32, 64, 112, 112], []]", 32, 0, 0, 237, 237], ["aten::max_pool2d", "[[32, 64, 112, 112], [], [], [], [], []]", 4, 0, 896, 224, 2837], ["aten::contiguous", "[[32, 64, 56, 56], []]", 244, 0, 0, 3433, 3433], ["aten::contiguous", "[[64, 64, 1, 1], []]", 8, 0, 0, 126, 126], ["aten::resize_", "[[64, 64, 1, 1], [], []]", 8, 0, 0, 103, 103], ["aten::resize_", "[[32, 64, 56, 56], [], []]", 112, 0, 0, 1337, 1337], ["aten::stride", "[[32, 64, 56, 56], []]", 396, 0, 0, 2995, 2995], ["aten::_convolution", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 4, 0, 382, 362, 3562], ["aten::convolution", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], []]", 4, 0, 382, 162, 3724], ["aten::conv2d", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], []]", 4, 0, 382, 202, 3926], ["aten::empty_like", "[[32, 64, 56, 56], [], [], [], [], []]", 24, 0, 0, 1144, 2143], ["aten::_batch_norm_impl_index", "[[32, 64, 56, 56], [64], [64], [64], [64], [], [], [], []]", 24, 0, 2658, 3290, 22723], ["aten::batch_norm", "[[32, 64, 56, 56], [64], [64], [64], [64], [], [], [], []]", 24, 0, 2658, 1126, 23849], ["aten::relu_", "[[32, 64, 56, 56]]", 24, 0, 1515, 3242, 5186], ["aten::contiguous", "[[64, 64, 3, 3], []]", 24, 0, 0, 402, 402], ["aten::resize_", "[[64, 64, 3, 3], [], []]", 24, 0, 0, 294, 294], ["aten::_convolution", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 12, 0, 4444, 1095, 9609], ["aten::convolution", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], []]", 12, 0, 4444, 510, 10119], ["aten::conv2d", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], []]", 12, 0, 4444, 588, 10707], ["aten::contiguous", "[[256, 64, 1, 1], []]", 32, 0, 0, 536, 536], ["aten::resize_", "[[256, 64, 1, 1], [], []]", 32, 0, 0, 397, 397], ["aten::_convolution", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 16, 0, 4806, 1632, 14167], ["aten::convolution", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], []]", 16, 0, 4806, 885, 15052], ["aten::conv2d", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], []]", 16, 0, 4806, 1049, 16101], ["aten::contiguous", "[[32, 256, 56, 56], []]", 144, 0, 0, 1785, 1785], ["aten::empty_like", "[[32, 256, 56, 56], [], [], [], [], []]", 16, 0, 0, 749, 1421], ["aten::_batch_norm_impl_index", "[[32, 256, 56, 56], [256], [256], [256], [256], [], [], [], []]", 16, 0, 6356, 1966, 14649], ["aten::batch_norm", "[[32, 256, 56, 56], [256], [256], [256], [256], [], [], [], []]", 16, 0, 6356, 759, 15408], ["aten::relu_", "[[32, 256, 56, 56]]", 12, 0, 2995, 1460, 2188], ["aten::contiguous", "[[64, 256, 1, 1], []]", 16, 0, 0, 241, 241], ["aten::resize_", "[[64, 256, 1, 1], [], []]", 16, 0, 0, 205, 205], ["aten::resize_", "[[32, 256, 56, 56], [], []]", 64, 0, 0, 736, 736], ["aten::stride", "[[32, 256, 56, 56], []]", 192, 0, 0, 1373, 1373], ["aten::_convolution", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 3250, 733, 5587], ["aten::convolution", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], []]", 8, 0, 3250, 347, 5934], ["aten::conv2d", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], []]", 8, 0, 3250, 408, 6342], ["aten::contiguous", "[[128, 256, 1, 1], []]", 8, 0, 0, 135, 135], ["aten::resize_", "[[128, 256, 1, 1], [], []]", 8, 0, 0, 121, 121], ["aten::_convolution", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 4, 0, 2079, 409, 4103], ["aten::convolution", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], []]", 4, 0, 2079, 183, 4286], ["aten::conv2d", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], []]", 4, 0, 2079, 514, 4800], ["aten::contiguous", "[[32, 128, 56, 56], []]", 36, 0, 0, 457, 457], ["aten::empty_like", "[[32, 128, 56, 56], [], [], [], [], []]", 4, 0, 0, 181, 340], ["aten::_batch_norm_impl_index", "[[32, 128, 56, 56], [128], [128], [128], [128], [], [], [], []]", 4, 0, 796, 485, 3493], ["aten::batch_norm", "[[32, 128, 56, 56], [128], [128], [128], [128], [], [], [], []]", 4, 0, 796, 188, 3681], ["aten::relu_", "[[32, 128, 56, 56]]", 4, 0, 502, 510, 746], ["aten::contiguous", "[[128, 128, 3, 3], []]", 32, 0, 0, 488, 488], ["aten::resize_", "[[128, 128, 3, 3], [], []]", 32, 0, 0, 388, 388], ["aten::resize_", "[[32, 128, 56, 56], [], []]", 16, 0, 0, 175, 175], ["aten::stride", "[[32, 128, 56, 56], []]", 48, 0, 0, 328, 328], ["aten::_convolution", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 4, 0, 2398, 354, 3894], ["aten::convolution", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], [], [], []]", 4, 0, 2398, 165, 4059], ["aten::conv2d", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], []]", 4, 0, 2398, 193, 4252], ["aten::contiguous", "[[32, 128, 28, 28], []]", 252, 0, 0, 3123, 3123], ["aten::empty_like", "[[32, 128, 28, 28], [], [], [], [], []]", 28, 0, 0, 1332, 2506], ["aten::_batch_norm_impl_index", "[[32, 128, 28, 28], [128], [128], [128], [128], [], [], [], []]", 28, 0, 1426, 3472, 24622], ["aten::batch_norm", "[[32, 128, 28, 28], [128], [128], [128], [128], [], [], [], []]", 28, 0, 1426, 1303, 25925], ["aten::relu_", "[[32, 128, 28, 28]]", 28, 0, 897, 3487, 5152], ["aten::contiguous", "[[512, 128, 1, 1], []]", 32, 0, 0, 508, 508], ["aten::resize_", "[[512, 128, 1, 1], [], []]", 32, 0, 0, 397, 397], ["aten::resize_", "[[32, 128, 28, 28], [], []]", 112, 0, 0, 1297, 1297], ["aten::stride", "[[32, 128, 28, 28], []]", 336, 0, 0, 2411, 2411], ["aten::_convolution", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 16, 0, 4451, 1471, 14576], ["aten::convolution", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], []]", 16, 0, 4451, 695, 15271], ["aten::conv2d", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], []]", 16, 0, 4451, 813, 16084], ["aten::contiguous", "[[32, 512, 28, 28], []]", 180, 0, 0, 2243, 2243], ["aten::empty_like", "[[32, 512, 28, 28], [], [], [], [], []]", 20, 0, 0, 964, 1797], ["aten::_batch_norm_impl_index", "[[32, 512, 28, 28], [512], [512], [512], [512], [], [], [], []]", 20, 0, 4119, 2491, 17688], ["aten::batch_norm", "[[32, 512, 28, 28], [512], [512], [512], [512], [], [], [], []]", 20, 0, 4119, 923, 18611], ["aten::contiguous", "[[512, 256, 1, 1], []]", 8, 0, 0, 122, 122], ["aten::resize_", "[[512, 256, 1, 1], [], []]", 8, 0, 0, 97, 97], ["aten::_convolution", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 4, 0, 2244, 369, 3659], ["aten::convolution", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], [], [], []]", 4, 0, 2244, 167, 3826], ["aten::conv2d", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], []]", 4, 0, 2244, 196, 4022], ["aten::relu_", "[[32, 512, 28, 28]]", 16, 0, 2004, 1977, 2925], ["aten::contiguous", "[[128, 512, 1, 1], []]", 24, 0, 0, 381, 381], ["aten::resize_", "[[128, 512, 1, 1], [], []]", 24, 0, 0, 291, 291], ["aten::resize_", "[[32, 512, 28, 28], [], []]", 80, 0, 0, 872, 872], ["aten::stride", "[[32, 512, 28, 28], []]", 240, 0, 0, 1918, 1918], ["aten::_convolution", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 12, 0, 4605, 1064, 8427], ["aten::convolution", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], []]", 12, 0, 4605, 500, 8927], ["aten::conv2d", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], []]", 12, 0, 4605, 681, 9608], ["aten::_convolution", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 12, 0, 3475, 1100, 9111], ["aten::convolution", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], []]", 12, 0, 3475, 521, 9632], ["aten::conv2d", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], []]", 12, 0, 3475, 594, 10226], ["aten::contiguous", "[[256, 512, 1, 1], []]", 8, 0, 0, 127, 127], ["aten::resize_", "[[256, 512, 1, 1], [], []]", 8, 0, 0, 98, 98], ["aten::_convolution", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 4, 0, 2752, 381, 2845], ["aten::convolution", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], []]", 4, 0, 2752, 171, 3016], ["aten::conv2d", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], []]", 4, 0, 2752, 197, 3213], ["aten::contiguous", "[[32, 256, 28, 28], []]", 36, 0, 0, 449, 449], ["aten::empty_like", "[[32, 256, 28, 28], [], [], [], [], []]", 4, 0, 0, 181, 345], ["aten::_batch_norm_impl_index", "[[32, 256, 28, 28], [256], [256], [256], [256], [], [], [], []]", 4, 0, 412, 500, 3479], ["aten::batch_norm", "[[32, 256, 28, 28], [256], [256], [256], [256], [], [], [], []]", 4, 0, 412, 203, 3682], ["aten::relu_", "[[32, 256, 28, 28]]", 4, 0, 252, 501, 735], ["aten::contiguous", "[[256, 256, 3, 3], []]", 48, 0, 0, 782, 782], ["aten::resize_", "[[256, 256, 3, 3], [], []]", 48, 0, 0, 758, 758], ["aten::resize_", "[[32, 256, 28, 28], [], []]", 16, 0, 0, 175, 175], ["aten::stride", "[[32, 256, 28, 28], []]", 48, 0, 0, 347, 347], ["aten::_convolution", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 4, 0, 3407, 372, 2807], ["aten::convolution", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], [], [], []]", 4, 0, 3407, 169, 2976], ["aten::conv2d", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], []]", 4, 0, 3407, 221, 3197], ["aten::contiguous", "[[32, 256, 14, 14], []]", 396, 0, 0, 5308, 5308], ["aten::empty_like", "[[32, 256, 14, 14], [], [], [], [], []]", 44, 0, 0, 2063, 3864], ["aten::_batch_norm_impl_index", "[[32, 256, 14, 14], [256], [256], [256], [256], [], [], [], []]", 44, 0, 995, 5311, 39223], ["aten::batch_norm", "[[32, 256, 14, 14], [256], [256], [256], [256], [], [], [], []]", 44, 0, 995, 2071, 41294], ["aten::relu_", "[[32, 256, 14, 14]]", 44, 0, 517, 5617, 8271], ["aten::contiguous", "[[1024, 256, 1, 1], []]", 48, 0, 0, 763, 763], ["aten::resize_", "[[1024, 256, 1, 1], [], []]", 48, 0, 0, 640, 640], ["aten::resize_", "[[32, 256, 14, 14], [], []]", 176, 0, 0, 2233, 2233], ["aten::stride", "[[32, 256, 14, 14], []]", 528, 0, 0, 4084, 4084], ["aten::_convolution", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 24, 0, 9411, 2144, 16957], ["aten::convolution", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], []]", 24, 0, 9411, 987, 17944], ["aten::conv2d", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], []]", 24, 0, 9411, 1185, 19129], ["aten::contiguous", "[[32, 1024, 14, 14], []]", 252, 0, 0, 3465, 3465], ["aten::empty_like", "[[32, 1024, 14, 14], [], [], [], [], []]", 28, 0, 0, 1329, 2495], ["aten::_batch_norm_impl_index", "[[32, 1024, 14, 14], [1024], [1024], [1024], [1024], [], [], [], []]", 28, 0, 2371, 3445, 27686], ["aten::batch_norm", "[[32, 1024, 14, 14], [1024], [1024], [1024], [1024], [], [], [], []]", 28, 0, 2371, 1312, 28998], ["aten::contiguous", "[[1024, 512, 1, 1], []]", 8, 0, 0, 123, 123], ["aten::resize_", "[[1024, 512, 1, 1], [], []]", 8, 0, 0, 104, 104], ["aten::_convolution", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 4, 0, 3051, 361, 2873], ["aten::convolution", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], [], [], []]", 4, 0, 3051, 200, 3073], ["aten::conv2d", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], []]", 4, 0, 3051, 199, 3272], ["aten::relu_", "[[32, 1024, 14, 14]]", 24, 0, 1513, 2950, 4348], ["aten::contiguous", "[[256, 1024, 1, 1], []]", 40, 0, 0, 643, 643], ["aten::resize_", "[[256, 1024, 1, 1], [], []]", 40, 0, 0, 502, 502], ["aten::resize_", "[[32, 1024, 14, 14], [], []]", 112, 0, 0, 1291, 1291], ["aten::stride", "[[32, 1024, 14, 14], []]", 336, 0, 0, 2769, 2769], ["aten::_convolution", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 20, 0, 7886, 1859, 14226], ["aten::convolution", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], []]", 20, 0, 7886, 864, 15090], ["aten::conv2d", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], []]", 20, 0, 7886, 1017, 16107], ["aten::_convolution", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 20, 0, 5720, 1822, 15617], ["aten::convolution", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], []]", 20, 0, 5720, 834, 16451], ["aten::conv2d", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], []]", 20, 0, 5720, 1077, 17528], ["aten::contiguous", "[[512, 1024, 1, 1], []]", 8, 0, 0, 123, 123], ["aten::resize_", "[[512, 1024, 1, 1], [], []]", 8, 0, 0, 114, 114], ["aten::_convolution", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 4, 0, 3108, 370, 2970], ["aten::convolution", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], []]", 4, 0, 3108, 165, 3135], ["aten::conv2d", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], []]", 4, 0, 3108, 210, 3345], ["aten::contiguous", "[[32, 512, 14, 14], []]", 36, 0, 0, 483, 483], ["aten::empty_like", "[[32, 512, 14, 14], [], [], [], [], []]", 4, 0, 0, 180, 342], ["aten::_batch_norm_impl_index", "[[32, 512, 14, 14], [512], [512], [512], [512], [], [], [], []]", 4, 0, 181, 486, 3491], ["aten::batch_norm", "[[32, 512, 14, 14], [512], [512], [512], [512], [], [], [], []]", 4, 0, 181, 188, 3679], ["aten::relu_", "[[32, 512, 14, 14]]", 4, 0, 122, 499, 734], ["aten::contiguous", "[[512, 512, 3, 3], []]", 24, 0, 0, 421, 421], ["aten::resize_", "[[512, 512, 3, 3], [], []]", 24, 0, 0, 323, 323], ["aten::resize_", "[[32, 512, 14, 14], [], []]", 16, 0, 0, 221, 221], ["aten::stride", "[[32, 512, 14, 14], []]", 48, 0, 0, 344, 344], ["aten::_convolution", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 4, 0, 3655, 350, 2928], ["aten::convolution", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], [], [], []]", 4, 0, 3655, 169, 3097], ["aten::conv2d", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], []]", 4, 0, 3655, 213, 3310], ["aten::contiguous", "[[32, 512, 7, 7], []]", 180, 0, 0, 2298, 2298], ["aten::empty_like", "[[32, 512, 7, 7], [], [], [], [], []]", 20, 0, 0, 918, 1759], ["aten::_batch_norm_impl_index", "[[32, 512, 7, 7], [512], [512], [512], [512], [], [], [], []]", 20, 0, 300, 2466, 17764], ["aten::batch_norm", "[[32, 512, 7, 7], [512], [512], [512], [512], [], [], [], []]", 20, 0, 300, 944, 18708], ["aten::relu_", "[[32, 512, 7, 7]]", 20, 0, 120, 2498, 3682], ["aten::contiguous", "[[2048, 512, 1, 1], []]", 24, 0, 0, 374, 374], ["aten::resize_", "[[2048, 512, 1, 1], [], []]", 24, 0, 0, 308, 308], ["aten::resize_", "[[32, 512, 7, 7], [], []]", 80, 0, 0, 899, 899], ["aten::stride", "[[32, 512, 7, 7], []]", 240, 0, 0, 1829, 1829], ["aten::_convolution", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 12, 0, 5020, 1070, 8409], ["aten::convolution", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], []]", 12, 0, 5020, 493, 8902], ["aten::conv2d", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], []]", 12, 0, 5020, 584, 9486], ["aten::contiguous", "[[32, 2048, 7, 7], []]", 120, 0, 0, 2026, 2026], ["aten::empty_like", "[[32, 2048, 7, 7], [], [], [], [], []]", 16, 0, 0, 745, 1429], ["aten::_batch_norm_impl_index", "[[32, 2048, 7, 7], [2048], [2048], [2048], [2048], [], [], [], []]", 16, 0, 902, 1966, 16427], ["aten::batch_norm", "[[32, 2048, 7, 7], [2048], [2048], [2048], [2048], [], [], [], []]", 16, 0, 902, 777, 17204], ["aten::contiguous", "[[2048, 1024, 1, 1], []]", 8, 0, 0, 123, 123], ["aten::resize_", "[[2048, 1024, 1, 1], [], []]", 8, 0, 0, 101, 101], ["aten::_convolution", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 4, 0, 3072, 372, 2973], ["aten::convolution", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], [], [], []]", 4, 0, 3072, 183, 3156], ["aten::conv2d", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], []]", 4, 0, 3072, 199, 3355], ["aten::relu_", "[[32, 2048, 7, 7]]", 12, 0, 385, 1469, 2177], ["aten::contiguous", "[[512, 2048, 1, 1], []]", 16, 0, 0, 246, 246], ["aten::resize_", "[[512, 2048, 1, 1], [], []]", 16, 0, 0, 197, 197], ["aten::resize_", "[[32, 2048, 7, 7], [], []]", 48, 0, 0, 586, 586], ["aten::stride", "[[32, 2048, 7, 7], []]", 96, 0, 0, 764, 764], ["aten::_convolution", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 3570, 718, 5571], ["aten::convolution", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], []]", 8, 0, 3570, 374, 5945], ["aten::conv2d", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], []]", 8, 0, 3570, 392, 6337], ["aten::_convolution", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 2469, 746, 6293], ["aten::convolution", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], []]", 8, 0, 2469, 350, 6643], ["aten::conv2d", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], []]", 8, 0, 2469, 391, 7034], ["aten::adaptive_avg_pool2d", "[[32, 2048, 7, 7], []]", 4, 0, 172, 187, 1231], ["aten::view", "[[32, 2048, 1, 1], []]", 4, 0, 0, 438, 438], ["aten::reshape", "[[32, 2048, 1, 1], []]", 4, 0, 0, 125, 563], ["aten::flatten", "[[32, 2048, 1, 1], [], []]", 4, 0, 0, 195, 758], ["aten::as_strided", "[[1000, 2048], [], [], []]", 8, 0, 0, 135, 135], ["aten::transpose", "[[1000, 2048], [], []]", 8, 0, 0, 386, 521], ["aten::t", "[[1000, 2048]]", 8, 0, 0, 668, 1189], ["aten::as_strided", "[[1000], [], [], []]", 4, 0, 0, 76, 76], ["aten::expand", "[[1000], [], []]", 4, 0, 0, 186, 262], ["aten::stride", "[[2048, 1000], []]", 4, 0, 0, 53, 53], ["aten::stride", "[[32, 2048], []]", 12, 0, 0, 96, 96], ["aten::stride", "[[32, 1000], []]", 8, 0, 0, 48, 48], ["aten::contiguous", "[[32, 1000], []]", 12, 0, 0, 160, 160], ["aten::empty_like", "[[32, 1000], [], [], [], [], []]", 8, 0, 0, 402, 740], ["aten::log_softmax", "[[32, 1000], [], []]", 4, 0, 40, 185, 1393], ["aten::nll_loss", "[[32, 1000], [32], [], [], []]", 4, 0, 16, 216, 1156], ["aten::is_floating_point", "[[]]", 4, 0, 0, 55, 55], ["aten::zero_", "[[64, 3, 7, 7]]", 4, 0, 4, 262, 496], ["aten::zero_", "[[64]]", 56, 0, 27, 3402, 6045], ["aten::zero_", "[[64, 64, 1, 1]]", 4, 0, 1, 261, 448], ["aten::zero_", "[[64, 64, 3, 3]]", 12, 0, 12, 750, 1346], ["aten::zero_", "[[256, 64, 1, 1]]", 16, 0, 16, 1027, 1773], ["aten::zero_", "[[256]]", 128, 0, 46, 7861, 13969], ["aten::zero_", "[[64, 256, 1, 1]]", 8, 0, 8, 491, 866], ["aten::zero_", "[[128, 256, 1, 1]]", 4, 0, 4, 272, 459], ["aten::zero_", "[[128]]", 64, 0, 51, 3896, 6909], ["aten::zero_", "[[128, 128, 3, 3]]", 16, 0, 16, 984, 1731], ["aten::zero_", "[[512, 128, 1, 1]]", 16, 0, 16, 1015, 1762], ["aten::zero_", "[[512]]", 88, 0, 54, 5508, 9693], ["aten::zero_", "[[512, 256, 1, 1]]", 4, 0, 4, 239, 429], ["aten::zero_", "[[128, 512, 1, 1]]", 12, 0, 12, 750, 1334], ["aten::zero_", "[[256, 512, 1, 1]]", 4, 0, 4, 238, 424], ["aten::zero_", "[[256, 256, 3, 3]]", 24, 0, 96, 1521, 2675], ["aten::zero_", "[[1024, 256, 1, 1]]", 24, 0, 48, 1494, 2647], ["aten::zero_", "[[1024]]", 56, 0, 44, 3563, 6330], ["aten::zero_", "[[1024, 512, 1, 1]]", 4, 0, 16, 334, 586], ["aten::zero_", "[[256, 1024, 1, 1]]", 20, 0, 40, 1264, 2242], ["aten::zero_", "[[512, 1024, 1, 1]]", 4, 0, 16, 262, 453], ["aten::zero_", "[[512, 512, 3, 3]]", 12, 0, 180, 733, 1311], ["aten::zero_", "[[2048, 512, 1, 1]]", 12, 0, 84, 763, 1333], ["aten::zero_", "[[2048]]", 32, 0, 15, 1956, 3728], ["aten::zero_", "[[2048, 1024, 1, 1]]", 4, 0, 52, 240, 427], ["aten::zero_", "[[512, 2048, 1, 1]]", 8, 0, 56, 487, 862], ["aten::zero_", "[[1000, 2048]]", 4, 0, 52, 240, 429], ["aten::zero_", "[[1000]]", 4, 0, 4, 239, 428], ["aten::empty_like", "[[], [], [], [], [], []]", 4, 0, 0, 197, 443], ["aten::ones_like", "[[], [], [], [], [], []]", 4, 0, 4, 264, 925], ["NllLossBackward", "[[]]", 4, 0, 12, 393, 1181], ["LogSoftmaxBackward", "[[32, 1000]]", 4, 0, 42, 285, 1530], ["aten::as_strided", "[[2048, 1000], [], [], []]", 8, 0, 0, 132, 132], ["aten::transpose", "[[2048, 1000], [], []]", 8, 0, 0, 327, 459], ["aten::t", "[[2048, 1000]]", 8, 0, 0, 513, 972], ["aten::conj", "[[1000, 2048]]", 4, 0, 0, 90, 90], ["aten::stride", "[[1000, 2048], []]", 8, 0, 0, 87, 87], ["aten::as_strided", "[[32, 1000], [], [], []]", 4, 0, 0, 70, 70], ["aten::transpose", "[[32, 1000], [], []]", 4, 0, 0, 178, 248], ["aten::t", "[[32, 1000]]", 4, 0, 0, 268, 516], ["aten::conj", "[[32, 2048]]", 4, 0, 0, 87, 87], ["aten::stride", "[[1000, 32], []]", 4, 0, 0, 28, 28], ["AddmmBackward", "[[32, 1000]]", 4, 0, 191, 794, 4874], ["torch::autograd::AccumulateGrad", "[[1000]]", 4, 0, 4, 181, 596], ["TBackward", "[[2048, 1000]]", 4, 0, 0, 153, 621], ["torch::autograd::AccumulateGrad", "[[1000, 2048]]", 4, 0, 124, 174, 579], ["aten::view", "[[32, 2048], []]", 4, 0, 0, 277, 277], ["aten::reshape", "[[32, 2048], []]", 4, 0, 0, 141, 418], ["ViewBackward", "[[32, 2048]]", 4, 0, 0, 175, 593], ["aten::as_strided", "[[32, 2048, 1, 1], [], [], []]", 4, 0, 0, 81, 81], ["aten::expand", "[[32, 2048, 1, 1], [], []]", 4, 0, 0, 403, 484], ["aten::to", "[[32, 2048, 7, 7], [], [], [], []]", 4, 0, 0, 64, 64], ["MeanBackward1", "[[32, 2048, 1, 1]]", 4, 0, 116, 420, 2018], ["ReluBackward1", "[[32, 2048, 7, 7]]", 12, 0, 606, 808, 3072], ["AddBackward0", "[[32, 2048, 7, 7]]", 12, 0, 0, 323, 323], ["CudnnBatchNormBackward", "[[32, 2048, 7, 7]]", 16, 0, 1140, 2117, 12623], ["torch::autograd::AccumulateGrad", "[[2048]]", 32, 0, 139, 1391, 4619], ["aten::cudnn_convolution_backward", "[[32, 512, 7, 7], [32, 2048, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], [], []]", 12, 0, 10027, 2307, 16907], ["CudnnConvolutionBackward", "[[32, 2048, 7, 7]]", 16, 0, 16681, 1516, 24301], ["torch::autograd::AccumulateGrad", "[[2048, 512, 1, 1]]", 12, 0, 192, 506, 1694], ["ReluBackward1", "[[32, 512, 7, 7]]", 20, 0, 320, 1352, 5281], ["CudnnBatchNormBackward", "[[32, 512, 7, 7]]", 20, 0, 444, 2592, 14512], ["torch::autograd::AccumulateGrad", "[[512]]", 88, 0, 377, 3665, 12799], ["aten::cudnn_convolution_backward", "[[32, 512, 7, 7], [32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], [], []]", 8, 0, 4957, 1588, 11660], ["CudnnConvolutionBackward", "[[32, 512, 7, 7]]", 20, 0, 17970, 1817, 31227], ["torch::autograd::AccumulateGrad", "[[512, 512, 3, 3]]", 12, 0, 440, 519, 1804], ["aten::cudnn_convolution_backward", "[[32, 2048, 7, 7], [32, 512, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 6543, 1546, 12311], ["torch::autograd::AccumulateGrad", "[[512, 2048, 1, 1]]", 8, 0, 163, 389, 1197], ["aten::cudnn_convolution_backward", "[[32, 1024, 14, 14], [32, 2048, 7, 7], [2048, 1024, 1, 1], [], [], [], [], [], [], [], []]", 4, 0, 6654, 918, 5878], ["torch::autograd::AccumulateGrad", "[[2048, 1024, 1, 1]]", 4, 0, 139, 172, 568], ["aten::cudnn_convolution_backward", "[[32, 512, 14, 14], [32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], [], []]", 4, 0, 6470, 754, 5439], ["ReluBackward1", "[[32, 512, 14, 14]]", 4, 0, 204, 264, 1032], ["CudnnBatchNormBackward", "[[32, 512, 14, 14]]", 4, 0, 363, 507, 3446], ["aten::cudnn_convolution_backward", "[[32, 1024, 14, 14], [32, 512, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], [], []]", 4, 0, 5695, 738, 5438], ["CudnnConvolutionBackward", "[[32, 512, 14, 14]]", 4, 0, 5695, 360, 5798], ["torch::autograd::AccumulateGrad", "[[512, 1024, 1, 1]]", 4, 0, 57, 188, 583], ["ReluBackward1", "[[32, 1024, 14, 14]]", 24, 0, 2299, 1639, 6799], ["AddBackward0", "[[32, 1024, 14, 14]]", 24, 0, 0, 743, 743], ["CudnnBatchNormBackward", "[[32, 1024, 14, 14]]", 28, 0, 5036, 3975, 21723], ["torch::autograd::AccumulateGrad", "[[1024]]", 56, 0, 255, 2685, 8704], ["aten::cudnn_convolution_backward", "[[32, 256, 14, 14], [32, 1024, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], [], []]", 24, 0, 17023, 4670, 38428], ["CudnnConvolutionBackward", "[[32, 1024, 14, 14]]", 28, 0, 23389, 2624, 47580], ["torch::autograd::AccumulateGrad", "[[1024, 256, 1, 1]]", 24, 0, 157, 1101, 3818], ["ReluBackward1", "[[32, 256, 14, 14]]", 44, 0, 1207, 3192, 12379], ["CudnnBatchNormBackward", "[[32, 256, 14, 14]]", 44, 0, 2086, 6198, 34678], ["torch::autograd::AccumulateGrad", "[[256]]", 128, 0, 552, 5970, 20970], ["aten::cudnn_convolution_backward", "[[32, 256, 14, 14], [32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], [], []]", 20, 0, 12144, 3955, 29734], ["CudnnConvolutionBackward", "[[32, 256, 14, 14]]", 44, 0, 34769, 4299, 68808], ["torch::autograd::AccumulateGrad", "[[256, 256, 3, 3]]", 24, 0, 231, 1133, 3579], ["aten::cudnn_convolution_backward", "[[32, 1024, 14, 14], [32, 256, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], [], []]", 20, 0, 16331, 4219, 29274], ["torch::autograd::AccumulateGrad", "[[256, 1024, 1, 1]]", 20, 0, 169, 866, 3102], ["aten::cudnn_convolution_backward", "[[32, 512, 28, 28], [32, 1024, 14, 14], [1024, 512, 1, 1], [], [], [], [], [], [], [], []]", 4, 0, 6366, 962, 6528], ["torch::autograd::AccumulateGrad", "[[1024, 512, 1, 1]]", 4, 0, 36, 165, 599], ["aten::cudnn_convolution_backward", "[[32, 256, 28, 28], [32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], [], []]", 4, 0, 6294, 769, 5501], ["ReluBackward1", "[[32, 256, 28, 28]]", 4, 0, 382, 254, 1036], ["CudnnBatchNormBackward", "[[32, 256, 28, 28]]", 4, 0, 662, 519, 2940], ["aten::cudnn_convolution_backward", "[[32, 512, 28, 28], [32, 256, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], [], []]", 4, 0, 5860, 819, 5364], ["CudnnConvolutionBackward", "[[32, 256, 28, 28]]", 4, 0, 5860, 361, 5725], ["torch::autograd::AccumulateGrad", "[[256, 512, 1, 1]]", 4, 0, 23, 183, 601], ["ReluBackward1", "[[32, 512, 28, 28]]", 16, 0, 2973, 1047, 4048], ["AddBackward0", "[[32, 512, 28, 28]]", 16, 0, 0, 414, 414], ["CudnnBatchNormBackward", "[[32, 512, 28, 28]]", 20, 0, 6656, 2495, 14156], ["aten::cudnn_convolution_backward", "[[32, 128, 28, 28], [32, 512, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], [], []]", 16, 0, 12405, 2905, 20429], ["CudnnConvolutionBackward", "[[32, 512, 28, 28]]", 20, 0, 18877, 1808, 27210], ["torch::autograd::AccumulateGrad", "[[512, 128, 1, 1]]", 16, 0, 85, 696, 2346], ["ReluBackward1", "[[32, 128, 28, 28]]", 28, 0, 1382, 1820, 7278], ["CudnnBatchNormBackward", "[[32, 128, 28, 28]]", 28, 0, 2565, 3496, 19729], ["torch::autograd::AccumulateGrad", "[[128]]", 64, 0, 300, 2682, 9050], ["aten::cudnn_convolution_backward", "[[32, 128, 28, 28], [32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], [], []]", 12, 0, 8317, 2216, 16378], ["CudnnConvolutionBackward", "[[32, 128, 28, 28]]", 28, 0, 24483, 2554, 41979], ["torch::autograd::AccumulateGrad", "[[128, 128, 3, 3]]", 16, 0, 92, 707, 2249], ["aten::cudnn_convolution_backward", "[[32, 512, 28, 28], [32, 128, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], [], []]", 12, 0, 8616, 2195, 17663], ["torch::autograd::AccumulateGrad", "[[128, 512, 1, 1]]", 12, 0, 61, 543, 1756], ["aten::cudnn_convolution_backward", "[[32, 256, 56, 56], [32, 512, 28, 28], [512, 256, 1, 1], [], [], [], [], [], [], [], []]", 4, 0, 6472, 711, 4973], ["torch::autograd::AccumulateGrad", "[[512, 256, 1, 1]]", 4, 0, 19, 162, 545], ["aten::cudnn_convolution_backward", "[[32, 128, 56, 56], [32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], [], []]", 4, 0, 7550, 736, 5384], ["ReluBackward1", "[[32, 128, 56, 56]]", 4, 0, 741, 255, 983], ["CudnnBatchNormBackward", "[[32, 128, 56, 56]]", 4, 0, 1389, 479, 3302], ["aten::cudnn_convolution_backward", "[[32, 256, 56, 56], [32, 128, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], [], []]", 4, 0, 5521, 745, 5933], ["CudnnConvolutionBackward", "[[32, 128, 56, 56]]", 4, 0, 5521, 363, 6296], ["torch::autograd::AccumulateGrad", "[[128, 256, 1, 1]]", 4, 0, 13, 165, 556], ["ReluBackward1", "[[32, 256, 56, 56]]", 12, 0, 4388, 787, 3073], ["AddBackward0", "[[32, 256, 56, 56]]", 12, 0, 0, 319, 319], ["CudnnBatchNormBackward", "[[32, 256, 56, 56]]", 16, 0, 10250, 1926, 11410], ["aten::cudnn_convolution_backward", "[[32, 64, 56, 56], [32, 256, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], [], []]", 16, 0, 12468, 3039, 21525], ["CudnnConvolutionBackward", "[[32, 256, 56, 56]]", 16, 0, 12468, 1469, 22994], ["torch::autograd::AccumulateGrad", "[[256, 64, 1, 1]]", 16, 0, 60, 668, 2302], ["ReluBackward1", "[[32, 64, 56, 56]]", 24, 0, 2207, 1831, 6532], ["CudnnBatchNormBackward", "[[32, 64, 56, 56]]", 24, 0, 5040, 3140, 17635], ["torch::autograd::AccumulateGrad", "[[64]]", 56, 0, 184, 2428, 8579], ["aten::cudnn_convolution_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], [], []]", 12, 0, 15411, 2312, 16557], ["CudnnConvolutionBackward", "[[32, 64, 56, 56]]", 24, 0, 25503, 2198, 35570], ["torch::autograd::AccumulateGrad", "[[64, 64, 3, 3]]", 12, 0, 47, 525, 1726], ["aten::cudnn_convolution_backward", "[[32, 256, 56, 56], [32, 64, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 8749, 1566, 11035], ["torch::autograd::AccumulateGrad", "[[64, 256, 1, 1]]", 8, 0, 30, 328, 1107], ["aten::cudnn_convolution_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], [], []]", 4, 0, 1343, 847, 5780], ["torch::autograd::AccumulateGrad", "[[64, 64, 1, 1]]", 4, 0, 12, 174, 611], ["aten::zero_", "[[32, 64, 112, 112]]", 4, 0, 637, 202, 513], ["aten::zeros_like", "[[32, 64, 112, 112], [], [], [], [], []]", 4, 0, 637, 207, 1128], ["aten::resize_", "[[32, 64, 112, 112], [], []]", 8, 0, 0, 113, 113], ["aten::resize_as_", "[[32, 64, 112, 112], [32, 64, 112, 112], []]", 4, 0, 0, 158, 212], ["MaxPool2DWithIndicesBackward", "[[32, 64, 56, 56]]", 4, 0, 3394, 365, 3376], ["ReluBackward1", "[[32, 64, 112, 112]]", 4, 0, 1459, 274, 1089], ["CudnnBatchNormBackward", "[[32, 64, 112, 112]]", 4, 0, 3220, 548, 3064], ["aten::cudnn_convolution_backward", "[[32, 3, 224, 224], [32, 64, 112, 112], [64, 3, 7, 7], [], [], [], [], [], [], [], []]", 4, 0, 3990, 567, 3344], ["CudnnConvolutionBackward", "[[32, 64, 112, 112]]", 4, 0, 3990, 386, 3730], ["torch::autograd::AccumulateGrad", "[[64, 3, 7, 7]]", 4, 0, 12, 174, 650]]}}, "kernel_op_table": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "string", "name": "Operator"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Total Duration (us)"}, {"type": "number", "name": "Mean Duration (us)"}, {"type": "number", "name": "Max Duration (us)"}, {"type": "number", "name": "Min Duration (us)"}], "rows": [["ncclAllReduceRingLLKernel_sum_f32(ncclColl)", "CallTreeRoot", 20, 831936, 41596.8, 15686, 63818], ["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", "aten::cudnn_convolution_backward_input", 88, 48693, 553.3295454545455, 340, 1091], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 104, 48563, 466.9519230769231, 384, 822], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", "aten::cudnn_batch_norm_backward", 176, 37267, 211.7443181818182, 45, 818], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 40, 18970, 474.25, 362, 856], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", "aten::threshold_backward", 196, 18168, 92.6938775510204, 13, 368], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", "aten::add_", 1996, 17488, 8.761523046092185, 1, 364], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 40, 17482, 437.05, 386, 770], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", "aten::cudnn_batch_norm", 100, 17474, 174.74, 50, 429], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", "aten::cudnn_convolution_backward_weight", 32, 14988, 468.375, 333, 720], ["volta_scudnn_128x64_stridedB_interior_nn_v1", "aten::cudnn_convolution_backward_input", 40, 11835, 295.875, 261, 307], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", "aten::threshold_", 196, 11821, 60.31122448979592, 6, 250], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 12, 10814, 901.1666666666666, 889, 915], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", "CallTreeRoot", 64, 10323, 161.296875, 49, 367], ["volta_sgemm_128x64_nt", "aten::cudnn_convolution_backward_weight", 40, 8644, 216.1, 192, 277], ["volta_sgemm_128x64_nt", "aten::cudnn_convolution_backward_input", 40, 7784, 194.6, 162, 212], ["volta_sgemm_128x64_nn", "aten::cudnn_convolution", 40, 7636, 190.9, 158, 207], ["volta_scudnn_128x64_relu_interior_nn_v1", "aten::cudnn_convolution", 24, 7219, 300.7916666666667, 93, 528], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 16, 6820, 426.25, 404, 449], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", "aten::cudnn_convolution_backward_weight", 8, 5510, 688.75, 673, 729], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 8, 4903, 612.875, 210, 1007], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", "aten::cudnn_batch_norm", 112, 4749, 42.401785714285715, 14, 86], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", "aten::cudnn_convolution_backward_input", 12, 4506, 375.5, 364, 386], ["volta_scudnn_128x128_relu_medium_nn_v1", "aten::cudnn_convolution", 16, 4406, 275.375, 271, 281], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", "aten::cudnn_convolution", 12, 4400, 366.6666666666667, 364, 370], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", "aten::cudnn_convolution_backward_input", 88, 3814, 43.34090909090909, 5, 163], ["volta_scudnn_128x128_stridedB_interior_nn_v1", "aten::cudnn_convolution_backward_input", 12, 3559, 296.5833333333333, 295, 299], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", "CallTreeRoot", 644, 3330, 5.170807453416149, 1, 29], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", "aten::cudnn_convolution", 4, 3261, 815.25, 813, 817], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 4, 3132, 783.0, 760, 798], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", "aten::max_pool2d_with_indices_backward", 4, 2757, 689.25, 683, 695], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 4, 2752, 688.0, 661, 766], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", "aten::cudnn_convolution_backward_weight", 4, 2736, 684.0, 676, 688], ["volta_scudnn_128x128_stridedB_medium_nn_v1", "aten::cudnn_convolution_backward_input", 8, 2582, 322.75, 314, 334], ["volta_scudnn_128x64_relu_medium_nn_v1", "aten::cudnn_convolution", 4, 2555, 638.75, 637, 642], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", "aten::cudnn_convolution", 4, 2390, 597.5, 570, 673], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", "aten::cudnn_convolution", 4, 2381, 595.25, 573, 662], ["volta_scudnn_128x128_relu_interior_nn_v1", "aten::cudnn_convolution", 4, 2236, 559.0, 558, 561], ["volta_scudnn_128x128_stridedB_small_nn_v1", "aten::cudnn_convolution_backward_input", 4, 2214, 553.5, 549, 558], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", "aten::add", 644, 2108, 3.2732919254658386, 1, 36], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", "aten::cudnn_convolution_backward_input", 40, 1816, 45.4, 21, 73], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", "aten::cudnn_convolution_backward_weight", 40, 1776, 44.4, 21, 66], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", "aten::cudnn_convolution_backward_input", 40, 1712, 42.8, 20, 66], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", "aten::cudnn_convolution_backward_weight", 40, 1685, 42.125, 17, 67], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", "aten::cudnn_convolution", 40, 1676, 41.9, 21, 67], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", "aten::fill_", 652, 1619, 2.483128834355828, 0, 161], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", "aten::cudnn_batch_norm_backward", 36, 1584, 44.0, 19, 74], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", "aten::mul_", 644, 1557, 2.4177018633540373, 1, 24], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", "aten::cudnn_convolution", 40, 1481, 37.025, 18, 60], ["ncclBroadcastRingLLKernel_copy_i8(ncclColl)", "CallTreeRoot", 8, 1430, 178.75, 77, 284], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", "aten::cudnn_convolution", 8, 1121, 140.125, 98, 183], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", "aten::cudnn_convolution_backward_weight", 40, 1002, 25.05, 6, 67], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", "aten::cudnn_convolution_backward_input", 40, 999, 24.975, 7, 67], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", "aten::max_pool2d_with_indices", 4, 896, 224.0, 223, 225], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", "aten::cudnn_convolution", 40, 871, 21.775, 5, 65], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", "aten::cudnn_convolution_backward_input", 68, 463, 6.8088235294117645, 2, 10], ["volta_scudnn_128x64_stridedB_small_nn_v1", "aten::cudnn_convolution_backward_input", 4, 390, 97.5, 94, 101], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", "aten::cudnn_convolution_backward_input", 68, 287, 4.220588235294118, 1, 8], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", "aten::cudnn_convolution_backward_weight", 44, 224, 5.090909090909091, 1, 7], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", "aten::add", 212, 217, 1.0235849056603774, 1, 2], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", "aten::cudnn_convolution_backward_weight", 44, 205, 4.659090909090909, 2, 7], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", "aten::mean", 4, 172, 43.0, 43, 43], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<float, unsigned int, 1, 128, 1>(float*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<float, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", "aten::_cat", 4, 128, 32.0, 32, 32], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", "aten::cudnn_convolution", 52, 125, 2.4038461538461537, 2, 4], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", "aten::div", 4, 116, 29.0, 29, 29], ["volta_sgemm_64x32_sliced1x4_nn", "aten::mm", 4, 107, 26.75, 26, 27], ["volta_sgemm_64x32_sliced1x4_tn", "aten::addmm", 4, 98, 24.5, 24, 25], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", "aten::cudnn_convolution_backward_input", 12, 78, 6.5, 3, 10], ["volta_sgemm_128x32_nt", "aten::mm", 4, 76, 19.0, 19, 19], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<long, unsigned int, 1, 128, 1>(long*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<long, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", "aten::_cat", 4, 64, 16.0, 16, 16], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", "aten::cudnn_convolution", 12, 44, 3.6666666666666665, 3, 5], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", "aten::_log_softmax_backward_data", 4, 42, 10.5, 10, 11], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", "aten::_log_softmax", 4, 40, 10.0, 10, 10], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", "CallTreeRoot", 4, 33, 8.25, 8, 9], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", "aten::addmm", 4, 20, 5.0, 5, 5], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", "aten::nll_loss_forward", 4, 16, 4.0, 4, 4], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", "aten::addmm", 4, 15, 3.75, 3, 4], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", "aten::nll_loss_backward", 4, 8, 2.0, 2, 2], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", "aten::mm", 4, 8, 2.0, 2, 2]]}}, "kernel_pie": {"total": {"columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["ncclAllReduceRingLLKernel_sum_f32(ncclColl)", {"py/object": "numpy.float64", "dtype": "float64", "value": 849517.0}], ["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 48693.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 48563.0}], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 37267.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 31325.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 29989.0}], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 18970.0}], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 17482.0}], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 17474.0}], ["volta_sgemm_128x64_nt", {"py/object": "numpy.float64", "dtype": "float64", "value": 16428.0}], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 14988.0}], ["volta_scudnn_128x64_stridedB_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 11835.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 10814.0}], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 8906.0}], ["volta_sgemm_128x64_nn", {"py/object": "numpy.float64", "dtype": "float64", "value": 7636.0}], ["volta_scudnn_128x64_relu_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 7219.0}], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 6820.0}], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 5510.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 5277.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 4903.0}], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", {"py/object": "numpy.float64", "dtype": "float64", "value": 4749.0}], ["volta_scudnn_128x128_relu_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 4406.0}], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3814.0}], ["volta_scudnn_128x128_stridedB_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 3559.0}], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3492.0}], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3261.0}], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3193.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3132.0}], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2757.0}], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2752.0}], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 2736.0}], ["volta_scudnn_128x128_stridedB_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 2582.0}], ["volta_scudnn_128x64_relu_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 2555.0}], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 2390.0}], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2381.0}], ["volta_scudnn_128x128_relu_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 2236.0}], ["volta_scudnn_128x128_stridedB_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 2214.0}], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1870.0}], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1776.0}], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1685.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1619.0}], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1584.0}], ["ncclBroadcastRingLLKernel_copy_i8(ncclColl)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1430.0}], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1121.0}], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1002.0}], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 896.0}], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 588.0}], ["volta_scudnn_128x64_stridedB_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 390.0}], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 287.0}], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 224.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 217.0}], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 205.0}], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 172.0}], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<float, unsigned int, 1, 128, 1>(float*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<float, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 128.0}], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 122.0}], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", {"py/object": "numpy.float64", "dtype": "float64", "value": 116.0}], ["volta_sgemm_64x32_sliced1x4_nn", {"py/object": "numpy.float64", "dtype": "float64", "value": 107.0}], ["volta_sgemm_64x32_sliced1x4_tn", {"py/object": "numpy.float64", "dtype": "float64", "value": 98.0}], ["volta_sgemm_128x32_nt", {"py/object": "numpy.float64", "dtype": "float64", "value": 76.0}], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<long, unsigned int, 1, 128, 1>(long*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<long, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 64.0}], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 42.0}], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 40.0}], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 33.0}], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 23.0}], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", {"py/object": "numpy.float64", "dtype": "float64", "value": 20.0}], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", {"py/object": "numpy.float64", "dtype": "float64", "value": 16.0}], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", {"py/object": "numpy.float64", "dtype": "float64", "value": 8.0}]]}}, "kernel_table": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Total Duration (us)"}, {"type": "number", "name": "Mean Duration (us)"}, {"type": "number", "name": "Max Duration (us)"}, {"type": "number", "name": "Min Duration (us)"}], "rows": [["ncclAllReduceRingLLKernel_sum_f32(ncclColl)", 21, 849517, 40453, 63818, 15686], ["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", 88, 48693, 553, 1091, 340], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 104, 48563, 467, 822, 384], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", 176, 37267, 212, 818, 45], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", 3187, 31325, 10, 367, 1], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", 392, 29989, 77, 368, 6], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 40, 18970, 474, 856, 362], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 40, 17482, 437, 770, 386], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", 100, 17474, 175, 429, 50], ["volta_sgemm_128x64_nt", 80, 16428, 205, 277, 162], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", 32, 14988, 468, 720, 333], ["volta_scudnn_128x64_stridedB_interior_nn_v1", 40, 11835, 296, 307, 261], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 12, 10814, 901, 915, 889], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", 24, 8906, 371, 386, 364], ["volta_sgemm_128x64_nn", 40, 7636, 191, 207, 158], ["volta_scudnn_128x64_relu_interior_nn_v1", 24, 7219, 301, 528, 93], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 16, 6820, 426, 449, 404], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", 8, 5510, 689, 729, 673], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", 1449, 5277, 4, 29, 1], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 8, 4903, 613, 1007, 210], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", 112, 4749, 42, 86, 14], ["volta_scudnn_128x128_relu_medium_nn_v1", 16, 4406, 275, 281, 271], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", 88, 3814, 43, 163, 5], ["volta_scudnn_128x128_stridedB_interior_nn_v1", 12, 3559, 297, 299, 295], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", 80, 3492, 44, 73, 21], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 4, 3261, 815, 817, 813], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 80, 3193, 40, 66, 18], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 4, 3132, 783, 798, 760], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", 4, 2757, 689, 695, 683], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 4, 2752, 688, 766, 661], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", 4, 2736, 684, 688, 676], ["volta_scudnn_128x128_stridedB_medium_nn_v1", 8, 2582, 323, 334, 314], ["volta_scudnn_128x64_relu_medium_nn_v1", 4, 2555, 639, 642, 637], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", 4, 2390, 598, 673, 570], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 4, 2381, 595, 662, 573], ["volta_scudnn_128x128_relu_interior_nn_v1", 4, 2236, 559, 561, 558], ["volta_scudnn_128x128_stridedB_small_nn_v1", 4, 2214, 554, 558, 549], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", 80, 1870, 23, 67, 5], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 40, 1776, 44, 66, 21], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", 40, 1685, 42, 67, 17], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", 652, 1619, 2, 161, 0], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", 36, 1584, 44, 74, 19], ["ncclBroadcastRingLLKernel_copy_i8(ncclColl)", 8, 1430, 179, 284, 77], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", 8, 1121, 140, 183, 98], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", 40, 1002, 25, 67, 6], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", 4, 896, 224, 225, 223], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", 120, 588, 5, 10, 2], ["volta_scudnn_128x64_stridedB_small_nn_v1", 4, 390, 98, 101, 94], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", 68, 287, 4, 8, 1], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", 44, 224, 5, 7, 1], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", 212, 217, 1, 2, 1], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", 44, 205, 5, 7, 2], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", 4, 172, 43, 43, 43], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<float, unsigned int, 1, 128, 1>(float*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<float, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", 4, 128, 32, 32, 32], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", 24, 122, 5, 10, 3], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", 4, 116, 29, 29, 29], ["volta_sgemm_64x32_sliced1x4_nn", 4, 107, 27, 27, 26], ["volta_sgemm_64x32_sliced1x4_tn", 4, 98, 24, 25, 24], ["volta_sgemm_128x32_nt", 4, 76, 19, 19, 19], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<long, unsigned int, 1, 128, 1>(long*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<long, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", 4, 64, 16, 16, 16], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", 4, 42, 10, 11, 10], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", 4, 40, 10, 10, 10], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", 4, 33, 8, 9, 8], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", 8, 23, 3, 4, 2], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", 4, 20, 5, 5, 5], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", 4, 16, 4, 4, 4], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", 4, 8, 2, 2, 2]]}}, "trace_file_path": "./data/tracing\\resnet50_newAPI_ddp\\worker1_span1.pt.trace.json.gz"}]}]}]}}