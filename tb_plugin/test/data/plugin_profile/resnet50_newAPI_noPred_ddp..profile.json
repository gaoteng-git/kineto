{"py/object": "tensorboard_plugin_torch_profiler.run.Run", "name": "resnet50_newAPI_noPred_ddp", "run_dir": "./data/tracing\\resnet50_newAPI_noPred_ddp", "profiles": {"py/reduce": [{"py/type": "collections.OrderedDict"}, {"py/tuple": []}, null, null, {"py/tuple": [{"py/tuple": ["worker0_span1", {"py/object": "tensorboard_plugin_torch_profiler.run.RunProfile", "worker": "worker0_span1", "views": [{"py/object": "tensorboard_plugin_torch_profiler.consts.View", "py/newargs": {"py/tuple": [1, "overall", "Overview"]}, "py/seq": [1, "overall", "Overview"]}, {"py/object": "tensorboard_plugin_torch_profiler.consts.View", "py/newargs": {"py/tuple": [2, "operator", "Operator"]}, "py/seq": [2, "operator", "Operator"]}, {"py/object": "tensorboard_plugin_torch_profiler.consts.View", "py/newargs": {"py/tuple": [3, "kernel", "Kernel"]}, "py/seq": [3, "kernel", "Kernel"]}, {"py/object": "tensorboard_plugin_torch_profiler.consts.View", "py/newargs": {"py/tuple": [4, "trace", "Trace"]}, "py/seq": [4, "trace", "Trace"]}], "is_gpu_used": true, "overview": {"steps": {"columns": [{"type": "string", "name": "Step"}, {"type": "number", "name": "Kernel"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memcpy"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memset"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Runtime"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "DataLoader"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "CPU Exec"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Other"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}], "rows": [["2", 255518, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 2<br>Total: 2146308us<br><b>Kernel: 255518us</b><br>Percentage: 11.91%</div>", 2031, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 2<br>Total: 2146308us<br><b>Memcpy: 2031us</b><br>Percentage: 0.09%</div>", 1, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 2<br>Total: 2146308us<br><b>Memset: 1us</b><br>Percentage: 0.0%</div>", 92834, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 2<br>Total: 2146308us<br><b>Runtime: 92834us</b><br>Percentage: 4.33%</div>", 1519154, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 2<br>Total: 2146308us<br><b>DataLoader: 1519154us</b><br>Percentage: 70.78%</div>", 246138, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 2<br>Total: 2146308us<br><b>CPU Exec: 246138us</b><br>Percentage: 11.47%</div>", 30632, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 2<br>Total: 2146308us<br><b>Other: 30632us</b><br>Percentage: 1.43%</div>"], ["3", 249312, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 3<br>Total: 2016356us<br><b>Kernel: 249312us</b><br>Percentage: 12.36%</div>", 1963, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 3<br>Total: 2016356us<br><b>Memcpy: 1963us</b><br>Percentage: 0.1%</div>", 1, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 3<br>Total: 2016356us<br><b>Memset: 1us</b><br>Percentage: 0.0%</div>", 17742, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 3<br>Total: 2016356us<br><b>Runtime: 17742us</b><br>Percentage: 0.88%</div>", 1486770, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 3<br>Total: 2016356us<br><b>DataLoader: 1486770us</b><br>Percentage: 73.74%</div>", 224008, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 3<br>Total: 2016356us<br><b>CPU Exec: 224008us</b><br>Percentage: 11.11%</div>", 36560, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 3<br>Total: 2016356us<br><b>Other: 36560us</b><br>Percentage: 1.81%</div>"], ["4", 250133, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 4<br>Total: 2041914us<br><b>Kernel: 250133us</b><br>Percentage: 12.25%</div>", 1987, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 4<br>Total: 2041914us<br><b>Memcpy: 1987us</b><br>Percentage: 0.1%</div>", 1, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 4<br>Total: 2041914us<br><b>Memset: 1us</b><br>Percentage: 0.0%</div>", 21217, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 4<br>Total: 2041914us<br><b>Runtime: 21217us</b><br>Percentage: 1.04%</div>", 1471126, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 4<br>Total: 2041914us<br><b>DataLoader: 1471126us</b><br>Percentage: 72.05%</div>", 266318, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 4<br>Total: 2041914us<br><b>CPU Exec: 266318us</b><br>Percentage: 13.04%</div>", 31132, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 4<br>Total: 2041914us<br><b>Other: 31132us</b><br>Percentage: 1.52%</div>"], ["5", 356190, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 1936968us<br><b>Kernel: 356190us</b><br>Percentage: 18.39%</div>", 1851, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 1936968us<br><b>Memcpy: 1851us</b><br>Percentage: 0.1%</div>", 1, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 1936968us<br><b>Memset: 1us</b><br>Percentage: 0.0%</div>", 10277, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 1936968us<br><b>Runtime: 10277us</b><br>Percentage: 0.53%</div>", 1382321, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 1936968us<br><b>DataLoader: 1382321us</b><br>Percentage: 71.37%</div>", 162194, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 1936968us<br><b>CPU Exec: 162194us</b><br>Percentage: 8.37%</div>", 24134, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 1936968us<br><b>Other: 24134us</b><br>Percentage: 1.25%</div>"], ["6", 460218, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1940219us<br><b>Kernel: 460218us</b><br>Percentage: 23.72%</div>", 1964, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1940219us<br><b>Memcpy: 1964us</b><br>Percentage: 0.1%</div>", 1, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1940219us<br><b>Memset: 1us</b><br>Percentage: 0.0%</div>", 10326, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1940219us<br><b>Runtime: 10326us</b><br>Percentage: 0.53%</div>", 1277880, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1940219us<br><b>DataLoader: 1277880us</b><br>Percentage: 65.86%</div>", 165375, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1940219us<br><b>CPU Exec: 165375us</b><br>Percentage: 8.52%</div>", 24455, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1940219us<br><b>Other: 24455us</b><br>Percentage: 1.26%</div>"], ["7", 477515, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 2004353us<br><b>Kernel: 477515us</b><br>Percentage: 23.82%</div>", 1970, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 2004353us<br><b>Memcpy: 1970us</b><br>Percentage: 0.1%</div>", 1, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 2004353us<br><b>Memset: 1us</b><br>Percentage: 0.0%</div>", 10660, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 2004353us<br><b>Runtime: 10660us</b><br>Percentage: 0.53%</div>", 1324608, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 2004353us<br><b>DataLoader: 1324608us</b><br>Percentage: 66.09%</div>", 164988, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 2004353us<br><b>CPU Exec: 164988us</b><br>Percentage: 8.23%</div>", 24611, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 2004353us<br><b>Other: 24611us</b><br>Percentage: 1.23%</div>"], ["8", 460765, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1930160us<br><b>Kernel: 460765us</b><br>Percentage: 23.87%</div>", 1956, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1930160us<br><b>Memcpy: 1956us</b><br>Percentage: 0.1%</div>", 1, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1930160us<br><b>Memset: 1us</b><br>Percentage: 0.0%</div>", 10758, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1930160us<br><b>Runtime: 10758us</b><br>Percentage: 0.56%</div>", 1269575, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1930160us<br><b>DataLoader: 1269575us</b><br>Percentage: 65.78%</div>", 162637, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1930160us<br><b>CPU Exec: 162637us</b><br>Percentage: 8.43%</div>", 24468, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1930160us<br><b>Other: 24468us</b><br>Percentage: 1.27%</div>"], ["9", 818, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 818us<br><b>Kernel: 818us</b><br>Percentage: 100.0%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 818us<br><b>Memcpy: 0us</b><br>Percentage: 0.0%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 818us<br><b>Memset: 0us</b><br>Percentage: 0.0%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 818us<br><b>Runtime: 0us</b><br>Percentage: 0.0%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 818us<br><b>DataLoader: 0us</b><br>Percentage: 0.0%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 818us<br><b>CPU Exec: 0us</b><br>Percentage: 0.0%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 818us<br><b>Other: 0us</b><br>Percentage: 0.0%</div>"]]}, "performance": [{"name": "Average Step Time", "description": "", "value": 1752137, "extra": 100, "children": [{"name": "Kernel", "description": "", "value": 313809, "extra": 17.91}, {"name": "Memcpy", "description": "", "value": 1715, "extra": 0.1}, {"name": "Memset", "description": "", "value": 1, "extra": 0.0}, {"name": "Runtime", "description": "", "value": 21727, "extra": 1.24}, {"name": "DataLoader", "description": "", "value": 1216429, "extra": 69.43}, {"name": "CPU Exec", "description": "", "value": 173957, "extra": 9.93}, {"name": "Other", "description": "", "value": 24499, "extra": 1.4}]}], "recommendations": "<ul><li>This run has high time cost on input data loading. 69.4% of the step time is in DataLoader. You could try to set num_workers on DataLoader's construction and enable multi-processes on data loading. Reference: <a href =\"https://pytorch.org/docs/stable/data.html#single-and-multi-process-data-loading\" target=\"_blank\">Single- and Multi-process Data Loading</a></li></ul>"}, "operation_pie_by_name": {"device_total_time": {"title": "Device Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward", 611668], ["CudnnConvolutionBackward", 611668], ["aten::cudnn_convolution", 325278], ["aten::_convolution", 325278], ["aten::convolution", 325278], ["aten::conv2d", 325278], ["aten::cudnn_convolution_backward_weight", 314406], ["aten::cudnn_convolution_backward_input", 297262], ["aten::cudnn_batch_norm_backward", 77881], ["CudnnBatchNormBackward", 77881], ["aten::cudnn_batch_norm", 44756], ["aten::_batch_norm_impl_index", 44756], ["aten::batch_norm", 44756], ["aten::threshold_backward", 36462], ["ReluBackward1", 36462], ["aten::add_", 33639], ["aten::threshold_", 23854], ["aten::relu_", 23854], ["aten::copy_", 15835], ["aten::to", 13595], ["torch::autograd::AccumulateGrad", 7509], ["aten::max_pool2d_with_indices_backward", 6837], ["MaxPool2DWithIndicesBackward", 6837], ["aten::add", 4678], ["aten::fill_", 2985], ["aten::zero_", 2977], ["aten::mul_", 2728], ["aten::max_pool2d_with_indices", 1785], ["aten::max_pool2d", 1785], ["aten::zeros_like", 1285], ["aten::_cat", 390], ["aten::cat", 390], ["aten::mm", 384], ["AddmmBackward", 384], ["aten::clone", 359], ["aten::mean", 346], ["aten::adaptive_avg_pool2d", 346], ["aten::addmm", 269], ["aten::div", 230], ["MeanBackward1", 230], ["aten::_log_softmax_backward_data", 86], ["LogSoftmaxBackward", 86], ["aten::_log_softmax", 82], ["aten::log_softmax", 82], ["aten::nll_loss_forward", 33], ["aten::nll_loss", 33], ["aten::nll_loss_backward", 24], ["NllLossBackward", 24], ["aten::_local_scalar_dense", 12], ["aten::item", 12], ["aten::ones_like", 8]]}, "device_self_time": {"title": "Device Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution", 325278], ["aten::cudnn_convolution_backward_weight", 314406], ["aten::cudnn_convolution_backward_input", 297262], ["aten::cudnn_batch_norm_backward", 77881], ["aten::cudnn_batch_norm", 44756], ["aten::threshold_backward", 36462], ["aten::add_", 33639], ["aten::threshold_", 23854], ["aten::copy_", 15835], ["aten::max_pool2d_with_indices_backward", 5552], ["aten::add", 4678], ["aten::fill_", 2985], ["aten::mul_", 2728], ["aten::max_pool2d_with_indices", 1785], ["aten::_cat", 390], ["aten::mm", 384], ["aten::mean", 346], ["aten::addmm", 269], ["aten::div", 230], ["aten::_log_softmax_backward_data", 86], ["aten::_log_softmax", 82], ["aten::nll_loss_forward", 33], ["aten::nll_loss_backward", 24], ["aten::_local_scalar_dense", 12]]}, "host_total_time": {"title": "Host Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 4496792], ["aten::cat", 4301571], ["aten::_cat", 4298425], ["aten::conv2d", 3274030], ["aten::convolution", 3252206], ["aten::_convolution", 3233642], ["aten::cudnn_convolution", 3187531], ["aten::to", 2166925], ["CudnnConvolutionBackward", 1620598], ["aten::cudnn_convolution_backward", 1584531], ["aten::contiguous", 1299782], ["aten::clone", 1235688], ["aten::div_", 1171774], ["aten::stack", 1138781], ["aten::div", 1122600], ["aten::sub_", 973440], ["aten::addmm", 880342], ["aten::cudnn_convolution_backward_weight", 878178], ["aten::cudnn_convolution_backward_input", 627054], ["aten::empty", 481619], ["aten::batch_norm", 480651], ["aten::_batch_norm_impl_index", 459678], ["aten::cudnn_batch_norm", 379724], ["aten::add_", 356725], ["aten::add", 306083], ["CudnnBatchNormBackward", 284403], ["aten::cudnn_batch_norm_backward", 227382], ["aten::view", 215975], ["torch::autograd::AccumulateGrad", 195245], ["aten::eq", 190971], ["aten::empty_strided", 182074], ["aten::lt", 177125], ["aten::item", 133584], ["aten::narrow", 130231], ["aten::zero_", 125873], ["aten::mul_", 122349], ["aten::pin_memory", 122219], ["aten::slice", 95822], ["ReluBackward1", 95372], ["aten::exp", 85468], ["aten::_local_scalar_dense", 72872], ["aten::relu_", 72153], ["aten::select", 69905], ["aten::threshold_backward", 69789], ["aten::any", 62668], ["aten::randint", 60289], ["aten::fill_", 59831], ["aten::empty_like", 59519], ["aten::uniform_", 58037], ["aten::resize_", 53786], ["aten::as_strided", 46936], ["aten::stride", 42392], ["aten::log", 40092], ["aten::is_nonzero", 36462], ["aten::rand", 32191], ["aten::permute", 25499], ["aten::threshold_", 23759], ["aten::set_", 18797], ["aten::random_", 15915], ["aten::is_floating_point", 12717], ["aten::unsqueeze", 11752], ["aten::detach_", 10657], ["AddmmBackward", 8872], ["aten::adaptive_avg_pool2d", 8833], ["aten::mean", 8436], ["aten::max_pool2d", 6137], ["aten::detach", 6004], ["MaxPool2DWithIndicesBackward", 5733], ["aten::max_pool2d_with_indices", 5679], ["aten::max_pool2d_with_indices_backward", 5077], ["detach_", 4657], ["aten::t", 4608], ["aten::mm", 4583], ["aten::zeros", 4284], ["aten::is_pinned", 4075], ["MeanBackward1", 3590], ["AddBackward0", 3559], ["aten::log_softmax", 2928], ["LogSoftmaxBackward", 2678], ["aten::_log_softmax", 2535], ["detach", 2417], ["aten::nll_loss", 2248], ["aten::_log_softmax_backward_data", 2166], ["NllLossBackward", 2149], ["aten::transpose", 2026], ["aten::reshape", 1899], ["aten::nll_loss_forward", 1865], ["aten::zeros_like", 1799], ["aten::ones_like", 1766], ["aten::flatten", 1510], ["aten::nll_loss_backward", 1406], ["aten::expand", 1335], ["ViewBackward", 1160], ["TBackward", 1103], ["aten::resize_as_", 533], ["nccl:broadcast", 532], ["aten::conj", 297]]}, "host_self_time": {"title": "Host Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 4496792], ["aten::_cat", 4288871], ["aten::cudnn_convolution", 3054770], ["aten::div_", 1171774], ["aten::div", 1079850], ["aten::sub_", 973440], ["aten::addmm", 876946], ["aten::cudnn_convolution_backward_weight", 815996], ["aten::cudnn_convolution_backward_input", 563905], ["aten::empty", 481619], ["aten::add_", 356725], ["aten::cudnn_batch_norm", 278027], ["aten::add", 234856], ["aten::view", 215975], ["aten::empty_strided", 182074], ["aten::cudnn_batch_norm_backward", 152711], ["aten::mul_", 122349], ["aten::contiguous", 108650], ["aten::to", 89651], ["aten::slice", 79648], ["aten::cudnn_convolution_backward", 74405], ["aten::_local_scalar_dense", 72872], ["aten::zero_", 70900], ["aten::eq", 62375], ["aten::item", 60712], ["aten::select", 60118], ["aten::fill_", 59831], ["aten::clone", 59059], ["aten::_batch_norm_impl_index", 58982], ["aten::uniform_", 58037], ["torch::autograd::AccumulateGrad", 57545], ["aten::lt", 54685], ["aten::resize_", 53786], ["aten::threshold_backward", 53428], ["CudnnBatchNormBackward", 49985], ["aten::exp", 48697], ["aten::relu_", 48394], ["aten::as_strided", 46936], ["aten::any", 44417], ["aten::stride", 42392], ["aten::_convolution", 40359], ["CudnnConvolutionBackward", 36067], ["aten::randint", 34989], ["aten::narrow", 34409], ["aten::log", 33857], ["aten::empty_like", 33235], ["ReluBackward1", 25583], ["aten::threshold_", 23759], ["aten::pin_memory", 22068], ["aten::conv2d", 21824], ["aten::permute", 21543], ["aten::batch_norm", 20973], ["aten::set_", 18797], ["aten::convolution", 18564], ["aten::rand", 17794], ["aten::random_", 15915], ["aten::is_floating_point", 12717], ["aten::is_nonzero", 11538], ["aten::unsqueeze", 8539], ["aten::mean", 8117], ["aten::detach_", 6000], ["aten::stack", 5232], ["detach_", 4657], ["aten::is_pinned", 4075], ["aten::max_pool2d_with_indices", 3871], ["aten::detach", 3587], ["aten::mm", 3582], ["AddBackward0", 3559], ["aten::cat", 3146], ["aten::t", 2582], ["detach", 2417], ["aten::max_pool2d_with_indices_backward", 2218], ["aten::zeros", 2146], ["aten::nll_loss_forward", 1865], ["aten::_log_softmax", 1719], ["aten::nll_loss_backward", 1406], ["aten::transpose", 1399], ["AddmmBackward", 1396], ["aten::_log_softmax_backward_data", 1244], ["aten::expand", 1074], ["NllLossBackward", 743], ["MeanBackward1", 682], ["MaxPool2DWithIndicesBackward", 656], ["nccl:broadcast", 532], ["aten::ones_like", 523], ["LogSoftmaxBackward", 512], ["aten::reshape", 497], ["aten::max_pool2d", 458], ["aten::flatten", 406], ["aten::adaptive_avg_pool2d", 397], ["aten::log_softmax", 393], ["aten::nll_loss", 383], ["aten::zeros_like", 372], ["ViewBackward", 365], ["aten::resize_as_", 349], ["aten::conj", 297], ["TBackward", 281]]}}, "operation_table_by_name": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Device Self Duration (us)"}, {"type": "number", "name": "Device Total Duration (us)"}, {"type": "number", "name": "Host Self Duration (us)"}, {"type": "number", "name": "Host Total Duration (us)"}], "rows": [["aten::cudnn_convolution", 424, 325278, 325278, 3054770, 3187531], ["aten::cudnn_convolution_backward_weight", 424, 314406, 314406, 815996, 878178], ["aten::cudnn_convolution_backward_input", 416, 297262, 297262, 563905, 627054], ["aten::cudnn_batch_norm_backward", 424, 77881, 77881, 152711, 227382], ["aten::cudnn_batch_norm", 424, 44756, 44756, 278027, 379724], ["aten::threshold_backward", 392, 36462, 36462, 53428, 69789], ["aten::add_", 3670, 33639, 33639, 356725, 356725], ["aten::threshold_", 392, 23854, 23854, 23759, 23759], ["aten::copy_", 3166, 15835, 15835, 4496792, 4496792], ["aten::max_pool2d_with_indices_backward", 8, 5552, 6837, 2218, 5077], ["aten::add", 1712, 4678, 4678, 234856, 306083], ["aten::fill_", 1431, 2985, 2985, 59831, 59831], ["aten::mul_", 1127, 2728, 2728, 122349, 122349], ["aten::max_pool2d_with_indices", 8, 1785, 1785, 3871, 5679], ["aten::_cat", 24, 390, 390, 4288871, 4298425], ["aten::mm", 16, 384, 384, 3582, 4583], ["aten::mean", 8, 346, 346, 8117, 8436], ["aten::addmm", 8, 269, 269, 876946, 880342], ["aten::div", 264, 230, 230, 1079850, 1122600], ["aten::_log_softmax_backward_data", 8, 86, 86, 1244, 2166], ["aten::_log_softmax", 8, 82, 82, 1719, 2535], ["aten::nll_loss_forward", 8, 33, 33, 1865, 1865], ["aten::nll_loss_backward", 8, 24, 24, 1406, 1406], ["aten::_local_scalar_dense", 2949, 12, 12, 72872, 72872], ["aten::empty", 13221, 0, 0, 481619, 481619], ["aten::random_", 513, 0, 0, 15915, 15915], ["aten::is_floating_point", 1223, 0, 0, 12717, 12717], ["aten::item", 2949, 0, 12, 60712, 133584], ["aten::zero_", 1167, 0, 2977, 70900, 125873], ["aten::zeros", 32, 0, 0, 2146, 4284], ["aten::uniform_", 958, 0, 0, 58037, 58037], ["aten::to", 1927, 0, 13595, 89651, 2166925], ["detach_", 359, 0, 0, 4657, 4657], ["aten::detach_", 359, 0, 0, 6000, 10657], ["aten::log", 351, 0, 0, 33857, 40092], ["aten::as_strided", 2967, 0, 0, 46936, 46936], ["aten::select", 702, 0, 0, 60118, 69905], ["aten::resize_", 3703, 0, 0, 53786, 53786], ["aten::exp", 702, 0, 0, 48697, 85468], ["aten::randint", 512, 0, 0, 34989, 60289], ["aten::rand", 256, 0, 0, 17794, 32191], ["aten::empty_strided", 1626, 0, 0, 182074, 182074], ["aten::lt", 512, 0, 0, 54685, 177125], ["aten::is_nonzero", 512, 0, 0, 11538, 36462], ["aten::set_", 272, 0, 0, 18797, 18797], ["aten::view", 4176, 0, 0, 215975, 215975], ["aten::permute", 256, 0, 0, 21543, 25499], ["aten::empty_like", 712, 0, 0, 33235, 59519], ["aten::contiguous", 7920, 0, 0, 108650, 1299782], ["aten::clone", 417, 0, 359, 59059, 1235688], ["aten::eq", 512, 0, 0, 62375, 190971], ["aten::any", 256, 0, 0, 44417, 62668], ["aten::sub_", 256, 0, 0, 973440, 973440], ["aten::div_", 256, 0, 0, 1171774, 1171774], ["aten::unsqueeze", 256, 0, 0, 8539, 11752], ["aten::slice", 1280, 0, 0, 79648, 95822], ["aten::narrow", 1280, 0, 0, 34409, 130231], ["aten::stride", 6528, 0, 0, 42392, 42392], ["aten::cat", 24, 0, 390, 3146, 4301571], ["aten::stack", 8, 0, 0, 5232, 1138781], ["aten::is_pinned", 16, 0, 0, 4075, 4075], ["aten::pin_memory", 16, 0, 0, 22068, 122219], ["nccl:broadcast", 18, 0, 0, 532, 532], ["aten::_convolution", 424, 0, 325278, 40359, 3233642], ["aten::convolution", 424, 0, 325278, 18564, 3252206], ["aten::conv2d", 424, 0, 325278, 21824, 3274030], ["aten::_batch_norm_impl_index", 424, 0, 44756, 58982, 459678], ["aten::batch_norm", 424, 0, 44756, 20973, 480651], ["aten::relu_", 392, 0, 23854, 48394, 72153], ["aten::max_pool2d", 8, 0, 1785, 458, 6137], ["aten::adaptive_avg_pool2d", 8, 0, 346, 397, 8833], ["aten::reshape", 16, 0, 0, 497, 1899], ["aten::flatten", 8, 0, 0, 406, 1510], ["aten::transpose", 40, 0, 0, 1399, 2026], ["aten::t", 40, 0, 0, 2582, 4608], ["aten::expand", 16, 0, 0, 1074, 1335], ["aten::log_softmax", 8, 0, 82, 393, 2928], ["aten::nll_loss", 8, 0, 33, 383, 2248], ["aten::ones_like", 8, 0, 8, 523, 1766], ["detach", 161, 0, 0, 2417, 2417], ["aten::detach", 161, 0, 0, 3587, 6004], ["NllLossBackward", 8, 0, 24, 743, 2149], ["LogSoftmaxBackward", 8, 0, 86, 512, 2678], ["aten::conj", 16, 0, 0, 297, 297], ["AddmmBackward", 8, 0, 384, 1396, 8872], ["torch::autograd::AccumulateGrad", 1288, 0, 7509, 57545, 195245], ["TBackward", 8, 0, 0, 281, 1103], ["ViewBackward", 8, 0, 0, 365, 1160], ["MeanBackward1", 8, 0, 230, 682, 3590], ["ReluBackward1", 392, 0, 36462, 25583, 95372], ["AddBackward0", 128, 0, 0, 3559, 3559], ["CudnnBatchNormBackward", 424, 0, 77881, 49985, 284403], ["aten::cudnn_convolution_backward", 424, 0, 611668, 74405, 1584531], ["CudnnConvolutionBackward", 424, 0, 611668, 36067, 1620598], ["aten::zeros_like", 8, 0, 1285, 372, 1799], ["aten::resize_as_", 8, 0, 0, 349, 533], ["MaxPool2DWithIndicesBackward", 8, 0, 6837, 656, 5733]]}}, "operation_pie_by_name_input": {"device_total_time": {"title": "Device Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["CudnnConvolutionBackward", 91176], ["CudnnConvolutionBackward", 79199], ["CudnnConvolutionBackward", 78021], ["CudnnConvolutionBackward", 70663], ["CudnnConvolutionBackward", 60092], ["CudnnConvolutionBackward", 56725], ["CudnnConvolutionBackward", 52689], ["aten::cudnn_convolution_backward", 42179], ["aten::cudnn_convolution_backward", 40994], ["aten::cudnn_convolution_backward", 39261], ["aten::cudnn_convolution_backward", 36392], ["CudnnConvolutionBackward", 36392], ["aten::cudnn_convolution_backward", 35958], ["aten::cudnn_convolution_backward", 32517], ["aten::cudnn_convolution_backward_weight", 31776], ["aten::cudnn_convolution_backward", 31714], ["aten::cudnn_convolution_backward", 29924], ["aten::cudnn_convolution_backward_input", 29075], ["aten::cudnn_convolution_backward", 28683], ["CudnnConvolutionBackward", 28683], ["aten::cudnn_convolution_backward", 28621], ["aten::cudnn_convolution_backward_input", 28016], ["aten::cudnn_convolution_backward_input", 25953], ["aten::cudnn_convolution_backward", 25120], ["aten::cudnn_convolution_backward", 24280], ["aten::cudnn_convolution", 24045], ["aten::_convolution", 24045], ["aten::convolution", 24045], ["aten::conv2d", 24045], ["aten::cudnn_convolution_backward", 23871], ["CudnnConvolutionBackward", 23871], ["aten::cudnn_convolution_backward", 23838], ["aten::cudnn_convolution_backward", 23625], ["aten::cudnn_convolution_backward", 23200], ["aten::cudnn_convolution_backward_weight", 21857], ["aten::cudnn_convolution_backward_weight", 21851], ["aten::cudnn_convolution_backward", 21505], ["CudnnConvolutionBackward", 21505], ["aten::cudnn_convolution", 21482], ["aten::_convolution", 21482], ["aten::convolution", 21482], ["aten::conv2d", 21482], ["aten::cudnn_convolution", 21136], ["aten::_convolution", 21136], ["aten::convolution", 21136], ["aten::conv2d", 21136], ["aten::cudnn_convolution_backward", 20975], ["aten::cudnn_convolution_backward", 20767], ["aten::cudnn_convolution_backward_input", 20738], ["aten::cudnn_batch_norm_backward", 20540], ["CudnnBatchNormBackward", 20540], ["aten::cudnn_convolution_backward_input", 20240], ["aten::cudnn_convolution_backward", 19398], ["aten::cudnn_convolution", 19366], ["aten::_convolution", 19366], ["aten::convolution", 19366], ["aten::conv2d", 19366], ["aten::cudnn_convolution_backward_input", 19137], ["aten::cudnn_convolution_backward", 19098], ["aten::cudnn_convolution_backward_weight", 18587], ["aten::cudnn_convolution_backward_weight", 18523], ["aten::cudnn_convolution", 17657], ["aten::_convolution", 17657], ["aten::convolution", 17657], ["aten::conv2d", 17657], ["aten::cudnn_convolution_backward_weight", 16632], ["aten::cudnn_convolution", 16606], ["aten::_convolution", 16606], ["aten::convolution", 16606], ["aten::conv2d", 16606], ["aten::cudnn_convolution", 16011], ["aten::_convolution", 16011], ["aten::convolution", 16011], ["aten::conv2d", 16011], ["aten::cudnn_convolution", 15786], ["aten::_convolution", 15786], ["aten::convolution", 15786], ["aten::conv2d", 15786], ["aten::cudnn_convolution_backward_weight", 15734], ["aten::cudnn_convolution_backward_weight", 15718], ["aten::cudnn_convolution", 15711], ["aten::_convolution", 15711], ["aten::convolution", 15711], ["aten::conv2d", 15711], ["aten::cudnn_convolution_backward_input", 15703], ["aten::cudnn_convolution", 15643], ["aten::_convolution", 15643], ["aten::convolution", 15643], ["aten::conv2d", 15643], ["aten::cudnn_convolution", 15399], ["aten::_convolution", 15399], ["aten::convolution", 15399], ["aten::conv2d", 15399], ["aten::cudnn_convolution_backward_weight", 15241], ["aten::cudnn_convolution_backward_input", 15082], ["aten::cudnn_convolution_backward_input", 14776], ["aten::cudnn_convolution_backward_input", 14541], ["aten::cudnn_convolution", 14401], ["aten::_convolution", 14401], ["aten::convolution", 14401], ["aten::conv2d", 14401], ["aten::cudnn_convolution", 13922], ["aten::_convolution", 13922], ["aten::convolution", 13922], ["aten::conv2d", 13922], ["aten::copy_", 13570], ["aten::to", 13570], ["aten::cudnn_convolution_backward_input", 13442], ["aten::cudnn_convolution", 13397], ["aten::_convolution", 13397], ["aten::convolution", 13397], ["aten::conv2d", 13397], ["aten::cudnn_batch_norm_backward", 13251], ["CudnnBatchNormBackward", 13251], ["aten::cudnn_convolution_backward_weight", 13208], ["aten::cudnn_convolution", 13117], ["aten::_convolution", 13117], ["aten::convolution", 13117], ["aten::conv2d", 13117], ["aten::cudnn_convolution_backward_input", 13012], ["aten::cudnn_convolution_backward_weight", 12918], ["aten::cudnn_batch_norm", 12806], ["aten::_batch_norm_impl_index", 12806], ["aten::batch_norm", 12806], ["aten::cudnn_convolution_backward_weight", 12652], ["aten::cudnn_convolution_backward", 12652], ["CudnnConvolutionBackward", 12652], ["aten::cudnn_convolution", 12301], ["aten::_convolution", 12301], ["aten::convolution", 12301], ["aten::conv2d", 12301], ["aten::cudnn_convolution_backward_weight", 12000], ["aten::cudnn_convolution_backward_input", 11640], ["aten::cudnn_convolution_backward_weight", 11556], ["aten::cudnn_convolution_backward_input", 11337], ["aten::cudnn_convolution_backward_weight", 10859], ["aten::cudnn_convolution", 10752], ["aten::_convolution", 10752], ["aten::convolution", 10752], ["aten::conv2d", 10752], ["aten::cudnn_convolution_backward_weight", 10661], ["aten::cudnn_convolution_backward_input", 10658], ["aten::cudnn_convolution_backward_input", 10630], ["aten::cudnn_convolution_backward_input", 10610], ["aten::cudnn_convolution", 10248], ["aten::_convolution", 10248], ["aten::convolution", 10248], ["aten::conv2d", 10248], ["aten::cudnn_convolution_backward_weight", 10157], ["aten::cudnn_batch_norm_backward", 10146], ["CudnnBatchNormBackward", 10146], ["aten::cudnn_batch_norm_backward", 10088], ["CudnnBatchNormBackward", 10088], ["aten::cudnn_convolution_backward_input", 9949], ["aten::cudnn_convolution", 9896], ["aten::_convolution", 9896], ["aten::convolution", 9896], ["aten::conv2d", 9896], ["aten::cudnn_convolution_backward_weight", 9664], ["aten::cudnn_convolution_backward_weight", 9335], ["aten::cudnn_convolution", 9179], ["aten::_convolution", 9179], ["aten::convolution", 9179], ["aten::conv2d", 9179], ["aten::cudnn_convolution_backward_weight", 8872], ["aten::threshold_backward", 8809], ["ReluBackward1", 8809], ["aten::add_", 8744], ["aten::cudnn_convolution", 8628], ["aten::_convolution", 8628], ["aten::convolution", 8628], ["aten::conv2d", 8628], ["aten::cudnn_convolution_backward_weight", 8440], ["aten::cudnn_batch_norm", 8277], ["aten::_batch_norm_impl_index", 8277], ["aten::batch_norm", 8277], ["aten::cudnn_convolution_backward_weight", 8165], ["aten::cudnn_convolution", 7781], ["aten::_convolution", 7781], ["aten::convolution", 7781], ["aten::conv2d", 7781], ["aten::cudnn_convolution_backward", 7096], ["aten::max_pool2d_with_indices_backward", 6837], ["MaxPool2DWithIndicesBackward", 6837], ["aten::cudnn_batch_norm_backward", 6504], ["CudnnBatchNormBackward", 6504], ["aten::threshold_", 6015], ["aten::relu_", 6015], ["aten::threshold_backward", 5941], ["ReluBackward1", 5941], ["aten::add_", 5915], ["aten::cudnn_batch_norm", 5344], ["aten::_batch_norm_impl_index", 5344], ["aten::batch_norm", 5344], ["aten::cudnn_batch_norm_backward", 5098], ["CudnnBatchNormBackward", 5098], ["aten::cudnn_batch_norm", 4748], ["aten::_batch_norm_impl_index", 4748], ["aten::batch_norm", 4748], ["aten::threshold_backward", 4606], ["ReluBackward1", 4606], ["aten::threshold_backward", 4440], ["ReluBackward1", 4440], ["aten::add_", 4413], ["aten::cudnn_batch_norm_backward", 4187], ["CudnnBatchNormBackward", 4187], ["aten::threshold_", 4052], ["aten::relu_", 4052], ["aten::cudnn_batch_norm", 3414], ["aten::_batch_norm_impl_index", 3414], ["aten::batch_norm", 3414], ["aten::threshold_", 3035], ["aten::relu_", 3035], ["aten::threshold_", 3033], ["aten::relu_", 3033], ["aten::threshold_backward", 2966], ["ReluBackward1", 2966], ["aten::cudnn_batch_norm", 2934], ["aten::_batch_norm_impl_index", 2934], ["aten::batch_norm", 2934], ["aten::cudnn_convolution", 2814], ["aten::_convolution", 2814], ["aten::convolution", 2814], ["aten::conv2d", 2814], ["aten::cudnn_batch_norm_backward", 2736], ["CudnnBatchNormBackward", 2736], ["aten::threshold_backward", 2732], ["ReluBackward1", 2732], ["aten::cudnn_convolution_backward_input", 2723], ["aten::threshold_backward", 2457], ["ReluBackward1", 2457], ["aten::add_", 2365], ["aten::cudnn_batch_norm_backward", 2347], ["CudnnBatchNormBackward", 2347], ["aten::cudnn_batch_norm", 1998], ["aten::_batch_norm_impl_index", 1998], ["aten::batch_norm", 1998], ["aten::threshold_", 1997], ["aten::relu_", 1997], ["aten::threshold_", 1855], ["aten::relu_", 1855], ["aten::cudnn_batch_norm", 1797], ["aten::_batch_norm_impl_index", 1797], ["aten::batch_norm", 1797], ["aten::max_pool2d_with_indices", 1785], ["aten::max_pool2d", 1785], ["aten::cudnn_batch_norm", 1597], ["aten::_batch_norm_impl_index", 1597], ["aten::batch_norm", 1597], ["aten::threshold_backward", 1473], ["ReluBackward1", 1473], ["aten::add_", 1389], ["aten::cudnn_batch_norm_backward", 1308], ["CudnnBatchNormBackward", 1308], ["aten::fill_", 1285], ["aten::zero_", 1285], ["aten::zeros_like", 1285], ["aten::threshold_backward", 1209], ["ReluBackward1", 1209], ["aten::add_", 1126], ["aten::threshold_", 1034], ["aten::relu_", 1034], ["aten::threshold_", 1007], ["aten::relu_", 1007], ["torch::autograd::AccumulateGrad", 990], ["aten::add_", 959], ["aten::cudnn_batch_norm_backward", 935], ["CudnnBatchNormBackward", 935], ["aten::add_", 921], ["aten::add_", 898], ["torch::autograd::AccumulateGrad", 881], ["aten::add", 840], ["aten::cudnn_batch_norm", 837], ["aten::_batch_norm_impl_index", 837], ["aten::batch_norm", 837], ["aten::threshold_", 794], ["aten::relu_", 794], ["aten::threshold_backward", 762], ["ReluBackward1", 762], ["aten::cudnn_batch_norm_backward", 741], ["CudnnBatchNormBackward", 741], ["aten::add_", 713], ["aten::add_", 690], ["aten::add_", 678], ["aten::threshold_backward", 664], ["ReluBackward1", 664], ["torch::autograd::AccumulateGrad", 652], ["aten::add_", 646], ["aten::cudnn_batch_norm", 633], ["aten::_batch_norm_impl_index", 633], ["aten::batch_norm", 633], ["aten::add_", 619], ["aten::add_", 612], ["aten::threshold_", 515], ["aten::relu_", 515], ["aten::mul_", 503], ["aten::add_", 484], ["aten::add", 479], ["torch::autograd::AccumulateGrad", 472], ["aten::add", 461], ["torch::autograd::AccumulateGrad", 456], ["torch::autograd::AccumulateGrad", 455], ["aten::add_", 453], ["aten::copy_", 424], ["torch::autograd::AccumulateGrad", 416], ["aten::threshold_backward", 403], ["ReluBackward1", 403], ["aten::_cat", 390], ["aten::cat", 390], ["torch::autograd::AccumulateGrad", 389], ["aten::add", 384], ["AddmmBackward", 384], ["aten::cudnn_batch_norm", 371], ["aten::_batch_norm_impl_index", 371], ["aten::batch_norm", 371], ["aten::copy_", 369], ["aten::add_", 363], ["aten::mean", 346], ["aten::adaptive_avg_pool2d", 346], ["torch::autograd::AccumulateGrad", 326], ["aten::fill_", 315], ["aten::zero_", 315], ["torch::autograd::AccumulateGrad", 314], ["torch::autograd::AccumulateGrad", 309], ["aten::add_", 278], ["aten::threshold_", 274], ["aten::relu_", 274], ["aten::addmm", 269], ["torch::autograd::AccumulateGrad", 269], ["aten::mul_", 261], ["aten::add", 257], ["aten::add", 256], ["torch::autograd::AccumulateGrad", 252], ["aten::add", 248], ["aten::add", 244], ["aten::threshold_", 243], ["aten::relu_", 243], ["aten::add", 239], ["torch::autograd::AccumulateGrad", 238], ["aten::mm", 232], ["aten::mul_", 231], ["aten::div", 230], ["MeanBackward1", 230], ["aten::mul_", 224], ["aten::copy_", 221], ["aten::add_", 205], ["aten::add_", 190], ["aten::add", 180], ["aten::add", 176], ["aten::copy_", 172], ["aten::copy_", 170], ["torch::autograd::AccumulateGrad", 169], ["aten::fill_", 168], ["aten::zero_", 168], ["aten::copy_", 166], ["aten::add_", 162], ["aten::mul_", 154], ["aten::add_", 153], ["aten::mul_", 152], ["aten::mm", 152], ["aten::mul_", 151], ["torch::autograd::AccumulateGrad", 150], ["aten::fill_", 147], ["aten::zero_", 147], ["aten::mul_", 147], ["aten::add_", 144], ["aten::copy_", 140], ["torch::autograd::AccumulateGrad", 134], ["aten::mul_", 131], ["aten::add", 128], ["aten::add_", 124], ["torch::autograd::AccumulateGrad", 114], ["aten::add", 112], ["aten::add", 112], ["aten::mul_", 112], ["aten::mul_", 105], ["torch::autograd::AccumulateGrad", 103], ["torch::autograd::AccumulateGrad", 102], ["aten::fill_", 98], ["aten::zero_", 98], ["aten::mul_", 98], ["aten::mul_", 98], ["aten::fill_", 91], ["aten::zero_", 91], ["aten::fill_", 91], ["aten::zero_", 91], ["aten::fill_", 90], ["aten::zero_", 90], ["aten::add_", 89], ["aten::fill_", 89], ["aten::zero_", 89], ["aten::add", 88], ["aten::_log_softmax_backward_data", 86], ["LogSoftmaxBackward", 86], ["aten::fill_", 84], ["aten::zero_", 84], ["aten::fill_", 84], ["aten::zero_", 84], ["aten::_log_softmax", 82], ["aten::log_softmax", 82], ["aten::copy_", 82], ["aten::copy_", 81], ["aten::add_", 80], ["aten::clone", 77], ["aten::fill_", 73], ["aten::zero_", 73], ["aten::add", 72], ["aten::add", 72], ["aten::add_", 70], ["aten::fill_", 70], ["aten::zero_", 70], ["aten::add", 65], ["aten::copy_", 65], ["aten::add", 65], ["torch::autograd::AccumulateGrad", 62], ["aten::mul_", 59], ["torch::autograd::AccumulateGrad", 59], ["aten::copy_", 58], ["aten::mul_", 56], ["aten::copy_", 53], ["torch::autograd::AccumulateGrad", 53], ["aten::add_", 48], ["aten::add", 48], ["aten::copy_", 48], ["aten::add_", 47], ["aten::copy_", 47], ["aten::copy_", 46], ["torch::autograd::AccumulateGrad", 42], ["aten::add_", 39], ["aten::mul_", 39], ["aten::mul_", 36], ["aten::fill_", 34], ["aten::zero_", 34], ["torch::autograd::AccumulateGrad", 34], ["torch::autograd::AccumulateGrad", 34], ["aten::nll_loss_forward", 33], ["aten::nll_loss", 33], ["aten::add", 32], ["aten::clone", 32], ["aten::clone", 30], ["aten::mul_", 30], ["aten::fill_", 28], ["aten::zero_", 28], ["aten::fill_", 28], ["aten::zero_", 28], ["aten::fill_", 28], ["aten::zero_", 28], ["aten::fill_", 28], ["aten::zero_", 28], ["aten::fill_", 28], ["aten::zero_", 28], ["aten::mul_", 28], ["torch::autograd::AccumulateGrad", 26], ["aten::copy_", 25], ["aten::to", 25], ["aten::fill_", 25], ["aten::zero_", 25], ["aten::add", 24], ["aten::add", 24], ["aten::add", 24], ["aten::nll_loss_backward", 24], ["NllLossBackward", 24], ["aten::clone", 23], ["aten::clone", 23], ["aten::clone", 22], ["aten::add_", 22], ["aten::clone", 21], ["aten::fill_", 21], ["aten::zero_", 21], ["aten::fill_", 21], ["aten::zero_", 21], ["aten::mul_", 21], ["aten::mul_", 21], ["aten::clone", 20], ["aten::copy_", 19], ["aten::add", 16], ["aten::clone", 16], ["aten::mul_", 15], ["aten::clone", 14], ["aten::clone", 14], ["aten::fill_", 14], ["aten::zero_", 14], ["aten::mul_", 14], ["aten::mul_", 14], ["aten::_local_scalar_dense", 12], ["aten::item", 12], ["aten::clone", 12], ["aten::copy_", 11], ["aten::clone", 10], ["aten::copy_", 9], ["aten::copy_", 9], ["aten::fill_", 8], ["aten::ones_like", 8], ["aten::add", 8], ["aten::add", 8], ["aten::copy_", 8], ["aten::add", 8], ["aten::clone", 8], ["aten::clone", 8], ["aten::add", 8], ["torch::autograd::AccumulateGrad", 8], ["aten::copy_", 7], ["aten::fill_", 7], ["aten::zero_", 7], ["aten::fill_", 7], ["aten::zero_", 7], ["aten::fill_", 7], ["aten::zero_", 7], ["aten::fill_", 7], ["aten::zero_", 7], ["aten::fill_", 7], ["aten::zero_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::copy_", 6], ["aten::copy_", 5], ["aten::copy_", 5], ["aten::clone", 4], ["aten::clone", 4], ["aten::copy_", 3], ["aten::clone", 3], ["aten::copy_", 3], ["aten::copy_", 3], ["aten::clone", 3], ["aten::clone", 3], ["aten::clone", 3], ["aten::copy_", 3], ["aten::copy_", 3], ["aten::copy_", 2], ["aten::clone", 2], ["aten::clone", 2], ["aten::copy_", 2], ["aten::fill_", 2], ["aten::zero_", 2], ["aten::clone", 1], ["aten::clone", 1], ["aten::clone", 1], ["aten::clone", 1], ["aten::clone", 1]]}, "device_self_time": {"title": "Device Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward_weight", 31776], ["aten::cudnn_convolution_backward_input", 29075], ["aten::cudnn_convolution_backward_input", 28016], ["aten::cudnn_convolution_backward_input", 25953], ["aten::cudnn_convolution", 24045], ["aten::cudnn_convolution_backward_weight", 21857], ["aten::cudnn_convolution_backward_weight", 21851], ["aten::cudnn_convolution", 21482], ["aten::cudnn_convolution", 21136], ["aten::cudnn_convolution_backward_input", 20738], ["aten::cudnn_batch_norm_backward", 20540], ["aten::cudnn_convolution_backward_input", 20240], ["aten::cudnn_convolution", 19366], ["aten::cudnn_convolution_backward_input", 19137], ["aten::cudnn_convolution_backward_weight", 18587], ["aten::cudnn_convolution_backward_weight", 18523], ["aten::cudnn_convolution", 17657], ["aten::cudnn_convolution_backward_weight", 16632], ["aten::cudnn_convolution", 16606], ["aten::cudnn_convolution", 16011], ["aten::cudnn_convolution", 15786], ["aten::cudnn_convolution_backward_weight", 15734], ["aten::cudnn_convolution_backward_weight", 15718], ["aten::cudnn_convolution", 15711], ["aten::cudnn_convolution_backward_input", 15703], ["aten::cudnn_convolution", 15643], ["aten::cudnn_convolution", 15399], ["aten::cudnn_convolution_backward_weight", 15241], ["aten::cudnn_convolution_backward_input", 15082], ["aten::cudnn_convolution_backward_input", 14776], ["aten::cudnn_convolution_backward_input", 14541], ["aten::cudnn_convolution", 14401], ["aten::cudnn_convolution", 13922], ["aten::copy_", 13570], ["aten::cudnn_convolution_backward_input", 13442], ["aten::cudnn_convolution", 13397], ["aten::cudnn_batch_norm_backward", 13251], ["aten::cudnn_convolution_backward_weight", 13208], ["aten::cudnn_convolution", 13117], ["aten::cudnn_convolution_backward_input", 13012], ["aten::cudnn_convolution_backward_weight", 12918], ["aten::cudnn_batch_norm", 12806], ["aten::cudnn_convolution_backward_weight", 12652], ["aten::cudnn_convolution", 12301], ["aten::cudnn_convolution_backward_weight", 12000], ["aten::cudnn_convolution_backward_input", 11640], ["aten::cudnn_convolution_backward_weight", 11556], ["aten::cudnn_convolution_backward_input", 11337], ["aten::cudnn_convolution_backward_weight", 10859], ["aten::cudnn_convolution", 10752], ["aten::cudnn_convolution_backward_weight", 10661], ["aten::cudnn_convolution_backward_input", 10658], ["aten::cudnn_convolution_backward_input", 10630], ["aten::cudnn_convolution_backward_input", 10610], ["aten::cudnn_convolution", 10248], ["aten::cudnn_convolution_backward_weight", 10157], ["aten::cudnn_batch_norm_backward", 10146], ["aten::cudnn_batch_norm_backward", 10088], ["aten::cudnn_convolution_backward_input", 9949], ["aten::cudnn_convolution", 9896], ["aten::cudnn_convolution_backward_weight", 9664], ["aten::cudnn_convolution_backward_weight", 9335], ["aten::cudnn_convolution", 9179], ["aten::cudnn_convolution_backward_weight", 8872], ["aten::threshold_backward", 8809], ["aten::add_", 8744], ["aten::cudnn_convolution", 8628], ["aten::cudnn_convolution_backward_weight", 8440], ["aten::cudnn_batch_norm", 8277], ["aten::cudnn_convolution_backward_weight", 8165], ["aten::cudnn_convolution", 7781], ["aten::cudnn_batch_norm_backward", 6504], ["aten::threshold_", 6015], ["aten::threshold_backward", 5941], ["aten::add_", 5915], ["aten::max_pool2d_with_indices_backward", 5552], ["aten::cudnn_batch_norm", 5344], ["aten::cudnn_batch_norm_backward", 5098], ["aten::cudnn_batch_norm", 4748], ["aten::threshold_backward", 4606], ["aten::threshold_backward", 4440], ["aten::add_", 4413], ["aten::cudnn_batch_norm_backward", 4187], ["aten::threshold_", 4052], ["aten::cudnn_batch_norm", 3414], ["aten::threshold_", 3035], ["aten::threshold_", 3033], ["aten::threshold_backward", 2966], ["aten::cudnn_batch_norm", 2934], ["aten::cudnn_convolution", 2814], ["aten::cudnn_batch_norm_backward", 2736], ["aten::threshold_backward", 2732], ["aten::cudnn_convolution_backward_input", 2723], ["aten::threshold_backward", 2457], ["aten::add_", 2365], ["aten::cudnn_batch_norm_backward", 2347], ["aten::cudnn_batch_norm", 1998], ["aten::threshold_", 1997], ["aten::threshold_", 1855], ["aten::cudnn_batch_norm", 1797], ["aten::max_pool2d_with_indices", 1785], ["aten::cudnn_batch_norm", 1597], ["aten::threshold_backward", 1473], ["aten::add_", 1389], ["aten::cudnn_batch_norm_backward", 1308], ["aten::fill_", 1285], ["aten::threshold_backward", 1209], ["aten::add_", 1126], ["aten::threshold_", 1034], ["aten::threshold_", 1007], ["aten::add_", 959], ["aten::cudnn_batch_norm_backward", 935], ["aten::add_", 921], ["aten::add_", 898], ["aten::add", 840], ["aten::cudnn_batch_norm", 837], ["aten::threshold_", 794], ["aten::threshold_backward", 762], ["aten::cudnn_batch_norm_backward", 741], ["aten::add_", 713], ["aten::add_", 690], ["aten::add_", 678], ["aten::threshold_backward", 664], ["aten::add_", 646], ["aten::cudnn_batch_norm", 633], ["aten::add_", 619], ["aten::add_", 612], ["aten::threshold_", 515], ["aten::mul_", 503], ["aten::add_", 484], ["aten::add", 479], ["aten::add", 461], ["aten::add_", 453], ["aten::copy_", 424], ["aten::threshold_backward", 403], ["aten::_cat", 390], ["aten::add", 384], ["aten::cudnn_batch_norm", 371], ["aten::copy_", 369], ["aten::add_", 363], ["aten::mean", 346], ["aten::fill_", 315], ["aten::add_", 278], ["aten::threshold_", 274], ["aten::addmm", 269], ["aten::mul_", 261], ["aten::add", 257], ["aten::add", 256], ["aten::add", 248], ["aten::add", 244], ["aten::threshold_", 243], ["aten::add", 239], ["aten::mm", 232], ["aten::mul_", 231], ["aten::div", 230], ["aten::mul_", 224], ["aten::copy_", 221], ["aten::add_", 205], ["aten::add_", 190], ["aten::add", 180], ["aten::add", 176], ["aten::copy_", 172], ["aten::copy_", 170], ["aten::fill_", 168], ["aten::copy_", 166], ["aten::add_", 162], ["aten::mul_", 154], ["aten::add_", 153], ["aten::mul_", 152], ["aten::mm", 152], ["aten::mul_", 151], ["aten::fill_", 147], ["aten::mul_", 147], ["aten::add_", 144], ["aten::copy_", 140], ["aten::mul_", 131], ["aten::add", 128], ["aten::add_", 124], ["aten::add", 112], ["aten::add", 112], ["aten::mul_", 112], ["aten::mul_", 105], ["aten::fill_", 98], ["aten::mul_", 98], ["aten::mul_", 98], ["aten::fill_", 91], ["aten::fill_", 91], ["aten::fill_", 90], ["aten::add_", 89], ["aten::fill_", 89], ["aten::add", 88], ["aten::_log_softmax_backward_data", 86], ["aten::fill_", 84], ["aten::fill_", 84], ["aten::_log_softmax", 82], ["aten::copy_", 82], ["aten::copy_", 81], ["aten::add_", 80], ["aten::fill_", 73], ["aten::add", 72], ["aten::add", 72], ["aten::add_", 70], ["aten::fill_", 70], ["aten::add", 65], ["aten::copy_", 65], ["aten::add", 65], ["aten::mul_", 59], ["aten::copy_", 58], ["aten::mul_", 56], ["aten::copy_", 53], ["aten::add_", 48], ["aten::add", 48], ["aten::copy_", 48], ["aten::add_", 47], ["aten::copy_", 47], ["aten::copy_", 46], ["aten::add_", 39], ["aten::mul_", 39], ["aten::mul_", 36], ["aten::fill_", 34], ["aten::nll_loss_forward", 33], ["aten::add", 32], ["aten::mul_", 30], ["aten::fill_", 28], ["aten::fill_", 28], ["aten::fill_", 28], ["aten::fill_", 28], ["aten::fill_", 28], ["aten::mul_", 28], ["aten::copy_", 25], ["aten::fill_", 25], ["aten::add", 24], ["aten::add", 24], ["aten::add", 24], ["aten::nll_loss_backward", 24], ["aten::add_", 22], ["aten::fill_", 21], ["aten::fill_", 21], ["aten::mul_", 21], ["aten::mul_", 21], ["aten::copy_", 19], ["aten::add", 16], ["aten::mul_", 15], ["aten::fill_", 14], ["aten::mul_", 14], ["aten::mul_", 14], ["aten::_local_scalar_dense", 12], ["aten::copy_", 11], ["aten::copy_", 9], ["aten::copy_", 9], ["aten::fill_", 8], ["aten::add", 8], ["aten::add", 8], ["aten::copy_", 8], ["aten::add", 8], ["aten::add", 8], ["aten::copy_", 7], ["aten::fill_", 7], ["aten::fill_", 7], ["aten::fill_", 7], ["aten::fill_", 7], ["aten::fill_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::copy_", 6], ["aten::copy_", 5], ["aten::copy_", 5], ["aten::copy_", 3], ["aten::copy_", 3], ["aten::copy_", 3], ["aten::copy_", 3], ["aten::copy_", 3], ["aten::copy_", 2], ["aten::copy_", 2], ["aten::fill_", 2]]}, "host_total_time": {"title": "Host Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cat", 4301571], ["aten::_cat", 4298425], ["aten::copy_", 4217743], ["aten::conv2d", 2374672], ["aten::convolution", 2374237], ["aten::_convolution", 2373866], ["aten::cudnn_convolution", 2372892], ["aten::to", 2045701], ["aten::contiguous", 1206437], ["aten::div_", 1171774], ["aten::stack", 1138781], ["aten::div", 1120641], ["aten::clone", 1070594], ["aten::sub_", 973440], ["aten::addmm", 880342], ["CudnnConvolutionBackward", 498240], ["aten::empty", 481619], ["aten::cudnn_convolution_backward", 328720], ["aten::cudnn_convolution_backward_weight", 300870], ["CudnnConvolutionBackward", 240054], ["aten::empty_strided", 182074], ["CudnnConvolutionBackward", 169279], ["aten::cudnn_convolution_backward", 168486], ["aten::cudnn_convolution_backward", 166854], ["aten::cudnn_convolution_backward_input", 154663], ["CudnnConvolutionBackward", 151760], ["aten::cudnn_convolution_backward_weight", 148327], ["aten::cudnn_convolution_backward", 147113], ["aten::conv2d", 142805], ["aten::convolution", 142417], ["aten::_convolution", 142090], ["aten::conv2d", 141504], ["aten::cudnn_convolution", 141259], ["aten::convolution", 141102], ["aten::_convolution", 140773], ["aten::cudnn_convolution", 139921], ["CudnnConvolutionBackward", 131307], ["CudnnConvolutionBackward", 123170], ["aten::pin_memory", 119177], ["aten::clone", 118290], ["aten::eq", 111725], ["aten::conv2d", 105625], ["aten::lt", 103964], ["aten::convolution", 103577], ["CudnnConvolutionBackward", 103164], ["aten::_convolution", 101917], ["aten::to", 100221], ["aten::cudnn_convolution", 97687], ["aten::copy_", 95197], ["aten::cudnn_convolution_backward", 87636], ["aten::batch_norm", 82643], ["aten::narrow", 81883], ["aten::batch_norm", 80900], ["aten::_batch_norm_impl_index", 80323], ["aten::eq", 79246], ["aten::cudnn_batch_norm", 78429], ["aten::_batch_norm_impl_index", 78407], ["aten::add", 76755], ["CudnnConvolutionBackward", 75302], ["aten::cudnn_convolution_backward_weight", 74374], ["aten::lt", 73161], ["aten::cudnn_convolution_backward_input", 71042], ["aten::select", 69905], ["aten::item", 69341], ["aten::copy_", 69327], ["aten::add_", 67093], ["aten::cudnn_convolution_backward", 64320], ["aten::item", 64243], ["aten::cudnn_batch_norm", 63146], ["aten::any", 62668], ["aten::slice", 60861], ["aten::exp", 60833], ["aten::randint", 60289], ["aten::cudnn_convolution_backward", 59121], ["aten::uniform_", 58037], ["aten::batch_norm", 57633], ["CudnnBatchNormBackward", 57503], ["CudnnConvolutionBackward", 56820], ["aten::_batch_norm_impl_index", 54899], ["aten::cudnn_convolution_backward", 54111], ["aten::cudnn_convolution_backward", 52430], ["aten::batch_norm", 51253], ["aten::cudnn_convolution_backward", 51119], ["aten::batch_norm", 48687], ["aten::_batch_norm_impl_index", 48554], ["aten::narrow", 47707], ["aten::cudnn_convolution_backward", 46392], ["aten::cudnn_convolution_backward", 46227], ["aten::_batch_norm_impl_index", 46174], ["aten::cudnn_convolution_backward", 46108], ["aten::add_", 46093], ["aten::cudnn_batch_norm_backward", 45950], ["aten::add", 45269], ["aten::conv2d", 44743], ["aten::cudnn_convolution_backward", 44493], ["aten::cudnn_convolution_backward_input", 43636], ["aten::convolution", 42371], ["aten::_local_scalar_dense", 40704], ["aten::cudnn_batch_norm", 40513], ["aten::conv2d", 40367], ["aten::_convolution", 40331], ["aten::log", 40092], ["aten::conv2d", 39697], ["aten::conv2d", 39594], ["aten::cudnn_convolution_backward_input", 39232], ["aten::conv2d", 39193], ["aten::convolution", 39148], ["CudnnBatchNormBackward", 39016], ["aten::cudnn_batch_norm", 38952], ["aten::_convolution", 38138], ["aten::convolution", 38065], ["CudnnBatchNormBackward", 38039], ["aten::convolution", 37865], ["aten::view", 37626], ["aten::batch_norm", 37600], ["aten::convolution", 37169], ["aten::cudnn_batch_norm", 37150], ["torch::autograd::AccumulateGrad", 37011], ["aten::_convolution", 36677], ["aten::batch_norm", 36517], ["aten::_convolution", 36352], ["aten::cudnn_convolution_backward_input", 36281], ["aten::_batch_norm_impl_index", 35671], ["aten::cudnn_convolution", 35602], ["aten::_convolution", 35518], ["aten::cudnn_convolution", 35431], ["aten::cudnn_convolution_backward_weight", 34812], ["aten::cudnn_convolution_backward_input", 34578], ["aten::slice", 34572], ["aten::view", 34524], ["aten::_batch_norm_impl_index", 34511], ["aten::cudnn_convolution_backward", 34236], ["aten::add_", 34221], ["aten::batch_norm", 33629], ["aten::cudnn_convolution", 33202], ["aten::conv2d", 32559], ["aten::conv2d", 32274], ["aten::rand", 32191], ["aten::cudnn_convolution", 32182], ["aten::_local_scalar_dense", 32168], ["aten::_batch_norm_impl_index", 31969], ["CudnnBatchNormBackward", 31861], ["aten::convolution", 31401], ["aten::cudnn_convolution", 31357], ["aten::convolution", 30798], ["aten::cudnn_batch_norm_backward", 30692], ["CudnnConvolutionBackward", 30656], ["aten::cudnn_batch_norm_backward", 30565], ["aten::add", 30512], ["aten::_convolution", 30420], ["aten::conv2d", 30024], ["aten::cudnn_convolution_backward", 29990], ["aten::_convolution", 29667], ["aten::copy_", 29665], ["aten::add_", 29647], ["aten::batch_norm", 29579], ["aten::cudnn_convolution_backward", 29422], ["aten::convolution", 29237], ["CudnnConvolutionBackward", 28975], ["aten::add_", 28956], ["aten::cudnn_batch_norm", 28768], ["aten::cudnn_convolution_backward_weight", 28731], ["aten::conv2d", 28711], ["aten::conv2d", 28589], ["aten::_convolution", 28569], ["aten::cudnn_convolution_backward", 28317], ["aten::_batch_norm_impl_index", 28078], ["aten::cudnn_convolution", 27978], ["aten::convolution", 27815], ["aten::cudnn_convolution_backward", 27811], ["aten::cudnn_batch_norm", 27563], ["aten::convolution", 27531], ["aten::cudnn_convolution_backward_weight", 27521], ["aten::cudnn_convolution_backward_weight", 27473], ["CudnnBatchNormBackward", 26944], ["aten::cudnn_convolution", 26901], ["aten::_convolution", 26894], ["aten::cudnn_convolution", 26803], ["aten::_convolution", 26524], ["aten::cudnn_convolution_backward_input", 26253], ["aten::cudnn_batch_norm", 25784], ["CudnnBatchNormBackward", 25643], ["aten::cudnn_convolution_backward_weight", 25559], ["torch::autograd::AccumulateGrad", 25512], ["aten::resize_", 25511], ["aten::permute", 25499], ["aten::cudnn_batch_norm_backward", 25439], ["aten::view", 25359], ["aten::cudnn_convolution", 25168], ["aten::cudnn_convolution_backward_weight", 24834], ["aten::zero_", 24722], ["aten::exp", 24635], ["aten::conv2d", 24596], ["aten::cudnn_convolution", 24039], ["aten::convolution", 23620], ["aten::mul_", 23459], ["aten::cudnn_convolution_backward_input", 23407], ["aten::conv2d", 23238], ["aten::view", 23182], ["aten::cudnn_convolution_backward_input", 23141], ["aten::cudnn_convolution_backward_weight", 22996], ["aten::cudnn_convolution_backward_input", 22968], ["aten::_convolution", 22860], ["aten::convolution", 22830], ["aten::add", 22741], ["CudnnBatchNormBackward", 22665], ["aten::cudnn_batch_norm", 22600], ["aten::cudnn_convolution_backward_input", 22462], ["aten::_convolution", 22459], ["aten::cudnn_convolution_backward_input", 22457], ["aten::view", 22119], ["ReluBackward1", 22112], ["aten::add", 22091], ["aten::cudnn_convolution_backward_input", 21947], ["aten::copy_", 21797], ["aten::cudnn_batch_norm_backward", 21664], ["aten::cudnn_convolution", 21616], ["aten::cudnn_convolution", 20982], ["aten::cudnn_convolution_backward", 20897], ["aten::cudnn_convolution_backward", 20887], ["CudnnBatchNormBackward", 20783], ["aten::cudnn_batch_norm_backward", 20585], ["aten::cudnn_convolution_backward_weight", 20317], ["aten::cudnn_convolution_backward_weight", 19963], ["aten::add", 19144], ["torch::autograd::AccumulateGrad", 18875], ["aten::cudnn_convolution_backward_input", 18636], ["aten::cudnn_convolution_backward", 18633], ["aten::is_nonzero", 18632], ["aten::conv2d", 18394], ["aten::cudnn_batch_norm_backward", 18292], ["aten::convolution", 17996], ["aten::set_", 17891], ["aten::cudnn_convolution_backward_weight", 17882], ["aten::is_nonzero", 17830], ["aten::_convolution", 17631], ["aten::conv2d", 17505], ["aten::view", 17240], ["aten::convolution", 17117], ["aten::zero_", 16856], ["aten::cudnn_convolution", 16805], ["aten::_convolution", 16720], ["aten::cudnn_batch_norm_backward", 16659], ["aten::view", 16637], ["aten::add_", 16470], ["torch::autograd::AccumulateGrad", 16274], ["torch::autograd::AccumulateGrad", 16147], ["aten::mul_", 16144], ["aten::cudnn_convolution", 15898], ["aten::conv2d", 15844], ["aten::random_", 15826], ["aten::cudnn_convolution_backward_input", 15820], ["aten::cudnn_convolution_backward_weight", 15798], ["aten::relu_", 15733], ["aten::empty_like", 15631], ["aten::threshold_backward", 15571], ["aten::cudnn_convolution_backward_input", 15521], ["aten::convolution", 15403], ["aten::copy_", 15379], ["aten::view", 15162], ["aten::cudnn_convolution_backward_input", 15122], ["aten::_convolution", 15061], ["aten::view", 14572], ["aten::conv2d", 14368], ["aten::cudnn_convolution", 14245], ["aten::conv2d", 13991], ["aten::convolution", 13979], ["ReluBackward1", 13677], ["aten::_convolution", 13660], ["aten::convolution", 13591], ["aten::_convolution", 13245], ["torch::autograd::AccumulateGrad", 13188], ["aten::conv2d", 13129], ["aten::cudnn_convolution_backward_weight", 13060], ["aten::copy_", 12895], ["aten::cudnn_convolution", 12848], ["aten::convolution", 12745], ["aten::conv2d", 12608], ["aten::is_floating_point", 12598], ["aten::cudnn_convolution_backward_weight", 12523], ["aten::add_", 12497], ["aten::add_", 12486], ["aten::copy_", 12466], ["aten::_convolution", 12403], ["aten::cudnn_convolution", 12389], ["aten::cudnn_convolution_backward_weight", 12367], ["aten::zero_", 12226], ["aten::convolution", 12192], ["CudnnConvolutionBackward", 11871], ["aten::_convolution", 11867], ["aten::mul_", 11817], ["aten::cudnn_convolution_backward_weight", 11783], ["aten::unsqueeze", 11752], ["ReluBackward1", 11624], ["aten::cudnn_convolution", 11567], ["ReluBackward1", 11485], ["aten::cudnn_convolution_backward", 11208], ["aten::add", 11073], ["aten::cudnn_convolution", 10759], ["aten::zero_", 10751], ["aten::fill_", 10737], ["aten::cudnn_convolution_backward_weight", 10708], ["aten::zero_", 10667], ["aten::cudnn_convolution_backward_input", 10517], ["aten::mul_", 10400], ["aten::add_", 10379], ["aten::detach_", 10358], ["aten::as_strided", 10353], ["aten::mul_", 10352], ["aten::relu_", 10143], ["aten::cudnn_convolution_backward_weight", 10111], ["aten::threshold_backward", 10043], ["aten::as_strided", 9787], ["aten::relu_", 9596], ["aten::to", 9527], ["ReluBackward1", 9412], ["aten::cudnn_convolution_backward_input", 9371], ["aten::cudnn_convolution_backward_weight", 9276], ["aten::contiguous", 9240], ["torch::autograd::AccumulateGrad", 9015], ["aten::cudnn_convolution_backward_weight", 8893], ["AddmmBackward", 8872], ["aten::adaptive_avg_pool2d", 8833], ["aten::add_", 8812], ["aten::contiguous", 8797], ["aten::threshold_backward", 8586], ["aten::add_", 8522], ["aten::relu_", 8438], ["aten::mean", 8436], ["aten::threshold_backward", 8424], ["aten::add", 8421], ["aten::copy_", 8370], ["aten::add_", 8358], ["aten::add", 8241], ["aten::view", 8152], ["ReluBackward1", 8120], ["aten::empty_like", 7953], ["aten::batch_norm", 7506], ["aten::batch_norm", 7397], ["aten::relu_", 7395], ["aten::clone", 7325], ["aten::batch_norm", 7307], ["aten::fill_", 7221], ["aten::_batch_norm_impl_index", 7128], ["aten::stride", 7110], ["torch::autograd::AccumulateGrad", 7063], ["aten::_batch_norm_impl_index", 7027], ["aten::threshold_backward", 6983], ["aten::_batch_norm_impl_index", 6937], ["aten::add", 6876], ["aten::add_", 6654], ["aten::add_", 6608], ["CudnnBatchNormBackward", 6476], ["aten::contiguous", 6467], ["aten::add_", 6351], ["aten::mul_", 6312], ["aten::add_", 6287], ["torch::autograd::AccumulateGrad", 6245], ["aten::add_", 6242], ["aten::empty_like", 6148], ["aten::max_pool2d", 6137], ["aten::threshold_backward", 6086], ["aten::zero_", 6034], ["aten::contiguous", 6032], ["aten::add", 6022], ["torch::autograd::AccumulateGrad", 5939], ["aten::contiguous", 5919], ["aten::contiguous", 5902], ["aten::contiguous", 5812], ["aten::relu_", 5780], ["aten::cudnn_batch_norm", 5750], ["MaxPool2DWithIndicesBackward", 5733], ["aten::as_strided", 5698], ["aten::add", 5680], ["aten::max_pool2d_with_indices", 5679], ["aten::add", 5639], ["ReluBackward1", 5622], ["ReluBackward1", 5587], ["aten::cudnn_batch_norm", 5545], ["aten::cudnn_batch_norm", 5524], ["aten::stride", 5489], ["aten::fill_", 5345], ["aten::clone", 5269], ["aten::to", 5207], ["CudnnBatchNormBackward", 5177], ["aten::empty_like", 5173], ["CudnnBatchNormBackward", 5173], ["aten::cudnn_batch_norm_backward", 5155], ["aten::threshold_", 5141], ["CudnnBatchNormBackward", 5123], ["aten::mul_", 5111], ["aten::max_pool2d_with_indices_backward", 5077], ["aten::fill_", 4939], ["aten::fill_", 4706], ["aten::stride", 4655], ["aten::fill_", 4651], ["aten::empty_like", 4649], ["aten::zero_", 4637], ["torch::autograd::AccumulateGrad", 4619], ["aten::zero_", 4604], ["torch::autograd::AccumulateGrad", 4596], ["aten::relu_", 4543], ["aten::mul_", 4514], ["detach_", 4503], ["aten::stride", 4446], ["aten::as_strided", 4417], ["aten::add", 4401], ["aten::contiguous", 4350], ["aten::empty_like", 4347], ["aten::add_", 4306], ["aten::zeros", 4284], ["aten::contiguous", 4274], ["aten::relu_", 4238], ["aten::add_", 4238], ["aten::add", 4224], ["aten::add", 4205], ["aten::zero_", 4191], ["aten::cudnn_batch_norm_backward", 4148], ["aten::as_strided", 4146], ["aten::contiguous", 4145], ["aten::threshold_backward", 4135], ["aten::cudnn_batch_norm_backward", 4132], ["aten::threshold_backward", 4130], ["aten::add", 4105], ["aten::cudnn_batch_norm_backward", 4101], ["aten::add_", 4095], ["aten::contiguous", 4070], ["aten::as_strided", 3956], ["aten::contiguous", 3943], ["aten::clone", 3943], ["aten::mul_", 3793], ["aten::is_pinned", 3718], ["torch::autograd::AccumulateGrad", 3616], ["MeanBackward1", 3590], ["aten::add_", 3550], ["aten::resize_", 3531], ["aten::empty_like", 3497], ["torch::autograd::AccumulateGrad", 3491], ["torch::autograd::AccumulateGrad", 3478], ["torch::autograd::AccumulateGrad", 3452], ["aten::add", 3435], ["aten::stride", 3406], ["aten::clone", 3344], ["aten::clone", 3319], ["aten::mul_", 3308], ["aten::contiguous", 3275], ["aten::threshold_", 3268], ["aten::threshold_", 3260], ["aten::clone", 3246], ["aten::mul_", 3232], ["aten::add_", 3230], ["aten::as_strided", 3213], ["aten::to", 3172], ["aten::zero_", 3167], ["aten::empty_like", 3129], ["aten::stride", 3119], ["aten::empty_like", 3117], ["aten::mul_", 3109], ["aten::pin_memory", 3042], ["aten::zero_", 2989], ["aten::zero_", 2974], ["aten::log_softmax", 2928], ["aten::clone", 2829], ["aten::to", 2807], ["aten::clone", 2800], ["aten::threshold_", 2773], ["aten::copy_", 2771], ["aten::add", 2754], ["aten::clone", 2729], ["aten::as_strided", 2714], ["aten::mm", 2700], ["aten::contiguous", 2698], ["LogSoftmaxBackward", 2678], ["aten::fill_", 2637], ["aten::mul_", 2633], ["aten::add_", 2558], ["aten::stride", 2538], ["aten::_log_softmax", 2535], ["aten::resize_", 2484], ["aten::resize_", 2434], ["aten::mul_", 2355], ["aten::resize_", 2353], ["torch::autograd::AccumulateGrad", 2349], ["aten::threshold_", 2333], ["torch::autograd::AccumulateGrad", 2315], ["aten::zero_", 2270], ["aten::zero_", 2262], ["aten::nll_loss", 2248], ["aten::zero_", 2245], ["aten::zero_", 2228], ["aten::add_", 2219], ["aten::mul_", 2213], ["aten::mul_", 2200], ["aten::stride", 2191], ["aten::add_", 2186], ["aten::add_", 2178], ["aten::_log_softmax_backward_data", 2166], ["aten::add_", 2160], ["NllLossBackward", 2149], ["aten::add_", 2110], ["aten::contiguous", 2099], ["aten::add_", 2081], ["ReluBackward1", 2080], ["aten::add_", 2048], ["aten::add_", 2046], ["aten::add_", 2044], ["aten::fill_", 2043], ["aten::t", 2032], ["aten::fill_", 2016], ["aten::fill_", 1996], ["aten::div", 1959], ["aten::relu_", 1922], ["ReluBackward1", 1922], ["aten::mm", 1883], ["aten::clone", 1878], ["ReluBackward1", 1868], ["aten::nll_loss_forward", 1865], ["ReluBackward1", 1863], ["aten::threshold_", 1831], ["aten::zeros_like", 1799], ["aten::ones_like", 1766], ["aten::t", 1719], ["aten::add", 1670], ["aten::mul_", 1660], ["aten::resize_", 1634], ["aten::resize_", 1607], ["aten::threshold_backward", 1605], ["aten::add", 1549], ["AddBackward0", 1537], ["aten::empty_like", 1523], ["aten::threshold_", 1522], ["aten::add", 1516], ["aten::zero_", 1512], ["aten::flatten", 1510], ["aten::relu_", 1485], ["aten::zero_", 1483], ["aten::mul_", 1480], ["aten::threshold_backward", 1462], ["aten::zero_", 1458], ["aten::relu_", 1453], ["torch::autograd::AccumulateGrad", 1448], ["aten::empty_like", 1442], ["aten::add", 1438], ["aten::add", 1428], ["aten::relu_", 1427], ["aten::clone", 1416], ["aten::stride", 1410], ["aten::add", 1408], ["torch::autograd::AccumulateGrad", 1408], ["aten::nll_loss_backward", 1406], ["aten::resize_", 1385], ["aten::add", 1385], ["aten::add", 1383], ["aten::threshold_backward", 1383], ["aten::threshold_backward", 1381], ["aten::contiguous", 1375], ["aten::add", 1364], ["aten::add", 1354], ["aten::contiguous", 1349], ["aten::threshold_", 1346], ["aten::fill_", 1306], ["aten::fill_", 1300], ["aten::fill_", 1291], ["aten::contiguous", 1251], ["aten::stride", 1221], ["torch::autograd::AccumulateGrad", 1207], ["aten::clone", 1204], ["aten::resize_", 1196], ["aten::detach", 1194], ["torch::autograd::AccumulateGrad", 1163], ["torch::autograd::AccumulateGrad", 1161], ["ViewBackward", 1160], ["torch::autograd::AccumulateGrad", 1147], ["aten::copy_", 1145], ["torch::autograd::AccumulateGrad", 1143], ["torch::autograd::AccumulateGrad", 1130], ["torch::autograd::AccumulateGrad", 1127], ["torch::autograd::AccumulateGrad", 1126], ["aten::resize_", 1124], ["aten::mul_", 1123], ["aten::copy_", 1119], ["aten::reshape", 1104], ["TBackward", 1103], ["aten::clone", 1096], ["aten::copy_", 1081], ["aten::resize_", 1025], ["aten::contiguous", 1002], ["aten::resize_", 996], ["aten::contiguous", 988], ["aten::fill_", 987], ["aten::fill_", 980], ["aten::fill_", 980], ["aten::fill_", 980], ["aten::clone", 957], ["aten::mul_", 952], ["aten::contiguous", 922], ["aten::set_", 906], ["aten::zero_", 901], ["aten::zero_", 890], ["aten::stride", 882], ["AddBackward0", 881], ["aten::copy_", 879], ["aten::contiguous", 863], ["aten::t", 857], ["aten::view", 852], ["aten::expand", 834], ["aten::transpose", 829], ["aten::contiguous", 827], ["aten::threshold_", 826], ["aten::detach", 825], ["aten::as_strided", 820], ["aten::contiguous", 814], ["aten::transpose", 814], ["aten::mul_", 813], ["aten::contiguous", 812], ["aten::mul_", 798], ["aten::reshape", 795], ["aten::empty_like", 792], ["aten::mul_", 785], ["aten::mul_", 784], ["aten::zero_", 781], ["aten::copy_", 776], ["aten::resize_", 775], ["aten::clone", 766], ["aten::resize_", 765], ["aten::zero_", 765], ["aten::mul_", 764], ["aten::zero_", 763], ["aten::zero_", 757], ["aten::zero_", 755], ["aten::mul_", 753], ["aten::zero_", 752], ["aten::contiguous", 751], ["aten::mul_", 749], ["aten::zero_", 747], ["aten::zero_", 745], ["aten::zero_", 741], ["aten::mul_", 736], ["aten::resize_", 734], ["aten::clone", 721], ["aten::clone", 718], ["aten::contiguous", 716], ["aten::copy_", 716], ["aten::empty_like", 709], ["aten::empty_like", 708], ["aten::empty_like", 701], ["aten::contiguous", 701], ["aten::clone", 699], ["aten::stride", 684], ["aten::contiguous", 679], ["aten::copy_", 675], ["aten::as_strided", 672], ["aten::stride", 655], ["aten::fill_", 652], ["aten::fill_", 646], ["aten::narrow", 641], ["aten::stride", 631], ["aten::stride", 628], ["aten::stride", 609], ["aten::detach", 604], ["aten::resize_", 596], ["aten::resize_", 572], ["AddBackward0", 571], ["AddBackward0", 570], ["aten::resize_", 566], ["aten::stride", 563], ["aten::resize_", 559], ["aten::view", 550], ["aten::stride", 543], ["aten::copy_", 536], ["aten::resize_as_", 533], ["nccl:broadcast", 532], ["aten::contiguous", 525], ["aten::stride", 517], ["aten::copy_", 515], ["aten::copy_", 511], ["aten::threshold_", 507], ["aten::copy_", 506], ["aten::detach", 504], ["aten::expand", 501], ["aten::detach", 501], ["detach", 499], ["aten::threshold_", 479], ["aten::threshold_", 473], ["aten::fill_", 469], ["aten::contiguous", 464], ["aten::clone", 455], ["aten::fill_", 451], ["aten::clone", 445], ["aten::fill_", 441], ["aten::fill_", 431], ["aten::resize_", 414], ["aten::resize_", 394], ["aten::slice", 389], ["aten::transpose", 383], ["aten::resize_", 377], ["aten::is_pinned", 357], ["aten::copy_", 355], ["aten::resize_", 350], ["aten::fill_", 349], ["aten::resize_", 338], ["aten::copy_", 336], ["aten::fill_", 334], ["detach", 328], ["aten::fill_", 326], ["aten::fill_", 326], ["aten::fill_", 325], ["aten::fill_", 324], ["aten::fill_", 322], ["aten::fill_", 320], ["aten::stride", 318], ["aten::resize_", 307], ["aten::detach_", 299], ["aten::contiguous", 296], ["aten::detach", 279], ["aten::contiguous", 275], ["aten::resize_", 272], ["aten::as_strided", 270], ["aten::clone", 259], ["aten::clone", 245], ["aten::clone", 245], ["detach", 243], ["aten::as_strided", 236], ["aten::contiguous", 235], ["aten::copy_", 235], ["aten::contiguous", 232], ["aten::contiguous", 229], ["aten::clone", 228], ["aten::resize_", 227], ["aten::clone", 226], ["aten::contiguous", 225], ["aten::detach", 225], ["aten::contiguous", 223], ["aten::contiguous", 223], ["aten::clone", 221], ["aten::clone", 221], ["aten::contiguous", 219], ["aten::detach", 218], ["aten::resize_", 211], ["aten::copy_", 206], ["detach", 201], ["aten::copy_", 199], ["aten::resize_", 195], ["detach", 195], ["aten::resize_", 194], ["aten::resize_", 192], ["aten::resize_", 185], ["aten::resize_", 184], ["aten::copy_", 184], ["aten::copy_", 184], ["aten::detach", 180], ["aten::stride", 178], ["aten::copy_", 176], ["aten::to", 175], ["aten::copy_", 173], ["aten::copy_", 172], ["aten::copy_", 170], ["aten::copy_", 169], ["aten::detach", 165], ["aten::copy_", 164], ["aten::stride", 158], ["detach_", 154], ["aten::detach", 154], ["aten::conj", 152], ["aten::detach", 151], ["aten::detach", 151], ["aten::as_strided", 149], ["aten::conj", 145], ["aten::as_strided", 140], ["aten::contiguous", 126], ["aten::stride", 124], ["aten::as_strided", 123], ["aten::as_strided", 121], ["aten::as_strided", 121], ["aten::is_floating_point", 119], ["aten::to", 115], ["aten::detach", 112], ["detach", 112], ["aten::detach", 109], ["aten::detach", 109], ["aten::resize_", 99], ["aten::stride", 91], ["aten::stride", 91], ["detach", 91], ["aten::stride", 90], ["aten::random_", 89], ["detach", 89], ["aten::detach", 75], ["aten::detach", 75], ["detach", 74], ["detach", 74], ["detach", 62], ["detach", 60], ["detach", 45], ["detach", 45], ["aten::stride", 45], ["detach", 44], ["detach", 44], ["aten::detach", 41], ["aten::detach", 39], ["aten::detach", 39], ["aten::detach", 39], ["aten::detach", 37], ["aten::detach", 36], ["aten::detach", 36], ["aten::detach", 36], ["aten::detach", 35], ["aten::detach", 35], ["detach", 31], ["detach", 30], ["detach", 16], ["detach", 16], ["detach", 16], ["detach", 15], ["detach", 15], ["detach", 15], ["detach", 15], ["detach", 14], ["detach", 14], ["detach", 14]]}, "host_self_time": {"title": "Host Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::_cat", 4288871], ["aten::copy_", 4217743], ["aten::cudnn_convolution", 2370703], ["aten::div_", 1171774], ["aten::div", 1078216], ["aten::sub_", 973440], ["aten::addmm", 876946], ["aten::empty", 481619], ["aten::cudnn_convolution_backward_weight", 297284], ["aten::empty_strided", 182074], ["aten::cudnn_convolution_backward_input", 153530], ["aten::cudnn_convolution_backward_weight", 147184], ["aten::cudnn_convolution", 139783], ["aten::cudnn_convolution", 137741], ["aten::copy_", 95197], ["aten::cudnn_batch_norm", 76206], ["aten::cudnn_convolution_backward_weight", 72806], ["aten::cudnn_convolution_backward_input", 69721], ["aten::copy_", 69327], ["aten::add_", 67093], ["aten::add", 60418], ["aten::select", 60118], ["aten::uniform_", 58037], ["aten::to", 52986], ["aten::slice", 50508], ["aten::add_", 46093], ["aten::any", 44417], ["aten::cudnn_batch_norm", 42947], ["aten::_local_scalar_dense", 40704], ["aten::clone", 40336], ["aten::view", 37626], ["aten::cudnn_convolution_backward_input", 36198], ["aten::randint", 34989], ["aten::add", 34757], ["aten::view", 34524], ["aten::add_", 34221], ["aten::log", 33857], ["aten::eq", 33799], ["aten::cudnn_convolution_backward_input", 32460], ["aten::cudnn_convolution", 32294], ["aten::_local_scalar_dense", 32168], ["aten::item", 32075], ["aten::cudnn_convolution_backward_input", 31973], ["aten::cudnn_batch_norm_backward", 30601], ["aten::exp", 29900], ["aten::copy_", 29665], ["aten::add_", 29647], ["aten::cudnn_convolution_backward_input", 29515], ["aten::add_", 28956], ["aten::slice", 28874], ["aten::cudnn_convolution", 28829], ["aten::cudnn_convolution", 28646], ["aten::item", 28637], ["aten::eq", 28576], ["aten::cudnn_convolution", 28262], ["aten::cudnn_convolution_backward_weight", 27828], ["aten::lt", 27788], ["aten::lt", 26897], ["aten::cudnn_convolution", 26554], ["aten::cudnn_batch_norm", 26489], ["aten::cudnn_convolution_backward_weight", 26410], ["aten::cudnn_batch_norm", 26037], ["aten::cudnn_convolution", 25724], ["aten::resize_", 25511], ["aten::view", 25359], ["aten::cudnn_batch_norm", 24814], ["aten::cudnn_convolution", 24696], ["aten::mul_", 23459], ["aten::add", 23419], ["aten::view", 23182], ["aten::cudnn_convolution_backward_weight", 23126], ["aten::cudnn_convolution", 22769], ["aten::cudnn_convolution", 22210], ["aten::cudnn_convolution", 22179], ["aten::view", 22119], ["aten::copy_", 21797], ["aten::permute", 21543], ["aten::cudnn_convolution_backward_weight", 21479], ["aten::narrow", 21022], ["aten::cudnn_batch_norm_backward", 20741], ["aten::cudnn_convolution_backward_input", 20738], ["aten::cudnn_convolution", 20667], ["aten::pin_memory", 20579], ["aten::cudnn_batch_norm_backward", 20539], ["aten::cudnn_convolution_backward_weight", 20468], ["aten::cudnn_convolution", 20423], ["aten::cudnn_convolution_backward_input", 20389], ["aten::to", 20198], ["aten::cudnn_convolution_backward_weight", 19966], ["aten::cudnn_convolution_backward_input", 19865], ["aten::exp", 18797], ["aten::cudnn_convolution_backward_input", 18781], ["aten::cudnn_batch_norm", 18779], ["aten::cudnn_convolution_backward_weight", 18633], ["aten::cudnn_batch_norm", 18568], ["aten::cudnn_convolution_backward_input", 18405], ["aten::cudnn_convolution", 18398], ["aten::cudnn_convolution_backward_input", 18112], ["aten::cudnn_convolution_backward_weight", 17971], ["aten::set_", 17891], ["aten::cudnn_convolution_backward_input", 17888], ["aten::rand", 17794], ["aten::cudnn_batch_norm", 17699], ["aten::add", 17571], ["aten::cudnn_convolution_backward_input", 17380], ["aten::view", 17240], ["aten::cudnn_batch_norm_backward", 16828], ["aten::view", 16637], ["aten::add_", 16470], ["aten::mul_", 16144], ["aten::random_", 15826], ["aten::cudnn_convolution_backward_weight", 15824], ["aten::cudnn_convolution", 15658], ["aten::add", 15431], ["aten::copy_", 15379], ["aten::contiguous", 15305], ["aten::view", 15162], ["aten::cudnn_batch_norm", 15070], ["aten::add", 14792], ["aten::view", 14572], ["aten::cudnn_batch_norm_backward", 14462], ["aten::cudnn_convolution", 14440], ["aten::cudnn_convolution_backward_weight", 14334], ["aten::cudnn_convolution_backward_input", 14207], ["aten::cudnn_convolution_backward_input", 14031], ["aten::zero_", 13985], ["aten::cudnn_batch_norm_backward", 13786], ["aten::cudnn_convolution_backward_weight", 13526], ["aten::narrow", 13135], ["aten::cudnn_convolution_backward_input", 13084], ["aten::cudnn_convolution", 13022], ["aten::copy_", 12895], ["aten::cudnn_batch_norm_backward", 12837], ["aten::is_floating_point", 12598], ["aten::add_", 12497], ["aten::add_", 12486], ["aten::copy_", 12466], ["aten::cudnn_convolution_backward_weight", 11968], ["aten::threshold_backward", 11870], ["aten::mul_", 11817], ["aten::_batch_norm_impl_index", 11706], ["torch::autograd::AccumulateGrad", 11477], ["aten::cudnn_convolution_backward_weight", 11322], ["aten::cudnn_convolution", 11276], ["aten::cudnn_batch_norm_backward", 11153], ["aten::cudnn_convolution", 11120], ["aten::_batch_norm_impl_index", 11040], ["aten::cudnn_convolution_backward_weight", 10789], ["aten::empty_like", 10774], ["aten::fill_", 10737], ["aten::relu_", 10592], ["aten::cudnn_convolution_backward_weight", 10588], ["aten::mul_", 10400], ["aten::add_", 10379], ["aten::cudnn_convolution", 10358], ["aten::as_strided", 10353], ["aten::mul_", 10352], ["CudnnBatchNormBackward", 10149], ["aten::as_strided", 9787], ["aten::zero_", 9635], ["aten::to", 9527], ["aten::cudnn_convolution_backward_weight", 9519], ["aten::cudnn_convolution_backward_input", 9440], ["aten::contiguous", 9240], ["aten::cudnn_convolution_backward_weight", 9069], ["aten::cudnn_convolution", 9018], ["aten::add_", 8812], ["aten::contiguous", 8797], ["aten::cudnn_convolution_backward", 8563], ["aten::unsqueeze", 8539], ["aten::add_", 8522], ["aten::add", 8441], ["aten::copy_", 8370], ["aten::add_", 8358], ["aten::cudnn_convolution_backward_input", 8188], ["aten::view", 8152], ["aten::mean", 8117], ["aten::cudnn_convolution_backward_weight", 8100], ["aten::cudnn_convolution_backward_weight", 7802], ["aten::threshold_backward", 7703], ["torch::autograd::AccumulateGrad", 7585], ["CudnnConvolutionBackward", 7422], ["CudnnBatchNormBackward", 7322], ["aten::cudnn_convolution_backward", 7276], ["aten::fill_", 7221], ["aten::stride", 7110], ["aten::_batch_norm_impl_index", 6957], ["aten::relu_", 6883], ["aten::zero_", 6881], ["aten::cudnn_convolution_backward", 6859], ["aten::threshold_backward", 6658], ["aten::add_", 6654], ["aten::add_", 6608], ["ReluBackward1", 6541], ["CudnnBatchNormBackward", 6531], ["aten::contiguous", 6467], ["aten::threshold_backward", 6450], ["aten::add", 6367], ["aten::add_", 6351], ["aten::_batch_norm_impl_index", 6339], ["aten::relu_", 6328], ["aten::mul_", 6312], ["aten::add", 6311], ["aten::add_", 6287], ["aten::add_", 6242], ["aten::zero_", 6100], ["aten::contiguous", 6032], ["aten::zero_", 5961], ["torch::autograd::AccumulateGrad", 5935], ["aten::contiguous", 5919], ["aten::contiguous", 5902], ["aten::is_nonzero", 5880], ["aten::detach_", 5855], ["aten::contiguous", 5812], ["aten::as_strided", 5698], ["aten::relu_", 5665], ["aten::is_nonzero", 5658], ["CudnnBatchNormBackward", 5581], ["aten::stride", 5489], ["aten::cudnn_convolution_backward", 5470], ["aten::fill_", 5345], ["aten::threshold_backward", 5322], ["aten::cudnn_convolution_backward", 5316], ["CudnnConvolutionBackward", 5305], ["aten::add", 5272], ["aten::stack", 5232], ["aten::to", 5207], ["aten::threshold_", 5141], ["aten::mul_", 5111], ["aten::relu_", 5062], ["aten::_batch_norm_impl_index", 5052], ["aten::_batch_norm_impl_index", 4992], ["aten::fill_", 4939], ["torch::autograd::AccumulateGrad", 4927], ["torch::autograd::AccumulateGrad", 4873], ["aten::threshold_backward", 4777], ["CudnnConvolutionBackward", 4758], ["aten::fill_", 4706], ["aten::stride", 4655], ["aten::fill_", 4651], ["aten::add", 4645], ["aten::cudnn_convolution_backward", 4599], ["CudnnBatchNormBackward", 4582], ["aten::mul_", 4514], ["detach_", 4503], ["aten::stride", 4446], ["aten::cudnn_convolution_backward", 4429], ["CudnnBatchNormBackward", 4425], ["aten::_batch_norm_impl_index", 4420], ["aten::as_strided", 4417], ["aten::cudnn_convolution_backward", 4372], ["aten::contiguous", 4350], ["aten::add", 4340], ["aten::_convolution", 4315], ["aten::add_", 4306], ["aten::add", 4300], ["aten::contiguous", 4274], ["aten::empty_like", 4268], ["aten::add_", 4238], ["aten::batch_norm", 4236], ["aten::as_strided", 4146], ["aten::contiguous", 4145], ["aten::add_", 4095], ["aten::contiguous", 4070], ["aten::cudnn_convolution_backward", 4004], ["aten::_batch_norm_impl_index", 3958], ["aten::as_strided", 3956], ["aten::relu_", 3949], ["aten::contiguous", 3943], ["aten::cudnn_batch_norm", 3923], ["CudnnConvolutionBackward", 3903], ["aten::max_pool2d_with_indices", 3871], ["CudnnBatchNormBackward", 3869], ["aten::mul_", 3793], ["aten::cudnn_batch_norm", 3757], ["aten::cudnn_batch_norm", 3738], ["aten::is_pinned", 3718], ["aten::_convolution", 3694], ["aten::_convolution", 3651], ["ReluBackward1", 3634], ["CudnnBatchNormBackward", 3630], ["aten::clone", 3552], ["aten::add_", 3550], ["aten::resize_", 3531], ["aten::_convolution", 3523], ["aten::cudnn_batch_norm_backward", 3456], ["aten::stride", 3406], ["aten::zero_", 3397], ["aten::add", 3336], ["aten::mul_", 3308], ["CudnnConvolutionBackward", 3296], ["aten::contiguous", 3275], ["aten::threshold_", 3268], ["aten::threshold_", 3260], ["aten::mul_", 3232], ["aten::add_", 3230], ["CudnnConvolutionBackward", 3228], ["aten::add", 3218], ["aten::as_strided", 3213], ["aten::add", 3213], ["aten::threshold_backward", 3204], ["aten::threshold_backward", 3183], ["aten::cat", 3146], ["aten::add", 3125], ["aten::stride", 3119], ["aten::mul_", 3109], ["aten::_convolution", 3064], ["ReluBackward1", 3061], ["ReluBackward1", 3038], ["aten::relu_", 3021], ["aten::relu_", 2892], ["aten::cudnn_batch_norm_backward", 2810], ["aten::empty_like", 2774], ["aten::threshold_", 2773], ["aten::copy_", 2771], ["aten::cudnn_convolution_backward", 2771], ["torch::autograd::AccumulateGrad", 2766], ["aten::cudnn_batch_norm_backward", 2758], ["aten::cudnn_convolution_backward", 2741], ["aten::cudnn_batch_norm_backward", 2740], ["aten::batch_norm", 2734], ["aten::as_strided", 2714], ["CudnnConvolutionBackward", 2709], ["aten::batch_norm", 2699], ["aten::contiguous", 2698], ["aten::cudnn_convolution_backward", 2697], ["aten::add", 2678], ["CudnnConvolutionBackward", 2666], ["aten::empty_like", 2653], ["aten::zero_", 2641], ["aten::fill_", 2637], ["aten::mul_", 2633], ["aten::zero_", 2588], ["aten::clone", 2561], ["aten::add_", 2558], ["aten::stride", 2538], ["aten::batch_norm", 2513], ["aten::_convolution", 2493], ["aten::resize_", 2484], ["aten::empty_like", 2470], ["aten::resize_", 2434], ["ReluBackward1", 2429], ["aten::conv2d", 2372], ["aten::mul_", 2355], ["aten::resize_", 2353], ["aten::threshold_", 2333], ["torch::autograd::AccumulateGrad", 2309], ["aten::add_", 2219], ["aten::max_pool2d_with_indices_backward", 2218], ["aten::mul_", 2213], ["aten::mm", 2204], ["aten::mul_", 2200], ["aten::stride", 2191], ["aten::_convolution", 2190], ["aten::_convolution", 2189], ["aten::add_", 2186], ["aten::add_", 2178], ["aten::add_", 2160], ["aten::_convolution", 2148], ["aten::zero_", 2148], ["aten::zeros", 2146], ["torch::autograd::AccumulateGrad", 2135], ["aten::add", 2116], ["aten::add_", 2110], ["aten::contiguous", 2099], ["aten::add_", 2081], ["aten::conv2d", 2048], ["aten::add_", 2048], ["aten::add_", 2046], ["aten::add_", 2044], ["aten::fill_", 2043], ["aten::convolution", 2040], ["ReluBackward1", 2034], ["aten::conv2d", 2024], ["aten::fill_", 2016], ["aten::batch_norm", 2006], ["aten::fill_", 1996], ["aten::clone", 1940], ["aten::batch_norm", 1929], ["aten::empty_like", 1912], ["aten::empty_like", 1893], ["aten::nll_loss_forward", 1865], ["aten::zero_", 1861], ["aten::threshold_", 1831], ["torch::autograd::AccumulateGrad", 1798], ["aten::empty_like", 1792], ["aten::conv2d", 1729], ["aten::_log_softmax", 1719], ["aten::cudnn_convolution_backward", 1712], ["aten::zero_", 1698], ["aten::zero_", 1674], ["aten::batch_norm", 1660], ["aten::_convolution", 1660], ["aten::convolution", 1660], ["aten::mul_", 1660], ["aten::convolution", 1651], ["aten::resize_", 1634], ["aten::div", 1634], ["aten::conv2d", 1632], ["aten::clone", 1611], ["aten::cudnn_convolution_backward", 1609], ["aten::resize_", 1607], ["aten::clone", 1571], ["AddBackward0", 1537], ["aten::empty_like", 1530], ["aten::_convolution", 1525], ["aten::threshold_", 1522], ["aten::convolution", 1513], ["torch::autograd::AccumulateGrad", 1512], ["aten::batch_norm", 1501], ["aten::pin_memory", 1489], ["ReluBackward1", 1487], ["aten::mul_", 1480], ["aten::conv2d", 1476], ["ReluBackward1", 1457], ["aten::_convolution", 1451], ["torch::autograd::AccumulateGrad", 1442], ["aten::cudnn_convolution_backward", 1434], ["aten::stride", 1410], ["aten::nll_loss_backward", 1406], ["torch::autograd::AccumulateGrad", 1405], ["aten::_batch_norm_impl_index", 1404], ["AddmmBackward", 1396], ["aten::cudnn_convolution_backward", 1393], ["aten::cudnn_convolution_backward", 1389], ["aten::convolution", 1388], ["aten::resize_", 1385], ["aten::mm", 1378], ["aten::contiguous", 1375], ["aten::cudnn_convolution_backward", 1371], ["aten::cudnn_convolution_backward", 1369], ["aten::cudnn_convolution_backward", 1358], ["aten::contiguous", 1349], ["aten::cudnn_convolution_backward", 1347], ["aten::threshold_", 1346], ["aten::cudnn_convolution_backward", 1313], ["aten::fill_", 1306], ["aten::fill_", 1300], ["aten::fill_", 1291], ["aten::zero_", 1290], ["aten::zero_", 1275], ["aten::add", 1272], ["aten::zero_", 1265], ["aten::contiguous", 1251], ["aten::zero_", 1248], ["aten::_log_softmax_backward_data", 1244], ["aten::stride", 1221], ["aten::add", 1221], ["aten::conv2d", 1219], ["aten::t", 1218], ["aten::resize_", 1196], ["CudnnBatchNormBackward", 1194], ["aten::conv2d", 1180], ["aten::add", 1166], ["aten::conv2d", 1158], ["aten::copy_", 1145], ["aten::convolution", 1131], ["aten::resize_", 1124], ["aten::mul_", 1123], ["aten::copy_", 1119], ["aten::add", 1115], ["aten::threshold_backward", 1115], ["aten::relu_", 1096], ["aten::_batch_norm_impl_index", 1089], ["aten::copy_", 1081], ["torch::autograd::AccumulateGrad", 1080], ["torch::autograd::AccumulateGrad", 1076], ["aten::add", 1073], ["aten::add", 1070], ["aten::add", 1060], ["aten::threshold_backward", 1058], ["aten::add", 1052], ["torch::autograd::AccumulateGrad", 1049], ["aten::add", 1045], ["torch::autograd::AccumulateGrad", 1045], ["aten::threshold_backward", 1045], ["aten::threshold_backward", 1043], ["aten::add", 1032], ["aten::resize_", 1025], ["aten::_batch_norm_impl_index", 1014], ["aten::cudnn_convolution_backward", 1013], ["aten::_batch_norm_impl_index", 1011], ["aten::convolution", 1010], ["aten::convolution", 1007], ["aten::_convolution", 1002], ["aten::contiguous", 1002], ["aten::resize_", 996], ["aten::contiguous", 988], ["aten::fill_", 987], ["aten::convolution", 981], ["aten::fill_", 980], ["aten::fill_", 980], ["aten::fill_", 980], ["aten::relu_", 978], ["aten::conv2d", 976], ["aten::relu_", 974], ["aten::clone", 955], ["aten::relu_", 954], ["aten::mul_", 952], ["aten::zero_", 926], ["aten::contiguous", 922], ["aten::convolution", 921], ["CudnnBatchNormBackward", 917], ["aten::set_", 906], ["CudnnBatchNormBackward", 902], ["aten::t", 890], ["CudnnBatchNormBackward", 883], ["aten::stride", 882], ["aten::empty_like", 882], ["AddBackward0", 881], ["aten::copy_", 879], ["aten::_convolution", 867], ["aten::contiguous", 863], ["aten::zero_", 860], ["aten::to", 852], ["aten::view", 852], ["aten::zero_", 837], ["aten::contiguous", 827], ["aten::threshold_", 826], ["aten::as_strided", 820], ["aten::contiguous", 814], ["aten::mul_", 813], ["aten::contiguous", 812], ["aten::mul_", 798], ["CudnnConvolutionBackward", 793], ["aten::conv2d", 787], ["aten::mul_", 785], ["aten::mul_", 784], ["aten::copy_", 776], ["aten::resize_", 775], ["aten::conv2d", 774], ["aten::resize_", 765], ["aten::mul_", 764], ["aten::empty_like", 763], ["aten::convolution", 760], ["torch::autograd::AccumulateGrad", 757], ["aten::_convolution", 753], ["aten::mul_", 753], ["aten::_convolution", 752], ["aten::contiguous", 751], ["aten::mul_", 749], ["aten::_convolution", 744], ["NllLossBackward", 743], ["aten::mul_", 736], ["aten::resize_", 734], ["aten::_convolution", 732], ["aten::_convolution", 727], ["aten::_convolution", 725], ["aten::_convolution", 723], ["aten::_convolution", 717], ["aten::contiguous", 716], ["aten::copy_", 716], ["aten::_convolution", 714], ["torch::autograd::AccumulateGrad", 703], ["aten::contiguous", 701], ["aten::detach", 695], ["aten::expand", 694], ["aten::clone", 688], ["aten::stride", 684], ["MeanBackward1", 682], ["aten::contiguous", 679], ["aten::copy_", 675], ["aten::as_strided", 672], ["aten::convolution", 668], ["CudnnConvolutionBackward", 666], ["CudnnConvolutionBackward", 663], ["CudnnConvolutionBackward", 658], ["MaxPool2DWithIndicesBackward", 656], ["aten::stride", 655], ["aten::clone", 654], ["aten::fill_", 652], ["aten::fill_", 646], ["aten::stride", 631], ["aten::stride", 628], ["aten::stride", 609], ["aten::clone", 598], ["aten::resize_", 596], ["aten::transpose", 593], ["aten::to", 591], ["aten::batch_norm", 577], ["aten::resize_", 572], ["AddBackward0", 571], ["AddBackward0", 570], ["aten::resize_", 566], ["aten::stride", 563], ["aten::resize_", 559], ["aten::view", 550], ["aten::transpose", 544], ["aten::stride", 543], ["aten::copy_", 536], ["nccl:broadcast", 532], ["aten::contiguous", 525], ["aten::ones_like", 523], ["aten::stride", 517], ["aten::copy_", 515], ["LogSoftmaxBackward", 512], ["aten::copy_", 511], ["aten::clone", 510], ["aten::clone", 508], ["aten::threshold_", 507], ["aten::copy_", 506], ["detach", 499], ["aten::detach", 497], ["ReluBackward1", 487], ["ReluBackward1", 480], ["aten::threshold_", 479], ["aten::clone", 477], ["ReluBackward1", 475], ["aten::t", 474], ["aten::threshold_", 473], ["aten::fill_", 469], ["aten::contiguous", 464], ["torch::autograd::AccumulateGrad", 464], ["aten::zero_", 460], ["ReluBackward1", 460], ["aten::zero_", 459], ["aten::max_pool2d", 458], ["aten::fill_", 451], ["aten::conv2d", 441], ["aten::fill_", 441], ["aten::zero_", 439], ["aten::conv2d", 435], ["aten::zero_", 433], ["aten::fill_", 431], ["aten::zero_", 427], ["aten::zero_", 423], ["aten::zero_", 421], ["aten::zero_", 421], ["aten::zero_", 419], ["aten::conv2d", 416], ["aten::zero_", 416], ["aten::resize_", 414], ["aten::conv2d", 408], ["aten::flatten", 406], ["aten::conv2d", 402], ["aten::conv2d", 400], ["aten::conv2d", 398], ["aten::convolution", 397], ["aten::adaptive_avg_pool2d", 397], ["aten::resize_", 394], ["aten::log_softmax", 393], ["aten::clone", 393], ["aten::conv2d", 389], ["aten::conv2d", 388], ["aten::conv2d", 388], ["aten::empty_like", 387], ["aten::conv2d", 384], ["aten::empty_like", 384], ["aten::nll_loss", 383], ["aten::expand", 380], ["aten::batch_norm", 378], ["aten::empty_like", 377], ["aten::resize_", 377], ["aten::empty_like", 376], ["torch::autograd::AccumulateGrad", 376], ["aten::zeros_like", 372], ["aten::convolution", 371], ["aten::convolution", 371], ["aten::batch_norm", 370], ["aten::batch_norm", 370], ["aten::clone", 368], ["torch::autograd::AccumulateGrad", 366], ["aten::convolution", 365], ["aten::clone", 365], ["ViewBackward", 365], ["torch::autograd::AccumulateGrad", 362], ["torch::autograd::AccumulateGrad", 362], ["aten::detach", 361], ["aten::is_pinned", 357], ["torch::autograd::AccumulateGrad", 356], ["aten::clone", 355], ["aten::copy_", 355], ["aten::resize_", 350], ["aten::fill_", 349], ["aten::resize_as_", 349], ["torch::autograd::AccumulateGrad", 348], ["torch::autograd::AccumulateGrad", 347], ["aten::convolution", 346], ["torch::autograd::AccumulateGrad", 345], ["torch::autograd::AccumulateGrad", 345], ["aten::convolution", 342], ["aten::convolution", 342], ["aten::resize_", 338], ["aten::copy_", 336], ["aten::fill_", 334], ["aten::convolution", 329], ["detach", 328], ["aten::convolution", 327], ["aten::fill_", 326], ["aten::fill_", 326], ["aten::convolution", 325], ["aten::fill_", 325], ["aten::fill_", 324], ["aten::fill_", 322], ["aten::fill_", 320], ["aten::convolution", 319], ["aten::stride", 318], ["aten::zero_", 312], ["aten::detach", 309], ["aten::resize_", 307], ["aten::detach", 300], ["aten::contiguous", 296], ["TBackward", 281], ["aten::contiguous", 275], ["aten::resize_", 272], ["aten::as_strided", 270], ["aten::slice", 266], ["aten::transpose", 262], ["aten::narrow", 252], ["aten::reshape", 252], ["aten::reshape", 245], ["detach", 243], ["aten::as_strided", 236], ["aten::contiguous", 235], ["aten::copy_", 235], ["aten::contiguous", 232], ["aten::contiguous", 229], ["aten::resize_", 227], ["aten::contiguous", 225], ["aten::contiguous", 223], ["aten::contiguous", 223], ["aten::clone", 220], ["aten::contiguous", 219], ["aten::clone", 217], ["aten::resize_", 211], ["aten::copy_", 206], ["detach", 201], ["aten::copy_", 199], ["aten::resize_", 195], ["detach", 195], ["aten::resize_", 194], ["aten::resize_", 192], ["aten::resize_", 185], ["aten::resize_", 184], ["aten::copy_", 184], ["aten::copy_", 184], ["aten::stride", 178], ["aten::copy_", 176], ["aten::to", 175], ["aten::copy_", 173], ["aten::copy_", 172], ["aten::copy_", 170], ["aten::copy_", 169], ["aten::detach", 167], ["aten::copy_", 164], ["aten::stride", 158], ["detach_", 154], ["aten::conj", 152], ["aten::as_strided", 149], ["aten::detach_", 145], ["aten::conj", 145], ["aten::clone", 141], ["aten::as_strided", 140], ["aten::detach", 134], ["aten::clone", 132], ["aten::detach", 129], ["aten::contiguous", 126], ["aten::stride", 124], ["aten::as_strided", 123], ["aten::as_strided", 121], ["aten::as_strided", 121], ["aten::clone", 120], ["aten::is_floating_point", 119], ["aten::clone", 118], ["aten::clone", 117], ["aten::clone", 116], ["aten::to", 115], ["detach", 112], ["aten::clone", 112], ["aten::clone", 110], ["aten::detach", 109], ["aten::clone", 108], ["aten::detach", 106], ["aten::clone", 106], ["aten::resize_", 99], ["aten::stride", 91], ["aten::stride", 91], ["aten::detach", 91], ["aten::detach", 91], ["detach", 91], ["aten::stride", 90], ["aten::random_", 89], ["aten::detach", 89], ["detach", 89], ["detach", 74], ["detach", 74], ["aten::detach", 67], ["aten::detach", 65], ["aten::detach", 65], ["detach", 62], ["detach", 60], ["detach", 45], ["detach", 45], ["aten::detach", 45], ["aten::stride", 45], ["aten::detach", 44], ["detach", 44], ["detach", 44], ["detach", 31], ["detach", 30], ["aten::detach", 26], ["aten::detach", 23], ["aten::detach", 23], ["aten::detach", 23], ["aten::detach", 22], ["aten::detach", 22], ["aten::detach", 22], ["aten::detach", 21], ["aten::detach", 21], ["aten::detach", 20], ["detach", 16], ["detach", 16], ["detach", 16], ["detach", 15], ["detach", 15], ["detach", 15], ["detach", 15], ["detach", 14], ["detach", 14], ["detach", 14]]}}, "operation_table_by_name_input": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "string", "name": "Input Shape"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Device Self Duration (us)"}, {"type": "number", "name": "Device Total Duration (us)"}, {"type": "number", "name": "Host Self Duration (us)"}, {"type": "number", "name": "Host Total Duration (us)"}], "rows": [["aten::cudnn_convolution_backward_weight", "[[], [32, 64, 56, 56], [32, 64, 56, 56], [], [], [], [], [], [], []]", 32, 31776, 31776, 23126, 27473], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], []]", 24, 29075, 29075, 32460, 36281], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], []]", 48, 28016, 28016, 31973, 39232], ["aten::cudnn_convolution_backward_input", "[[], [32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], []]", 32, 25953, 25953, 29515, 34578], ["aten::cudnn_convolution", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], []]", 48, 24045, 24045, 28646, 35431], ["aten::cudnn_convolution_backward_weight", "[[], [32, 1024, 14, 14], [32, 256, 14, 14], [], [], [], [], [], [], []]", 48, 21857, 21857, 27828, 34812], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 56, 56], [32, 64, 56, 56], [], [], [], [], [], [], []]", 32, 21851, 21851, 20468, 24834], ["aten::cudnn_convolution", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], []]", 24, 21482, 21482, 32294, 35602], ["aten::cudnn_convolution", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], []]", 40, 21136, 21136, 25724, 31357], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], []]", 40, 20738, 20738, 20389, 26253], ["aten::cudnn_batch_norm_backward", "[[32, 256, 56, 56], [32, 256, 56, 56], [256], [256], [256], [256], [256], [], [0]]", 32, 20540, 20540, 11153, 16659], ["aten::cudnn_convolution_backward_input", "[[], [32, 2048, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], []]", 24, 20240, 20240, 19865, 23141], ["aten::cudnn_convolution", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], []]", 16, 19366, 19366, 24696, 26901], ["aten::cudnn_convolution_backward_input", "[[], [32, 1024, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], []]", 48, 19137, 19137, 36198, 43636], ["aten::cudnn_convolution_backward_weight", "[[], [32, 64, 56, 56], [32, 256, 56, 56], [], [], [], [], [], [], []]", 16, 18587, 18587, 13526, 15798], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 14, 14], [32, 1024, 14, 14], [], [], [], [], [], [], []]", 40, 18523, 18523, 19966, 25559], ["aten::cudnn_convolution", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], []]", 40, 17657, 17657, 28829, 97687], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 28, 28], [32, 128, 28, 28], [], [], [], [], [], [], []]", 32, 16632, 16632, 18633, 22996], ["aten::cudnn_convolution", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], []]", 16, 16606, 16606, 22179, 25168], ["aten::cudnn_convolution", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], []]", 32, 16011, 16011, 26554, 32182], ["aten::cudnn_convolution", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], [], [], []]", 8, 15786, 15786, 14440, 15898], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 14, 14], [32, 256, 14, 14], [], [], [], [], [], [], []]", 40, 15734, 15734, 21479, 27521], ["aten::cudnn_convolution_backward_weight", "[[], [32, 2048, 7, 7], [32, 512, 7, 7], [], [], [], [], [], [], []]", 24, 15718, 15718, 297284, 300870], ["aten::cudnn_convolution", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 15711, 15711, 139783, 141259], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], []]", 16, 15703, 15703, 20738, 22968], ["aten::cudnn_convolution", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], []]", 8, 15643, 15643, 2370703, 2372892], ["aten::cudnn_convolution", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], []]", 24, 15399, 15399, 22769, 26803], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 56, 56], [32, 256, 56, 56], [], [], [], [], [], [], []]", 8, 15241, 15241, 147184, 148327], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], []]", 32, 15082, 15082, 17888, 22462], ["aten::cudnn_convolution_backward_input", "[[], [32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], []]", 24, 14776, 14776, 18781, 22457], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], []]", 32, 14541, 14541, 18405, 23407], ["aten::cudnn_convolution", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], []]", 8, 14401, 14401, 20423, 21616], ["aten::cudnn_convolution", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], []]", 24, 13922, 13922, 20667, 24039], ["aten::copy_", "[[32, 3, 224, 224], [32, 3, 224, 224], []]", 16, 13570, 13570, 95197, 95197], ["aten::cudnn_convolution_backward_input", "[[], [32, 128, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], []]", 8, 13442, 13442, 17380, 18636], ["aten::cudnn_convolution", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], []]", 32, 13397, 13397, 28262, 33202], ["aten::cudnn_batch_norm_backward", "[[32, 512, 28, 28], [32, 512, 28, 28], [512], [512], [512], [512], [512], [], [0]]", 40, 13251, 13251, 14462, 21664], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 28, 28], [32, 512, 28, 28], [], [], [], [], [], [], []]", 24, 13208, 13208, 14334, 17882], ["aten::cudnn_convolution", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], []]", 8, 13117, 13117, 15658, 16805], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 13012, 13012, 14031, 15122], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 7, 7], [32, 2048, 7, 7], [], [], [], [], [], [], []]", 16, 12918, 12918, 17971, 20317], ["aten::cudnn_batch_norm", "[[32, 256, 56, 56], [256], [256], [256], [256], [], [], []]", 32, 12806, 12806, 17699, 25784], ["aten::cudnn_convolution_backward_weight", "[[], [32, 64, 112, 112], [32, 3, 224, 224], [], [], [], [], [], [], []]", 8, 12652, 12652, 9069, 10111], ["aten::cudnn_convolution", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], []]", 24, 12301, 12301, 22210, 27978], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 28, 28], [32, 128, 28, 28], [], [], [], [], [], [], []]", 24, 12000, 12000, 15824, 19963], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 28, 28], [512, 256, 1, 1], [], [], [], [], [], [], []]", 8, 11640, 11640, 9440, 10517], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 28, 28], [32, 512, 28, 28], [], [], [], [], [], [], []]", 8, 11556, 11556, 10789, 12367], ["aten::cudnn_convolution_backward_input", "[[], [32, 64, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], []]", 16, 11337, 11337, 13084, 15521], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 14, 14], [32, 1024, 14, 14], [], [], [], [], [], [], []]", 8, 10859, 10859, 10588, 11783], ["aten::cudnn_convolution", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], []]", 16, 10752, 10752, 18398, 20982], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 7, 7], [32, 512, 7, 7], [], [], [], [], [], [], []]", 16, 10661, 10661, 26410, 28731], ["aten::cudnn_convolution_backward_input", "[[], [32, 1024, 14, 14], [1024, 512, 1, 1], [], [], [], [], [], [], []]", 8, 10658, 10658, 69721, 71042], ["aten::cudnn_convolution_backward_input", "[[], [32, 128, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], []]", 24, 10630, 10630, 18112, 21947], ["aten::cudnn_convolution_backward_input", "[[], [32, 2048, 7, 7], [2048, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 10610, 10610, 153530, 154663], ["aten::cudnn_convolution", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], [], [], []]", 8, 10248, 10248, 13022, 14245], ["aten::cudnn_convolution_backward_weight", "[[], [32, 2048, 7, 7], [32, 1024, 14, 14], [], [], [], [], [], [], []]", 8, 10157, 10157, 9519, 10708], ["aten::cudnn_batch_norm_backward", "[[32, 1024, 14, 14], [32, 1024, 14, 14], [1024], [1024], [1024], [1024], [1024], [], [0]]", 56, 10146, 10146, 20741, 30692], ["aten::cudnn_batch_norm_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], [64], [64], [64], [64], [64], [], [0]]", 48, 10088, 10088, 16828, 25439], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], []]", 8, 9949, 9949, 14207, 15820], ["aten::cudnn_convolution", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], [], [], []]", 8, 9896, 9896, 137741, 139921], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 7, 7], [32, 512, 14, 14], [], [], [], [], [], [], []]", 8, 9664, 9664, 11322, 12523], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 28, 28], [32, 256, 56, 56], [], [], [], [], [], [], []]", 8, 9335, 9335, 7802, 8893], ["aten::cudnn_convolution", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 9179, 9179, 11276, 12389], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 28, 28], [32, 128, 56, 56], [], [], [], [], [], [], []]", 8, 8872, 8872, 11968, 13060], ["aten::threshold_backward", "[[32, 256, 56, 56], [32, 256, 56, 56], []]", 24, 8809, 8809, 3183, 4130], ["aten::add_", "[[32, 256, 56, 56], [32, 256, 56, 56], []]", 24, 8744, 8744, 3550, 3550], ["aten::cudnn_convolution", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], [], [], []]", 8, 8628, 8628, 10358, 11567], ["aten::cudnn_convolution_backward_weight", "[[], [32, 1024, 14, 14], [32, 512, 28, 28], [], [], [], [], [], [], []]", 8, 8440, 8440, 72806, 74374], ["aten::cudnn_batch_norm", "[[32, 512, 28, 28], [512], [512], [512], [512], [], [], []]", 40, 8277, 8277, 18779, 28768], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 14, 14], [32, 256, 28, 28], [], [], [], [], [], [], []]", 8, 8165, 8165, 8100, 9276], ["aten::cudnn_convolution", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], [], [], []]", 8, 7781, 7781, 11120, 12848], ["aten::cudnn_batch_norm_backward", "[[32, 64, 112, 112], [32, 64, 112, 112], [64], [64], [64], [64], [64], [], [0]]", 8, 6504, 6504, 2758, 4132], ["aten::threshold_", "[[32, 256, 56, 56], [], []]", 24, 6015, 6015, 1522, 1522], ["aten::threshold_backward", "[[32, 512, 28, 28], [32, 512, 28, 28], []]", 32, 5941, 5941, 4777, 6086], ["aten::add_", "[[32, 512, 28, 28], [32, 512, 28, 28], []]", 32, 5915, 5915, 4306, 4306], ["aten::max_pool2d_with_indices_backward", "[[32, 64, 56, 56], [32, 64, 112, 112], [], [], [], [], [], [32, 64, 56, 56]]", 8, 5552, 6837, 2218, 5077], ["aten::cudnn_batch_norm", "[[32, 64, 56, 56], [64], [64], [64], [64], [], [], []]", 48, 5344, 5344, 24814, 37150], ["aten::cudnn_batch_norm_backward", "[[32, 128, 28, 28], [32, 128, 28, 28], [128], [128], [128], [128], [128], [], [0]]", 56, 5098, 5098, 20539, 30565], ["aten::cudnn_batch_norm", "[[32, 1024, 14, 14], [1024], [1024], [1024], [1024], [], [], []]", 56, 4748, 4748, 26489, 40513], ["aten::threshold_backward", "[[32, 1024, 14, 14], [32, 1024, 14, 14], []]", 48, 4606, 4606, 6658, 8586], ["aten::threshold_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], []]", 48, 4440, 4440, 6450, 8424], ["aten::add_", "[[32, 1024, 14, 14], [32, 1024, 14, 14], []]", 48, 4413, 4413, 6608, 6608], ["aten::cudnn_batch_norm_backward", "[[32, 256, 14, 14], [32, 256, 14, 14], [256], [256], [256], [256], [256], [], [0]]", 88, 4187, 4187, 30601, 45950], ["aten::threshold_", "[[32, 512, 28, 28], [], []]", 32, 4052, 4052, 1831, 1831], ["aten::cudnn_batch_norm", "[[32, 64, 112, 112], [64], [64], [64], [64], [], [], []]", 8, 3414, 3414, 76206, 78429], ["aten::threshold_", "[[32, 64, 56, 56], [], []]", 48, 3035, 3035, 3268, 3268], ["aten::threshold_", "[[32, 1024, 14, 14], [], []]", 48, 3033, 3033, 2773, 2773], ["aten::threshold_backward", "[[32, 64, 112, 112], [32, 64, 112, 112], []]", 8, 2966, 2966, 1045, 1462], ["aten::cudnn_batch_norm", "[[32, 128, 28, 28], [128], [128], [128], [128], [], [], []]", 56, 2934, 2934, 26037, 38952], ["aten::cudnn_convolution", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], []]", 8, 2814, 2814, 9018, 10759], ["aten::cudnn_batch_norm_backward", "[[32, 128, 56, 56], [32, 128, 56, 56], [128], [128], [128], [128], [128], [], [0]]", 8, 2736, 2736, 2810, 4148], ["aten::threshold_backward", "[[32, 128, 28, 28], [32, 128, 28, 28], []]", 56, 2732, 2732, 7703, 10043], ["aten::cudnn_convolution_backward_input", "[[], [32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], []]", 8, 2723, 2723, 8188, 9371], ["aten::threshold_backward", "[[32, 256, 14, 14], [32, 256, 14, 14], []]", 88, 2457, 2457, 11870, 15571], ["aten::add_", "[[512, 512, 3, 3], [512, 512, 3, 3], []]", 66, 2365, 2365, 6287, 6287], ["aten::cudnn_batch_norm_backward", "[[32, 2048, 7, 7], [32, 2048, 7, 7], [2048], [2048], [2048], [2048], [2048], [], [0]]", 32, 2347, 2347, 12837, 18292], ["aten::cudnn_batch_norm", "[[32, 256, 14, 14], [256], [256], [256], [256], [], [], []]", 88, 1998, 1998, 42947, 63146], ["aten::threshold_", "[[32, 64, 112, 112], [], []]", 8, 1997, 1997, 826, 826], ["aten::threshold_", "[[32, 128, 28, 28], [], []]", 56, 1855, 1855, 3260, 3260], ["aten::cudnn_batch_norm", "[[32, 2048, 7, 7], [2048], [2048], [2048], [2048], [], [], []]", 32, 1797, 1797, 15070, 22600], ["aten::max_pool2d_with_indices", "[[32, 64, 112, 112], [], [], [], [], []]", 8, 1785, 1785, 3871, 5679], ["aten::cudnn_batch_norm", "[[32, 128, 56, 56], [128], [128], [128], [128], [], [], []]", 8, 1597, 1597, 3757, 5545], ["aten::threshold_backward", "[[32, 128, 56, 56], [32, 128, 56, 56], []]", 8, 1473, 1473, 1058, 1381], ["aten::add_", "[[256], [256], []]", 704, 1389, 1389, 67093, 67093], ["aten::cudnn_batch_norm_backward", "[[32, 256, 28, 28], [32, 256, 28, 28], [256], [256], [256], [256], [256], [], [0]]", 8, 1308, 1308, 3456, 5155], ["aten::fill_", "[[32, 64, 112, 112], []]", 8, 1285, 1285, 469, 469], ["aten::threshold_backward", "[[32, 2048, 7, 7], [32, 2048, 7, 7], []]", 24, 1209, 1209, 3204, 4135], ["aten::add_", "[[32, 2048, 7, 7], [32, 2048, 7, 7], []]", 24, 1126, 1126, 3230, 3230], ["aten::threshold_", "[[32, 256, 14, 14], [], []]", 88, 1034, 1034, 5141, 5141], ["aten::threshold_", "[[32, 128, 56, 56], [], []]", 8, 1007, 1007, 479, 479], ["aten::add_", "[[512], [512], []]", 484, 959, 959, 46093, 46093], ["aten::cudnn_batch_norm_backward", "[[32, 512, 7, 7], [32, 512, 7, 7], [512], [512], [512], [512], [512], [], [0]]", 40, 935, 935, 13786, 20585], ["aten::add_", "[[2048, 512, 1, 1], [2048, 512, 1, 1], []]", 66, 921, 921, 6242, 6242], ["aten::add_", "[[256, 256, 3, 3], [256, 256, 3, 3], []]", 132, 898, 898, 12497, 12497], ["aten::add", "[[512, 512, 3, 3], [512, 512, 3, 3], []]", 24, 840, 840, 3218, 4224], ["aten::cudnn_batch_norm", "[[32, 256, 28, 28], [256], [256], [256], [256], [], [], []]", 8, 837, 837, 3923, 5750], ["aten::threshold_", "[[32, 2048, 7, 7], [], []]", 24, 794, 794, 1346, 1346], ["aten::threshold_backward", "[[32, 256, 28, 28], [32, 256, 28, 28], []]", 8, 762, 762, 1115, 1605], ["aten::cudnn_batch_norm_backward", "[[32, 512, 14, 14], [32, 512, 14, 14], [512], [512], [512], [512], [512], [], [0]]", 8, 741, 741, 2740, 4101], ["aten::add_", "[[2048, 1024, 1, 1], [2048, 1024, 1, 1], []]", 22, 713, 713, 2044, 2044], ["aten::add_", "[[128], [128], []]", 352, 690, 690, 34221, 34221], ["aten::add_", "[[1000, 2048], [1000, 2048], []]", 22, 678, 678, 2186, 2186], ["aten::threshold_backward", "[[32, 512, 7, 7], [32, 512, 7, 7], []]", 40, 664, 664, 5322, 6983], ["aten::add_", "[[512, 2048, 1, 1], [512, 2048, 1, 1], []]", 44, 646, 646, 4095, 4095], ["aten::cudnn_batch_norm", "[[32, 512, 7, 7], [512], [512], [512], [512], [], [], []]", 40, 633, 633, 18568, 27563], ["aten::add_", "[[1024], [1024], []]", 308, 619, 619, 28956, 28956], ["aten::add_", "[[64], [64], []]", 308, 612, 612, 29647, 29647], ["aten::threshold_", "[[32, 256, 28, 28], [], []]", 8, 515, 515, 473, 473], ["aten::mul_", "[[512, 512, 3, 3], []]", 21, 503, 503, 2200, 2200], ["aten::add_", "[[1024, 256, 1, 1], [1024, 256, 1, 1], []]", 132, 484, 484, 12486, 12486], ["aten::add", "[[256, 256, 3, 3], [256, 256, 3, 3], []]", 48, 479, 479, 6367, 8421], ["aten::add", "[[], [], []]", 424, 461, 461, 60418, 76755], ["aten::add_", "[[256, 1024, 1, 1], [256, 1024, 1, 1], []]", 110, 453, 453, 10379, 10379], ["aten::copy_", "[[], [], []]", 1192, 424, 424, 69327, 69327], ["aten::threshold_backward", "[[32, 512, 14, 14], [32, 512, 14, 14], []]", 8, 403, 403, 1043, 1383], ["aten::_cat", "[[], []]", 24, 390, 390, 4288871, 4298425], ["aten::add", "[[2048, 512, 1, 1], [2048, 512, 1, 1], []]", 24, 384, 384, 3125, 4105], ["aten::cudnn_batch_norm", "[[32, 512, 14, 14], [512], [512], [512], [512], [], [], []]", 8, 371, 371, 3738, 5524], ["aten::copy_", "[[256], [256], []]", 320, 369, 369, 29665, 29665], ["aten::add_", "[[2048], [2048], []]", 176, 363, 363, 16470, 16470], ["aten::mean", "[[32, 2048, 7, 7], [], [], []]", 8, 346, 346, 8117, 8436], ["aten::fill_", "[[512, 512, 3, 3], []]", 21, 315, 315, 980, 980], ["aten::add_", "[[128, 128, 3, 3], [128, 128, 3, 3], []]", 88, 278, 278, 8812, 8812], ["aten::threshold_", "[[32, 512, 7, 7], [], []]", 40, 274, 274, 2333, 2333], ["aten::addmm", "[[1000], [32, 2048], [2048, 1000], [], []]", 8, 269, 269, 876946, 880342], ["aten::mul_", "[[256, 256, 3, 3], []]", 42, 261, 261, 5111, 5111], ["aten::add", "[[512, 2048, 1, 1], [512, 2048, 1, 1], []]", 16, 257, 257, 2116, 2754], ["aten::add", "[[256], [256], []]", 256, 256, 256, 34757, 45269], ["aten::add", "[[2048, 1024, 1, 1], [2048, 1024, 1, 1], []]", 8, 248, 248, 1032, 1354], ["aten::add", "[[1000, 2048], [1000, 2048], []]", 8, 244, 244, 1070, 1383], ["aten::threshold_", "[[32, 512, 14, 14], [], []]", 8, 243, 243, 507, 507], ["aten::add", "[[1024, 256, 1, 1], [1024, 256, 1, 1], []]", 48, 239, 239, 6311, 8241], ["aten::mm", "[[32, 1000], [1000, 2048]]", 8, 232, 232, 2204, 2700], ["aten::mul_", "[[2048, 512, 1, 1], []]", 21, 231, 231, 2213, 2213], ["aten::div", "[[32, 2048, 7, 7], []]", 8, 230, 230, 1634, 1959], ["aten::mul_", "[[256], []]", 224, 224, 224, 23459, 23459], ["aten::copy_", "[[512], [512], []]", 220, 221, 221, 21797, 21797], ["aten::add_", "[[512, 128, 1, 1], [512, 128, 1, 1], []]", 88, 205, 205, 8522, 8522], ["aten::add_", "[[256, 64, 1, 1], [256, 64, 1, 1], []]", 88, 190, 190, 8358, 8358], ["aten::add", "[[256, 1024, 1, 1], [256, 1024, 1, 1], []]", 40, 180, 180, 5272, 6876], ["aten::add", "[[512], [512], []]", 176, 176, 176, 23419, 30512], ["aten::copy_", "[[1024], [1024], []]", 140, 172, 172, 12466, 12466], ["aten::copy_", "[[512, 512, 3, 3], [512, 512, 3, 3], []]", 6, 170, 170, 515, 515], ["aten::fill_", "[[256, 256, 3, 3], []]", 42, 168, 168, 1996, 1996], ["aten::copy_", "[[128], [128], []]", 160, 166, 166, 15379, 15379], ["aten::add_", "[[512, 1024, 1, 1], [512, 1024, 1, 1], []]", 22, 162, 162, 2046, 2046], ["aten::mul_", "[[512], []]", 154, 154, 154, 16144, 16144], ["aten::add_", "[[128, 512, 1, 1], [128, 512, 1, 1], []]", 66, 153, 153, 6351, 6351], ["aten::mul_", "[[512, 2048, 1, 1], []]", 14, 152, 152, 1480, 1480], ["aten::mm", "[[1000, 32], [32, 2048]]", 8, 152, 152, 1378, 1883], ["aten::mul_", "[[2048, 1024, 1, 1], []]", 7, 151, 151, 749, 749], ["aten::fill_", "[[2048, 512, 1, 1], []]", 21, 147, 147, 980, 980], ["aten::mul_", "[[1000, 2048], []]", 7, 147, 147, 1123, 1123], ["aten::add_", "[[64, 64, 3, 3], [64, 64, 3, 3], []]", 66, 144, 144, 6654, 6654], ["aten::copy_", "[[64], [64], []]", 140, 140, 140, 12895, 12895], ["aten::mul_", "[[1024, 256, 1, 1], []]", 42, 131, 131, 4514, 4514], ["aten::add", "[[128], [128], []]", 128, 128, 128, 17571, 22741], ["aten::add_", "[[1024, 512, 1, 1], [1024, 512, 1, 1], []]", 22, 124, 124, 2178, 2178], ["aten::add", "[[64], [64], []]", 112, 112, 112, 15431, 22091], ["aten::add", "[[1024], [1024], []]", 112, 112, 112, 14792, 19144], ["aten::mul_", "[[128], []]", 112, 112, 112, 11817, 11817], ["aten::mul_", "[[256, 1024, 1, 1], []]", 35, 105, 105, 3793, 3793], ["aten::fill_", "[[512, 2048, 1, 1], []]", 14, 98, 98, 646, 646], ["aten::mul_", "[[64], []]", 98, 98, 98, 10400, 10400], ["aten::mul_", "[[1024], []]", 98, 98, 98, 10352, 10352], ["aten::fill_", "[[2048, 1024, 1, 1], []]", 7, 91, 91, 322, 322], ["aten::fill_", "[[1000, 2048], []]", 7, 91, 91, 325, 325], ["aten::fill_", "[[256], []]", 224, 90, 90, 10737, 10737], ["aten::add_", "[[64, 256, 1, 1], [64, 256, 1, 1], []]", 44, 89, 89, 4238, 4238], ["aten::fill_", "[[512], []]", 154, 89, 89, 7221, 7221], ["aten::add", "[[128, 128, 3, 3], [128, 128, 3, 3], []]", 32, 88, 88, 4645, 6022], ["aten::_log_softmax_backward_data", "[[32, 1000], [32, 1000], [], [32, 1000]]", 8, 86, 86, 1244, 2166], ["aten::fill_", "[[128], []]", 112, 84, 84, 5345, 5345], ["aten::fill_", "[[1024, 256, 1, 1], []]", 42, 84, 84, 2016, 2016], ["aten::_log_softmax", "[[32, 1000], [], []]", 8, 82, 82, 1719, 2535], ["aten::copy_", "[[256, 256, 3, 3], [256, 256, 3, 3], []]", 12, 82, 82, 1081, 1081], ["aten::copy_", "[[2048], [2048], []]", 80, 81, 81, 8370, 8370], ["aten::add_", "[[256, 512, 1, 1], [256, 512, 1, 1], []]", 22, 80, 80, 2558, 2558], ["aten::fill_", "[[1024], []]", 98, 73, 73, 4706, 4706], ["aten::add", "[[1024, 512, 1, 1], [1024, 512, 1, 1], []]", 8, 72, 72, 1060, 1385], ["aten::add", "[[512, 1024, 1, 1], [512, 1024, 1, 1], []]", 8, 72, 72, 1045, 1364], ["aten::add_", "[[512, 256, 1, 1], [512, 256, 1, 1], []]", 22, 70, 70, 2110, 2110], ["aten::fill_", "[[256, 1024, 1, 1], []]", 35, 70, 70, 2043, 2043], ["aten::add", "[[512, 128, 1, 1], [512, 128, 1, 1], []]", 32, 65, 65, 4340, 5680], ["aten::copy_", "[[2048, 512, 1, 1], [2048, 512, 1, 1], []]", 6, 65, 65, 511, 511], ["aten::add", "[[2048], [2048], []]", 64, 65, 65, 8441, 11073], ["aten::mul_", "[[128, 128, 3, 3], []]", 28, 59, 59, 3232, 3232], ["aten::copy_", "[[512, 2048, 1, 1], [512, 2048, 1, 1], []]", 4, 58, 58, 355, 355], ["aten::mul_", "[[2048], []]", 56, 56, 56, 6312, 6312], ["aten::copy_", "[[1024, 256, 1, 1], [1024, 256, 1, 1], []]", 12, 53, 53, 1119, 1119], ["aten::add_", "[[64, 3, 7, 7], [64, 3, 7, 7], []]", 22, 48, 48, 2219, 2219], ["aten::add", "[[128, 512, 1, 1], [128, 512, 1, 1], []]", 24, 48, 48, 3336, 4401], ["aten::copy_", "[[2048, 1024, 1, 1], [2048, 1024, 1, 1], []]", 2, 48, 48, 169, 169], ["aten::add_", "[[128, 256, 1, 1], [128, 256, 1, 1], []]", 22, 47, 47, 2160, 2160], ["aten::copy_", "[[256, 1024, 1, 1], [256, 1024, 1, 1], []]", 10, 47, 47, 879, 879], ["aten::copy_", "[[1000, 2048], [1000, 2048], []]", 2, 46, 46, 164, 164], ["aten::add_", "[[64, 64, 1, 1], [64, 64, 1, 1], []]", 22, 39, 39, 2081, 2081], ["aten::mul_", "[[1024, 512, 1, 1], []]", 7, 39, 39, 753, 753], ["aten::mul_", "[[512, 1024, 1, 1], []]", 7, 36, 36, 764, 764], ["aten::fill_", "[[64], []]", 98, 34, 34, 4651, 4651], ["aten::nll_loss_forward", "[[32, 1000], [32], [], [], []]", 8, 33, 33, 1865, 1865], ["aten::add", "[[256, 64, 1, 1], [256, 64, 1, 1], []]", 32, 32, 32, 4300, 5639], ["aten::mul_", "[[512, 128, 1, 1], []]", 28, 30, 30, 3308, 3308], ["aten::fill_", "[[256, 64, 1, 1], []]", 28, 28, 28, 1300, 1300], ["aten::fill_", "[[128, 128, 3, 3], []]", 28, 28, 28, 1291, 1291], ["aten::fill_", "[[512, 128, 1, 1], []]", 28, 28, 28, 1306, 1306], ["aten::fill_", "[[1024, 512, 1, 1], []]", 7, 28, 28, 324, 324], ["aten::fill_", "[[512, 1024, 1, 1], []]", 7, 28, 28, 441, 441], ["aten::mul_", "[[256, 64, 1, 1], []]", 28, 28, 28, 3109, 3109], ["aten::copy_", "[[32], [32], []]", 16, 25, 25, 2771, 2771], ["aten::fill_", "[[2048], []]", 56, 25, 25, 2637, 2637], ["aten::add", "[[64, 64, 3, 3], [64, 64, 3, 3], []]", 24, 24, 24, 3213, 4205], ["aten::add", "[[512, 256, 1, 1], [512, 256, 1, 1], []]", 8, 24, 24, 1115, 1438], ["aten::add", "[[256, 512, 1, 1], [256, 512, 1, 1], []]", 8, 24, 24, 1221, 1549], ["aten::nll_loss_backward", "[[], [32, 1000], [32], [], [], [], []]", 8, 24, 24, 1406, 1406], ["aten::add_", "[[1000], [1000], []]", 22, 22, 22, 2048, 2048], ["aten::fill_", "[[64, 64, 3, 3], []]", 21, 21, 21, 980, 980], ["aten::fill_", "[[128, 512, 1, 1], []]", 21, 21, 21, 987, 987], ["aten::mul_", "[[64, 64, 3, 3], []]", 21, 21, 21, 2633, 2633], ["aten::mul_", "[[128, 512, 1, 1], []]", 21, 21, 21, 2355, 2355], ["aten::copy_", "[[128, 128, 3, 3], [128, 128, 3, 3], []]", 8, 19, 19, 776, 776], ["aten::add", "[[64, 256, 1, 1], [64, 256, 1, 1], []]", 16, 16, 16, 2678, 3435], ["aten::mul_", "[[256, 512, 1, 1], []]", 7, 15, 15, 952, 952], ["aten::fill_", "[[64, 256, 1, 1], []]", 14, 14, 14, 652, 652], ["aten::mul_", "[[64, 256, 1, 1], []]", 14, 14, 14, 1660, 1660], ["aten::mul_", "[[512, 256, 1, 1], []]", 7, 14, 14, 785, 785], ["aten::_local_scalar_dense", "[[]]", 1479, 12, 12, 32168, 32168], ["aten::copy_", "[[512, 1024, 1, 1], [512, 1024, 1, 1], []]", 2, 11, 11, 170, 170], ["aten::copy_", "[[512, 128, 1, 1], [512, 128, 1, 1], []]", 8, 9, 9, 716, 716], ["aten::copy_", "[[128, 512, 1, 1], [128, 512, 1, 1], []]", 6, 9, 9, 536, 536], ["aten::fill_", "[[], []]", 8, 8, 8, 451, 451], ["aten::add", "[[64, 3, 7, 7], [64, 3, 7, 7], []]", 8, 8, 8, 1166, 1516], ["aten::add", "[[64, 64, 1, 1], [64, 64, 1, 1], []]", 8, 8, 8, 1052, 1408], ["aten::copy_", "[[256, 64, 1, 1], [256, 64, 1, 1], []]", 8, 8, 8, 675, 675], ["aten::add", "[[128, 256, 1, 1], [128, 256, 1, 1], []]", 8, 8, 8, 1073, 1428], ["aten::add", "[[1000], [1000], []]", 8, 8, 8, 1272, 1670], ["aten::copy_", "[[64, 64, 3, 3], [64, 64, 3, 3], []]", 6, 7, 7, 506, 506], ["aten::fill_", "[[64, 3, 7, 7], []]", 7, 7, 7, 431, 431], ["aten::fill_", "[[128, 256, 1, 1], []]", 7, 7, 7, 326, 326], ["aten::fill_", "[[512, 256, 1, 1], []]", 7, 7, 7, 320, 320], ["aten::fill_", "[[256, 512, 1, 1], []]", 7, 7, 7, 334, 334], ["aten::fill_", "[[1000], []]", 7, 7, 7, 349, 349], ["aten::mul_", "[[64, 3, 7, 7], []]", 7, 7, 7, 798, 798], ["aten::mul_", "[[64, 64, 1, 1], []]", 7, 7, 7, 784, 784], ["aten::mul_", "[[128, 256, 1, 1], []]", 7, 7, 7, 813, 813], ["aten::mul_", "[[1000], []]", 7, 7, 7, 736, 736], ["aten::copy_", "[[1024, 512, 1, 1], [1024, 512, 1, 1], []]", 2, 6, 6, 172, 172], ["aten::copy_", "[[64, 256, 1, 1], [64, 256, 1, 1], []]", 4, 5, 5, 336, 336], ["aten::copy_", "[[256, 512, 1, 1], [256, 512, 1, 1], []]", 2, 5, 5, 235, 235], ["aten::copy_", "[[64, 64, 1, 1], [64, 64, 1, 1], []]", 2, 3, 3, 173, 173], ["aten::copy_", "[[128, 256, 1, 1], [128, 256, 1, 1], []]", 2, 3, 3, 206, 206], ["aten::copy_", "[[512, 256, 1, 1], [512, 256, 1, 1], []]", 2, 3, 3, 184, 184], ["aten::copy_", "[[162], [162], []]", 2, 3, 3, 1145, 1145], ["aten::copy_", "[[5], [5], []]", 2, 3, 3, 199, 199], ["aten::copy_", "[[64, 3, 7, 7], [64, 3, 7, 7], []]", 2, 2, 2, 176, 176], ["aten::copy_", "[[1000], [1000], []]", 2, 2, 2, 184, 184], ["aten::fill_", "[[64, 64, 1, 1], []]", 7, 2, 2, 326, 326], ["aten::empty", "[[], [], [], [], [], []]", 13221, 0, 0, 481619, 481619], ["aten::random_", "[[], []]", 1, 0, 0, 89, 89], ["aten::is_floating_point", "[[]]", 9, 0, 0, 119, 119], ["aten::item", "[[]]", 1479, 0, 12, 32075, 64243], ["aten::fill_", "[[1], []]", 288, 0, 0, 4939, 4939], ["aten::zero_", "[[1]]", 32, 0, 0, 926, 1458], ["aten::zeros", "[[], [], [], [], []]", 32, 0, 0, 2146, 4284], ["aten::uniform_", "[[1], [], [], []]", 958, 0, 0, 58037, 58037], ["aten::is_floating_point", "[[1]]", 1214, 0, 0, 12598, 12598], ["aten::_local_scalar_dense", "[[1]]", 1470, 0, 0, 40704, 40704], ["aten::item", "[[1]]", 1470, 0, 0, 28637, 69341], ["aten::to", "[[2], [], [], [], [], []]", 351, 0, 0, 5207, 5207], ["detach_", "[[2]]", 351, 0, 0, 4503, 4503], ["aten::detach_", "[[2]]", 351, 0, 0, 5855, 10358], ["aten::log", "[[2]]", 351, 0, 0, 33857, 40092], ["aten::as_strided", "[[2], [], [], []]", 702, 0, 0, 9787, 9787], ["aten::select", "[[2], [], []]", 702, 0, 0, 60118, 69905], ["aten::resize_", "[[0], [], []]", 1167, 0, 0, 25511, 25511], ["aten::exp", "[[0], [1]]", 351, 0, 0, 18797, 24635], ["aten::exp", "[[1]]", 351, 0, 0, 29900, 60833], ["aten::random_", "[[1], [], [], []]", 512, 0, 0, 15826, 15826], ["aten::randint", "[[], [], [], [], [], [], [], []]", 512, 0, 0, 34989, 60289], ["aten::rand", "[[], [], [], [], []]", 256, 0, 0, 17794, 32191], ["aten::empty_strided", "[[], [], [], [], [], []]", 1626, 0, 0, 182074, 182074], ["aten::to", "[[], [], [], [], []]", 768, 0, 0, 52986, 100221], ["aten::lt", "[[0], [1], []]", 256, 0, 0, 27788, 73161], ["aten::lt", "[[1], []]", 256, 0, 0, 26897, 103964], ["aten::is_nonzero", "[[1]]", 256, 0, 0, 5880, 17830], ["aten::set_", "[[], []]", 256, 0, 0, 17891, 17891], ["aten::view", "[[150528], []]", 256, 0, 0, 17240, 17240], ["aten::as_strided", "[[224, 224, 3], [], [], []]", 256, 0, 0, 3956, 3956], ["aten::permute", "[[224, 224, 3], []]", 256, 0, 0, 21543, 25499], ["aten::empty_like", "[[3, 224, 224], [], [], [], [], []]", 256, 0, 0, 10774, 15631], ["aten::copy_", "[[3, 224, 224], [3, 224, 224], []]", 768, 0, 0, 4217743, 4217743], ["aten::contiguous", "[[3, 224, 224], []]", 256, 0, 0, 15305, 1206437], ["aten::to", "[[3, 224, 224], [], [], [], []]", 256, 0, 0, 20198, 2045701], ["aten::div", "[[3, 224, 224], []]", 256, 0, 0, 1078216, 1120641], ["aten::clone", "[[3, 224, 224], []]", 256, 0, 0, 40336, 1070594], ["aten::to", "[[3], [], [], [], [], []]", 512, 0, 0, 9527, 9527], ["aten::eq", "[[0], [3], []]", 256, 0, 0, 33799, 79246], ["aten::eq", "[[3], []]", 256, 0, 0, 28576, 111725], ["aten::as_strided", "[[], [], [], []]", 256, 0, 0, 4146, 4146], ["aten::any", "[[3]]", 256, 0, 0, 44417, 62668], ["aten::is_nonzero", "[[]]", 256, 0, 0, 5658, 18632], ["aten::view", "[[3], []]", 512, 0, 0, 37626, 37626], ["aten::sub_", "[[3, 224, 224], [3, 1, 1], []]", 256, 0, 0, 973440, 973440], ["aten::div_", "[[3, 224, 224], [3, 1, 1]]", 256, 0, 0, 1171774, 1171774], ["aten::as_strided", "[[3, 224, 224], [], [], []]", 256, 0, 0, 3213, 3213], ["aten::unsqueeze", "[[3, 224, 224], []]", 256, 0, 0, 8539, 11752], ["aten::as_strided", "[[32, 3, 224, 224], [], [], []]", 8, 0, 0, 123, 123], ["aten::slice", "[[32, 3, 224, 224], [], [], [], []]", 8, 0, 0, 266, 389], ["aten::narrow", "[[32, 3, 224, 224], [], [], []]", 8, 0, 0, 252, 641], ["aten::stride", "[[32, 3, 224, 224], []]", 72, 0, 0, 517, 517], ["aten::cat", "[[], []]", 24, 0, 390, 3146, 4301571], ["aten::stack", "[[], []]", 8, 0, 0, 5232, 1138781], ["aten::to", "[[32], [], [], [], [], []]", 8, 0, 0, 175, 175], ["detach_", "[[32]]", 8, 0, 0, 154, 154], ["aten::detach_", "[[32]]", 8, 0, 0, 145, 299], ["aten::is_pinned", "[[32, 3, 224, 224]]", 8, 0, 0, 3718, 3718], ["aten::set_", "[[0], [], [], [], []]", 16, 0, 0, 906, 906], ["aten::pin_memory", "[[32, 3, 224, 224]]", 8, 0, 0, 20579, 119177], ["aten::is_pinned", "[[32]]", 8, 0, 0, 357, 357], ["aten::pin_memory", "[[32]]", 8, 0, 0, 1489, 3042], ["aten::to", "[[32, 3, 224, 224], [], [], [], [], [], [], []]", 16, 0, 13570, 852, 2807], ["aten::to", "[[32], [], [], [], [], [], [], []]", 8, 0, 25, 591, 3172], ["aten::contiguous", "[[64], []]", 336, 0, 0, 4145, 4145], ["aten::view", "[[64], []]", 336, 0, 0, 15162, 15162], ["aten::contiguous", "[[256], []]", 768, 0, 0, 8797, 8797], ["aten::view", "[[256], []]", 768, 0, 0, 34524, 34524], ["aten::contiguous", "[[128], []]", 384, 0, 0, 4274, 4274], ["aten::view", "[[128], []]", 384, 0, 0, 16637, 16637], ["aten::contiguous", "[[512], []]", 528, 0, 0, 5919, 5919], ["aten::view", "[[512], []]", 528, 0, 0, 23182, 23182], ["aten::contiguous", "[[1024], []]", 336, 0, 0, 3943, 3943], ["aten::view", "[[1024], []]", 336, 0, 0, 14572, 14572], ["aten::contiguous", "[[2048], []]", 192, 0, 0, 2099, 2099], ["aten::view", "[[2048], []]", 192, 0, 0, 8152, 8152], ["aten::stride", "[[64], []]", 112, 0, 0, 684, 684], ["aten::stride", "[[256], []]", 256, 0, 0, 1410, 1410], ["aten::stride", "[[128], []]", 128, 0, 0, 655, 655], ["aten::stride", "[[512], []]", 176, 0, 0, 882, 882], ["aten::stride", "[[1024], []]", 112, 0, 0, 563, 563], ["aten::stride", "[[2048], []]", 64, 0, 0, 318, 318], ["aten::stride", "[[53120], []]", 16, 0, 0, 91, 91], ["nccl:broadcast", "[]", 18, 0, 0, 532, 532], ["aten::contiguous", "[[], []]", 424, 0, 0, 5812, 5812], ["aten::view", "[[], []]", 424, 0, 0, 22119, 22119], ["aten::stride", "[[1], []]", 424, 0, 0, 2191, 2191], ["aten::stride", "[[53], []]", 16, 0, 0, 90, 90], ["aten::as_strided", "[[53120], [], [], []]", 848, 0, 0, 10353, 10353], ["aten::slice", "[[53120], [], [], [], []]", 848, 0, 0, 50508, 60861], ["aten::narrow", "[[53120], [], [], []]", 848, 0, 0, 21022, 81883], ["aten::as_strided", "[[53], [], [], []]", 424, 0, 0, 5698, 5698], ["aten::slice", "[[53], [], [], [], []]", 424, 0, 0, 28874, 34572], ["aten::narrow", "[[53], [], [], []]", 424, 0, 0, 13135, 47707], ["aten::view", "[[1], []]", 424, 0, 0, 25359, 25359], ["aten::contiguous", "[[32, 3, 224, 224], []]", 24, 0, 0, 275, 275], ["aten::contiguous", "[[64, 3, 7, 7], []]", 8, 0, 0, 126, 126], ["aten::resize_", "[[64, 3, 7, 7], [], []]", 8, 0, 0, 99, 99], ["aten::resize_", "[[32, 3, 224, 224], [], []]", 16, 0, 0, 211, 211], ["aten::_convolution", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 15643, 867, 2373866], ["aten::convolution", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], []]", 8, 0, 15643, 371, 2374237], ["aten::conv2d", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], []]", 8, 0, 15643, 435, 2374672], ["aten::contiguous", "[[32, 64, 112, 112], []]", 56, 0, 0, 716, 716], ["aten::empty_like", "[[32, 64, 112, 112], [], [], [], [], []]", 16, 0, 0, 882, 1523], ["aten::_batch_norm_impl_index", "[[32, 64, 112, 112], [64], [64], [64], [64], [], [], [], []]", 8, 0, 3414, 1404, 80323], ["aten::batch_norm", "[[32, 64, 112, 112], [64], [64], [64], [64], [], [], [], []]", 8, 0, 3414, 577, 80900], ["aten::relu_", "[[32, 64, 112, 112]]", 8, 0, 1997, 1096, 1922], ["aten::stride", "[[32, 64, 112, 112], []]", 64, 0, 0, 543, 543], ["aten::max_pool2d", "[[32, 64, 112, 112], [], [], [], [], []]", 8, 0, 1785, 458, 6137], ["aten::contiguous", "[[32, 64, 56, 56], []]", 488, 0, 0, 6467, 6467], ["aten::contiguous", "[[64, 64, 1, 1], []]", 16, 0, 0, 229, 229], ["aten::resize_", "[[64, 64, 1, 1], [], []]", 16, 0, 0, 184, 184], ["aten::resize_", "[[32, 64, 56, 56], [], []]", 224, 0, 0, 2434, 2434], ["aten::stride", "[[32, 64, 56, 56], []]", 792, 0, 0, 5489, 5489], ["aten::_convolution", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 2814, 1002, 11867], ["aten::convolution", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], []]", 8, 0, 2814, 325, 12192], ["aten::conv2d", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], []]", 8, 0, 2814, 416, 12608], ["aten::empty_like", "[[32, 64, 56, 56], [], [], [], [], []]", 48, 0, 0, 2470, 4649], ["aten::_batch_norm_impl_index", "[[32, 64, 56, 56], [64], [64], [64], [64], [], [], [], []]", 48, 0, 5344, 6339, 46174], ["aten::batch_norm", "[[32, 64, 56, 56], [64], [64], [64], [64], [], [], [], []]", 48, 0, 5344, 2513, 48687], ["aten::relu_", "[[32, 64, 56, 56]]", 48, 0, 3035, 6328, 9596], ["aten::contiguous", "[[64, 64, 3, 3], []]", 48, 0, 0, 863, 863], ["aten::resize_", "[[64, 64, 3, 3], [], []]", 48, 0, 0, 572, 572], ["aten::_convolution", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 24, 0, 15399, 2493, 29667], ["aten::convolution", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], []]", 24, 0, 15399, 1131, 30798], ["aten::conv2d", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], []]", 24, 0, 15399, 1476, 32274], ["aten::contiguous", "[[256, 64, 1, 1], []]", 64, 0, 0, 1002, 1002], ["aten::resize_", "[[256, 64, 1, 1], [], []]", 64, 0, 0, 775, 775], ["aten::_convolution", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 32, 0, 16011, 3523, 36352], ["aten::convolution", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], []]", 32, 0, 16011, 1513, 37865], ["aten::conv2d", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], []]", 32, 0, 16011, 1729, 39594], ["aten::contiguous", "[[32, 256, 56, 56], []]", 288, 0, 0, 3275, 3275], ["aten::empty_like", "[[32, 256, 56, 56], [], [], [], [], []]", 32, 0, 0, 1792, 3129], ["aten::_batch_norm_impl_index", "[[32, 256, 56, 56], [256], [256], [256], [256], [], [], [], []]", 32, 0, 12806, 4420, 31969], ["aten::batch_norm", "[[32, 256, 56, 56], [256], [256], [256], [256], [], [], [], []]", 32, 0, 12806, 1660, 33629], ["aten::relu_", "[[32, 256, 56, 56]]", 24, 0, 6015, 3021, 4543], ["aten::contiguous", "[[64, 256, 1, 1], []]", 32, 0, 0, 525, 525], ["aten::resize_", "[[64, 256, 1, 1], [], []]", 32, 0, 0, 394, 394], ["aten::resize_", "[[32, 256, 56, 56], [], []]", 128, 0, 0, 1385, 1385], ["aten::stride", "[[32, 256, 56, 56], []]", 384, 0, 0, 2538, 2538], ["aten::_convolution", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 16, 0, 10752, 1660, 22860], ["aten::convolution", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], []]", 16, 0, 10752, 760, 23620], ["aten::conv2d", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], []]", 16, 0, 10752, 976, 24596], ["aten::contiguous", "[[128, 256, 1, 1], []]", 16, 0, 0, 225, 225], ["aten::resize_", "[[128, 256, 1, 1], [], []]", 16, 0, 0, 195, 195], ["aten::_convolution", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 14401, 744, 22459], ["aten::convolution", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], []]", 8, 0, 14401, 371, 22830], ["aten::conv2d", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], []]", 8, 0, 14401, 408, 23238], ["aten::contiguous", "[[32, 128, 56, 56], []]", 72, 0, 0, 814, 814], ["aten::empty_like", "[[32, 128, 56, 56], [], [], [], [], []]", 8, 0, 0, 377, 701], ["aten::_batch_norm_impl_index", "[[32, 128, 56, 56], [128], [128], [128], [128], [], [], [], []]", 8, 0, 1597, 1014, 6937], ["aten::batch_norm", "[[32, 128, 56, 56], [128], [128], [128], [128], [], [], [], []]", 8, 0, 1597, 370, 7307], ["aten::relu_", "[[32, 128, 56, 56]]", 8, 0, 1007, 974, 1453], ["aten::contiguous", "[[128, 128, 3, 3], []]", 64, 0, 0, 988, 988], ["aten::resize_", "[[128, 128, 3, 3], [], []]", 64, 0, 0, 734, 734], ["aten::resize_", "[[32, 128, 56, 56], [], []]", 32, 0, 0, 338, 338], ["aten::stride", "[[32, 128, 56, 56], []]", 96, 0, 0, 628, 628], ["aten::_convolution", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 9896, 752, 140773], ["aten::convolution", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], [], [], []]", 8, 0, 9896, 329, 141102], ["aten::conv2d", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], []]", 8, 0, 9896, 402, 141504], ["aten::contiguous", "[[32, 128, 28, 28], []]", 504, 0, 0, 5902, 5902], ["aten::empty_like", "[[32, 128, 28, 28], [], [], [], [], []]", 56, 0, 0, 2774, 5173], ["aten::_batch_norm_impl_index", "[[32, 128, 28, 28], [128], [128], [128], [128], [], [], [], []]", 56, 0, 2934, 6957, 48554], ["aten::batch_norm", "[[32, 128, 28, 28], [128], [128], [128], [128], [], [], [], []]", 56, 0, 2934, 2699, 51253], ["aten::relu_", "[[32, 128, 28, 28]]", 56, 0, 1855, 6883, 10143], ["aten::contiguous", "[[512, 128, 1, 1], []]", 64, 0, 0, 922, 922], ["aten::resize_", "[[512, 128, 1, 1], [], []]", 64, 0, 0, 765, 765], ["aten::resize_", "[[32, 128, 28, 28], [], []]", 224, 0, 0, 2484, 2484], ["aten::stride", "[[32, 128, 28, 28], []]", 672, 0, 0, 4655, 4655], ["aten::_convolution", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 32, 0, 13397, 3064, 36677], ["aten::convolution", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], []]", 32, 0, 13397, 1388, 38065], ["aten::conv2d", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], []]", 32, 0, 13397, 1632, 39697], ["aten::contiguous", "[[32, 512, 28, 28], []]", 360, 0, 0, 4350, 4350], ["aten::empty_like", "[[32, 512, 28, 28], [], [], [], [], []]", 40, 0, 0, 1912, 4347], ["aten::_batch_norm_impl_index", "[[32, 512, 28, 28], [512], [512], [512], [512], [], [], [], []]", 40, 0, 8277, 4992, 35671], ["aten::batch_norm", "[[32, 512, 28, 28], [512], [512], [512], [512], [], [], [], []]", 40, 0, 8277, 1929, 37600], ["aten::contiguous", "[[512, 256, 1, 1], []]", 16, 0, 0, 219, 219], ["aten::resize_", "[[512, 256, 1, 1], [], []]", 16, 0, 0, 185, 185], ["aten::_convolution", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 7781, 714, 13660], ["aten::convolution", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], [], [], []]", 8, 0, 7781, 319, 13979], ["aten::conv2d", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], []]", 8, 0, 7781, 389, 14368], ["aten::relu_", "[[32, 512, 28, 28]]", 32, 0, 4052, 3949, 5780], ["aten::contiguous", "[[128, 512, 1, 1], []]", 48, 0, 0, 751, 751], ["aten::resize_", "[[128, 512, 1, 1], [], []]", 48, 0, 0, 596, 596], ["aten::resize_", "[[32, 512, 28, 28], [], []]", 160, 0, 0, 1607, 1607], ["aten::stride", "[[32, 512, 28, 28], []]", 480, 0, 0, 3406, 3406], ["aten::_convolution", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 24, 0, 13922, 2189, 26524], ["aten::convolution", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], []]", 24, 0, 13922, 1007, 27531], ["aten::conv2d", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], []]", 24, 0, 13922, 1180, 28711], ["aten::_convolution", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 24, 0, 12301, 2148, 30420], ["aten::convolution", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], []]", 24, 0, 12301, 981, 31401], ["aten::conv2d", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], []]", 24, 0, 12301, 1158, 32559], ["aten::contiguous", "[[256, 512, 1, 1], []]", 16, 0, 0, 235, 235], ["aten::resize_", "[[256, 512, 1, 1], [], []]", 16, 0, 0, 350, 350], ["aten::_convolution", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 13117, 727, 17631], ["aten::convolution", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], []]", 8, 0, 13117, 365, 17996], ["aten::conv2d", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], []]", 8, 0, 13117, 398, 18394], ["aten::contiguous", "[[32, 256, 28, 28], []]", 72, 0, 0, 812, 812], ["aten::empty_like", "[[32, 256, 28, 28], [], [], [], [], []]", 8, 0, 0, 387, 708], ["aten::_batch_norm_impl_index", "[[32, 256, 28, 28], [256], [256], [256], [256], [], [], [], []]", 8, 0, 837, 1011, 7128], ["aten::batch_norm", "[[32, 256, 28, 28], [256], [256], [256], [256], [], [], [], []]", 8, 0, 837, 378, 7506], ["aten::relu_", "[[32, 256, 28, 28]]", 8, 0, 515, 954, 1427], ["aten::contiguous", "[[256, 256, 3, 3], []]", 96, 0, 0, 1375, 1375], ["aten::resize_", "[[256, 256, 3, 3], [], []]", 96, 0, 0, 1124, 1124], ["aten::resize_", "[[32, 256, 28, 28], [], []]", 32, 0, 0, 414, 414], ["aten::stride", "[[32, 256, 28, 28], []]", 96, 0, 0, 631, 631], ["aten::_convolution", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 10248, 717, 15061], ["aten::convolution", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], [], [], []]", 8, 0, 10248, 342, 15403], ["aten::conv2d", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], []]", 8, 0, 10248, 441, 15844], ["aten::contiguous", "[[32, 256, 14, 14], []]", 792, 0, 0, 9240, 9240], ["aten::empty_like", "[[32, 256, 14, 14], [], [], [], [], []]", 88, 0, 0, 4268, 7953], ["aten::_batch_norm_impl_index", "[[32, 256, 14, 14], [256], [256], [256], [256], [], [], [], []]", 88, 0, 1998, 11040, 78407], ["aten::batch_norm", "[[32, 256, 14, 14], [256], [256], [256], [256], [], [], [], []]", 88, 0, 1998, 4236, 82643], ["aten::relu_", "[[32, 256, 14, 14]]", 88, 0, 1034, 10592, 15733], ["aten::contiguous", "[[1024, 256, 1, 1], []]", 96, 0, 0, 1349, 1349], ["aten::resize_", "[[1024, 256, 1, 1], [], []]", 96, 0, 0, 1196, 1196], ["aten::resize_", "[[32, 256, 14, 14], [], []]", 352, 0, 0, 3531, 3531], ["aten::stride", "[[32, 256, 14, 14], []]", 1056, 0, 0, 7110, 7110], ["aten::_convolution", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 48, 0, 24045, 4315, 40331], ["aten::convolution", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], []]", 48, 0, 24045, 2040, 42371], ["aten::conv2d", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], []]", 48, 0, 24045, 2372, 44743], ["aten::contiguous", "[[32, 1024, 14, 14], []]", 504, 0, 0, 6032, 6032], ["aten::empty_like", "[[32, 1024, 14, 14], [], [], [], [], []]", 56, 0, 0, 2653, 6148], ["aten::_batch_norm_impl_index", "[[32, 1024, 14, 14], [1024], [1024], [1024], [1024], [], [], [], []]", 56, 0, 4748, 11706, 54899], ["aten::batch_norm", "[[32, 1024, 14, 14], [1024], [1024], [1024], [1024], [], [], [], []]", 56, 0, 4748, 2734, 57633], ["aten::contiguous", "[[1024, 512, 1, 1], []]", 16, 0, 0, 232, 232], ["aten::resize_", "[[1024, 512, 1, 1], [], []]", 16, 0, 0, 194, 194], ["aten::_convolution", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 8628, 723, 12403], ["aten::convolution", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], [], [], []]", 8, 0, 8628, 342, 12745], ["aten::conv2d", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], []]", 8, 0, 8628, 384, 13129], ["aten::relu_", "[[32, 1024, 14, 14]]", 48, 0, 3033, 5665, 8438], ["aten::contiguous", "[[256, 1024, 1, 1], []]", 80, 0, 0, 1251, 1251], ["aten::resize_", "[[256, 1024, 1, 1], [], []]", 80, 0, 0, 1025, 1025], ["aten::resize_", "[[32, 1024, 14, 14], [], []]", 224, 0, 0, 2353, 2353], ["aten::stride", "[[32, 1024, 14, 14], []]", 672, 0, 0, 4446, 4446], ["aten::_convolution", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 40, 0, 21136, 3651, 35518], ["aten::convolution", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], []]", 40, 0, 21136, 1651, 37169], ["aten::conv2d", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], []]", 40, 0, 21136, 2024, 39193], ["aten::_convolution", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 40, 0, 17657, 3694, 101917], ["aten::convolution", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], []]", 40, 0, 17657, 1660, 103577], ["aten::conv2d", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], []]", 40, 0, 17657, 2048, 105625], ["aten::contiguous", "[[512, 1024, 1, 1], []]", 16, 0, 0, 223, 223], ["aten::resize_", "[[512, 1024, 1, 1], [], []]", 16, 0, 0, 227, 227], ["aten::_convolution", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 15711, 732, 142090], ["aten::convolution", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 0, 15711, 327, 142417], ["aten::conv2d", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], []]", 8, 0, 15711, 388, 142805], ["aten::contiguous", "[[32, 512, 14, 14], []]", 72, 0, 0, 827, 827], ["aten::empty_like", "[[32, 512, 14, 14], [], [], [], [], []]", 8, 0, 0, 376, 709], ["aten::_batch_norm_impl_index", "[[32, 512, 14, 14], [512], [512], [512], [512], [], [], [], []]", 8, 0, 371, 1089, 7027], ["aten::batch_norm", "[[32, 512, 14, 14], [512], [512], [512], [512], [], [], [], []]", 8, 0, 371, 370, 7397], ["aten::relu_", "[[32, 512, 14, 14]]", 8, 0, 243, 978, 1485], ["aten::contiguous", "[[512, 512, 3, 3], []]", 48, 0, 0, 679, 679], ["aten::resize_", "[[512, 512, 3, 3], [], []]", 48, 0, 0, 566, 566], ["aten::resize_", "[[32, 512, 14, 14], [], []]", 32, 0, 0, 307, 307], ["aten::stride", "[[32, 512, 14, 14], []]", 96, 0, 0, 609, 609], ["aten::_convolution", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 15786, 725, 16720], ["aten::convolution", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], [], [], []]", 8, 0, 15786, 397, 17117], ["aten::conv2d", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], []]", 8, 0, 15786, 388, 17505], ["aten::contiguous", "[[32, 512, 7, 7], []]", 360, 0, 0, 4070, 4070], ["aten::empty_like", "[[32, 512, 7, 7], [], [], [], [], []]", 40, 0, 0, 1893, 3497], ["aten::_batch_norm_impl_index", "[[32, 512, 7, 7], [512], [512], [512], [512], [], [], [], []]", 40, 0, 633, 5052, 34511], ["aten::batch_norm", "[[32, 512, 7, 7], [512], [512], [512], [512], [], [], [], []]", 40, 0, 633, 2006, 36517], ["aten::relu_", "[[32, 512, 7, 7]]", 40, 0, 274, 5062, 7395], ["aten::contiguous", "[[2048, 512, 1, 1], []]", 48, 0, 0, 701, 701], ["aten::resize_", "[[2048, 512, 1, 1], [], []]", 48, 0, 0, 559, 559], ["aten::resize_", "[[32, 512, 7, 7], [], []]", 160, 0, 0, 1634, 1634], ["aten::stride", "[[32, 512, 7, 7], []]", 480, 0, 0, 3119, 3119], ["aten::_convolution", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 24, 0, 21482, 2190, 38138], ["aten::convolution", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], []]", 24, 0, 21482, 1010, 39148], ["aten::conv2d", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], []]", 24, 0, 21482, 1219, 40367], ["aten::contiguous", "[[32, 2048, 7, 7], []]", 240, 0, 0, 2698, 2698], ["aten::empty_like", "[[32, 2048, 7, 7], [], [], [], [], []]", 32, 0, 0, 1530, 3117], ["aten::_batch_norm_impl_index", "[[32, 2048, 7, 7], [2048], [2048], [2048], [2048], [], [], [], []]", 32, 0, 1797, 3958, 28078], ["aten::batch_norm", "[[32, 2048, 7, 7], [2048], [2048], [2048], [2048], [], [], [], []]", 32, 0, 1797, 1501, 29579], ["aten::contiguous", "[[2048, 1024, 1, 1], []]", 16, 0, 0, 223, 223], ["aten::resize_", "[[2048, 1024, 1, 1], [], []]", 16, 0, 0, 192, 192], ["aten::_convolution", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 9179, 753, 13245], ["aten::convolution", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 0, 9179, 346, 13591], ["aten::conv2d", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], []]", 8, 0, 9179, 400, 13991], ["aten::relu_", "[[32, 2048, 7, 7]]", 24, 0, 794, 2892, 4238], ["aten::contiguous", "[[512, 2048, 1, 1], []]", 32, 0, 0, 464, 464], ["aten::resize_", "[[512, 2048, 1, 1], [], []]", 32, 0, 0, 377, 377], ["aten::resize_", "[[32, 2048, 7, 7], [], []]", 96, 0, 0, 996, 996], ["aten::stride", "[[32, 2048, 7, 7], []]", 192, 0, 0, 1221, 1221], ["aten::_convolution", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 16, 0, 19366, 1451, 28569], ["aten::convolution", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], []]", 16, 0, 19366, 668, 29237], ["aten::conv2d", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], []]", 16, 0, 19366, 787, 30024], ["aten::_convolution", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 16, 0, 16606, 1525, 26894], ["aten::convolution", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], []]", 16, 0, 16606, 921, 27815], ["aten::conv2d", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], []]", 16, 0, 16606, 774, 28589], ["aten::adaptive_avg_pool2d", "[[32, 2048, 7, 7], []]", 8, 0, 346, 397, 8833], ["aten::view", "[[32, 2048, 1, 1], []]", 8, 0, 0, 852, 852], ["aten::reshape", "[[32, 2048, 1, 1], []]", 8, 0, 0, 252, 1104], ["aten::flatten", "[[32, 2048, 1, 1], [], []]", 8, 0, 0, 406, 1510], ["aten::as_strided", "[[1000, 2048], [], [], []]", 16, 0, 0, 270, 270], ["aten::transpose", "[[1000, 2048], [], []]", 16, 0, 0, 544, 814], ["aten::t", "[[1000, 2048]]", 16, 0, 0, 1218, 2032], ["aten::as_strided", "[[1000], [], [], []]", 8, 0, 0, 121, 121], ["aten::expand", "[[1000], [], []]", 8, 0, 0, 380, 501], ["aten::stride", "[[2048, 1000], []]", 8, 0, 0, 124, 124], ["aten::stride", "[[32, 2048], []]", 24, 0, 0, 178, 178], ["aten::stride", "[[32, 1000], []]", 16, 0, 0, 91, 91], ["aten::contiguous", "[[32, 1000], []]", 24, 0, 0, 296, 296], ["aten::empty_like", "[[32, 1000], [], [], [], [], []]", 16, 0, 0, 763, 1442], ["aten::log_softmax", "[[32, 1000], [], []]", 8, 0, 82, 393, 2928], ["aten::nll_loss", "[[32, 1000], [32], [], [], []]", 8, 0, 33, 383, 2248], ["aten::empty_like", "[[], [], [], [], [], []]", 8, 0, 0, 384, 792], ["aten::ones_like", "[[], [], [], [], [], []]", 8, 0, 8, 523, 1766], ["aten::clone", "[[64, 3, 7, 7], []]", 1, 0, 1, 118, 245], ["detach", "[[64, 3, 7, 7]]", 1, 0, 0, 16, 16], ["aten::detach", "[[64, 3, 7, 7]]", 1, 0, 0, 23, 39], ["aten::clone", "[[64], []]", 14, 0, 14, 1571, 3246], ["detach", "[[64]]", 14, 0, 0, 201, 201], ["aten::detach", "[[64]]", 14, 0, 0, 300, 501], ["aten::clone", "[[64, 64, 1, 1], []]", 1, 0, 1, 110, 228], ["detach", "[[64, 64, 1, 1]]", 1, 0, 0, 14, 14], ["aten::detach", "[[64, 64, 1, 1]]", 1, 0, 0, 22, 36], ["aten::clone", "[[64, 64, 3, 3], []]", 3, 0, 3, 368, 721], ["detach", "[[64, 64, 3, 3]]", 3, 0, 0, 45, 45], ["aten::detach", "[[64, 64, 3, 3]]", 3, 0, 0, 67, 112], ["aten::clone", "[[256, 64, 1, 1], []]", 4, 0, 4, 477, 957], ["detach", "[[256, 64, 1, 1]]", 4, 0, 0, 62, 62], ["aten::detach", "[[256, 64, 1, 1]]", 4, 0, 0, 89, 151], ["aten::clone", "[[256], []]", 32, 0, 32, 3552, 7325], ["detach", "[[256]]", 32, 0, 0, 499, 499], ["aten::detach", "[[256]]", 32, 0, 0, 695, 1194], ["aten::clone", "[[64, 256, 1, 1], []]", 2, 0, 2, 220, 455], ["detach", "[[64, 256, 1, 1]]", 2, 0, 0, 31, 31], ["aten::detach", "[[64, 256, 1, 1]]", 2, 0, 0, 44, 75], ["aten::clone", "[[128, 256, 1, 1], []]", 1, 0, 1, 116, 3344], ["detach", "[[128, 256, 1, 1]]", 1, 0, 0, 15, 15], ["aten::detach", "[[128, 256, 1, 1]]", 1, 0, 0, 22, 37], ["aten::clone", "[[128], []]", 16, 0, 16, 1940, 3943], ["detach", "[[128]]", 16, 0, 0, 243, 243], ["aten::detach", "[[128]]", 16, 0, 0, 361, 604], ["aten::clone", "[[128, 128, 3, 3], []]", 4, 0, 8, 508, 2800], ["detach", "[[128, 128, 3, 3]]", 4, 0, 0, 60, 60], ["aten::detach", "[[128, 128, 3, 3]]", 4, 0, 0, 91, 151], ["aten::clone", "[[512, 128, 1, 1], []]", 4, 0, 4, 510, 1096], ["detach", "[[512, 128, 1, 1]]", 4, 0, 0, 74, 74], ["aten::detach", "[[512, 128, 1, 1]]", 4, 0, 0, 91, 165], ["aten::clone", "[[512], []]", 22, 0, 22, 2561, 5269], ["detach", "[[512]]", 22, 0, 0, 328, 328], ["aten::detach", "[[512]]", 22, 0, 0, 497, 825], ["aten::clone", "[[512, 256, 1, 1], []]", 1, 0, 1, 117, 2729], ["detach", "[[512, 256, 1, 1]]", 1, 0, 0, 16, 16], ["aten::detach", "[[512, 256, 1, 1]]", 1, 0, 0, 23, 39], ["aten::clone", "[[128, 512, 1, 1], []]", 3, 0, 3, 393, 766], ["detach", "[[128, 512, 1, 1]]", 3, 0, 0, 45, 45], ["aten::detach", "[[128, 512, 1, 1]]", 3, 0, 0, 109, 154], ["aten::clone", "[[256, 512, 1, 1], []]", 1, 0, 2, 120, 118290], ["detach", "[[256, 512, 1, 1]]", 1, 0, 0, 16, 16], ["aten::detach", "[[256, 512, 1, 1]]", 1, 0, 0, 23, 39], ["aten::clone", "[[256, 256, 3, 3], []]", 6, 0, 21, 654, 1416], ["detach", "[[256, 256, 3, 3]]", 6, 0, 0, 89, 89], ["aten::detach", "[[256, 256, 3, 3]]", 6, 0, 0, 129, 218], ["aten::clone", "[[1024, 256, 1, 1], []]", 6, 0, 12, 688, 2829], ["detach", "[[1024, 256, 1, 1]]", 6, 0, 0, 91, 91], ["aten::detach", "[[1024, 256, 1, 1]]", 6, 0, 0, 134, 225], ["aten::clone", "[[1024], []]", 14, 0, 14, 1611, 3319], ["detach", "[[1024]]", 14, 0, 0, 195, 195], ["aten::detach", "[[1024]]", 14, 0, 0, 309, 504], ["aten::clone", "[[1024, 512, 1, 1], []]", 1, 0, 3, 108, 221], ["detach", "[[1024, 512, 1, 1]]", 1, 0, 0, 15, 15], ["aten::detach", "[[1024, 512, 1, 1]]", 1, 0, 0, 26, 41], ["aten::clone", "[[256, 1024, 1, 1], []]", 5, 0, 10, 598, 1204], ["detach", "[[256, 1024, 1, 1]]", 5, 0, 0, 74, 74], ["aten::detach", "[[256, 1024, 1, 1]]", 5, 0, 0, 106, 180], ["aten::clone", "[[512, 1024, 1, 1], []]", 1, 0, 3, 141, 259], ["detach", "[[512, 1024, 1, 1]]", 1, 0, 0, 15, 15], ["aten::detach", "[[512, 1024, 1, 1]]", 1, 0, 0, 21, 36], ["aten::clone", "[[512, 512, 3, 3], []]", 3, 0, 77, 365, 718], ["detach", "[[512, 512, 3, 3]]", 3, 0, 0, 44, 44], ["aten::detach", "[[512, 512, 3, 3]]", 3, 0, 0, 65, 109], ["aten::clone", "[[2048, 512, 1, 1], []]", 3, 0, 30, 355, 699], ["detach", "[[2048, 512, 1, 1]]", 3, 0, 0, 44, 44], ["aten::detach", "[[2048, 512, 1, 1]]", 3, 0, 0, 65, 109], ["aten::clone", "[[2048], []]", 8, 0, 8, 955, 1878], ["detach", "[[2048]]", 8, 0, 0, 112, 112], ["aten::detach", "[[2048]]", 8, 0, 0, 167, 279], ["aten::clone", "[[2048, 1024, 1, 1], []]", 1, 0, 23, 112, 226], ["detach", "[[2048, 1024, 1, 1]]", 1, 0, 0, 15, 15], ["aten::detach", "[[2048, 1024, 1, 1]]", 1, 0, 0, 20, 35], ["aten::clone", "[[512, 2048, 1, 1], []]", 2, 0, 20, 217, 445], ["detach", "[[512, 2048, 1, 1]]", 2, 0, 0, 30, 30], ["aten::detach", "[[512, 2048, 1, 1]]", 2, 0, 0, 45, 75], ["aten::clone", "[[1000, 2048], []]", 1, 0, 23, 106, 221], ["detach", "[[1000, 2048]]", 1, 0, 0, 14, 14], ["aten::detach", "[[1000, 2048]]", 1, 0, 0, 21, 35], ["aten::clone", "[[1000], []]", 1, 0, 1, 132, 245], ["detach", "[[1000]]", 1, 0, 0, 14, 14], ["aten::detach", "[[1000]]", 1, 0, 0, 22, 36], ["aten::as_strided", "[[2049000], [], [], []]", 2, 0, 0, 149, 149], ["aten::as_strided", "[[7875584], [], [], []]", 15, 0, 0, 820, 820], ["aten::as_strided", "[[6563840], [], [], []]", 12, 0, 0, 672, 672], ["aten::as_strided", "[[6637568], [], [], []]", 51, 0, 0, 2714, 2714], ["aten::as_strided", "[[2431040], [], [], []]", 81, 0, 0, 4417, 4417], ["aten::zero_", "[[64, 3, 7, 7]]", 7, 0, 7, 459, 890], ["aten::zero_", "[[64]]", 98, 0, 34, 6100, 10751], ["aten::zero_", "[[64, 64, 1, 1]]", 7, 0, 2, 421, 747], ["aten::zero_", "[[64, 64, 3, 3]]", 21, 0, 21, 1265, 2245], ["aten::zero_", "[[256, 64, 1, 1]]", 28, 0, 28, 1674, 2974], ["aten::zero_", "[[256]]", 224, 0, 90, 13985, 24722], ["aten::zero_", "[[64, 256, 1, 1]]", 14, 0, 14, 860, 1512], ["aten::zero_", "[[128, 256, 1, 1]]", 7, 0, 7, 419, 745], ["aten::zero_", "[[128]]", 112, 0, 84, 6881, 12226], ["aten::zero_", "[[128, 128, 3, 3]]", 28, 0, 28, 1698, 2989], ["aten::zero_", "[[512, 128, 1, 1]]", 28, 0, 28, 1861, 3167], ["aten::zero_", "[[512]]", 154, 0, 89, 9635, 16856], ["aten::zero_", "[[512, 256, 1, 1]]", 7, 0, 7, 421, 741], ["aten::zero_", "[[128, 512, 1, 1]]", 21, 0, 21, 1275, 2262], ["aten::zero_", "[[256, 512, 1, 1]]", 7, 0, 7, 423, 757], ["aten::zero_", "[[256, 256, 3, 3]]", 42, 0, 168, 2641, 4637], ["aten::zero_", "[[1024, 256, 1, 1]]", 42, 0, 84, 2588, 4604], ["aten::zero_", "[[1024]]", 98, 0, 73, 5961, 10667], ["aten::zero_", "[[1024, 512, 1, 1]]", 7, 0, 28, 439, 763], ["aten::zero_", "[[256, 1024, 1, 1]]", 35, 0, 70, 2148, 4191], ["aten::zero_", "[[512, 1024, 1, 1]]", 7, 0, 28, 460, 901], ["aten::zero_", "[[512, 512, 3, 3]]", 21, 0, 315, 1248, 2228], ["aten::zero_", "[[2048, 512, 1, 1]]", 21, 0, 147, 1290, 2270], ["aten::zero_", "[[2048]]", 56, 0, 25, 3397, 6034], ["aten::zero_", "[[2048, 1024, 1, 1]]", 7, 0, 91, 433, 755], ["aten::zero_", "[[512, 2048, 1, 1]]", 14, 0, 98, 837, 1483], ["aten::zero_", "[[1000, 2048]]", 7, 0, 91, 427, 752], ["aten::zero_", "[[1000]]", 7, 0, 7, 416, 765], ["NllLossBackward", "[[]]", 8, 0, 24, 743, 2149], ["LogSoftmaxBackward", "[[32, 1000]]", 8, 0, 86, 512, 2678], ["aten::as_strided", "[[2048, 1000], [], [], []]", 16, 0, 0, 236, 236], ["aten::transpose", "[[2048, 1000], [], []]", 16, 0, 0, 593, 829], ["aten::t", "[[2048, 1000]]", 16, 0, 0, 890, 1719], ["aten::conj", "[[1000, 2048]]", 8, 0, 0, 152, 152], ["aten::stride", "[[1000, 2048], []]", 16, 0, 0, 158, 158], ["aten::as_strided", "[[32, 1000], [], [], []]", 8, 0, 0, 121, 121], ["aten::transpose", "[[32, 1000], [], []]", 8, 0, 0, 262, 383], ["aten::t", "[[32, 1000]]", 8, 0, 0, 474, 857], ["aten::conj", "[[32, 2048]]", 8, 0, 0, 145, 145], ["aten::stride", "[[1000, 32], []]", 8, 0, 0, 45, 45], ["AddmmBackward", "[[32, 1000]]", 8, 0, 384, 1396, 8872], ["torch::autograd::AccumulateGrad", "[[1000]]", 8, 0, 8, 356, 1163], ["TBackward", "[[2048, 1000]]", 8, 0, 0, 281, 1103], ["torch::autograd::AccumulateGrad", "[[1000, 2048]]", 8, 0, 238, 362, 1161], ["aten::view", "[[32, 2048], []]", 8, 0, 0, 550, 550], ["aten::reshape", "[[32, 2048], []]", 8, 0, 0, 245, 795], ["ViewBackward", "[[32, 2048]]", 8, 0, 0, 365, 1160], ["aten::as_strided", "[[32, 2048, 1, 1], [], [], []]", 8, 0, 0, 140, 140], ["aten::expand", "[[32, 2048, 1, 1], [], []]", 8, 0, 0, 694, 834], ["aten::to", "[[32, 2048, 7, 7], [], [], [], []]", 8, 0, 0, 115, 115], ["MeanBackward1", "[[32, 2048, 1, 1]]", 8, 0, 230, 682, 3590], ["ReluBackward1", "[[32, 2048, 7, 7]]", 24, 0, 1209, 1487, 5622], ["AddBackward0", "[[32, 2048, 7, 7]]", 24, 0, 0, 570, 570], ["CudnnBatchNormBackward", "[[32, 2048, 7, 7]]", 32, 0, 2347, 3869, 22665], ["torch::autograd::AccumulateGrad", "[[2048]]", 64, 0, 252, 2766, 9015], ["aten::cudnn_convolution_backward", "[[32, 512, 7, 7], [32, 2048, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], [], []]", 24, 0, 35958, 4429, 328720], ["CudnnConvolutionBackward", "[[32, 2048, 7, 7]]", 32, 0, 56725, 2666, 498240], ["torch::autograd::AccumulateGrad", "[[2048, 512, 1, 1]]", 24, 0, 389, 1080, 3452], ["ReluBackward1", "[[32, 512, 7, 7]]", 40, 0, 664, 2429, 9412], ["CudnnBatchNormBackward", "[[32, 512, 7, 7]]", 40, 0, 935, 4425, 25643], ["torch::autograd::AccumulateGrad", "[[512]]", 176, 0, 652, 7585, 25512], ["aten::cudnn_convolution_backward", "[[32, 512, 7, 7], [32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], [], []]", 16, 0, 25120, 2697, 52430], ["CudnnConvolutionBackward", "[[32, 512, 7, 7]]", 40, 0, 78021, 3228, 131307], ["torch::autograd::AccumulateGrad", "[[512, 512, 3, 3]]", 24, 0, 881, 1045, 3491], ["aten::cudnn_convolution_backward", "[[32, 2048, 7, 7], [32, 512, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], [], []]", 16, 0, 28621, 2771, 46227], ["torch::autograd::AccumulateGrad", "[[512, 2048, 1, 1]]", 16, 0, 309, 703, 2315], ["aten::cudnn_convolution_backward", "[[32, 1024, 14, 14], [32, 2048, 7, 7], [2048, 1024, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 20767, 1393, 166854], ["torch::autograd::AccumulateGrad", "[[2048, 1024, 1, 1]]", 8, 0, 269, 347, 1127], ["aten::cudnn_convolution_backward", "[[32, 512, 14, 14], [32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], [], []]", 8, 0, 24280, 1358, 29422], ["ReluBackward1", "[[32, 512, 14, 14]]", 8, 0, 403, 480, 1863], ["CudnnBatchNormBackward", "[[32, 512, 14, 14]]", 8, 0, 741, 883, 5123], ["aten::cudnn_convolution_backward", "[[32, 1024, 14, 14], [32, 512, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 23871, 1313, 28317], ["CudnnConvolutionBackward", "[[32, 512, 14, 14]]", 8, 0, 23871, 658, 28975], ["torch::autograd::AccumulateGrad", "[[512, 1024, 1, 1]]", 8, 0, 102, 348, 1147], ["ReluBackward1", "[[32, 1024, 14, 14]]", 48, 0, 4606, 3038, 11624], ["AddBackward0", "[[32, 1024, 14, 14]]", 48, 0, 0, 1537, 1537], ["CudnnBatchNormBackward", "[[32, 1024, 14, 14]]", 56, 0, 10146, 7322, 39016], ["torch::autograd::AccumulateGrad", "[[1024]]", 112, 0, 455, 4873, 16274], ["aten::cudnn_convolution_backward", "[[32, 256, 14, 14], [32, 1024, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], [], []]", 48, 0, 40994, 8563, 87636], ["CudnnConvolutionBackward", "[[32, 1024, 14, 14]]", 56, 0, 60092, 5305, 240054], ["torch::autograd::AccumulateGrad", "[[1024, 256, 1, 1]]", 48, 0, 326, 2135, 13188], ["ReluBackward1", "[[32, 256, 14, 14]]", 88, 0, 2457, 6541, 22112], ["CudnnBatchNormBackward", "[[32, 256, 14, 14]]", 88, 0, 4187, 10149, 57503], ["torch::autograd::AccumulateGrad", "[[256]]", 256, 0, 990, 11477, 37011], ["aten::cudnn_convolution_backward", "[[32, 256, 14, 14], [32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], [], []]", 40, 0, 32517, 7276, 64320], ["CudnnConvolutionBackward", "[[32, 256, 14, 14]]", 88, 0, 91176, 7422, 151760], ["torch::autograd::AccumulateGrad", "[[256, 256, 3, 3]]", 48, 0, 456, 2309, 7063], ["aten::cudnn_convolution_backward", "[[32, 1024, 14, 14], [32, 256, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], [], []]", 40, 0, 39261, 6859, 59121], ["torch::autograd::AccumulateGrad", "[[256, 1024, 1, 1]]", 40, 0, 314, 1798, 5939], ["aten::cudnn_convolution_backward", "[[32, 512, 28, 28], [32, 1024, 14, 14], [1024, 512, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 19098, 1609, 147113], ["torch::autograd::AccumulateGrad", "[[1024, 512, 1, 1]]", 8, 0, 59, 464, 1408], ["aten::cudnn_convolution_backward", "[[32, 256, 28, 28], [32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], [], []]", 8, 0, 19398, 1371, 20897], ["ReluBackward1", "[[32, 256, 28, 28]]", 8, 0, 762, 475, 2080], ["CudnnBatchNormBackward", "[[32, 256, 28, 28]]", 8, 0, 1308, 1194, 6476], ["aten::cudnn_convolution_backward", "[[32, 512, 28, 28], [32, 256, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 21505, 1712, 29990], ["CudnnConvolutionBackward", "[[32, 256, 28, 28]]", 8, 0, 21505, 666, 30656], ["torch::autograd::AccumulateGrad", "[[256, 512, 1, 1]]", 8, 0, 53, 376, 1448], ["ReluBackward1", "[[32, 512, 28, 28]]", 32, 0, 5941, 2034, 8120], ["AddBackward0", "[[32, 512, 28, 28]]", 32, 0, 0, 881, 881], ["CudnnBatchNormBackward", "[[32, 512, 28, 28]]", 40, 0, 13251, 4582, 26944], ["aten::cudnn_convolution_backward", "[[32, 128, 28, 28], [32, 512, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], [], []]", 32, 0, 31714, 5316, 51119], ["CudnnConvolutionBackward", "[[32, 512, 28, 28]]", 40, 0, 52689, 3296, 75302], ["torch::autograd::AccumulateGrad", "[[512, 128, 1, 1]]", 32, 0, 150, 1442, 4619], ["ReluBackward1", "[[32, 128, 28, 28]]", 56, 0, 2732, 3634, 13677], ["CudnnBatchNormBackward", "[[32, 128, 28, 28]]", 56, 0, 5098, 6531, 38039], ["torch::autograd::AccumulateGrad", "[[128]]", 128, 0, 472, 5935, 18875], ["aten::cudnn_convolution_backward", "[[32, 128, 28, 28], [32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], [], []]", 24, 0, 23200, 4599, 46108], ["CudnnConvolutionBackward", "[[32, 128, 28, 28]]", 56, 0, 70663, 4758, 123170], ["torch::autograd::AccumulateGrad", "[[128, 128, 3, 3]]", 32, 0, 169, 1512, 6245], ["aten::cudnn_convolution_backward", "[[32, 512, 28, 28], [32, 128, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], [], []]", 24, 0, 23838, 4372, 44493], ["torch::autograd::AccumulateGrad", "[[128, 512, 1, 1]]", 24, 0, 114, 1076, 3478], ["aten::cudnn_convolution_backward", "[[32, 256, 56, 56], [32, 512, 28, 28], [512, 256, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 20975, 1389, 20887], ["torch::autograd::AccumulateGrad", "[[512, 256, 1, 1]]", 8, 0, 42, 345, 1143], ["aten::cudnn_convolution_backward", "[[32, 128, 56, 56], [32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], [], []]", 8, 0, 23625, 1369, 27811], ["ReluBackward1", "[[32, 128, 56, 56]]", 8, 0, 1473, 487, 1868], ["CudnnBatchNormBackward", "[[32, 128, 56, 56]]", 8, 0, 2736, 902, 5177], ["aten::cudnn_convolution_backward", "[[32, 256, 56, 56], [32, 128, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 28683, 1434, 168486], ["CudnnConvolutionBackward", "[[32, 128, 56, 56]]", 8, 0, 28683, 793, 169279], ["torch::autograd::AccumulateGrad", "[[128, 256, 1, 1]]", 8, 0, 34, 362, 1207], ["ReluBackward1", "[[32, 256, 56, 56]]", 24, 0, 8809, 1457, 5587], ["AddBackward0", "[[32, 256, 56, 56]]", 24, 0, 0, 571, 571], ["CudnnBatchNormBackward", "[[32, 256, 56, 56]]", 32, 0, 20540, 3630, 20783], ["aten::cudnn_convolution_backward", "[[32, 64, 56, 56], [32, 256, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], [], []]", 32, 0, 36392, 5470, 54111], ["CudnnConvolutionBackward", "[[32, 256, 56, 56]]", 32, 0, 36392, 2709, 56820], ["torch::autograd::AccumulateGrad", "[[256, 64, 1, 1]]", 32, 0, 134, 1405, 4596], ["ReluBackward1", "[[32, 64, 56, 56]]", 48, 0, 4440, 3061, 11485], ["CudnnBatchNormBackward", "[[32, 64, 56, 56]]", 48, 0, 10088, 5581, 31861], ["torch::autograd::AccumulateGrad", "[[64]]", 112, 0, 416, 4927, 16147], ["aten::cudnn_convolution_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], [], []]", 24, 0, 42179, 4004, 46392], ["CudnnConvolutionBackward", "[[32, 64, 56, 56]]", 48, 0, 79199, 3903, 103164], ["torch::autograd::AccumulateGrad", "[[64, 64, 3, 3]]", 24, 0, 103, 1049, 3616], ["aten::cudnn_convolution_backward", "[[32, 256, 56, 56], [32, 64, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], [], []]", 16, 0, 29924, 2741, 34236], ["torch::autograd::AccumulateGrad", "[[64, 256, 1, 1]]", 16, 0, 62, 757, 2349], ["aten::cudnn_convolution_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 7096, 1347, 18633], ["torch::autograd::AccumulateGrad", "[[64, 64, 1, 1]]", 8, 0, 26, 366, 1130], ["aten::zero_", "[[32, 64, 112, 112]]", 8, 0, 1285, 312, 781], ["aten::zeros_like", "[[32, 64, 112, 112], [], [], [], [], []]", 8, 0, 1285, 372, 1799], ["aten::resize_", "[[32, 64, 112, 112], [], []]", 16, 0, 0, 272, 272], ["aten::resize_as_", "[[32, 64, 112, 112], [32, 64, 112, 112], []]", 8, 0, 0, 349, 533], ["MaxPool2DWithIndicesBackward", "[[32, 64, 56, 56]]", 8, 0, 6837, 656, 5733], ["ReluBackward1", "[[32, 64, 112, 112]]", 8, 0, 2966, 460, 1922], ["CudnnBatchNormBackward", "[[32, 64, 112, 112]]", 8, 0, 6504, 917, 5173], ["aten::cudnn_convolution_backward", "[[32, 3, 224, 224], [32, 64, 112, 112], [64, 3, 7, 7], [], [], [], [], [], [], [], []]", 8, 0, 12652, 1013, 11208], ["CudnnConvolutionBackward", "[[32, 64, 112, 112]]", 8, 0, 12652, 663, 11871], ["torch::autograd::AccumulateGrad", "[[64, 3, 7, 7]]", 8, 0, 34, 345, 1126]]}}, "kernel_op_table": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "string", "name": "Operator"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Total Duration (us)"}, {"type": "number", "name": "Mean Duration (us)"}, {"type": "number", "name": "Max Duration (us)"}, {"type": "number", "name": "Min Duration (us)"}], "rows": [["ncclAllReduceRingLLKernel_sum_f32(ncclColl)", "CallTreeRoot", 40, 2634946, 65873.65, 3656, 288933], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 256, 129872, 507.3125, 382, 1443], ["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", "aten::cudnn_convolution_backward_input", 212, 121084, 571.1509433962265, 150, 1200], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", "aten::cudnn_batch_norm_backward", 352, 74599, 211.92897727272728, 43, 853], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 86, 41904, 487.25581395348837, 362, 954], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 84, 37005, 440.5357142857143, 385, 897], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", "aten::cudnn_convolution_backward_weight", 76, 36672, 482.5263157894737, 336, 745], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", "aten::threshold_backward", 392, 36462, 93.01530612244898, 13, 394], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", "aten::cudnn_batch_norm", 200, 35209, 176.045, 50, 438], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", "aten::add_", 3670, 33639, 9.165940054495913, 1, 391], ["volta_scudnn_128x64_stridedB_interior_nn_v1", "aten::cudnn_convolution_backward_input", 95, 30372, 319.70526315789476, 264, 545], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 30, 28861, 962.0333333333333, 888, 1403], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", "aten::threshold_", 392, 23854, 60.85204081632653, 6, 273], ["volta_gcgemm_32x32_nt", "aten::cudnn_convolution", 110, 23543, 214.02727272727273, 19, 2437], ["volta_scudnn_128x64_relu_interior_nn_v1", "aten::cudnn_convolution", 61, 22008, 360.78688524590166, 92, 688], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", "CallTreeRoot", 128, 20736, 162.0, 49, 395], ["volta_gcgemm_32x32_nt", "aten::cudnn_convolution_backward_input", 29, 19471, 671.4137931034483, 70, 2233], ["volta_cgemm_32x32_tn", "aten::cudnn_convolution", 14, 17876, 1276.857142857143, 233, 3460], ["volta_sgemm_128x64_nt", "aten::cudnn_convolution_backward_weight", 84, 17545, 208.86904761904762, 172, 677], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 28, 17462, 623.6428571428571, 440, 1103], ["volta_sgemm_128x64_nt", "aten::cudnn_convolution_backward_input", 84, 16295, 193.98809523809524, 156, 211], ["volta_cgemm_32x32_tn", "aten::cudnn_convolution_backward_input", 14, 16294, 1163.857142857143, 214, 3140], ["volta_sgemm_128x64_nn", "aten::cudnn_convolution", 84, 16285, 193.86904761904762, 157, 229], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 22, 13565, 616.5909090909091, 212, 1005], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", "aten::cudnn_convolution", 19, 12733, 670.1578947368421, 140, 902], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", "aten::cudnn_convolution", 19, 12168, 640.421052631579, 366, 801], ["volta_cgemm_32x32_tn", "aten::cudnn_convolution_backward_weight", 14, 11511, 822.2142857142857, 215, 1707], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", "aten::cudnn_convolution_backward_weight", 16, 11300, 706.25, 668, 887], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", "aten::cudnn_convolution", 28, 11027, 393.82142857142856, 362, 848], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", "aten::cudnn_convolution_backward_input", 28, 10963, 391.5357142857143, 366, 778], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", "aten::cudnn_convolution_backward_weight", 17, 10821, 636.5294117647059, 362, 1112], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", "aten::cudnn_convolution_backward_input", 218, 9802, 44.96330275229358, 6, 162], ["volta_scudnn_128x128_relu_medium_nn_v1", "aten::cudnn_convolution", 34, 9777, 287.55882352941177, 269, 457], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", "aten::cudnn_batch_norm", 224, 9547, 42.620535714285715, 14, 89], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 12, 8676, 723.0, 664, 881], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 11, 8566, 778.7272727272727, 750, 794], ["volta_scudnn_128x64_relu_medium_nn_v1", "aten::cudnn_convolution", 12, 7690, 640.8333333333334, 421, 706], ["volta_scudnn_128x128_stridedB_interior_nn_v1", "aten::cudnn_convolution_backward_input", 25, 7256, 290.24, 271, 299], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", "aten::cudnn_convolution", 39, 7032, 180.30769230769232, 80, 447], ["void flip_filter<float, float>(float*, float const*, int, int, int, int)", "aten::cudnn_convolution", 16, 6614, 413.375, 9, 1807], ["volta_cgemm_64x32_tn", "aten::cudnn_convolution_backward_weight", 2, 6401, 3200.5, 3199, 3202], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", "CallTreeRoot", 1288, 6265, 4.864130434782608, 1, 30], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", "aten::cudnn_convolution", 10, 6165, 616.5, 569, 697], ["void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution_backward_input", 13, 6158, 473.6923076923077, 51, 1648], ["volta_scudnn_128x128_stridedB_small_nn_v1", "aten::cudnn_convolution_backward_input", 10, 5901, 590.1, 535, 941], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution_backward_input", 14, 5841, 417.2142857142857, 37, 1593], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution", 14, 5830, 416.42857142857144, 37, 1575], ["volta_scudnn_128x64_relu_small_nn_v1", "aten::cudnn_convolution", 19, 5815, 306.05263157894734, 269, 654], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", "aten::max_pool2d_with_indices_backward", 8, 5552, 694.0, 692, 697], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution_backward_weight", 7, 5531, 790.1428571428571, 127, 1685], ["volta_scudnn_128x128_stridedB_medium_nn_v1", "aten::cudnn_convolution_backward_input", 17, 5454, 320.8235294117647, 311, 331], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1", "aten::cudnn_convolution", 9, 5311, 590.1111111111111, 575, 639], ["volta_scudnn_128x128_relu_interior_nn_v1", "aten::cudnn_convolution", 9, 5111, 567.8888888888889, 551, 620], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", "aten::cudnn_convolution_backward_weight", 15, 5064, 337.6, 99, 1343], ["void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution", 8, 4551, 568.875, 15, 1757], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", "aten::cudnn_convolution_backward_input", 9, 4301, 477.8888888888889, 85, 1396], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", "aten::add", 1288, 4217, 3.2740683229813663, 1, 35], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", "aten::cudnn_convolution", 9, 4165, 462.77777777777777, 85, 1379], ["void flip_filter<float, float>(float*, float const*, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 16, 3947, 246.6875, 28, 1122], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", "aten::cudnn_convolution_backward_input", 84, 3829, 45.583333333333336, 21, 116], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", "aten::cudnn_convolution_backward_weight", 84, 3789, 45.107142857142854, 20, 136], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", "aten::cudnn_convolution_backward_input", 84, 3635, 43.273809523809526, 19, 135], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", "aten::cudnn_convolution_backward_weight", 84, 3611, 42.98809523809524, 18, 140], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", "aten::cudnn_convolution", 84, 3603, 42.892857142857146, 20, 110], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 5, 6, 4, 3, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", "aten::cudnn_convolution_backward_input", 3, 3501, 1167.0, 1112, 1273], ["void fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)", "aten::cudnn_convolution_backward_input", 28, 3405, 121.60714285714286, 15, 291], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", "aten::cudnn_convolution", 84, 3368, 40.095238095238095, 17, 137], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", "aten::cudnn_batch_norm_backward", 72, 3277, 45.513888888888886, 18, 80], ["void cudnn::detail::dgrad_alg1_engine<float, 128, 6, 8, 3, 3, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)", "aten::cudnn_convolution_backward_input", 1, 3170, 3170.0, 3170, 3170], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution", 10, 3132, 313.2, 89, 943], ["void fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)", "aten::cudnn_convolution", 16, 3016, 188.5, 63, 308], ["void fft2d_c2r_32x32<float, true, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution", 87, 3012, 34.62068965517241, 23, 131], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", "aten::fill_", 1143, 2985, 2.611548556430446, 0, 162], ["volta_scudnn_128x64_stridedB_small_nn_v1", "aten::cudnn_convolution_backward_input", 12, 2815, 234.58333333333334, 94, 691], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution_backward_input", 10, 2793, 279.3, 87, 875], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution", 95, 2778, 29.242105263157896, 13, 224], ["ncclBroadcastRingLLKernel_copy_i8(ncclColl)", "CallTreeRoot", 18, 2744, 152.44444444444446, 69, 276], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", "aten::mul_", 1127, 2728, 2.4205856255545695, 1, 24], ["volta_scudnn_128x64_stridedB_splitK_interior_nn_v1", "aten::cudnn_convolution_backward_weight", 3, 2341, 780.3333333333334, 569, 891], ["void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution", 7, 2193, 313.2857142857143, 98, 806], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1", "aten::cudnn_convolution", 3, 2159, 719.6666666666666, 638, 762], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", "aten::cudnn_convolution_backward_input", 84, 2143, 25.511904761904763, 4, 72], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", "aten::cudnn_convolution_backward_weight", 84, 2107, 25.083333333333332, 3, 68], ["void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)", "aten::cudnn_convolution_backward_input", 16, 1971, 123.1875, 33, 257], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", "aten::cudnn_convolution", 84, 1846, 21.976190476190474, 4, 72], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution_backward_weight", 5, 1830, 366.0, 132, 758], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 10, 1825, 182.5, 98, 362], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", "aten::max_pool2d_with_indices", 8, 1785, 223.125, 222, 224], ["volta_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1", "aten::cudnn_convolution_backward_weight", 1, 1654, 1654.0, 1654, 1654], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution_backward_weight", 4, 1633, 408.25, 128, 704], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 4, 6, 3, 2, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", "aten::cudnn_convolution_backward_input", 1, 1595, 1595.0, 1595, 1595], ["void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)", "aten::cudnn_convolution", 16, 1547, 96.6875, 37, 215], ["void fft1d_r2c_32<float, float, float2, true, false>(float2*, float const*, int, int3, int3, int2, int2)", "aten::cudnn_convolution", 12, 1525, 127.08333333333333, 20, 418], ["void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution_backward_input", 14, 1384, 98.85714285714286, 42, 198], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 4, 1337, 334.25, 142, 526], ["volta_scudnn_128x64_stridedB_splitK_small_nn_v1", "aten::cudnn_convolution_backward_weight", 2, 1297, 648.5, 647, 650], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution_backward_input", 5, 1204, 240.8, 119, 436], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 14, 1119, 79.92857142857143, 36, 166], ["void pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)", "aten::cudnn_convolution", 2, 1051, 525.5, 512, 539], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution_backward_weight", 8, 1042, 130.25, 69, 220], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", "aten::cudnn_convolution_backward_input", 1, 1039, 1039.0, 1039, 1039], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution", 5, 1015, 203.0, 124, 414], ["void pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)", "aten::cudnn_convolution_backward_input", 2, 1006, 503.0, 491, 515], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", "aten::cudnn_convolution_backward_input", 160, 983, 6.14375, 2, 11], ["void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", "aten::cudnn_convolution", 26, 925, 35.57692307692308, 9, 67], ["void explicit_convolve_sgemm<float, int, 512, 6, 8, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", "aten::cudnn_convolution", 1, 746, 746.0, 746, 746], ["void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution", 9, 741, 82.33333333333333, 42, 200], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution_backward_input", 9, 713, 79.22222222222223, 35, 193], ["volta_scudnn_128x64_stridedB_medium_nn_v1", "aten::cudnn_convolution_backward_input", 1, 659, 659.0, 659, 659], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", "aten::cudnn_convolution_backward_input", 160, 614, 3.8375, 1, 7], ["volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1", "aten::cudnn_convolution", 1, 570, 570.0, 570, 570], ["volta_scudnn_128x64_stridedB_splitK_medium_nn_v1", "aten::cudnn_convolution_backward_weight", 1, 538, 538.0, 538, 538], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution_backward_input", 7, 528, 75.42857142857143, 35, 139], ["void cudnn::cnn::wgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)", "aten::cudnn_convolution_backward_weight", 1, 509, 509.0, 509, 509], ["void fft2d_r2c_32x32<float, true, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution_backward_input", 6, 507, 84.5, 55, 142], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution", 7, 479, 68.42857142857143, 36, 137], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", "aten::add", 424, 461, 1.0872641509433962, 1, 3], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1", "aten::cudnn_convolution", 1, 454, 454.0, 454, 454], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", "aten::cudnn_convolution", 159, 430, 2.7044025157232703, 2, 6], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", "aten::cudnn_convolution_backward_weight", 116, 422, 3.6379310344827585, 1, 7], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", "aten::cudnn_convolution_backward_weight", 116, 386, 3.3275862068965516, 1, 6], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution_backward_input", 3, 348, 116.0, 81, 142], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", "aten::mean", 8, 346, 43.25, 42, 48], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<float, unsigned int, 1, 128, 1>(float*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<float, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", "aten::_cat", 8, 260, 32.5, 32, 36], ["void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", "aten::cudnn_convolution", 14, 250, 17.857142857142858, 11, 37], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", "aten::div", 8, 230, 28.75, 27, 29], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", "aten::cudnn_convolution_backward_input", 28, 228, 8.142857142857142, 4, 37], ["volta_sgemm_64x32_sliced1x4_nn", "aten::mm", 8, 215, 26.875, 25, 28], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution", 2, 210, 105.0, 80, 130], ["volta_sgemm_64x32_sliced1x4_tn", "aten::addmm", 8, 195, 24.375, 24, 27], ["volta_sgemm_128x32_nt", "aten::mm", 8, 152, 19.0, 19, 19], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", "aten::cudnn_convolution", 28, 138, 4.928571428571429, 2, 44], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<long, unsigned int, 1, 128, 1>(long*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<long, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", "aten::_cat", 8, 130, 16.25, 16, 18], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", "aten::_log_softmax_backward_data", 8, 86, 10.75, 10, 11], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", "aten::_log_softmax", 8, 82, 10.25, 10, 11], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", "CallTreeRoot", 8, 70, 8.75, 8, 9], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", "aten::addmm", 8, 45, 5.625, 5, 7], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", "aten::nll_loss_forward", 8, 33, 4.125, 4, 5], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", "aten::addmm", 8, 28, 3.5, 3, 4], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", "aten::nll_loss_backward", 8, 16, 2.0, 2, 2], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", "aten::mm", 8, 16, 2.0, 2, 2]]}}, "kernel_pie": {"total": {"columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["ncclAllReduceRingLLKernel_sum_f32(ncclColl)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2634946.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 129872.0}], ["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 121084.0}], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 74599.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 60316.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 58592.0}], ["volta_cgemm_32x32_tn", {"py/object": "numpy.float64", "dtype": "float64", "value": 45681.0}], ["volta_gcgemm_32x32_nt", {"py/object": "numpy.float64", "dtype": "float64", "value": 43014.0}], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 41904.0}], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 37005.0}], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 36672.0}], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 35209.0}], ["volta_sgemm_128x64_nt", {"py/object": "numpy.float64", "dtype": "float64", "value": 33840.0}], ["volta_scudnn_128x64_stridedB_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 30372.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 28861.0}], ["volta_scudnn_128x64_relu_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 22008.0}], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 21990.0}], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 17462.0}], ["volta_sgemm_128x64_nn", {"py/object": "numpy.float64", "dtype": "float64", "value": 16285.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 13565.0}], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 13530.0}], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 12790.0}], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 12733.0}], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 12168.0}], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 11300.0}], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 10821.0}], ["void flip_filter<float, float>(float*, float const*, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 10561.0}], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 9802.0}], ["volta_scudnn_128x128_relu_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 9777.0}], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", {"py/object": "numpy.float64", "dtype": "float64", "value": 9547.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 8993.0}], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 8676.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 8566.0}], ["void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 8351.0}], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 7750.0}], ["volta_scudnn_128x64_relu_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 7690.0}], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 7432.0}], ["volta_scudnn_128x128_stridedB_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 7256.0}], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 7032.0}], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 7003.0}], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 6538.0}], ["void fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)", {"py/object": "numpy.float64", "dtype": "float64", "value": 6421.0}], ["volta_cgemm_64x32_tn", {"py/object": "numpy.float64", "dtype": "float64", "value": 6401.0}], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 6165.0}], ["volta_scudnn_128x128_stridedB_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 5901.0}], ["volta_scudnn_128x64_relu_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 5815.0}], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 5552.0}], ["volta_scudnn_128x128_stridedB_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 5454.0}], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 5311.0}], ["volta_scudnn_128x128_relu_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 5111.0}], ["void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 4551.0}], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 4533.0}], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 4049.0}], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3989.0}], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3789.0}], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3611.0}], ["void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3518.0}], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 5, 6, 4, 3, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3501.0}], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3277.0}], ["void cudnn::detail::dgrad_alg1_engine<float, 128, 6, 8, 3, 3, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3170.0}], ["void fft2d_c2r_32x32<float, true, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3012.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2985.0}], ["volta_scudnn_128x64_stridedB_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 2815.0}], ["ncclBroadcastRingLLKernel_copy_i8(ncclColl)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2744.0}], ["volta_scudnn_128x64_stridedB_splitK_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 2341.0}], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2191.0}], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 2159.0}], ["void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2125.0}], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2107.0}], ["void pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2057.0}], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1785.0}], ["volta_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 1654.0}], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 4, 6, 3, 2, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1595.0}], ["void fft1d_r2c_32<float, float, float2, true, false>(float2*, float const*, int, int3, int3, int2, int2)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1525.0}], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1413.0}], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1337.0}], ["volta_scudnn_128x64_stridedB_splitK_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 1297.0}], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1039.0}], ["void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 925.0}], ["void explicit_convolve_sgemm<float, int, 512, 6, 8, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 746.0}], ["volta_scudnn_128x64_stridedB_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 659.0}], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 614.0}], ["volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 570.0}], ["volta_scudnn_128x64_stridedB_splitK_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 538.0}], ["void cudnn::cnn::wgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 509.0}], ["void fft2d_r2c_32x32<float, true, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 507.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 461.0}], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 454.0}], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 422.0}], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 386.0}], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 366.0}], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 346.0}], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<float, unsigned int, 1, 128, 1>(float*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<float, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 260.0}], ["void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 250.0}], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", {"py/object": "numpy.float64", "dtype": "float64", "value": 230.0}], ["volta_sgemm_64x32_sliced1x4_nn", {"py/object": "numpy.float64", "dtype": "float64", "value": 215.0}], ["volta_sgemm_64x32_sliced1x4_tn", {"py/object": "numpy.float64", "dtype": "float64", "value": 195.0}], ["volta_sgemm_128x32_nt", {"py/object": "numpy.float64", "dtype": "float64", "value": 152.0}], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<long, unsigned int, 1, 128, 1>(long*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<long, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 130.0}], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 86.0}], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 82.0}], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 70.0}], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", {"py/object": "numpy.float64", "dtype": "float64", "value": 45.0}], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 44.0}], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", {"py/object": "numpy.float64", "dtype": "float64", "value": 33.0}], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", {"py/object": "numpy.float64", "dtype": "float64", "value": 16.0}]]}}, "kernel_table": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Total Duration (us)"}, {"type": "number", "name": "Mean Duration (us)"}, {"type": "number", "name": "Max Duration (us)"}, {"type": "number", "name": "Min Duration (us)"}], "rows": [["ncclAllReduceRingLLKernel_sum_f32(ncclColl)", 40, 2634946, 65874, 288933, 3656], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 256, 129872, 507, 1443, 382], ["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", 212, 121084, 571, 1200, 150], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", 352, 74599, 212, 853, 43], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", 784, 60316, 77, 394, 6], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", 5086, 58592, 12, 395, 1], ["volta_cgemm_32x32_tn", 42, 45681, 1088, 3460, 214], ["volta_gcgemm_32x32_nt", 139, 43014, 309, 2437, 19], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 86, 41904, 487, 954, 362], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 84, 37005, 441, 897, 385], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", 76, 36672, 483, 745, 336], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", 200, 35209, 176, 438, 50], ["volta_sgemm_128x64_nt", 168, 33840, 201, 677, 156], ["volta_scudnn_128x64_stridedB_interior_nn_v1", 95, 30372, 320, 545, 264], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 30, 28861, 962, 1403, 888], ["volta_scudnn_128x64_relu_interior_nn_v1", 61, 22008, 361, 688, 92], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", 56, 21990, 393, 848, 362], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 28, 17462, 624, 1103, 440], ["volta_sgemm_128x64_nn", 84, 16285, 194, 229, 157], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 22, 13565, 617, 1005, 212], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", 33, 13530, 410, 1396, 85], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", 42, 12790, 305, 1593, 36], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 19, 12733, 670, 902, 140], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 19, 12168, 640, 801, 366], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", 16, 11300, 706, 887, 668], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", 17, 10821, 637, 1112, 362], ["void flip_filter<float, float>(float*, float const*, int, int, int, int)", 32, 10561, 330, 1807, 9], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", 218, 9802, 45, 162, 6], ["volta_scudnn_128x128_relu_medium_nn_v1", 34, 9777, 288, 457, 269], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", 224, 9547, 43, 89, 14], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", 2415, 8993, 4, 30, 1], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 12, 8676, 723, 881, 664], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 11, 8566, 779, 794, 750], ["void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 20, 8351, 418, 1648, 51], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", 30, 7750, 258, 943, 87], ["volta_scudnn_128x64_relu_medium_nn_v1", 12, 7690, 641, 706, 421], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", 168, 7432, 44, 116, 20], ["volta_scudnn_128x128_stridedB_interior_nn_v1", 25, 7256, 290, 299, 271], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", 39, 7032, 180, 447, 80], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 168, 7003, 42, 137, 17], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", 21, 6538, 311, 1685, 35], ["void fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)", 44, 6421, 146, 308, 15], ["volta_cgemm_64x32_tn", 2, 6401, 3200, 3202, 3199], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", 10, 6165, 616, 697, 569], ["volta_scudnn_128x128_stridedB_small_nn_v1", 10, 5901, 590, 941, 535], ["volta_scudnn_128x64_relu_small_nn_v1", 19, 5815, 306, 654, 269], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", 8, 5552, 694, 697, 692], ["volta_scudnn_128x128_stridedB_medium_nn_v1", 17, 5454, 321, 331, 311], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1", 9, 5311, 590, 639, 575], ["volta_scudnn_128x128_relu_interior_nn_v1", 9, 5111, 568, 620, 551], ["void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 8, 4551, 569, 1757, 15], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 112, 4533, 40, 224, 13], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", 15, 4049, 270, 758, 119], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", 168, 3989, 24, 72, 4], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 84, 3789, 45, 136, 20], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", 84, 3611, 43, 140, 18], ["void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)", 32, 3518, 110, 257, 33], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 5, 6, 4, 3, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 3, 3501, 1167, 1273, 1112], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", 72, 3277, 46, 80, 18], ["void cudnn::detail::dgrad_alg1_engine<float, 128, 6, 8, 3, 3, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)", 1, 3170, 3170, 3170, 3170], ["void fft2d_c2r_32x32<float, true, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 87, 3012, 35, 131, 23], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", 1143, 2985, 3, 162, 0], ["volta_scudnn_128x64_stridedB_small_nn_v1", 12, 2815, 235, 691, 94], ["ncclBroadcastRingLLKernel_copy_i8(ncclColl)", 18, 2744, 152, 276, 69], ["volta_scudnn_128x64_stridedB_splitK_interior_nn_v1", 3, 2341, 780, 891, 569], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 9, 2191, 243, 704, 80], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1", 3, 2159, 720, 762, 638], ["void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 23, 2125, 92, 200, 42], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", 84, 2107, 25, 68, 3], ["void pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)", 4, 2057, 514, 539, 491], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", 8, 1785, 223, 224, 222], ["volta_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1", 1, 1654, 1654, 1654, 1654], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 4, 6, 3, 2, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 1, 1595, 1595, 1595, 1595], ["void fft1d_r2c_32<float, float, float2, true, false>(float2*, float const*, int, int3, int3, int2, int2)", 12, 1525, 127, 418, 20], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", 319, 1413, 4, 11, 2], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 4, 1337, 334, 526, 142], ["volta_scudnn_128x64_stridedB_splitK_small_nn_v1", 2, 1297, 648, 650, 647], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 1, 1039, 1039, 1039, 1039], ["void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", 26, 925, 36, 67, 9], ["void explicit_convolve_sgemm<float, int, 512, 6, 8, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 1, 746, 746, 746, 746], ["volta_scudnn_128x64_stridedB_medium_nn_v1", 1, 659, 659, 659, 659], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", 160, 614, 4, 7, 1], ["volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1", 1, 570, 570, 570, 570], ["volta_scudnn_128x64_stridedB_splitK_medium_nn_v1", 1, 538, 538, 538, 538], ["void cudnn::cnn::wgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)", 1, 509, 509, 509, 509], ["void fft2d_r2c_32x32<float, true, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 6, 507, 84, 142, 55], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", 424, 461, 1, 3, 1], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1", 1, 454, 454, 454, 454], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", 116, 422, 4, 7, 1], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", 116, 386, 3, 6, 1], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", 56, 366, 7, 44, 2], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", 8, 346, 43, 48, 42], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<float, unsigned int, 1, 128, 1>(float*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<float, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", 8, 260, 32, 36, 32], ["void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", 14, 250, 18, 37, 11], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", 8, 230, 29, 29, 27], ["volta_sgemm_64x32_sliced1x4_nn", 8, 215, 27, 28, 25], ["volta_sgemm_64x32_sliced1x4_tn", 8, 195, 24, 27, 24], ["volta_sgemm_128x32_nt", 8, 152, 19, 19, 19], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<long, unsigned int, 1, 128, 1>(long*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<long, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", 8, 130, 16, 18, 16], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", 8, 86, 11, 11, 10], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", 8, 82, 10, 11, 10], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", 8, 70, 9, 9, 8], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", 8, 45, 6, 7, 5], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", 16, 44, 3, 4, 2], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", 8, 33, 4, 5, 4], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", 8, 16, 2, 2, 2]]}}, "trace_file_path": "./data/tracing\\resnet50_newAPI_noPred_ddp\\worker0_span1.pt.trace.json.gz"}]}, {"py/tuple": ["worker1_span1", {"py/object": "tensorboard_plugin_torch_profiler.run.RunProfile", "worker": "worker1_span1", "views": [{"py/id": 4}, {"py/id": 5}, {"py/id": 6}, {"py/id": 7}], "is_gpu_used": true, "overview": {"steps": {"columns": [{"type": "string", "name": "Step"}, {"type": "number", "name": "Kernel"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memcpy"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memset"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Runtime"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "DataLoader"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "CPU Exec"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Other"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}], "rows": [["2", 285995, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 2<br>Total: 2156088us<br><b>Kernel: 285995us</b><br>Percentage: 13.26%</div>", 1971, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 2<br>Total: 2156088us<br><b>Memcpy: 1971us</b><br>Percentage: 0.09%</div>", 1, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 2<br>Total: 2156088us<br><b>Memset: 1us</b><br>Percentage: 0.0%</div>", 72712, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 2<br>Total: 2156088us<br><b>Runtime: 72712us</b><br>Percentage: 3.37%</div>", 1507525, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 2<br>Total: 2156088us<br><b>DataLoader: 1507525us</b><br>Percentage: 69.92%</div>", 253482, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 2<br>Total: 2156088us<br><b>CPU Exec: 253482us</b><br>Percentage: 11.76%</div>", 34402, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 2<br>Total: 2156088us<br><b>Other: 34402us</b><br>Percentage: 1.6%</div>"], ["3", 330468, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 3<br>Total: 1992047us<br><b>Kernel: 330468us</b><br>Percentage: 16.59%</div>", 1894, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 3<br>Total: 1992047us<br><b>Memcpy: 1894us</b><br>Percentage: 0.1%</div>", 1, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 3<br>Total: 1992047us<br><b>Memset: 1us</b><br>Percentage: 0.0%</div>", 13403, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 3<br>Total: 1992047us<br><b>Runtime: 13403us</b><br>Percentage: 0.67%</div>", 1456800, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 3<br>Total: 1992047us<br><b>DataLoader: 1456800us</b><br>Percentage: 73.13%</div>", 172295, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 3<br>Total: 1992047us<br><b>CPU Exec: 172295us</b><br>Percentage: 8.65%</div>", 17186, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 3<br>Total: 1992047us<br><b>Other: 17186us</b><br>Percentage: 0.86%</div>"], ["4", 387956, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 4<br>Total: 1965182us<br><b>Kernel: 387956us</b><br>Percentage: 19.74%</div>", 1733, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 4<br>Total: 1965182us<br><b>Memcpy: 1733us</b><br>Percentage: 0.09%</div>", 1, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 4<br>Total: 1965182us<br><b>Memset: 1us</b><br>Percentage: 0.0%</div>", 6551, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 4<br>Total: 1965182us<br><b>Runtime: 6551us</b><br>Percentage: 0.33%</div>", 1445242, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 4<br>Total: 1965182us<br><b>DataLoader: 1445242us</b><br>Percentage: 73.54%</div>", 111690, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 4<br>Total: 1965182us<br><b>CPU Exec: 111690us</b><br>Percentage: 5.68%</div>", 12009, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 4<br>Total: 1965182us<br><b>Other: 12009us</b><br>Percentage: 0.61%</div>"], ["5", 281774, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 2257637us<br><b>Kernel: 281774us</b><br>Percentage: 12.48%</div>", 2033, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 2257637us<br><b>Memcpy: 2033us</b><br>Percentage: 0.09%</div>", 3, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 2257637us<br><b>Memset: 3us</b><br>Percentage: 0.0%</div>", 19883, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 2257637us<br><b>Runtime: 19883us</b><br>Percentage: 0.88%</div>", 1648529, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 2257637us<br><b>DataLoader: 1648529us</b><br>Percentage: 73.02%</div>", 279882, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 2257637us<br><b>CPU Exec: 279882us</b><br>Percentage: 12.4%</div>", 25533, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 2257637us<br><b>Other: 25533us</b><br>Percentage: 1.13%</div>"], ["6", 248044, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1953510us<br><b>Kernel: 248044us</b><br>Percentage: 12.7%</div>", 1959, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1953510us<br><b>Memcpy: 1959us</b><br>Percentage: 0.1%</div>", 1, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1953510us<br><b>Memset: 1us</b><br>Percentage: 0.0%</div>", 17955, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1953510us<br><b>Runtime: 17955us</b><br>Percentage: 0.92%</div>", 1427744, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1953510us<br><b>DataLoader: 1427744us</b><br>Percentage: 73.09%</div>", 232680, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1953510us<br><b>CPU Exec: 232680us</b><br>Percentage: 11.91%</div>", 25127, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 1953510us<br><b>Other: 25127us</b><br>Percentage: 1.29%</div>"], ["7", 257715, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 1987306us<br><b>Kernel: 257715us</b><br>Percentage: 12.97%</div>", 1936, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 1987306us<br><b>Memcpy: 1936us</b><br>Percentage: 0.1%</div>", 5, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 1987306us<br><b>Memset: 5us</b><br>Percentage: 0.0%</div>", 21043, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 1987306us<br><b>Runtime: 21043us</b><br>Percentage: 1.06%</div>", 1418691, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 1987306us<br><b>DataLoader: 1418691us</b><br>Percentage: 71.39%</div>", 259007, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 1987306us<br><b>CPU Exec: 259007us</b><br>Percentage: 13.03%</div>", 28909, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 1987306us<br><b>Other: 28909us</b><br>Percentage: 1.45%</div>"], ["8", 247376, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1969785us<br><b>Kernel: 247376us</b><br>Percentage: 12.56%</div>", 1952, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1969785us<br><b>Memcpy: 1952us</b><br>Percentage: 0.1%</div>", 1, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1969785us<br><b>Memset: 1us</b><br>Percentage: 0.0%</div>", 19840, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1969785us<br><b>Runtime: 19840us</b><br>Percentage: 1.01%</div>", 1431149, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1969785us<br><b>DataLoader: 1431149us</b><br>Percentage: 72.66%</div>", 241803, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1969785us<br><b>CPU Exec: 241803us</b><br>Percentage: 12.28%</div>", 27664, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 1969785us<br><b>Other: 27664us</b><br>Percentage: 1.4%</div>"], ["9", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 804us<br><b>Kernel: 0us</b><br>Percentage: 0.0%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 804us<br><b>Memcpy: 0us</b><br>Percentage: 0.0%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 804us<br><b>Memset: 0us</b><br>Percentage: 0.0%</div>", 21, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 804us<br><b>Runtime: 21us</b><br>Percentage: 2.61%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 804us<br><b>DataLoader: 0us</b><br>Percentage: 0.0%</div>", 19, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 804us<br><b>CPU Exec: 19us</b><br>Percentage: 2.36%</div>", 764, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 804us<br><b>Other: 764us</b><br>Percentage: 95.02%</div>"]]}, "performance": [{"name": "Average Step Time", "description": "", "value": 1785295, "extra": 100, "children": [{"name": "Kernel", "description": "", "value": 254916, "extra": 14.28}, {"name": "Memcpy", "description": "", "value": 1685, "extra": 0.09}, {"name": "Memset", "description": "", "value": 2, "extra": 0.0}, {"name": "Runtime", "description": "", "value": 21426, "extra": 1.2}, {"name": "DataLoader", "description": "", "value": 1291960, "extra": 72.37}, {"name": "CPU Exec", "description": "", "value": 193857, "extra": 10.86}, {"name": "Other", "description": "", "value": 21449, "extra": 1.2}]}], "recommendations": "<ul><li>This run has high time cost on input data loading. 72.4% of the step time is in DataLoader. You could try to set num_workers on DataLoader's construction and enable multi-processes on data loading. Reference: <a href =\"https://pytorch.org/docs/stable/data.html#single-and-multi-process-data-loading\" target=\"_blank\">Single- and Multi-process Data Loading</a></li></ul>"}, "operation_pie_by_name": {"device_total_time": {"title": "Device Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward", 617481], ["CudnnConvolutionBackward", 617481], ["aten::cudnn_convolution", 320735], ["aten::_convolution", 320735], ["aten::convolution", 320735], ["aten::conv2d", 320735], ["aten::cudnn_convolution_backward_weight", 313891], ["aten::cudnn_convolution_backward_input", 303590], ["aten::cudnn_batch_norm_backward", 78217], ["CudnnBatchNormBackward", 78217], ["aten::cudnn_batch_norm", 44825], ["aten::_batch_norm_impl_index", 44825], ["aten::batch_norm", 44825], ["aten::threshold_backward", 36420], ["ReluBackward1", 36420], ["aten::add_", 33635], ["aten::threshold_", 23848], ["aten::relu_", 23848], ["aten::copy_", 15954], ["aten::to", 13507], ["torch::autograd::AccumulateGrad", 7539], ["aten::max_pool2d_with_indices_backward", 6824], ["MaxPool2DWithIndicesBackward", 6824], ["aten::add", 4654], ["aten::fill_", 2975], ["aten::zero_", 2967], ["aten::mul_", 2728], ["aten::max_pool2d_with_indices", 1783], ["aten::max_pool2d", 1783], ["aten::zeros_like", 1280], ["aten::_cat", 394], ["aten::cat", 394], ["aten::mm", 379], ["AddmmBackward", 379], ["aten::clone", 357], ["aten::mean", 345], ["aten::adaptive_avg_pool2d", 345], ["aten::addmm", 272], ["aten::div", 230], ["MeanBackward1", 230], ["aten::_log_softmax_backward_data", 85], ["LogSoftmaxBackward", 85], ["aten::_log_softmax", 80], ["aten::log_softmax", 80], ["aten::nll_loss_forward", 32], ["aten::nll_loss", 32], ["aten::nll_loss_backward", 24], ["NllLossBackward", 24], ["aten::_local_scalar_dense", 13], ["aten::item", 13], ["aten::ones_like", 8]]}, "device_self_time": {"title": "Device Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution", 320735], ["aten::cudnn_convolution_backward_weight", 313891], ["aten::cudnn_convolution_backward_input", 303590], ["aten::cudnn_batch_norm_backward", 78217], ["aten::cudnn_batch_norm", 44825], ["aten::threshold_backward", 36420], ["aten::add_", 33635], ["aten::threshold_", 23848], ["aten::copy_", 15954], ["aten::max_pool2d_with_indices_backward", 5544], ["aten::add", 4654], ["aten::fill_", 2975], ["aten::mul_", 2728], ["aten::max_pool2d_with_indices", 1783], ["aten::_cat", 394], ["aten::mm", 379], ["aten::mean", 345], ["aten::addmm", 272], ["aten::div", 230], ["aten::_log_softmax_backward_data", 85], ["aten::_log_softmax", 80], ["aten::nll_loss_forward", 32], ["aten::nll_loss_backward", 24], ["aten::_local_scalar_dense", 13]]}, "host_total_time": {"title": "Host Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 4576951], ["aten::cat", 4222769], ["aten::_cat", 4219527], ["aten::conv2d", 3224239], ["aten::convolution", 3202325], ["aten::_convolution", 3183540], ["aten::cudnn_convolution", 3138077], ["aten::to", 2179865], ["CudnnConvolutionBackward", 1523278], ["aten::cudnn_convolution_backward", 1486015], ["aten::contiguous", 1346647], ["aten::clone", 1239703], ["aten::div_", 1152229], ["aten::div", 1079470], ["aten::stack", 1076465], ["aten::sub_", 947087], ["aten::addmm", 859710], ["aten::cudnn_convolution_backward_weight", 721960], ["aten::cudnn_convolution_backward_input", 683255], ["aten::batch_norm", 480992], ["aten::_batch_norm_impl_index", 460408], ["aten::empty", 458342], ["aten::cudnn_batch_norm", 383167], ["aten::add_", 356444], ["torch::autograd::AccumulateGrad", 320161], ["aten::empty_strided", 306944], ["aten::add", 299401], ["CudnnBatchNormBackward", 286393], ["aten::cudnn_batch_norm_backward", 228174], ["aten::view", 213450], ["aten::eq", 174369], ["aten::lt", 173634], ["aten::narrow", 140937], ["aten::item", 137768], ["aten::zero_", 127593], ["aten::mul_", 123597], ["aten::pin_memory", 115463], ["aten::slice", 107530], ["aten::exp", 99037], ["ReluBackward1", 95626], ["aten::_local_scalar_dense", 75339], ["aten::relu_", 71272], ["aten::threshold_backward", 71145], ["aten::select", 68904], ["aten::randint", 65058], ["aten::any", 60951], ["aten::fill_", 60855], ["aten::empty_like", 60180], ["aten::uniform_", 56898], ["aten::resize_", 52404], ["aten::as_strided", 47346], ["aten::stride", 40743], ["aten::log", 40627], ["aten::is_nonzero", 35891], ["aten::rand", 32532], ["aten::permute", 26484], ["aten::threshold_", 23306], ["aten::set_", 19271], ["aten::random_", 15947], ["aten::is_floating_point", 13182], ["aten::detach_", 11485], ["aten::unsqueeze", 11426], ["AddmmBackward", 9007], ["aten::detach", 6010], ["MaxPool2DWithIndicesBackward", 5564], ["aten::adaptive_avg_pool2d", 5378], ["aten::max_pool2d", 5136], ["aten::mean", 4967], ["aten::max_pool2d_with_indices_backward", 4902], ["detach_", 4879], ["aten::max_pool2d_with_indices", 4686], ["aten::mm", 4676], ["aten::t", 4624], ["aten::zeros", 4527], ["MeanBackward1", 3989], ["AddBackward0", 3336], ["aten::log_softmax", 3021], ["aten::_log_softmax", 2626], ["LogSoftmaxBackward", 2567], ["detach", 2422], ["aten::nll_loss", 2257], ["NllLossBackward", 2134], ["aten::_log_softmax_backward_data", 2042], ["aten::transpose", 2034], ["aten::reshape", 1892], ["aten::nll_loss_forward", 1884], ["aten::zeros_like", 1767], ["aten::ones_like", 1755], ["aten::flatten", 1540], ["aten::nll_loss_backward", 1406], ["aten::expand", 1370], ["TBackward", 1123], ["aten::is_pinned", 1120], ["ViewBackward", 1068], ["nccl:broadcast", 555], ["aten::conj", 341], ["aten::resize_as_", 336]]}, "host_self_time": {"title": "Host Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 4576951], ["aten::_cat", 4210564], ["aten::cudnn_convolution", 3027189], ["aten::div_", 1152229], ["aten::div", 1037382], ["aten::sub_", 947087], ["aten::addmm", 856337], ["aten::cudnn_convolution_backward_weight", 660620], ["aten::cudnn_convolution_backward_input", 621378], ["aten::empty", 458342], ["aten::add_", 356444], ["aten::empty_strided", 306944], ["aten::cudnn_batch_norm", 282205], ["aten::add", 229940], ["aten::view", 213450], ["aten::cudnn_batch_norm_backward", 153127], ["aten::mul_", 123597], ["aten::contiguous", 110002], ["aten::slice", 91163], ["aten::to", 90919], ["aten::cudnn_convolution_backward", 75954], ["aten::_local_scalar_dense", 75339], ["aten::zero_", 71628], ["aten::item", 62429], ["aten::fill_", 60855], ["torch::autograd::AccumulateGrad", 59301], ["aten::select", 58985], ["aten::clone", 57109], ["aten::uniform_", 56898], ["aten::exp", 56210], ["aten::_batch_norm_impl_index", 55520], ["aten::threshold_backward", 54691], ["aten::lt", 53383], ["aten::resize_", 52404], ["CudnnBatchNormBackward", 51066], ["aten::eq", 50656], ["aten::relu_", 47966], ["aten::as_strided", 47346], ["aten::any", 44223], ["aten::stride", 40743], ["aten::_convolution", 39962], ["aten::randint", 39627], ["CudnnConvolutionBackward", 37263], ["aten::log", 33642], ["aten::narrow", 33407], ["aten::empty_like", 33344], ["ReluBackward1", 24481], ["aten::threshold_", 23306], ["aten::permute", 22261], ["aten::conv2d", 21914], ["aten::batch_norm", 20584], ["aten::pin_memory", 19615], ["aten::set_", 19271], ["aten::convolution", 18785], ["aten::rand", 17684], ["aten::random_", 15947], ["aten::is_floating_point", 13182], ["aten::is_nonzero", 11472], ["aten::unsqueeze", 8270], ["aten::detach_", 6606], ["detach_", 4879], ["aten::stack", 4813], ["aten::mean", 4636], ["aten::mm", 3705], ["aten::detach", 3588], ["AddBackward0", 3336], ["aten::max_pool2d_with_indices", 3302], ["aten::cat", 3242], ["aten::t", 2590], ["detach", 2422], ["aten::max_pool2d_with_indices_backward", 2266], ["aten::zeros", 2261], ["aten::nll_loss_forward", 1884], ["aten::_log_softmax", 1839], ["AddmmBackward", 1429], ["aten::transpose", 1409], ["aten::nll_loss_backward", 1406], ["aten::_log_softmax_backward_data", 1173], ["aten::is_pinned", 1120], ["aten::expand", 1099], ["NllLossBackward", 728], ["MeanBackward1", 680], ["MaxPool2DWithIndicesBackward", 662], ["nccl:broadcast", 555], ["LogSoftmaxBackward", 525], ["aten::ones_like", 524], ["aten::reshape", 503], ["aten::max_pool2d", 450], ["aten::adaptive_avg_pool2d", 411], ["aten::flatten", 399], ["aten::log_softmax", 395], ["aten::nll_loss", 373], ["aten::zeros_like", 348], ["aten::conj", 341], ["ViewBackward", 317], ["TBackward", 306], ["aten::resize_as_", 265]]}}, "operation_table_by_name": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Device Self Duration (us)"}, {"type": "number", "name": "Device Total Duration (us)"}, {"type": "number", "name": "Host Self Duration (us)"}, {"type": "number", "name": "Host Total Duration (us)"}], "rows": [["aten::cudnn_convolution", 424, 320735, 320735, 3027189, 3138077], ["aten::cudnn_convolution_backward_weight", 424, 313891, 313891, 660620, 721960], ["aten::cudnn_convolution_backward_input", 416, 303590, 303590, 621378, 683255], ["aten::cudnn_batch_norm_backward", 424, 78217, 78217, 153127, 228174], ["aten::cudnn_batch_norm", 424, 44825, 44825, 282205, 383167], ["aten::threshold_backward", 392, 36420, 36420, 54691, 71145], ["aten::add_", 3670, 33635, 33635, 356444, 356444], ["aten::threshold_", 392, 23848, 23848, 23306, 23306], ["aten::copy_", 3166, 15954, 15954, 4576951, 4576951], ["aten::max_pool2d_with_indices_backward", 8, 5544, 6824, 2266, 4902], ["aten::add", 1712, 4654, 4654, 229940, 299401], ["aten::fill_", 1431, 2975, 2975, 60855, 60855], ["aten::mul_", 1127, 2728, 2728, 123597, 123597], ["aten::max_pool2d_with_indices", 8, 1783, 1783, 3302, 4686], ["aten::_cat", 24, 394, 394, 4210564, 4219527], ["aten::mm", 16, 379, 379, 3705, 4676], ["aten::mean", 8, 345, 345, 4636, 4967], ["aten::addmm", 8, 272, 272, 856337, 859710], ["aten::div", 264, 230, 230, 1037382, 1079470], ["aten::_log_softmax_backward_data", 8, 85, 85, 1173, 2042], ["aten::_log_softmax", 8, 80, 80, 1839, 2626], ["aten::nll_loss_forward", 8, 32, 32, 1884, 1884], ["aten::nll_loss_backward", 8, 24, 24, 1406, 1406], ["aten::_local_scalar_dense", 2985, 13, 13, 75339, 75339], ["aten::empty", 13266, 0, 0, 458342, 458342], ["aten::random_", 513, 0, 0, 15947, 15947], ["aten::is_floating_point", 1241, 0, 0, 13182, 13182], ["aten::item", 2985, 0, 13, 62429, 137768], ["aten::zero_", 1167, 0, 2967, 71628, 127593], ["aten::zeros", 32, 0, 0, 2261, 4527], ["aten::uniform_", 976, 0, 0, 56898, 56898], ["aten::to", 1936, 0, 13507, 90919, 2179865], ["detach_", 368, 0, 0, 4879, 4879], ["aten::detach_", 368, 0, 0, 6606, 11485], ["aten::log", 360, 0, 0, 33642, 40627], ["aten::as_strided", 2985, 0, 0, 47346, 47346], ["aten::select", 720, 0, 0, 58985, 68904], ["aten::resize_", 3712, 0, 0, 52404, 52404], ["aten::exp", 720, 0, 0, 56210, 99037], ["aten::randint", 512, 0, 0, 39627, 65058], ["aten::rand", 256, 0, 0, 17684, 32532], ["aten::empty_strided", 1626, 0, 0, 306944, 306944], ["aten::lt", 512, 0, 0, 53383, 173634], ["aten::is_nonzero", 512, 0, 0, 11472, 35891], ["aten::set_", 272, 0, 0, 19271, 19271], ["aten::view", 4176, 0, 0, 213450, 213450], ["aten::permute", 256, 0, 0, 22261, 26484], ["aten::empty_like", 712, 0, 0, 33344, 60180], ["aten::contiguous", 7920, 0, 0, 110002, 1346647], ["aten::clone", 417, 0, 357, 57109, 1239703], ["aten::eq", 512, 0, 0, 50656, 174369], ["aten::any", 256, 0, 0, 44223, 60951], ["aten::sub_", 256, 0, 0, 947087, 947087], ["aten::div_", 256, 0, 0, 1152229, 1152229], ["aten::unsqueeze", 256, 0, 0, 8270, 11426], ["aten::slice", 1280, 0, 0, 91163, 107530], ["aten::narrow", 1280, 0, 0, 33407, 140937], ["aten::stride", 6528, 0, 0, 40743, 40743], ["aten::cat", 24, 0, 394, 3242, 4222769], ["aten::stack", 8, 0, 0, 4813, 1076465], ["aten::is_pinned", 16, 0, 0, 1120, 1120], ["aten::pin_memory", 16, 0, 0, 19615, 115463], ["nccl:broadcast", 18, 0, 0, 555, 555], ["aten::_convolution", 424, 0, 320735, 39962, 3183540], ["aten::convolution", 424, 0, 320735, 18785, 3202325], ["aten::conv2d", 424, 0, 320735, 21914, 3224239], ["aten::_batch_norm_impl_index", 424, 0, 44825, 55520, 460408], ["aten::batch_norm", 424, 0, 44825, 20584, 480992], ["aten::relu_", 392, 0, 23848, 47966, 71272], ["aten::max_pool2d", 8, 0, 1783, 450, 5136], ["aten::adaptive_avg_pool2d", 8, 0, 345, 411, 5378], ["aten::reshape", 16, 0, 0, 503, 1892], ["aten::flatten", 8, 0, 0, 399, 1540], ["aten::transpose", 40, 0, 0, 1409, 2034], ["aten::t", 40, 0, 0, 2590, 4624], ["aten::expand", 16, 0, 0, 1099, 1370], ["aten::log_softmax", 8, 0, 80, 395, 3021], ["aten::nll_loss", 8, 0, 32, 373, 2257], ["aten::ones_like", 8, 0, 8, 524, 1755], ["detach", 161, 0, 0, 2422, 2422], ["aten::detach", 161, 0, 0, 3588, 6010], ["NllLossBackward", 8, 0, 24, 728, 2134], ["LogSoftmaxBackward", 8, 0, 85, 525, 2567], ["aten::conj", 16, 0, 0, 341, 341], ["AddmmBackward", 8, 0, 379, 1429, 9007], ["torch::autograd::AccumulateGrad", 1288, 0, 7539, 59301, 320161], ["TBackward", 8, 0, 0, 306, 1123], ["ViewBackward", 8, 0, 0, 317, 1068], ["MeanBackward1", 8, 0, 230, 680, 3989], ["ReluBackward1", 392, 0, 36420, 24481, 95626], ["AddBackward0", 128, 0, 0, 3336, 3336], ["CudnnBatchNormBackward", 424, 0, 78217, 51066, 286393], ["aten::cudnn_convolution_backward", 424, 0, 617481, 75954, 1486015], ["CudnnConvolutionBackward", 424, 0, 617481, 37263, 1523278], ["aten::zeros_like", 8, 0, 1280, 348, 1767], ["aten::resize_as_", 8, 0, 0, 265, 336], ["MaxPool2DWithIndicesBackward", 8, 0, 6824, 662, 5564]]}}, "operation_pie_by_name_input": {"device_total_time": {"title": "Device Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["CudnnConvolutionBackward", 91064], ["CudnnConvolutionBackward", 78943], ["CudnnConvolutionBackward", 77236], ["CudnnConvolutionBackward", 70983], ["CudnnConvolutionBackward", 66934], ["CudnnConvolutionBackward", 56566], ["CudnnConvolutionBackward", 52505], ["aten::cudnn_convolution_backward", 47634], ["aten::cudnn_convolution_backward", 42043], ["aten::cudnn_convolution_backward", 39174], ["aten::cudnn_convolution_backward", 36403], ["CudnnConvolutionBackward", 36403], ["aten::cudnn_convolution_backward", 35505], ["aten::cudnn_convolution_backward", 32433], ["aten::cudnn_convolution_backward_weight", 31750], ["aten::cudnn_convolution_backward", 31611], ["aten::cudnn_convolution_backward", 29807], ["aten::cudnn_convolution_backward", 28850], ["CudnnConvolutionBackward", 28850], ["aten::cudnn_convolution_backward_input", 28772], ["aten::cudnn_convolution_backward", 28274], ["aten::cudnn_convolution_backward_input", 28028], ["aten::cudnn_convolution_backward_input", 26007], ["aten::cudnn_convolution_backward_input", 25825], ["aten::cudnn_convolution_backward", 24769], ["aten::cudnn_convolution_backward", 24193], ["aten::cudnn_convolution_backward", 23912], ["aten::cudnn_convolution_backward", 23882], ["aten::cudnn_convolution_backward", 23638], ["CudnnConvolutionBackward", 23638], ["aten::cudnn_convolution", 23302], ["aten::_convolution", 23302], ["aten::convolution", 23302], ["aten::conv2d", 23302], ["aten::cudnn_convolution_backward", 23189], ["aten::cudnn_convolution_backward_weight", 21839], ["aten::cudnn_convolution_backward_weight", 21809], ["aten::cudnn_convolution_backward", 21704], ["CudnnConvolutionBackward", 21704], ["aten::cudnn_convolution_backward", 21061], ["aten::cudnn_convolution_backward", 20894], ["aten::cudnn_batch_norm_backward", 20666], ["CudnnBatchNormBackward", 20666], ["aten::cudnn_convolution_backward_input", 20659], ["aten::cudnn_convolution", 20393], ["aten::_convolution", 20393], ["aten::convolution", 20393], ["aten::conv2d", 20393], ["aten::cudnn_convolution", 20275], ["aten::_convolution", 20275], ["aten::convolution", 20275], ["aten::conv2d", 20275], ["aten::cudnn_convolution_backward_input", 20053], ["aten::cudnn_convolution_backward", 19457], ["aten::cudnn_convolution_backward", 19300], ["aten::cudnn_convolution_backward_weight", 18522], ["aten::cudnn_convolution_backward_weight", 18515], ["aten::cudnn_convolution", 18174], ["aten::_convolution", 18174], ["aten::convolution", 18174], ["aten::conv2d", 18174], ["aten::cudnn_convolution", 17502], ["aten::_convolution", 17502], ["aten::convolution", 17502], ["aten::conv2d", 17502], ["aten::cudnn_convolution", 16978], ["aten::_convolution", 16978], ["aten::convolution", 16978], ["aten::conv2d", 16978], ["aten::cudnn_convolution_backward_weight", 16624], ["aten::cudnn_convolution", 15955], ["aten::_convolution", 15955], ["aten::convolution", 15955], ["aten::conv2d", 15955], ["aten::cudnn_convolution_backward_weight", 15701], ["aten::cudnn_convolution", 15700], ["aten::_convolution", 15700], ["aten::convolution", 15700], ["aten::conv2d", 15700], ["aten::cudnn_convolution", 15638], ["aten::_convolution", 15638], ["aten::convolution", 15638], ["aten::conv2d", 15638], ["aten::cudnn_convolution_backward_input", 15494], ["aten::cudnn_convolution_backward_weight", 15452], ["aten::cudnn_convolution_backward_weight", 15414], ["aten::cudnn_convolution", 15313], ["aten::_convolution", 15313], ["aten::convolution", 15313], ["aten::conv2d", 15313], ["aten::cudnn_convolution", 15023], ["aten::_convolution", 15023], ["aten::convolution", 15023], ["aten::conv2d", 15023], ["aten::cudnn_convolution_backward_input", 14987], ["aten::cudnn_convolution_backward_input", 14666], ["aten::cudnn_convolution_backward_input", 14564], ["aten::cudnn_convolution", 14405], ["aten::_convolution", 14405], ["aten::convolution", 14405], ["aten::conv2d", 14405], ["aten::cudnn_convolution", 14352], ["aten::_convolution", 14352], ["aten::convolution", 14352], ["aten::conv2d", 14352], ["aten::copy_", 13482], ["aten::to", 13482], ["aten::cudnn_convolution_backward_input", 13436], ["aten::cudnn_convolution", 13315], ["aten::_convolution", 13315], ["aten::convolution", 13315], ["aten::conv2d", 13315], ["aten::cudnn_batch_norm_backward", 13306], ["CudnnBatchNormBackward", 13306], ["aten::cudnn_convolution_backward_weight", 13189], ["aten::cudnn_convolution_backward_input", 12956], ["aten::cudnn_batch_norm", 12820], ["aten::_batch_norm_impl_index", 12820], ["aten::batch_norm", 12820], ["aten::cudnn_convolution_backward_weight", 12780], ["aten::cudnn_convolution_backward_weight", 12655], ["aten::cudnn_convolution_backward", 12655], ["CudnnConvolutionBackward", 12655], ["aten::cudnn_convolution_backward_weight", 12651], ["aten::cudnn_convolution", 12624], ["aten::_convolution", 12624], ["aten::convolution", 12624], ["aten::conv2d", 12624], ["aten::cudnn_convolution", 11702], ["aten::_convolution", 11702], ["aten::convolution", 11702], ["aten::conv2d", 11702], ["aten::cudnn_convolution_backward_weight", 11629], ["aten::cudnn_convolution_backward_input", 11616], ["aten::cudnn_convolution_backward_input", 11285], ["aten::cudnn_convolution", 11226], ["aten::_convolution", 11226], ["aten::convolution", 11226], ["aten::conv2d", 11226], ["aten::cudnn_convolution_backward_input", 11007], ["aten::cudnn_convolution_backward_input", 10747], ["aten::cudnn_convolution_backward_input", 10693], ["aten::cudnn_convolution_backward_weight", 10682], ["aten::cudnn_convolution", 10661], ["aten::_convolution", 10661], ["aten::convolution", 10661], ["aten::conv2d", 10661], ["aten::cudnn_convolution_backward_weight", 10545], ["aten::cudnn_batch_norm_backward", 10178], ["CudnnBatchNormBackward", 10178], ["aten::cudnn_batch_norm_backward", 10113], ["CudnnBatchNormBackward", 10113], ["aten::cudnn_convolution_backward_input", 10075], ["aten::cudnn_convolution_backward_weight", 10054], ["aten::cudnn_convolution", 9767], ["aten::_convolution", 9767], ["aten::convolution", 9767], ["aten::conv2d", 9767], ["aten::cudnn_convolution_backward_weight", 9645], ["aten::cudnn_convolution_backward_weight", 9278], ["aten::cudnn_convolution", 9195], ["aten::_convolution", 9195], ["aten::convolution", 9195], ["aten::conv2d", 9195], ["aten::cudnn_convolution", 8995], ["aten::_convolution", 8995], ["aten::convolution", 8995], ["aten::conv2d", 8995], ["aten::threshold_backward", 8811], ["ReluBackward1", 8811], ["aten::add_", 8742], ["aten::cudnn_convolution_backward_weight", 8553], ["aten::cudnn_convolution_backward_weight", 8443], ["aten::cudnn_batch_norm", 8352], ["aten::_batch_norm_impl_index", 8352], ["aten::batch_norm", 8352], ["aten::cudnn_convolution_backward_weight", 8161], ["aten::cudnn_convolution", 7426], ["aten::_convolution", 7426], ["aten::convolution", 7426], ["aten::conv2d", 7426], ["aten::cudnn_convolution_backward", 7093], ["aten::max_pool2d_with_indices_backward", 6824], ["MaxPool2DWithIndicesBackward", 6824], ["aten::cudnn_batch_norm_backward", 6524], ["CudnnBatchNormBackward", 6524], ["aten::threshold_", 6013], ["aten::relu_", 6013], ["aten::threshold_backward", 5951], ["ReluBackward1", 5951], ["aten::add_", 5906], ["aten::cudnn_batch_norm", 5326], ["aten::_batch_norm_impl_index", 5326], ["aten::batch_norm", 5326], ["aten::cudnn_batch_norm_backward", 5138], ["CudnnBatchNormBackward", 5138], ["aten::cudnn_batch_norm", 4740], ["aten::_batch_norm_impl_index", 4740], ["aten::batch_norm", 4740], ["aten::threshold_backward", 4613], ["ReluBackward1", 4613], ["aten::threshold_backward", 4422], ["ReluBackward1", 4422], ["aten::add_", 4413], ["aten::cudnn_batch_norm_backward", 4199], ["CudnnBatchNormBackward", 4199], ["aten::threshold_", 4051], ["aten::relu_", 4051], ["aten::cudnn_batch_norm", 3416], ["aten::_batch_norm_impl_index", 3416], ["aten::batch_norm", 3416], ["aten::threshold_", 3049], ["aten::relu_", 3049], ["aten::threshold_", 3028], ["aten::relu_", 3028], ["aten::threshold_backward", 2960], ["ReluBackward1", 2960], ["aten::cudnn_batch_norm", 2924], ["aten::_batch_norm_impl_index", 2924], ["aten::batch_norm", 2924], ["aten::cudnn_convolution", 2814], ["aten::_convolution", 2814], ["aten::convolution", 2814], ["aten::conv2d", 2814], ["aten::cudnn_batch_norm_backward", 2761], ["CudnnBatchNormBackward", 2761], ["aten::threshold_backward", 2737], ["ReluBackward1", 2737], ["aten::cudnn_convolution_backward_input", 2720], ["aten::threshold_backward", 2442], ["ReluBackward1", 2442], ["aten::cudnn_batch_norm_backward", 2355], ["CudnnBatchNormBackward", 2355], ["aten::add_", 2354], ["aten::cudnn_batch_norm", 1999], ["aten::_batch_norm_impl_index", 1999], ["aten::batch_norm", 1999], ["aten::threshold_", 1996], ["aten::relu_", 1996], ["aten::threshold_", 1852], ["aten::relu_", 1852], ["aten::cudnn_batch_norm", 1820], ["aten::_batch_norm_impl_index", 1820], ["aten::batch_norm", 1820], ["aten::max_pool2d_with_indices", 1783], ["aten::max_pool2d", 1783], ["aten::cudnn_batch_norm", 1593], ["aten::_batch_norm_impl_index", 1593], ["aten::batch_norm", 1593], ["aten::threshold_backward", 1475], ["ReluBackward1", 1475], ["aten::add_", 1443], ["aten::cudnn_batch_norm_backward", 1321], ["CudnnBatchNormBackward", 1321], ["aten::fill_", 1280], ["aten::zero_", 1280], ["aten::zeros_like", 1280], ["aten::threshold_backward", 1202], ["ReluBackward1", 1202], ["aten::add_", 1124], ["torch::autograd::AccumulateGrad", 1046], ["aten::threshold_", 1031], ["aten::relu_", 1031], ["aten::threshold_", 1006], ["aten::relu_", 1006], ["aten::add_", 979], ["aten::cudnn_batch_norm_backward", 917], ["CudnnBatchNormBackward", 917], ["aten::add_", 908], ["aten::add_", 908], ["torch::autograd::AccumulateGrad", 872], ["aten::add", 841], ["aten::cudnn_batch_norm", 828], ["aten::_batch_norm_impl_index", 828], ["aten::batch_norm", 828], ["aten::threshold_", 796], ["aten::relu_", 796], ["aten::threshold_backward", 757], ["ReluBackward1", 757], ["aten::cudnn_batch_norm_backward", 739], ["CudnnBatchNormBackward", 739], ["aten::add_", 730], ["aten::add_", 707], ["aten::add_", 674], ["torch::autograd::AccumulateGrad", 672], ["aten::add_", 645], ["aten::threshold_backward", 640], ["ReluBackward1", 640], ["aten::cudnn_batch_norm", 637], ["aten::_batch_norm_impl_index", 637], ["aten::batch_norm", 637], ["aten::add_", 635], ["aten::add_", 604], ["torch::autograd::AccumulateGrad", 514], ["aten::threshold_", 506], ["aten::relu_", 506], ["aten::mul_", 504], ["aten::add", 484], ["torch::autograd::AccumulateGrad", 474], ["aten::add_", 471], ["torch::autograd::AccumulateGrad", 459], ["aten::add", 455], ["aten::add_", 450], ["aten::copy_", 424], ["aten::copy_", 422], ["aten::threshold_backward", 410], ["ReluBackward1", 410], ["torch::autograd::AccumulateGrad", 408], ["aten::_cat", 394], ["aten::cat", 394], ["aten::add", 383], ["torch::autograd::AccumulateGrad", 381], ["AddmmBackward", 379], ["aten::cudnn_batch_norm", 370], ["aten::_batch_norm_impl_index", 370], ["aten::batch_norm", 370], ["aten::add_", 354], ["aten::mean", 345], ["aten::adaptive_avg_pool2d", 345], ["torch::autograd::AccumulateGrad", 323], ["aten::fill_", 315], ["aten::zero_", 315], ["torch::autograd::AccumulateGrad", 307], ["torch::autograd::AccumulateGrad", 301], ["aten::threshold_", 276], ["aten::relu_", 276], ["aten::add_", 276], ["aten::addmm", 272], ["aten::copy_", 270], ["torch::autograd::AccumulateGrad", 265], ["aten::add", 256], ["aten::add", 256], ["aten::mul_", 256], ["aten::add", 249], ["aten::threshold_", 244], ["aten::relu_", 244], ["torch::autograd::AccumulateGrad", 244], ["aten::add", 240], ["torch::autograd::AccumulateGrad", 237], ["aten::mul_", 231], ["aten::div", 230], ["MeanBackward1", 230], ["aten::add", 226], ["aten::mm", 226], ["aten::mul_", 224], ["aten::copy_", 217], ["aten::add_", 197], ["aten::copy_", 196], ["aten::add", 176], ["aten::add", 175], ["aten::add_", 172], ["aten::copy_", 169], ["torch::autograd::AccumulateGrad", 169], ["aten::fill_", 168], ["aten::zero_", 168], ["aten::copy_", 161], ["aten::add_", 158], ["aten::mul_", 154], ["aten::mul_", 153], ["aten::mm", 153], ["aten::mul_", 149], ["aten::fill_", 147], ["aten::zero_", 147], ["aten::mul_", 147], ["aten::add_", 145], ["torch::autograd::AccumulateGrad", 142], ["aten::mul_", 138], ["aten::add_", 131], ["aten::add", 128], ["aten::add_", 123], ["torch::autograd::AccumulateGrad", 116], ["aten::add", 112], ["aten::add", 112], ["aten::mul_", 112], ["aten::mul_", 108], ["torch::autograd::AccumulateGrad", 106], ["aten::fill_", 98], ["aten::zero_", 98], ["aten::mul_", 98], ["aten::mul_", 98], ["torch::autograd::AccumulateGrad", 97], ["aten::fill_", 96], ["aten::zero_", 96], ["aten::copy_", 94], ["aten::fill_", 91], ["aten::zero_", 91], ["aten::fill_", 91], ["aten::zero_", 91], ["torch::autograd::AccumulateGrad", 89], ["aten::add_", 88], ["aten::add", 88], ["aten::fill_", 87], ["aten::zero_", 87], ["aten::_log_softmax_backward_data", 85], ["LogSoftmaxBackward", 85], ["aten::fill_", 84], ["aten::zero_", 84], ["aten::add_", 81], ["aten::_log_softmax", 80], ["aten::log_softmax", 80], ["aten::fill_", 76], ["aten::zero_", 76], ["aten::clone", 75], ["aten::copy_", 74], ["aten::add", 73], ["aten::add", 72], ["aten::fill_", 70], ["aten::zero_", 70], ["aten::copy_", 65], ["aten::add", 65], ["aten::add", 64], ["aten::add_", 63], ["torch::autograd::AccumulateGrad", 63], ["torch::autograd::AccumulateGrad", 61], ["aten::fill_", 57], ["aten::zero_", 57], ["aten::mul_", 56], ["aten::mul_", 56], ["aten::fill_", 55], ["aten::zero_", 55], ["aten::copy_", 54], ["aten::copy_", 54], ["torch::autograd::AccumulateGrad", 54], ["aten::add", 48], ["aten::copy_", 48], ["aten::copy_", 47], ["aten::add_", 45], ["aten::copy_", 45], ["aten::add_", 44], ["aten::add_", 43], ["aten::mul_", 38], ["aten::mul_", 38], ["torch::autograd::AccumulateGrad", 35], ["torch::autograd::AccumulateGrad", 35], ["aten::nll_loss_forward", 32], ["aten::nll_loss", 32], ["aten::add", 32], ["aten::clone", 32], ["torch::autograd::AccumulateGrad", 31], ["aten::clone", 30], ["torch::autograd::AccumulateGrad", 30], ["aten::fill_", 28], ["aten::zero_", 28], ["aten::fill_", 28], ["aten::zero_", 28], ["aten::fill_", 28], ["aten::zero_", 28], ["aten::fill_", 28], ["aten::zero_", 28], ["aten::fill_", 28], ["aten::zero_", 28], ["aten::mul_", 28], ["aten::mul_", 28], ["aten::copy_", 25], ["aten::to", 25], ["aten::add", 24], ["aten::add", 24], ["aten::nll_loss_backward", 24], ["NllLossBackward", 24], ["aten::clone", 23], ["aten::clone", 23], ["aten::clone", 22], ["aten::add", 22], ["aten::add_", 22], ["aten::copy_", 21], ["aten::fill_", 21], ["aten::zero_", 21], ["aten::fill_", 21], ["aten::zero_", 21], ["aten::mul_", 21], ["aten::mul_", 21], ["aten::clone", 20], ["aten::clone", 20], ["aten::fill_", 20], ["aten::zero_", 20], ["aten::add", 16], ["aten::clone", 16], ["aten::clone", 14], ["aten::clone", 14], ["aten::fill_", 14], ["aten::zero_", 14], ["aten::mul_", 14], ["aten::mul_", 14], ["aten::mul_", 14], ["aten::_local_scalar_dense", 13], ["aten::item", 13], ["aten::clone", 13], ["aten::copy_", 11], ["aten::clone", 10], ["aten::copy_", 10], ["aten::copy_", 9], ["aten::copy_", 9], ["aten::add", 9], ["aten::fill_", 8], ["aten::ones_like", 8], ["aten::add", 8], ["aten::add", 8], ["aten::copy_", 8], ["aten::add", 8], ["aten::clone", 8], ["aten::clone", 8], ["torch::autograd::AccumulateGrad", 8], ["aten::copy_", 7], ["aten::fill_", 7], ["aten::zero_", 7], ["aten::fill_", 7], ["aten::zero_", 7], ["aten::fill_", 7], ["aten::zero_", 7], ["aten::fill_", 7], ["aten::zero_", 7], ["aten::fill_", 7], ["aten::zero_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::copy_", 6], ["aten::copy_", 5], ["aten::copy_", 5], ["aten::clone", 4], ["aten::clone", 4], ["aten::copy_", 3], ["aten::clone", 3], ["aten::copy_", 3], ["aten::clone", 3], ["aten::clone", 3], ["aten::clone", 3], ["aten::copy_", 3], ["aten::copy_", 3], ["aten::copy_", 2], ["aten::clone", 2], ["aten::clone", 2], ["aten::copy_", 2], ["aten::clone", 1], ["aten::clone", 1], ["aten::clone", 1], ["aten::clone", 1], ["aten::clone", 1], ["aten::fill_", 1], ["aten::zero_", 1]]}, "device_self_time": {"title": "Device Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward_weight", 31750], ["aten::cudnn_convolution_backward_input", 28772], ["aten::cudnn_convolution_backward_input", 28028], ["aten::cudnn_convolution_backward_input", 26007], ["aten::cudnn_convolution_backward_input", 25825], ["aten::cudnn_convolution", 23302], ["aten::cudnn_convolution_backward_weight", 21839], ["aten::cudnn_convolution_backward_weight", 21809], ["aten::cudnn_batch_norm_backward", 20666], ["aten::cudnn_convolution_backward_input", 20659], ["aten::cudnn_convolution", 20393], ["aten::cudnn_convolution", 20275], ["aten::cudnn_convolution_backward_input", 20053], ["aten::cudnn_convolution_backward_weight", 18522], ["aten::cudnn_convolution_backward_weight", 18515], ["aten::cudnn_convolution", 18174], ["aten::cudnn_convolution", 17502], ["aten::cudnn_convolution", 16978], ["aten::cudnn_convolution_backward_weight", 16624], ["aten::cudnn_convolution", 15955], ["aten::cudnn_convolution_backward_weight", 15701], ["aten::cudnn_convolution", 15700], ["aten::cudnn_convolution", 15638], ["aten::cudnn_convolution_backward_input", 15494], ["aten::cudnn_convolution_backward_weight", 15452], ["aten::cudnn_convolution_backward_weight", 15414], ["aten::cudnn_convolution", 15313], ["aten::cudnn_convolution", 15023], ["aten::cudnn_convolution_backward_input", 14987], ["aten::cudnn_convolution_backward_input", 14666], ["aten::cudnn_convolution_backward_input", 14564], ["aten::cudnn_convolution", 14405], ["aten::cudnn_convolution", 14352], ["aten::copy_", 13482], ["aten::cudnn_convolution_backward_input", 13436], ["aten::cudnn_convolution", 13315], ["aten::cudnn_batch_norm_backward", 13306], ["aten::cudnn_convolution_backward_weight", 13189], ["aten::cudnn_convolution_backward_input", 12956], ["aten::cudnn_batch_norm", 12820], ["aten::cudnn_convolution_backward_weight", 12780], ["aten::cudnn_convolution_backward_weight", 12655], ["aten::cudnn_convolution_backward_weight", 12651], ["aten::cudnn_convolution", 12624], ["aten::cudnn_convolution", 11702], ["aten::cudnn_convolution_backward_weight", 11629], ["aten::cudnn_convolution_backward_input", 11616], ["aten::cudnn_convolution_backward_input", 11285], ["aten::cudnn_convolution", 11226], ["aten::cudnn_convolution_backward_input", 11007], ["aten::cudnn_convolution_backward_input", 10747], ["aten::cudnn_convolution_backward_input", 10693], ["aten::cudnn_convolution_backward_weight", 10682], ["aten::cudnn_convolution", 10661], ["aten::cudnn_convolution_backward_weight", 10545], ["aten::cudnn_batch_norm_backward", 10178], ["aten::cudnn_batch_norm_backward", 10113], ["aten::cudnn_convolution_backward_input", 10075], ["aten::cudnn_convolution_backward_weight", 10054], ["aten::cudnn_convolution", 9767], ["aten::cudnn_convolution_backward_weight", 9645], ["aten::cudnn_convolution_backward_weight", 9278], ["aten::cudnn_convolution", 9195], ["aten::cudnn_convolution", 8995], ["aten::threshold_backward", 8811], ["aten::add_", 8742], ["aten::cudnn_convolution_backward_weight", 8553], ["aten::cudnn_convolution_backward_weight", 8443], ["aten::cudnn_batch_norm", 8352], ["aten::cudnn_convolution_backward_weight", 8161], ["aten::cudnn_convolution", 7426], ["aten::cudnn_batch_norm_backward", 6524], ["aten::threshold_", 6013], ["aten::threshold_backward", 5951], ["aten::add_", 5906], ["aten::max_pool2d_with_indices_backward", 5544], ["aten::cudnn_batch_norm", 5326], ["aten::cudnn_batch_norm_backward", 5138], ["aten::cudnn_batch_norm", 4740], ["aten::threshold_backward", 4613], ["aten::threshold_backward", 4422], ["aten::add_", 4413], ["aten::cudnn_batch_norm_backward", 4199], ["aten::threshold_", 4051], ["aten::cudnn_batch_norm", 3416], ["aten::threshold_", 3049], ["aten::threshold_", 3028], ["aten::threshold_backward", 2960], ["aten::cudnn_batch_norm", 2924], ["aten::cudnn_convolution", 2814], ["aten::cudnn_batch_norm_backward", 2761], ["aten::threshold_backward", 2737], ["aten::cudnn_convolution_backward_input", 2720], ["aten::threshold_backward", 2442], ["aten::cudnn_batch_norm_backward", 2355], ["aten::add_", 2354], ["aten::cudnn_batch_norm", 1999], ["aten::threshold_", 1996], ["aten::threshold_", 1852], ["aten::cudnn_batch_norm", 1820], ["aten::max_pool2d_with_indices", 1783], ["aten::cudnn_batch_norm", 1593], ["aten::threshold_backward", 1475], ["aten::add_", 1443], ["aten::cudnn_batch_norm_backward", 1321], ["aten::fill_", 1280], ["aten::threshold_backward", 1202], ["aten::add_", 1124], ["aten::threshold_", 1031], ["aten::threshold_", 1006], ["aten::add_", 979], ["aten::cudnn_batch_norm_backward", 917], ["aten::add_", 908], ["aten::add_", 908], ["aten::add", 841], ["aten::cudnn_batch_norm", 828], ["aten::threshold_", 796], ["aten::threshold_backward", 757], ["aten::cudnn_batch_norm_backward", 739], ["aten::add_", 730], ["aten::add_", 707], ["aten::add_", 674], ["aten::add_", 645], ["aten::threshold_backward", 640], ["aten::cudnn_batch_norm", 637], ["aten::add_", 635], ["aten::add_", 604], ["aten::threshold_", 506], ["aten::mul_", 504], ["aten::add", 484], ["aten::add_", 471], ["aten::add", 455], ["aten::add_", 450], ["aten::copy_", 424], ["aten::copy_", 422], ["aten::threshold_backward", 410], ["aten::_cat", 394], ["aten::add", 383], ["aten::cudnn_batch_norm", 370], ["aten::add_", 354], ["aten::mean", 345], ["aten::fill_", 315], ["aten::threshold_", 276], ["aten::add_", 276], ["aten::addmm", 272], ["aten::copy_", 270], ["aten::add", 256], ["aten::add", 256], ["aten::mul_", 256], ["aten::add", 249], ["aten::threshold_", 244], ["aten::add", 240], ["aten::mul_", 231], ["aten::div", 230], ["aten::add", 226], ["aten::mm", 226], ["aten::mul_", 224], ["aten::copy_", 217], ["aten::add_", 197], ["aten::copy_", 196], ["aten::add", 176], ["aten::add", 175], ["aten::add_", 172], ["aten::copy_", 169], ["aten::fill_", 168], ["aten::copy_", 161], ["aten::add_", 158], ["aten::mul_", 154], ["aten::mul_", 153], ["aten::mm", 153], ["aten::mul_", 149], ["aten::fill_", 147], ["aten::mul_", 147], ["aten::add_", 145], ["aten::mul_", 138], ["aten::add_", 131], ["aten::add", 128], ["aten::add_", 123], ["aten::add", 112], ["aten::add", 112], ["aten::mul_", 112], ["aten::mul_", 108], ["aten::fill_", 98], ["aten::mul_", 98], ["aten::mul_", 98], ["aten::fill_", 96], ["aten::copy_", 94], ["aten::fill_", 91], ["aten::fill_", 91], ["aten::add_", 88], ["aten::add", 88], ["aten::fill_", 87], ["aten::_log_softmax_backward_data", 85], ["aten::fill_", 84], ["aten::add_", 81], ["aten::_log_softmax", 80], ["aten::fill_", 76], ["aten::copy_", 74], ["aten::add", 73], ["aten::add", 72], ["aten::fill_", 70], ["aten::copy_", 65], ["aten::add", 65], ["aten::add", 64], ["aten::add_", 63], ["aten::fill_", 57], ["aten::mul_", 56], ["aten::mul_", 56], ["aten::fill_", 55], ["aten::copy_", 54], ["aten::copy_", 54], ["aten::add", 48], ["aten::copy_", 48], ["aten::copy_", 47], ["aten::add_", 45], ["aten::copy_", 45], ["aten::add_", 44], ["aten::add_", 43], ["aten::mul_", 38], ["aten::mul_", 38], ["aten::nll_loss_forward", 32], ["aten::add", 32], ["aten::fill_", 28], ["aten::fill_", 28], ["aten::fill_", 28], ["aten::fill_", 28], ["aten::fill_", 28], ["aten::mul_", 28], ["aten::mul_", 28], ["aten::copy_", 25], ["aten::add", 24], ["aten::add", 24], ["aten::nll_loss_backward", 24], ["aten::add", 22], ["aten::add_", 22], ["aten::copy_", 21], ["aten::fill_", 21], ["aten::fill_", 21], ["aten::mul_", 21], ["aten::mul_", 21], ["aten::fill_", 20], ["aten::add", 16], ["aten::fill_", 14], ["aten::mul_", 14], ["aten::mul_", 14], ["aten::mul_", 14], ["aten::_local_scalar_dense", 13], ["aten::copy_", 11], ["aten::copy_", 10], ["aten::copy_", 9], ["aten::copy_", 9], ["aten::add", 9], ["aten::fill_", 8], ["aten::add", 8], ["aten::add", 8], ["aten::copy_", 8], ["aten::add", 8], ["aten::copy_", 7], ["aten::fill_", 7], ["aten::fill_", 7], ["aten::fill_", 7], ["aten::fill_", 7], ["aten::fill_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::copy_", 6], ["aten::copy_", 5], ["aten::copy_", 5], ["aten::copy_", 3], ["aten::copy_", 3], ["aten::copy_", 3], ["aten::copy_", 3], ["aten::copy_", 2], ["aten::copy_", 2], ["aten::fill_", 1]]}, "host_total_time": {"title": "Host Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 4279740], ["aten::cat", 4222769], ["aten::_cat", 4219527], ["aten::conv2d", 2356890], ["aten::convolution", 2356441], ["aten::_convolution", 2356063], ["aten::cudnn_convolution", 2355109], ["aten::to", 2058888], ["aten::contiguous", 1252772], ["aten::div_", 1152229], ["aten::div", 1077151], ["aten::stack", 1076465], ["aten::clone", 1075822], ["aten::sub_", 947087], ["aten::addmm", 859710], ["CudnnConvolutionBackward", 504288], ["aten::empty", 458342], ["aten::cudnn_convolution_backward", 336556], ["aten::cudnn_convolution_backward_weight", 308289], ["aten::empty_strided", 306944], ["CudnnConvolutionBackward", 189777], ["aten::cudnn_convolution_backward", 187161], ["CudnnConvolutionBackward", 170373], ["aten::conv2d", 164382], ["aten::cudnn_convolution_backward", 164374], ["aten::convolution", 162815], ["aten::_convolution", 161404], ["aten::cudnn_convolution", 158064], ["aten::cudnn_convolution_backward_input", 157307], ["CudnnConvolutionBackward", 151610], ["aten::cudnn_convolution_backward_input", 147294], ["torch::autograd::AccumulateGrad", 137059], ["aten::conv2d", 136483], ["aten::convolution", 136091], ["aten::_convolution", 135749], ["aten::cudnn_convolution", 134937], ["aten::clone", 125826], ["CudnnConvolutionBackward", 112924], ["aten::pin_memory", 112348], ["CudnnConvolutionBackward", 105296], ["aten::lt", 102158], ["aten::to", 101676], ["aten::eq", 101299], ["CudnnConvolutionBackward", 98428], ["aten::narrow", 95046], ["aten::copy_", 93752], ["aten::cudnn_convolution_backward", 88796], ["aten::conv2d", 85676], ["aten::convolution", 83421], ["aten::batch_norm", 82901], ["aten::_convolution", 81594], ["aten::_batch_norm_impl_index", 78694], ["aten::batch_norm", 78524], ["aten::_batch_norm_impl_index", 78091], ["aten::cudnn_convolution", 77431], ["aten::cudnn_batch_norm", 76594], ["aten::add", 74141], ["aten::slice", 73482], ["CudnnConvolutionBackward", 73442], ["aten::eq", 73070], ["aten::item", 72995], ["aten::lt", 71476], ["aten::copy_", 70514], ["aten::cudnn_convolution_backward", 68971], ["aten::select", 68904], ["aten::exp", 68577], ["aten::add_", 65336], ["aten::randint", 65058], ["aten::cudnn_convolution_backward", 64794], ["aten::item", 64773], ["aten::cudnn_convolution_backward_weight", 63084], ["aten::cudnn_batch_norm", 62024], ["aten::any", 60951], ["CudnnBatchNormBackward", 59256], ["aten::batch_norm", 59050], ["aten::cudnn_convolution_backward", 58960], ["aten::uniform_", 56898], ["aten::_batch_norm_impl_index", 56393], ["aten::batch_norm", 53776], ["aten::_batch_norm_impl_index", 51070], ["aten::cudnn_convolution_backward", 49358], ["aten::cudnn_convolution_backward", 49218], ["aten::add_", 48134], ["aten::cudnn_convolution_backward", 46563], ["aten::cudnn_batch_norm", 46414], ["aten::cudnn_batch_norm_backward", 46071], ["aten::conv2d", 45811], ["aten::batch_norm", 45407], ["aten::narrow", 45236], ["aten::_local_scalar_dense", 43799], ["aten::add", 43701], ["aten::cudnn_convolution_backward", 43450], ["aten::convolution", 43421], ["aten::cudnn_convolution_backward", 43227], ["aten::_batch_norm_impl_index", 43099], ["CudnnConvolutionBackward", 41824], ["aten::_convolution", 41393], ["aten::cudnn_convolution_backward", 41143], ["aten::cudnn_batch_norm", 41129], ["aten::log", 40627], ["aten::cudnn_convolution_backward_input", 39723], ["aten::conv2d", 39310], ["aten::conv2d", 38585], ["aten::batch_norm", 38122], ["aten::cudnn_convolution_backward_input", 37721], ["aten::convolution", 37546], ["aten::batch_norm", 37369], ["aten::conv2d", 36730], ["CudnnBatchNormBackward", 36639], ["aten::convolution", 36587], ["CudnnBatchNormBackward", 36397], ["aten::cudnn_convolution", 36359], ["aten::cudnn_convolution_backward", 36318], ["torch::autograd::AccumulateGrad", 36313], ["aten::_batch_norm_impl_index", 36220], ["aten::_convolution", 35987], ["aten::convolution", 35536], ["aten::_batch_norm_impl_index", 35460], ["aten::view", 35240], ["aten::_convolution", 34808], ["aten::_convolution", 34518], ["aten::cudnn_batch_norm", 34227], ["aten::view", 34092], ["aten::slice", 33600], ["aten::batch_norm", 33567], ["aten::add_", 33049], ["aten::rand", 32532], ["aten::cudnn_convolution", 32176], ["aten::cudnn_convolution", 32011], ["aten::_batch_norm_impl_index", 31785], ["aten::cudnn_convolution_backward_input", 31686], ["aten::_local_scalar_dense", 31540], ["aten::cudnn_convolution_backward_weight", 31370], ["CudnnBatchNormBackward", 31064], ["CudnnBatchNormBackward", 30941], ["aten::conv2d", 30690], ["aten::cudnn_convolution", 30610], ["aten::exp", 30460], ["aten::conv2d", 30274], ["CudnnConvolutionBackward", 30252], ["aten::add", 30126], ["aten::conv2d", 29964], ["aten::batch_norm", 29923], ["aten::cudnn_convolution_backward", 29584], ["aten::convolution", 29469], ["aten::convolution", 29452], ["aten::conv2d", 29316], ["aten::cudnn_batch_norm", 29268], ["aten::cudnn_batch_norm_backward", 29183], ["aten::cudnn_batch_norm_backward", 29034], ["aten::cudnn_convolution_backward_input", 28900], ["aten::add_", 28876], ["aten::add_", 28845], ["CudnnConvolutionBackward", 28814], ["aten::_convolution", 28785], ["aten::convolution", 28749], ["aten::cudnn_convolution_backward", 28550], ["aten::cudnn_batch_norm", 28540], ["aten::_batch_norm_impl_index", 28406], ["aten::_convolution", 28404], ["aten::copy_", 28229], ["aten::cudnn_convolution_backward", 28161], ["aten::convolution", 28091], ["aten::cudnn_convolution_backward_weight", 27875], ["aten::conv2d", 27863], ["aten::copy_", 27847], ["torch::autograd::AccumulateGrad", 27711], ["aten::_convolution", 27706], ["aten::cudnn_convolution_backward_weight", 27662], ["aten::cudnn_convolution_backward_input", 27276], ["aten::cudnn_convolution", 27095], ["aten::convolution", 27046], ["aten::_convolution", 27011], ["aten::permute", 26484], ["aten::_convolution", 26310], ["CudnnBatchNormBackward", 26287], ["aten::cudnn_convolution", 25731], ["aten::cudnn_batch_norm", 25334], ["aten::cudnn_convolution", 25159], ["aten::zero_", 24926], ["aten::cudnn_batch_norm_backward", 24921], ["aten::cudnn_batch_norm_backward", 24896], ["aten::cudnn_convolution_backward", 24707], ["aten::cudnn_convolution_backward_input", 24693], ["aten::cudnn_convolution", 24603], ["aten::view", 24580], ["aten::cudnn_convolution", 24500], ["aten::cudnn_convolution_backward_weight", 24459], ["aten::conv2d", 24170], ["aten::resize_", 24049], ["aten::cudnn_convolution_backward_weight", 23952], ["aten::convolution", 23720], ["CudnnBatchNormBackward", 23564], ["aten::cudnn_convolution_backward_input", 23384], ["aten::_convolution", 23364], ["aten::mul_", 23316], ["aten::conv2d", 23202], ["aten::cudnn_convolution_backward_input", 23171], ["aten::view", 23021], ["aten::cudnn_batch_norm", 22595], ["aten::conv2d", 22542], ["aten::view", 22539], ["aten::cudnn_convolution", 22504], ["aten::convolution", 22318], ["aten::cudnn_convolution_backward_weight", 22289], ["aten::cudnn_convolution_backward_input", 22217], ["aten::convolution", 22146], ["aten::add", 21894], ["aten::_convolution", 21812], ["CudnnBatchNormBackward", 21729], ["aten::_convolution", 21589], ["aten::cudnn_convolution_backward", 21553], ["ReluBackward1", 21459], ["aten::cudnn_convolution_backward_input", 21340], ["aten::cudnn_convolution_backward_input", 21038], ["aten::cudnn_convolution", 20965], ["aten::cudnn_convolution_backward_weight", 20956], ["aten::cudnn_batch_norm_backward", 20947], ["aten::cudnn_convolution_backward", 20848], ["aten::conv2d", 20527], ["aten::cudnn_convolution_backward", 20523], ["aten::convolution", 20122], ["aten::add", 20017], ["aten::cudnn_convolution", 19919], ["aten::_convolution", 19769], ["aten::add", 19491], ["aten::copy_", 19241], ["aten::cudnn_batch_norm_backward", 19182], ["aten::add_", 19021], ["aten::cudnn_convolution", 18944], ["aten::is_nonzero", 18580], ["aten::cudnn_convolution_backward", 18421], ["aten::set_", 18337], ["aten::cudnn_convolution_backward_weight", 18281], ["torch::autograd::AccumulateGrad", 18047], ["aten::conv2d", 18001], ["aten::view", 17870], ["aten::convolution", 17607], ["aten::cudnn_batch_norm_backward", 17570], ["aten::cudnn_convolution_backward_weight", 17320], ["aten::is_nonzero", 17311], ["aten::mul_", 17275], ["aten::_convolution", 17269], ["aten::cudnn_convolution_backward_input", 16929], ["aten::view", 16842], ["aten::zero_", 16758], ["aten::cudnn_convolution_backward_weight", 16489], ["torch::autograd::AccumulateGrad", 16474], ["aten::cudnn_convolution_backward_weight", 16439], ["aten::cudnn_convolution", 16386], ["aten::empty_like", 16336], ["CudnnConvolutionBackward", 16250], ["aten::cudnn_convolution_backward_input", 15954], ["aten::threshold_backward", 15934], ["torch::autograd::AccumulateGrad", 15880], ["aten::relu_", 15840], ["aten::random_", 15826], ["aten::cudnn_convolution_backward_weight", 15589], ["aten::view", 15066], ["aten::cudnn_convolution_backward_input", 14830], ["aten::cudnn_convolution_backward", 14779], ["aten::view", 14455], ["aten::conv2d", 14350], ["aten::copy_", 14137], ["aten::conv2d", 14066], ["aten::convolution", 13935], ["aten::convolution", 13635], ["aten::_convolution", 13579], ["ReluBackward1", 13371], ["aten::_convolution", 13261], ["aten::is_floating_point", 13051], ["aten::copy_", 12977], ["aten::conv2d", 12920], ["aten::cudnn_convolution_backward_weight", 12807], ["aten::cudnn_convolution", 12681], ["aten::convolution", 12490], ["aten::cudnn_convolution_backward_weight", 12377], ["aten::cudnn_convolution", 12308], ["aten::add_", 12303], ["aten::add_", 12264], ["aten::mul_", 12235], ["aten::copy_", 12222], ["aten::zero_", 12195], ["aten::cudnn_convolution_backward_weight", 12181], ["aten::_convolution", 12147], ["ReluBackward1", 12073], ["aten::cudnn_convolution_backward_weight", 11745], ["aten::cudnn_convolution_backward_weight", 11680], ["aten::unsqueeze", 11426], ["aten::add", 11400], ["aten::cudnn_convolution", 11330], ["aten::conv2d", 11271], ["aten::conv2d", 11216], ["ReluBackward1", 11186], ["aten::zero_", 11166], ["aten::detach_", 11140], ["aten::fill_", 11134], ["aten::mul_", 11041], ["aten::convolution", 10875], ["aten::mul_", 10870], ["ReluBackward1", 10863], ["aten::convolution", 10812], ["aten::zero_", 10713], ["aten::_convolution", 10542], ["aten::as_strided", 10502], ["aten::_convolution", 10476], ["aten::cudnn_convolution_backward_input", 10457], ["aten::cudnn_convolution_backward_input", 10447], ["aten::add_", 10288], ["aten::relu_", 10185], ["aten::as_strided", 9919], ["aten::threshold_backward", 9839], ["aten::cudnn_convolution", 9681], ["aten::cudnn_convolution", 9574], ["torch::autograd::AccumulateGrad", 9347], ["aten::contiguous", 9261], ["aten::cudnn_convolution_backward_weight", 9210], ["aten::contiguous", 9144], ["aten::threshold_backward", 9085], ["AddmmBackward", 9007], ["aten::to", 8976], ["aten::relu_", 8968], ["aten::cudnn_convolution_backward_weight", 8956], ["aten::cudnn_convolution_backward_weight", 8950], ["aten::cudnn_convolution_backward_input", 8888], ["aten::relu_", 8510], ["aten::add_", 8447], ["aten::add", 8367], ["aten::view", 8356], ["aten::add", 8330], ["aten::add_", 8296], ["aten::threshold_backward", 8280], ["aten::threshold_backward", 8256], ["aten::add_", 8200], ["aten::empty_like", 7895], ["ReluBackward1", 7682], ["aten::batch_norm", 7598], ["aten::batch_norm", 7463], ["aten::fill_", 7313], ["aten::batch_norm", 7292], ["aten::clone", 7220], ["aten::_batch_norm_impl_index", 7206], ["aten::relu_", 7118], ["aten::add_", 7102], ["aten::_batch_norm_impl_index", 7089], ["aten::add", 6947], ["torch::autograd::AccumulateGrad", 6911], ["aten::copy_", 6905], ["aten::_batch_norm_impl_index", 6895], ["aten::stride", 6696], ["aten::add_", 6386], ["aten::add_", 6315], ["aten::zero_", 6232], ["aten::contiguous", 6147], ["aten::add_", 6128], ["aten::empty_like", 6109], ["aten::add_", 6069], ["aten::mul_", 5924], ["aten::contiguous", 5915], ["aten::contiguous", 5915], ["aten::contiguous", 5907], ["torch::autograd::AccumulateGrad", 5841], ["aten::cudnn_batch_norm", 5817], ["aten::add", 5774], ["aten::contiguous", 5765], ["ReluBackward1", 5763], ["aten::as_strided", 5750], ["torch::autograd::AccumulateGrad", 5749], ["aten::cudnn_batch_norm", 5708], ["ReluBackward1", 5659], ["aten::add", 5649], ["aten::relu_", 5616], ["aten::threshold_backward", 5609], ["aten::add", 5568], ["MaxPool2DWithIndicesBackward", 5564], ["aten::cudnn_batch_norm", 5517], ["aten::to", 5429], ["aten::zero_", 5425], ["aten::stride", 5422], ["aten::fill_", 5414], ["aten::adaptive_avg_pool2d", 5378], ["aten::threshold_", 5206], ["aten::empty_like", 5197], ["CudnnBatchNormBackward", 5162], ["CudnnBatchNormBackward", 5150], ["aten::max_pool2d", 5136], ["CudnnBatchNormBackward", 5130], ["CudnnBatchNormBackward", 5074], ["aten::add", 5009], ["aten::clone", 4993], ["aten::fill_", 4990], ["aten::mean", 4967], ["aten::add_", 4956], ["aten::max_pool2d_with_indices_backward", 4902], ["aten::fill_", 4808], ["aten::fill_", 4775], ["aten::zero_", 4736], ["aten::relu_", 4692], ["detach_", 4691], ["aten::max_pool2d_with_indices", 4686], ["torch::autograd::AccumulateGrad", 4589], ["aten::mul_", 4550], ["torch::autograd::AccumulateGrad", 4545], ["aten::empty_like", 4540], ["aten::zeros", 4527], ["aten::mul_", 4525], ["aten::contiguous", 4419], ["aten::empty_like", 4376], ["aten::as_strided", 4367], ["aten::add", 4364], ["aten::stride", 4326], ["aten::contiguous", 4316], ["aten::threshold_backward", 4309], ["aten::add_", 4271], ["aten::stride", 4261], ["aten::contiguous", 4260], ["aten::add", 4259], ["aten::threshold_backward", 4225], ["aten::as_strided", 4223], ["aten::relu_", 4185], ["aten::add", 4145], ["aten::cudnn_batch_norm_backward", 4135], ["aten::cudnn_batch_norm_backward", 4130], ["aten::cudnn_batch_norm_backward", 4064], ["aten::cudnn_batch_norm_backward", 4041], ["aten::add_", 4021], ["torch::autograd::AccumulateGrad", 3994], ["MeanBackward1", 3989], ["aten::contiguous", 3925], ["aten::as_strided", 3920], ["aten::zero_", 3904], ["aten::clone", 3897], ["aten::resize_", 3892], ["aten::contiguous", 3853], ["aten::mul_", 3804], ["torch::autograd::AccumulateGrad", 3751], ["aten::add_", 3681], ["aten::clone", 3594], ["aten::empty_like", 3591], ["torch::autograd::AccumulateGrad", 3443], ["torch::autograd::AccumulateGrad", 3416], ["aten::contiguous", 3323], ["aten::threshold_", 3318], ["aten::add_", 3231], ["aten::empty_like", 3227], ["aten::clone", 3215], ["aten::stride", 3181], ["aten::as_strided", 3156], ["aten::stride", 3140], ["aten::mul_", 3131], ["aten::pin_memory", 3115], ["aten::mul_", 3052], ["aten::zero_", 3039], ["aten::log_softmax", 3021], ["aten::empty_like", 3014], ["aten::zero_", 3006], ["aten::zero_", 3005], ["aten::mul_", 3003], ["aten::contiguous", 2989], ["aten::threshold_", 2952], ["aten::as_strided", 2832], ["aten::add", 2827], ["aten::mm", 2805], ["aten::to", 2782], ["aten::add", 2743], ["aten::threshold_", 2742], ["aten::fill_", 2724], ["torch::autograd::AccumulateGrad", 2658], ["aten::_log_softmax", 2626], ["LogSoftmaxBackward", 2567], ["aten::mul_", 2479], ["aten::contiguous", 2450], ["aten::stride", 2430], ["aten::threshold_", 2353], ["aten::mul_", 2330], ["aten::div", 2319], ["aten::add_", 2297], ["aten::zero_", 2294], ["aten::add_", 2289], ["aten::zero_", 2288], ["aten::zero_", 2287], ["aten::resize_", 2267], ["aten::zero_", 2267], ["aten::mul_", 2258], ["aten::nll_loss", 2257], ["aten::stride", 2251], ["aten::mul_", 2248], ["torch::autograd::AccumulateGrad", 2247], ["aten::resize_", 2246], ["aten::resize_", 2246], ["aten::add_", 2242], ["aten::add_", 2172], ["NllLossBackward", 2134], ["aten::fill_", 2130], ["aten::fill_", 2105], ["aten::add_", 2070], ["aten::t", 2058], ["aten::add_", 2058], ["aten::add_", 2053], ["aten::_log_softmax_backward_data", 2042], ["aten::add_", 2037], ["aten::add_", 2006], ["aten::add_", 2001], ["ReluBackward1", 1922], ["ReluBackward1", 1913], ["aten::nll_loss_forward", 1884], ["ReluBackward1", 1879], ["aten::mm", 1871], ["ReluBackward1", 1856], ["aten::clone", 1846], ["aten::threshold_", 1823], ["aten::to", 1773], ["aten::zeros_like", 1767], ["aten::ones_like", 1755], ["aten::relu_", 1720], ["aten::fill_", 1715], ["aten::resize_", 1708], ["aten::resize_", 1683], ["aten::t", 1674], ["aten::add", 1664], ["aten::zero_", 1599], ["aten::add", 1563], ["torch::autograd::AccumulateGrad", 1559], ["aten::zero_", 1556], ["aten::flatten", 1540], ["aten::relu_", 1539], ["aten::add", 1537], ["aten::mul_", 1533], ["aten::threshold_", 1514], ["aten::add", 1512], ["aten::zero_", 1507], ["aten::mul_", 1503], ["aten::relu_", 1483], ["aten::contiguous", 1470], ["aten::copy_", 1465], ["aten::add", 1448], ["aten::threshold_backward", 1426], ["aten::relu_", 1416], ["aten::threshold_backward", 1409], ["aten::nll_loss_backward", 1406], ["aten::add", 1401], ["aten::threshold_backward", 1394], ["aten::add", 1390], ["aten::add", 1389], ["aten::empty_like", 1384], ["aten::add", 1382], ["aten::threshold_backward", 1379], ["aten::empty_like", 1375], ["aten::clone", 1370], ["aten::add", 1363], ["aten::contiguous", 1349], ["aten::fill_", 1347], ["aten::threshold_", 1338], ["aten::clone", 1328], ["aten::fill_", 1316], ["aten::stride", 1314], ["aten::fill_", 1314], ["aten::stride", 1308], ["aten::resize_", 1284], ["torch::autograd::AccumulateGrad", 1257], ["torch::autograd::AccumulateGrad", 1233], ["torch::autograd::AccumulateGrad", 1219], ["torch::autograd::AccumulateGrad", 1182], ["torch::autograd::AccumulateGrad", 1176], ["AddBackward0", 1174], ["aten::resize_", 1170], ["aten::mul_", 1163], ["torch::autograd::AccumulateGrad", 1157], ["aten::detach", 1156], ["aten::clone", 1150], ["aten::reshape", 1141], ["torch::autograd::AccumulateGrad", 1141], ["torch::autograd::AccumulateGrad", 1138], ["aten::clone", 1124], ["torch::autograd::AccumulateGrad", 1124], ["TBackward", 1123], ["aten::contiguous", 1118], ["aten::resize_", 1110], ["ViewBackward", 1068], ["aten::resize_", 1059], ["aten::copy_", 1058], ["aten::copy_", 1014], ["aten::fill_", 1003], ["aten::resize_", 1002], ["aten::fill_", 990], ["aten::fill_", 981], ["aten::fill_", 976], ["aten::contiguous", 974], ["aten::clone", 963], ["aten::mul_", 936], ["aten::set_", 934], ["aten::resize_", 922], ["aten::clone", 922], ["aten::contiguous", 919], ["aten::empty_like", 918], ["aten::contiguous", 909], ["aten::zero_", 907], ["aten::t", 892], ["aten::stride", 890], ["aten::view", 884], ["aten::copy_", 877], ["aten::mul_", 873], ["aten::contiguous", 866], ["aten::expand", 863], ["aten::contiguous", 860], ["aten::zero_", 859], ["AddBackward0", 859], ["aten::mul_", 848], ["aten::as_strided", 845], ["aten::mul_", 841], ["aten::contiguous", 838], ["aten::zero_", 830], ["aten::contiguous", 829], ["aten::contiguous", 828], ["aten::detach", 824], ["aten::transpose", 820], ["aten::mul_", 808], ["aten::transpose", 798], ["aten::mul_", 796], ["aten::zero_", 787], ["aten::resize_", 786], ["aten::empty_like", 784], ["aten::zero_", 776], ["aten::resize_", 770], ["aten::zero_", 768], ["aten::zero_", 764], ["aten::zero_", 763], ["aten::mul_", 755], ["aten::zero_", 754], ["aten::mul_", 754], ["aten::is_pinned", 753], ["aten::reshape", 751], ["aten::zero_", 747], ["aten::mul_", 746], ["aten::resize_", 737], ["aten::zero_", 735], ["aten::empty_like", 731], ["aten::copy_", 726], ["AddBackward0", 707], ["aten::clone", 706], ["aten::empty_like", 703], ["aten::contiguous", 699], ["aten::clone", 697], ["aten::copy_", 697], ["aten::clone", 693], ["aten::copy_", 690], ["aten::contiguous", 687], ["aten::contiguous", 686], ["aten::as_strided", 684], ["aten::fill_", 679], ["aten::clone", 667], ["aten::stride", 664], ["aten::narrow", 655], ["aten::fill_", 652], ["aten::threshold_", 644], ["aten::stride", 617], ["aten::stride", 616], ["aten::detach", 610], ["aten::stride", 609], ["aten::clone", 601], ["AddBackward0", 596], ["aten::resize_", 587], ["aten::stride", 581], ["aten::copy_", 572], ["aten::resize_", 560], ["nccl:broadcast", 555], ["aten::resize_", 548], ["aten::stride", 546], ["aten::contiguous", 533], ["aten::resize_", 531], ["aten::clone", 525], ["aten::copy_", 519], ["aten::copy_", 518], ["aten::detach", 517], ["aten::copy_", 511], ["aten::expand", 507], ["aten::view", 505], ["aten::stride", 503], ["aten::detach", 502], ["aten::threshold_", 491], ["detach", 471], ["aten::threshold_", 465], ["aten::clone", 463], ["aten::clone", 461], ["aten::threshold_", 460], ["aten::fill_", 459], ["aten::contiguous", 450], ["aten::slice", 448], ["aten::fill_", 447], ["aten::fill_", 446], ["aten::transpose", 416], ["aten::fill_", 412], ["aten::fill_", 399], ["aten::resize_", 389], ["aten::stride", 368], ["aten::is_pinned", 367], ["aten::copy_", 362], ["aten::resize_", 360], ["aten::fill_", 355], ["aten::detach_", 345], ["aten::fill_", 345], ["aten::copy_", 337], ["aten::resize_as_", 336], ["aten::fill_", 327], ["aten::fill_", 327], ["aten::fill_", 326], ["aten::fill_", 323], ["aten::fill_", 323], ["aten::stride", 318], ["detach", 315], ["aten::resize_", 309], ["aten::resize_", 309], ["aten::resize_", 307], ["aten::detach", 298], ["aten::contiguous", 281], ["aten::contiguous", 281], ["aten::as_strided", 267], ["aten::clone", 252], ["detach", 250], ["aten::clone", 240], ["aten::clone", 237], ["aten::contiguous", 231], ["aten::as_strided", 231], ["aten::copy_", 230], ["aten::contiguous", 227], ["aten::clone", 227], ["aten::contiguous", 224], ["aten::contiguous", 224], ["aten::contiguous", 223], ["aten::contiguous", 223], ["aten::clone", 222], ["aten::clone", 222], ["aten::contiguous", 221], ["aten::detach", 221], ["aten::clone", 220], ["aten::detach", 219], ["detach", 216], ["aten::to", 214], ["detach", 203], ["aten::resize_", 201], ["aten::copy_", 197], ["aten::detach", 195], ["aten::copy_", 192], ["aten::resize_", 191], ["aten::resize_", 191], ["aten::copy_", 191], ["aten::copy_", 191], ["detach_", 188], ["aten::resize_", 187], ["aten::resize_", 187], ["aten::resize_", 184], ["aten::resize_", 181], ["aten::copy_", 177], ["aten::conj", 176], ["aten::copy_", 175], ["aten::copy_", 174], ["aten::copy_", 173], ["aten::copy_", 172], ["aten::stride", 171], ["aten::copy_", 169], ["aten::detach", 167], ["aten::conj", 165], ["aten::resize_", 153], ["aten::as_strided", 152], ["aten::detach", 148], ["aten::detach", 148], ["aten::as_strided", 137], ["aten::contiguous", 136], ["aten::is_floating_point", 131], ["aten::as_strided", 127], ["aten::to", 127], ["aten::stride", 126], ["aten::random_", 121], ["aten::as_strided", 119], ["detach", 117], ["aten::as_strided", 115], ["aten::detach", 114], ["aten::detach", 111], ["aten::detach", 109], ["aten::detach", 109], ["aten::stride", 106], ["aten::resize_", 98], ["detach", 91], ["detach", 90], ["aten::stride", 89], ["aten::stride", 86], ["aten::stride", 81], ["detach", 77], ["detach", 76], ["aten::detach", 74], ["aten::detach", 73], ["aten::detach", 64], ["detach", 61], ["detach", 60], ["aten::detach", 54], ["detach", 46], ["detach", 46], ["detach", 46], ["detach", 45], ["aten::stride", 43], ["aten::detach", 39], ["aten::detach", 38], ["aten::detach", 38], ["aten::detach", 37], ["aten::detach", 37], ["aten::detach", 37], ["aten::detach", 36], ["aten::detach", 35], ["detach", 31], ["detach", 30], ["detach", 17], ["detach", 16], ["detach", 16], ["detach", 15], ["detach", 15], ["detach", 15], ["detach", 15], ["detach", 14], ["detach", 14], ["detach", 14]]}, "host_self_time": {"title": "Host Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 4279740], ["aten::_cat", 4210564], ["aten::cudnn_convolution", 2353145], ["aten::div_", 1152229], ["aten::div", 1035539], ["aten::sub_", 947087], ["aten::addmm", 856337], ["aten::empty", 458342], ["aten::empty_strided", 306944], ["aten::cudnn_convolution_backward_weight", 304537], ["aten::cudnn_convolution", 153680], ["aten::cudnn_convolution_backward_input", 152390], ["aten::cudnn_convolution_backward_input", 146185], ["aten::cudnn_convolution", 133455], ["aten::copy_", 93752], ["aten::cudnn_batch_norm", 74669], ["aten::copy_", 70514], ["aten::add_", 65336], ["aten::slice", 62980], ["aten::cudnn_convolution_backward_weight", 60226], ["aten::select", 58985], ["aten::add", 57672], ["aten::uniform_", 56898], ["aten::to", 52584], ["aten::add_", 48134], ["aten::any", 44223], ["aten::_local_scalar_dense", 43799], ["aten::cudnn_batch_norm", 41824], ["aten::randint", 39627], ["aten::clone", 39120], ["aten::view", 35240], ["aten::view", 34092], ["aten::log", 33642], ["aten::add", 33573], ["aten::cudnn_convolution_backward_input", 33566], ["aten::item", 33233], ["aten::add_", 33049], ["aten::cudnn_convolution_backward_input", 32350], ["aten::cudnn_batch_norm", 32240], ["aten::exp", 31708], ["aten::_local_scalar_dense", 31540], ["aten::cudnn_batch_norm_backward", 30950], ["aten::item", 29196], ["aten::cudnn_convolution", 29149], ["aten::add_", 28876], ["aten::add_", 28845], ["aten::cudnn_convolution", 28697], ["aten::copy_", 28229], ["aten::cudnn_convolution", 28065], ["aten::cudnn_batch_norm", 28015], ["aten::slice", 27850], ["aten::copy_", 27847], ["aten::cudnn_convolution_backward_input", 26878], ["aten::lt", 26814], ["aten::lt", 26569], ["aten::cudnn_convolution", 26405], ["aten::eq", 26085], ["aten::cudnn_convolution", 25161], ["aten::cudnn_convolution_backward_weight", 25008], ["aten::cudnn_convolution", 24935], ["aten::view", 24580], ["aten::eq", 24571], ["aten::exp", 24502], ["aten::resize_", 24049], ["aten::mul_", 23316], ["aten::cudnn_convolution_backward_weight", 23305], ["aten::cudnn_batch_norm", 23152], ["aten::add", 23132], ["aten::view", 23021], ["aten::view", 22539], ["aten::cudnn_convolution_backward_input", 22316], ["aten::permute", 22261], ["aten::to", 22142], ["aten::cudnn_convolution_backward_input", 21983], ["aten::cudnn_convolution_backward_input", 21842], ["aten::cudnn_convolution_backward_input", 21714], ["aten::cudnn_convolution", 21643], ["aten::narrow", 21564], ["aten::cudnn_convolution", 21462], ["aten::cudnn_convolution", 21458], ["aten::cudnn_convolution_backward_weight", 21311], ["aten::cudnn_convolution", 21277], ["aten::cudnn_convolution", 20627], ["aten::cudnn_convolution_backward_input", 19899], ["aten::cudnn_convolution", 19861], ["aten::cudnn_batch_norm_backward", 19604], ["aten::cudnn_convolution_backward_weight", 19581], ["aten::cudnn_batch_norm_backward", 19483], ["aten::cudnn_batch_norm", 19389], ["aten::copy_", 19241], ["aten::cudnn_batch_norm", 19062], ["aten::cudnn_convolution_backward_weight", 19052], ["aten::add_", 19021], ["aten::cudnn_convolution_backward_input", 18612], ["aten::set_", 18337], ["aten::cudnn_convolution_backward_weight", 18265], ["aten::pin_memory", 18151], ["aten::cudnn_convolution_backward_weight", 17999], ["aten::view", 17870], ["aten::rand", 17684], ["aten::cudnn_convolution_backward_input", 17682], ["aten::cudnn_convolution", 17535], ["aten::mul_", 17275], ["aten::cudnn_batch_norm", 17261], ["aten::cudnn_batch_norm_backward", 16911], ["aten::add", 16843], ["aten::view", 16842], ["aten::cudnn_convolution", 16738], ["aten::cudnn_convolution_backward_input", 16617], ["aten::cudnn_batch_norm_backward", 16602], ["aten::contiguous", 16127], ["aten::random_", 15826], ["aten::cudnn_convolution_backward_weight", 15388], ["aten::cudnn_convolution", 15287], ["aten::add", 15277], ["aten::cudnn_batch_norm", 15238], ["aten::view", 15066], ["aten::add", 14921], ["aten::cudnn_convolution_backward_input", 14877], ["aten::cudnn_convolution_backward_weight", 14850], ["aten::cudnn_convolution_backward_input", 14497], ["aten::view", 14455], ["aten::cudnn_convolution_backward_weight", 14371], ["aten::cudnn_convolution_backward_weight", 14329], ["aten::copy_", 14137], ["aten::cudnn_convolution_backward_weight", 14033], ["aten::cudnn_batch_norm_backward", 14025], ["aten::zero_", 13792], ["aten::cudnn_convolution_backward_input", 13589], ["aten::cudnn_batch_norm_backward", 13377], ["aten::is_floating_point", 13051], ["aten::copy_", 12977], ["aten::add_", 12303], ["aten::add_", 12264], ["aten::mul_", 12235], ["aten::copy_", 12222], ["aten::threshold_backward", 12168], ["aten::_batch_norm_impl_index", 11912], ["CudnnBatchNormBackward", 11761], ["aten::narrow", 11636], ["aten::cudnn_convolution_backward_weight", 11601], ["torch::autograd::AccumulateGrad", 11384], ["aten::cudnn_batch_norm_backward", 11169], ["aten::empty_like", 11162], ["aten::fill_", 11134], ["aten::cudnn_convolution_backward_weight", 11093], ["aten::mul_", 11041], ["aten::cudnn_convolution_backward_weight", 10971], ["aten::cudnn_convolution", 10959], ["aten::mul_", 10870], ["aten::relu_", 10634], ["aten::cudnn_convolution_backward_weight", 10556], ["aten::as_strided", 10502], ["aten::cudnn_convolution", 10485], ["aten::cudnn_convolution_backward_weight", 10475], ["aten::add_", 10288], ["aten::cudnn_convolution", 10234], ["aten::as_strided", 9919], ["aten::zero_", 9445], ["aten::cudnn_convolution_backward_input", 9369], ["aten::cudnn_convolution_backward_input", 9360], ["aten::contiguous", 9261], ["aten::contiguous", 9144], ["aten::to", 8976], ["aten::add", 8850], ["torch::autograd::AccumulateGrad", 8594], ["aten::cudnn_convolution", 8581], ["aten::add_", 8447], ["aten::view", 8356], ["aten::cudnn_convolution", 8350], ["aten::add_", 8296], ["aten::unsqueeze", 8270], ["aten::add_", 8200], ["aten::cudnn_convolution_backward", 8163], ["aten::cudnn_convolution_backward_weight", 8051], ["aten::cudnn_convolution_backward_weight", 7875], ["aten::cudnn_convolution_backward_weight", 7743], ["aten::cudnn_convolution_backward_input", 7652], ["aten::threshold_backward", 7526], ["CudnnConvolutionBackward", 7333], ["aten::fill_", 7313], ["aten::_batch_norm_impl_index", 7221], ["aten::_batch_norm_impl_index", 7148], ["aten::threshold_backward", 7130], ["aten::cudnn_convolution_backward", 7112], ["aten::add_", 7102], ["aten::copy_", 6905], ["aten::relu_", 6867], ["aten::cudnn_convolution_backward", 6790], ["aten::zero_", 6781], ["aten::stride", 6696], ["CudnnBatchNormBackward", 6518], ["aten::threshold_backward", 6512], ["aten::detach_", 6449], ["CudnnBatchNormBackward", 6393], ["aten::add_", 6386], ["aten::zero_", 6358], ["aten::add", 6332], ["aten::add", 6325], ["aten::threshold_backward", 6321], ["aten::add_", 6315], ["aten::_batch_norm_impl_index", 6207], ["aten::contiguous", 6147], ["aten::add_", 6128], ["aten::add_", 6069], ["aten::relu_", 6016], ["aten::zero_", 5938], ["aten::mul_", 5924], ["aten::contiguous", 5915], ["aten::contiguous", 5915], ["aten::is_nonzero", 5909], ["aten::contiguous", 5907], ["aten::relu_", 5768], ["aten::contiguous", 5765], ["aten::as_strided", 5750], ["torch::autograd::AccumulateGrad", 5672], ["torch::autograd::AccumulateGrad", 5610], ["aten::is_nonzero", 5563], ["aten::cudnn_convolution_backward", 5547], ["aten::cudnn_convolution_backward", 5543], ["ReluBackward1", 5525], ["aten::to", 5429], ["aten::stride", 5422], ["aten::fill_", 5414], ["CudnnBatchNormBackward", 5410], ["aten::add", 5297], ["aten::threshold_", 5206], ["CudnnBatchNormBackward", 5192], ["aten::_batch_norm_impl_index", 5039], ["aten::fill_", 4990], ["aten::_batch_norm_impl_index", 4968], ["aten::add_", 4956], ["torch::autograd::AccumulateGrad", 4900], ["aten::stack", 4813], ["aten::fill_", 4808], ["aten::fill_", 4775], ["aten::_batch_norm_impl_index", 4773], ["aten::relu_", 4765], ["CudnnConvolutionBackward", 4750], ["CudnnConvolutionBackward", 4694], ["detach_", 4691], ["CudnnBatchNormBackward", 4677], ["aten::mean", 4636], ["aten::cudnn_convolution_backward", 4610], ["aten::mul_", 4550], ["aten::mul_", 4525], ["aten::add", 4436], ["aten::contiguous", 4419], ["aten::_convolution", 4411], ["aten::as_strided", 4367], ["aten::stride", 4326], ["aten::contiguous", 4316], ["aten::add", 4308], ["aten::cudnn_convolution_backward", 4303], ["aten::threshold_backward", 4277], ["aten::add_", 4271], ["aten::stride", 4261], ["aten::contiguous", 4260], ["aten::empty_like", 4258], ["aten::cudnn_convolution_backward", 4236], ["aten::add", 4231], ["aten::as_strided", 4223], ["aten::batch_norm", 4207], ["aten::_batch_norm_impl_index", 4165], ["aten::cudnn_convolution_backward", 4090], ["aten::add_", 4021], ["CudnnConvolutionBackward", 3994], ["aten::contiguous", 3925], ["aten::as_strided", 3920], ["aten::add", 3910], ["aten::resize_", 3892], ["aten::contiguous", 3853], ["CudnnBatchNormBackward", 3844], ["aten::cudnn_batch_norm", 3823], ["aten::cudnn_batch_norm", 3822], ["aten::mul_", 3804], ["aten::relu_", 3793], ["aten::cudnn_batch_norm", 3710], ["aten::_convolution", 3691], ["aten::add_", 3681], ["CudnnConvolutionBackward", 3669], ["aten::_convolution", 3658], ["CudnnBatchNormBackward", 3628], ["aten::cudnn_convolution_backward", 3532], ["ReluBackward1", 3532], ["aten::clone", 3508], ["aten::zero_", 3508], ["aten::_convolution", 3401], ["CudnnConvolutionBackward", 3376], ["CudnnConvolutionBackward", 3358], ["aten::contiguous", 3323], ["aten::threshold_", 3318], ["aten::max_pool2d_with_indices", 3302], ["aten::add", 3301], ["aten::zero_", 3295], ["aten::add", 3255], ["aten::cat", 3242], ["aten::threshold_backward", 3241], ["aten::add_", 3231], ["aten::threshold_backward", 3199], ["aten::stride", 3181], ["aten::cudnn_convolution_backward", 3179], ["aten::relu_", 3178], ["aten::as_strided", 3156], ["aten::stride", 3140], ["aten::mul_", 3131], ["aten::add", 3116], ["aten::mul_", 3052], ["aten::mul_", 3003], ["aten::contiguous", 2989], ["ReluBackward1", 2988], ["aten::threshold_", 2952], ["aten::_convolution", 2915], ["ReluBackward1", 2906], ["torch::autograd::AccumulateGrad", 2891], ["aten::relu_", 2847], ["aten::as_strided", 2832], ["aten::cudnn_batch_norm_backward", 2788], ["aten::cudnn_batch_norm_backward", 2749], ["aten::cudnn_batch_norm_backward", 2745], ["aten::threshold_", 2742], ["aten::cudnn_convolution_backward", 2728], ["aten::empty_like", 2724], ["aten::empty_like", 2724], ["aten::fill_", 2724], ["aten::cudnn_batch_norm_backward", 2724], ["aten::batch_norm", 2706], ["aten::batch_norm", 2657], ["aten::zero_", 2631], ["CudnnConvolutionBackward", 2616], ["ReluBackward1", 2607], ["aten::mul_", 2479], ["aten::contiguous", 2450], ["aten::stride", 2430], ["aten::conv2d", 2390], ["aten::clone", 2377], ["aten::_convolution", 2359], ["aten::threshold_", 2353], ["aten::empty_like", 2346], ["aten::mul_", 2330], ["aten::mm", 2310], ["aten::batch_norm", 2308], ["aten::add_", 2297], ["aten::add_", 2289], ["aten::resize_", 2267], ["aten::max_pool2d_with_indices_backward", 2266], ["aten::zeros", 2261], ["aten::mul_", 2258], ["aten::conv2d", 2255], ["aten::stride", 2251], ["aten::mul_", 2248], ["aten::resize_", 2246], ["aten::resize_", 2246], ["aten::add_", 2242], ["aten::_convolution", 2233], ["aten::_convolution", 2206], ["aten::_convolution", 2204], ["aten::zero_", 2189], ["aten::add", 2176], ["aten::add_", 2172], ["aten::cudnn_convolution_backward", 2165], ["torch::autograd::AccumulateGrad", 2139], ["aten::fill_", 2130], ["torch::autograd::AccumulateGrad", 2124], ["aten::fill_", 2105], ["aten::add", 2082], ["ReluBackward1", 2073], ["aten::add_", 2070], ["aten::add_", 2058], ["aten::add_", 2053], ["aten::add_", 2037], ["aten::convolution", 2028], ["aten::add_", 2006], ["aten::add_", 2001], ["aten::conv2d", 1998], ["aten::batch_norm", 1909], ["aten::empty_like", 1905], ["aten::batch_norm", 1902], ["aten::empty_like", 1892], ["aten::nll_loss_forward", 1884], ["aten::empty_like", 1872], ["aten::div", 1843], ["aten::_log_softmax", 1839], ["aten::convolution", 1827], ["aten::threshold_", 1823], ["torch::autograd::AccumulateGrad", 1788], ["aten::batch_norm", 1782], ["aten::convolution", 1779], ["aten::clone", 1775], ["aten::conv2d", 1764], ["aten::fill_", 1715], ["aten::resize_", 1708], ["aten::zero_", 1692], ["aten::zero_", 1691], ["aten::zero_", 1690], ["aten::resize_", 1683], ["aten::clone", 1682], ["aten::conv2d", 1567], ["aten::convolution", 1559], ["aten::clone", 1544], ["aten::mul_", 1533], ["aten::batch_norm", 1517], ["aten::threshold_", 1514], ["aten::_convolution", 1506], ["aten::mul_", 1503], ["aten::cudnn_convolution_backward", 1500], ["aten::_convolution", 1486], ["CudnnConvolutionBackward", 1471], ["aten::contiguous", 1470], ["aten::_convolution", 1467], ["torch::autograd::AccumulateGrad", 1467], ["aten::copy_", 1465], ["aten::pin_memory", 1464], ["ReluBackward1", 1454], ["aten::empty_like", 1452], ["aten::cudnn_convolution_backward", 1439], ["ReluBackward1", 1434], ["AddmmBackward", 1429], ["aten::cudnn_convolution_backward", 1425], ["torch::autograd::AccumulateGrad", 1418], ["aten::convolution", 1411], ["aten::nll_loss_backward", 1406], ["aten::cudnn_convolution_backward", 1404], ["aten::mm", 1395], ["torch::autograd::AccumulateGrad", 1390], ["aten::cudnn_convolution_backward", 1390], ["aten::cudnn_convolution_backward", 1379], ["aten::cudnn_convolution_backward", 1366], ["aten::cudnn_convolution_backward", 1359], ["aten::cudnn_convolution_backward", 1357], ["aten::contiguous", 1349], ["aten::fill_", 1347], ["aten::threshold_", 1338], ["aten::cudnn_convolution_backward", 1337], ["aten::fill_", 1316], ["aten::stride", 1314], ["aten::fill_", 1314], ["aten::zero_", 1311], ["aten::stride", 1308], ["aten::zero_", 1307], ["aten::zero_", 1291], ["aten::resize_", 1284], ["aten::zero_", 1277], ["aten::conv2d", 1238], ["aten::t", 1238], ["aten::conv2d", 1225], ["aten::conv2d", 1215], ["aten::conv2d", 1194], ["AddBackward0", 1174], ["aten::_log_softmax_backward_data", 1173], ["aten::resize_", 1170], ["aten::add", 1168], ["aten::add", 1163], ["aten::mul_", 1163], ["torch::autograd::AccumulateGrad", 1131], ["aten::contiguous", 1118], ["aten::resize_", 1110], ["aten::add", 1107], ["aten::threshold_backward", 1107], ["aten::_batch_norm_impl_index", 1105], ["aten::add", 1097], ["aten::add", 1094], ["torch::autograd::AccumulateGrad", 1092], ["aten::threshold_backward", 1091], ["aten::convolution", 1080], ["torch::autograd::AccumulateGrad", 1078], ["aten::add", 1077], ["aten::relu_", 1076], ["aten::relu_", 1074], ["torch::autograd::AccumulateGrad", 1067], ["aten::threshold_backward", 1060], ["aten::resize_", 1059], ["aten::threshold_backward", 1059], ["aten::copy_", 1058], ["aten::add", 1056], ["aten::add", 1054], ["aten::zero_", 1052], ["aten::convolution", 1048], ["aten::add", 1047], ["aten::convolution", 1043], ["aten::add", 1040], ["torch::autograd::AccumulateGrad", 1035], ["aten::convolution", 1018], ["aten::copy_", 1014], ["aten::fill_", 1003], ["aten::resize_", 1002], ["aten::_batch_norm_impl_index", 1002], ["aten::_batch_norm_impl_index", 995], ["aten::relu_", 992], ["aten::fill_", 990], ["aten::_batch_norm_impl_index", 985], ["aten::fill_", 981], ["aten::fill_", 976], ["aten::contiguous", 974], ["aten::relu_", 956], ["CudnnBatchNormBackward", 941], ["aten::mul_", 936], ["aten::set_", 934], ["aten::resize_", 922], ["aten::contiguous", 919], ["aten::contiguous", 909], ["CudnnBatchNormBackward", 907], ["CudnnBatchNormBackward", 906], ["aten::clone", 901], ["aten::stride", 890], ["CudnnBatchNormBackward", 889], ["aten::conv2d", 884], ["aten::view", 884], ["aten::copy_", 877], ["aten::zero_", 877], ["aten::to", 876], ["aten::t", 876], ["aten::mul_", 873], ["aten::contiguous", 866], ["aten::contiguous", 860], ["AddBackward0", 859], ["aten::zero_", 855], ["aten::_convolution", 849], ["aten::mul_", 848], ["aten::_convolution", 847], ["aten::as_strided", 845], ["aten::mul_", 841], ["aten::contiguous", 838], ["aten::contiguous", 829], ["aten::contiguous", 828], ["aten::conv2d", 817], ["aten::mul_", 808], ["aten::conv2d", 805], ["aten::mul_", 796], ["aten::resize_", 786], ["aten::_convolution", 777], ["aten::resize_", 770], ["aten::_convolution", 768], ["aten::_convolution", 766], ["aten::_convolution", 759], ["aten::_convolution", 758], ["aten::mul_", 755], ["aten::mul_", 754], ["aten::is_pinned", 753], ["aten::_convolution", 747], ["aten::mul_", 746], ["aten::resize_", 737], ["aten::convolution", 736], ["aten::empty_like", 734], ["aten::convolution", 729], ["NllLossBackward", 728], ["aten::copy_", 726], ["aten::_convolution", 725], ["aten::empty_like", 725], ["torch::autograd::AccumulateGrad", 721], ["aten::_convolution", 715], ["aten::_convolution", 714], ["aten::expand", 711], ["AddBackward0", 707], ["aten::clone", 706], ["aten::contiguous", 699], ["aten::copy_", 697], ["aten::copy_", 690], ["aten::contiguous", 687], ["aten::contiguous", 686], ["aten::detach", 685], ["aten::convolution", 684], ["aten::as_strided", 684], ["CudnnConvolutionBackward", 681], ["MeanBackward1", 680], ["aten::fill_", 679], ["CudnnConvolutionBackward", 668], ["aten::stride", 664], ["aten::clone", 663], ["MaxPool2DWithIndicesBackward", 662], ["CudnnConvolutionBackward", 653], ["aten::fill_", 652], ["aten::threshold_", 644], ["aten::stride", 617], ["aten::stride", 616], ["aten::stride", 609], ["AddBackward0", 596], ["aten::resize_", 587], ["aten::stride", 581], ["aten::copy_", 572], ["aten::to", 571], ["aten::clone", 571], ["aten::transpose", 567], ["aten::resize_", 560], ["nccl:broadcast", 555], ["aten::transpose", 553], ["aten::resize_", 548], ["aten::stride", 546], ["aten::contiguous", 533], ["aten::resize_", 531], ["LogSoftmaxBackward", 525], ["aten::ones_like", 524], ["aten::copy_", 519], ["ReluBackward1", 519], ["aten::copy_", 518], ["torch::autograd::AccumulateGrad", 517], ["aten::copy_", 511], ["aten::detach", 509], ["aten::view", 505], ["aten::stride", 503], ["ReluBackward1", 496], ["aten::threshold_", 491], ["ReluBackward1", 477], ["aten::t", 476], ["detach", 471], ["aten::clone", 471], ["ReluBackward1", 470], ["aten::threshold_", 465], ["aten::threshold_", 460], ["aten::zero_", 460], ["aten::zero_", 460], ["aten::fill_", 459], ["aten::clone", 453], ["aten::max_pool2d", 450], ["aten::contiguous", 450], ["aten::conv2d", 450], ["aten::conv2d", 449], ["aten::zero_", 448], ["aten::fill_", 447], ["aten::fill_", 446], ["aten::clone", 444], ["aten::zero_", 437], ["aten::batch_norm", 433], ["aten::conv2d", 431], ["aten::conv2d", 430], ["aten::zero_", 427], ["aten::zero_", 424], ["aten::zero_", 423], ["aten::zero_", 421], ["aten::zero_", 418], ["aten::conv2d", 415], ["aten::zero_", 412], ["aten::fill_", 412], ["aten::adaptive_avg_pool2d", 411], ["torch::autograd::AccumulateGrad", 410], ["aten::conv2d", 405], ["aten::conv2d", 404], ["aten::empty_like", 404], ["aten::flatten", 399], ["aten::fill_", 399], ["aten::batch_norm", 397], ["aten::conv2d", 396], ["aten::conv2d", 396], ["aten::log_softmax", 395], ["aten::conv2d", 394], ["aten::batch_norm", 392], ["aten::conv2d", 392], ["aten::resize_", 389], ["aten::expand", 388], ["aten::empty_like", 387], ["aten::empty_like", 382], ["aten::convolution", 378], ["aten::empty_like", 377], ["aten::batch_norm", 374], ["aten::convolution", 374], ["aten::nll_loss", 373], ["torch::autograd::AccumulateGrad", 373], ["torch::autograd::AccumulateGrad", 371], ["torch::autograd::AccumulateGrad", 371], ["aten::stride", 368], ["aten::is_pinned", 367], ["aten::copy_", 362], ["aten::detach", 360], ["torch::autograd::AccumulateGrad", 360], ["aten::resize_", 360], ["aten::convolution", 356], ["aten::convolution", 356], ["aten::fill_", 355], ["aten::convolution", 353], ["torch::autograd::AccumulateGrad", 353], ["aten::clone", 352], ["torch::autograd::AccumulateGrad", 351], ["torch::autograd::AccumulateGrad", 349], ["aten::zeros_like", 348], ["aten::fill_", 345], ["torch::autograd::AccumulateGrad", 345], ["aten::convolution", 343], ["aten::convolution", 342], ["aten::convolution", 338], ["aten::copy_", 337], ["aten::convolution", 336], ["aten::convolution", 334], ["aten::slice", 333], ["aten::convolution", 333], ["aten::clone", 332], ["aten::fill_", 327], ["aten::fill_", 327], ["aten::fill_", 326], ["aten::fill_", 323], ["aten::fill_", 323], ["aten::clone", 322], ["aten::clone", 319], ["aten::stride", 318], ["aten::zero_", 318], ["ViewBackward", 317], ["detach", 315], ["aten::resize_", 309], ["aten::resize_", 309], ["aten::resize_", 307], ["TBackward", 306], ["aten::detach", 301], ["aten::detach", 299], ["aten::transpose", 289], ["aten::contiguous", 281], ["aten::contiguous", 281], ["aten::as_strided", 267], ["aten::resize_as_", 265], ["aten::reshape", 257], ["detach", 250], ["aten::reshape", 246], ["aten::contiguous", 231], ["aten::as_strided", 231], ["aten::copy_", 230], ["aten::contiguous", 227], ["aten::clone", 226], ["aten::contiguous", 224], ["aten::contiguous", 224], ["aten::contiguous", 223], ["aten::contiguous", 223], ["aten::contiguous", 221], ["detach", 216], ["aten::to", 214], ["aten::clone", 213], ["aten::narrow", 207], ["detach", 203], ["aten::resize_", 201], ["aten::copy_", 197], ["aten::copy_", 192], ["aten::resize_", 191], ["aten::resize_", 191], ["aten::copy_", 191], ["aten::copy_", 191], ["detach_", 188], ["aten::resize_", 187], ["aten::resize_", 187], ["aten::resize_", 184], ["aten::resize_", 181], ["aten::detach", 181], ["aten::copy_", 177], ["aten::conj", 176], ["aten::copy_", 175], ["aten::copy_", 174], ["aten::copy_", 173], ["aten::copy_", 172], ["aten::stride", 171], ["aten::copy_", 169], ["aten::conj", 165], ["aten::detach_", 157], ["aten::resize_", 153], ["aten::as_strided", 152], ["aten::as_strided", 137], ["aten::contiguous", 136], ["aten::clone", 132], ["aten::is_floating_point", 131], ["aten::detach", 130], ["aten::detach", 129], ["aten::as_strided", 127], ["aten::to", 127], ["aten::stride", 126], ["aten::random_", 121], ["aten::as_strided", 119], ["aten::detach", 119], ["aten::clone", 117], ["detach", 117], ["aten::as_strided", 115], ["aten::clone", 115], ["aten::clone", 112], ["aten::clone", 112], ["aten::clone", 111], ["aten::clone", 111], ["aten::clone", 108], ["aten::clone", 107], ["aten::stride", 106], ["aten::clone", 105], ["aten::resize_", 98], ["detach", 91], ["aten::detach", 90], ["detach", 90], ["aten::stride", 89], ["aten::detach", 88], ["aten::detach", 87], ["aten::stride", 86], ["aten::stride", 81], ["detach", 77], ["detach", 76], ["aten::detach", 68], ["aten::detach", 65], ["aten::detach", 64], ["aten::detach", 63], ["detach", 61], ["detach", 60], ["aten::detach", 48], ["detach", 46], ["detach", 46], ["detach", 46], ["detach", 45], ["aten::detach", 43], ["aten::detach", 43], ["aten::stride", 43], ["aten::detach", 37], ["detach", 31], ["detach", 30], ["aten::detach", 23], ["aten::detach", 23], ["aten::detach", 23], ["aten::detach", 23], ["aten::detach", 23], ["aten::detach", 22], ["aten::detach", 21], ["aten::detach", 21], ["detach", 17], ["detach", 16], ["detach", 16], ["detach", 15], ["detach", 15], ["detach", 15], ["detach", 15], ["detach", 14], ["detach", 14], ["detach", 14]]}}, "operation_table_by_name_input": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "string", "name": "Input Shape"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Device Self Duration (us)"}, {"type": "number", "name": "Device Total Duration (us)"}, {"type": "number", "name": "Host Self Duration (us)"}, {"type": "number", "name": "Host Total Duration (us)"}], "rows": [["aten::cudnn_convolution_backward_weight", "[[], [32, 64, 56, 56], [32, 64, 56, 56], [], [], [], [], [], [], []]", 32, 31750, 31750, 23305, 27875], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], []]", 24, 28772, 28772, 33566, 37721], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], []]", 48, 28028, 28028, 32350, 39723], ["aten::cudnn_convolution_backward_input", "[[], [32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], []]", 32, 26007, 26007, 26878, 31686], ["aten::cudnn_convolution_backward_input", "[[], [32, 1024, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], []]", 48, 25825, 25825, 22316, 28900], ["aten::cudnn_convolution", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], []]", 48, 23302, 23302, 29149, 36359], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 56, 56], [32, 64, 56, 56], [], [], [], [], [], [], []]", 32, 21839, 21839, 19581, 23952], ["aten::cudnn_convolution_backward_weight", "[[], [32, 1024, 14, 14], [32, 256, 14, 14], [], [], [], [], [], [], []]", 48, 21809, 21809, 25008, 31370], ["aten::cudnn_batch_norm_backward", "[[32, 256, 56, 56], [32, 256, 56, 56], [256], [256], [256], [256], [256], [], [0]]", 32, 20666, 20666, 11169, 17570], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], []]", 40, 20659, 20659, 21714, 27276], ["aten::cudnn_convolution", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], []]", 40, 20393, 20393, 25161, 30610], ["aten::cudnn_convolution", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], []]", 24, 20275, 20275, 28697, 32011], ["aten::cudnn_convolution_backward_input", "[[], [32, 2048, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], []]", 24, 20053, 20053, 19899, 23384], ["aten::cudnn_convolution_backward_weight", "[[], [32, 64, 56, 56], [32, 256, 56, 56], [], [], [], [], [], [], []]", 16, 18522, 18522, 14329, 16489], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 14, 14], [32, 1024, 14, 14], [], [], [], [], [], [], []]", 40, 18515, 18515, 19052, 24459], ["aten::cudnn_convolution", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], []]", 16, 18174, 18174, 24935, 27095], ["aten::cudnn_convolution", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], []]", 32, 17502, 17502, 153680, 158064], ["aten::cudnn_convolution", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], []]", 40, 16978, 16978, 28065, 77431], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 28, 28], [32, 128, 28, 28], [], [], [], [], [], [], []]", 32, 16624, 16624, 17999, 22289], ["aten::cudnn_convolution", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], []]", 32, 15955, 15955, 26405, 32176], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 14, 14], [32, 256, 14, 14], [], [], [], [], [], [], []]", 40, 15701, 15701, 21311, 27662], ["aten::cudnn_convolution", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], []]", 16, 15700, 15700, 21643, 24603], ["aten::cudnn_convolution", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], []]", 8, 15638, 15638, 2353145, 2355109], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], []]", 16, 15494, 15494, 21842, 24693], ["aten::cudnn_convolution_backward_weight", "[[], [32, 2048, 7, 7], [32, 512, 7, 7], [], [], [], [], [], [], []]", 24, 15452, 15452, 304537, 308289], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 56, 56], [32, 256, 56, 56], [], [], [], [], [], [], []]", 8, 15414, 15414, 15388, 16439], ["aten::cudnn_convolution", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], []]", 24, 15313, 15313, 21458, 25159], ["aten::cudnn_convolution", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], [], [], []]", 8, 15023, 15023, 133455, 134937], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], []]", 32, 14987, 14987, 16617, 21038], ["aten::cudnn_convolution_backward_input", "[[], [32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], []]", 24, 14666, 14666, 18612, 22217], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], []]", 32, 14564, 14564, 152390, 157307], ["aten::cudnn_convolution", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 14405, 14405, 19861, 20965], ["aten::cudnn_convolution", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], []]", 8, 14352, 14352, 21277, 22504], ["aten::copy_", "[[32, 3, 224, 224], [32, 3, 224, 224], []]", 16, 13482, 13482, 93752, 93752], ["aten::cudnn_convolution_backward_input", "[[], [32, 128, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], []]", 8, 13436, 13436, 21983, 23171], ["aten::cudnn_convolution", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], []]", 24, 13315, 13315, 20627, 24500], ["aten::cudnn_batch_norm_backward", "[[32, 512, 28, 28], [32, 512, 28, 28], [512], [512], [512], [512], [512], [], [0]]", 40, 13306, 13306, 14025, 20947], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 28, 28], [32, 512, 28, 28], [], [], [], [], [], [], []]", 24, 13189, 13189, 14033, 17320], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 12956, 12956, 14877, 15954], ["aten::cudnn_batch_norm", "[[32, 256, 56, 56], [256], [256], [256], [256], [], [], []]", 32, 12820, 12820, 17261, 25334], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 7, 7], [32, 2048, 7, 7], [], [], [], [], [], [], []]", 16, 12780, 12780, 18265, 20956], ["aten::cudnn_convolution_backward_weight", "[[], [32, 64, 112, 112], [32, 3, 224, 224], [], [], [], [], [], [], []]", 8, 12655, 12655, 11093, 12377], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 28, 28], [32, 128, 28, 28], [], [], [], [], [], [], []]", 24, 12651, 12651, 14850, 18281], ["aten::cudnn_convolution", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], []]", 8, 12624, 12624, 15287, 16386], ["aten::cudnn_convolution", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], []]", 24, 11702, 11702, 21462, 25731], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 28, 28], [32, 512, 28, 28], [], [], [], [], [], [], []]", 8, 11629, 11629, 10556, 11745], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 28, 28], [512, 256, 1, 1], [], [], [], [], [], [], []]", 8, 11616, 11616, 9360, 10457], ["aten::cudnn_convolution_backward_input", "[[], [32, 64, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], []]", 16, 11285, 11285, 14497, 16929], ["aten::cudnn_convolution", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], [], [], []]", 8, 11226, 11226, 10234, 11330], ["aten::cudnn_convolution_backward_input", "[[], [32, 2048, 7, 7], [2048, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 11007, 11007, 146185, 147294], ["aten::cudnn_convolution_backward_input", "[[], [32, 1024, 14, 14], [1024, 512, 1, 1], [], [], [], [], [], [], []]", 8, 10747, 10747, 9369, 10447], ["aten::cudnn_convolution_backward_input", "[[], [32, 128, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], []]", 24, 10693, 10693, 17682, 21340], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 14, 14], [32, 1024, 14, 14], [], [], [], [], [], [], []]", 8, 10682, 10682, 10971, 12181], ["aten::cudnn_convolution", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], []]", 16, 10661, 10661, 17535, 19919], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 7, 7], [32, 512, 7, 7], [], [], [], [], [], [], []]", 16, 10545, 10545, 60226, 63084], ["aten::cudnn_batch_norm_backward", "[[32, 1024, 14, 14], [32, 1024, 14, 14], [1024], [1024], [1024], [1024], [1024], [], [0]]", 56, 10178, 10178, 19604, 29183], ["aten::cudnn_batch_norm_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], [64], [64], [64], [64], [64], [], [0]]", 48, 10113, 10113, 16602, 24896], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], []]", 8, 10075, 10075, 13589, 14830], ["aten::cudnn_convolution_backward_weight", "[[], [32, 2048, 7, 7], [32, 1024, 14, 14], [], [], [], [], [], [], []]", 8, 10054, 10054, 14371, 15589], ["aten::cudnn_convolution", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], [], [], []]", 8, 9767, 9767, 16738, 18944], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 7, 7], [32, 512, 14, 14], [], [], [], [], [], [], []]", 8, 9645, 9645, 10475, 11680], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 28, 28], [32, 256, 56, 56], [], [], [], [], [], [], []]", 8, 9278, 9278, 7875, 8950], ["aten::cudnn_convolution", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 9195, 9195, 10959, 12308], ["aten::cudnn_convolution", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], [], [], []]", 8, 8995, 8995, 8581, 9681], ["aten::threshold_backward", "[[32, 256, 56, 56], [32, 256, 56, 56], []]", 24, 8811, 8811, 3199, 4225], ["aten::add_", "[[32, 256, 56, 56], [32, 256, 56, 56], []]", 24, 8742, 8742, 3681, 3681], ["aten::cudnn_convolution_backward_weight", "[[], [32, 1024, 14, 14], [32, 512, 28, 28], [], [], [], [], [], [], []]", 8, 8553, 8553, 11601, 12807], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 28, 28], [32, 128, 56, 56], [], [], [], [], [], [], []]", 8, 8443, 8443, 8051, 9210], ["aten::cudnn_batch_norm", "[[32, 512, 28, 28], [512], [512], [512], [512], [], [], []]", 40, 8352, 8352, 19062, 29268], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 14, 14], [32, 256, 28, 28], [], [], [], [], [], [], []]", 8, 8161, 8161, 7743, 8956], ["aten::cudnn_convolution", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], [], [], []]", 8, 7426, 7426, 10485, 12681], ["aten::cudnn_batch_norm_backward", "[[32, 64, 112, 112], [32, 64, 112, 112], [64], [64], [64], [64], [64], [], [0]]", 8, 6524, 6524, 2745, 4064], ["aten::threshold_", "[[32, 256, 56, 56], [], []]", 24, 6013, 6013, 1514, 1514], ["aten::threshold_backward", "[[32, 512, 28, 28], [32, 512, 28, 28], []]", 32, 5951, 5951, 4277, 5609], ["aten::add_", "[[32, 512, 28, 28], [32, 512, 28, 28], []]", 32, 5906, 5906, 4956, 4956], ["aten::max_pool2d_with_indices_backward", "[[32, 64, 56, 56], [32, 64, 112, 112], [], [], [], [], [], [32, 64, 56, 56]]", 8, 5544, 6824, 2266, 4902], ["aten::cudnn_batch_norm", "[[32, 64, 56, 56], [64], [64], [64], [64], [], [], []]", 48, 5326, 5326, 23152, 34227], ["aten::cudnn_batch_norm_backward", "[[32, 128, 28, 28], [32, 128, 28, 28], [128], [128], [128], [128], [128], [], [0]]", 56, 5138, 5138, 19483, 29034], ["aten::cudnn_batch_norm", "[[32, 1024, 14, 14], [1024], [1024], [1024], [1024], [], [], []]", 56, 4740, 4740, 32240, 46414], ["aten::threshold_backward", "[[32, 1024, 14, 14], [32, 1024, 14, 14], []]", 48, 4613, 4613, 7130, 9085], ["aten::threshold_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], []]", 48, 4422, 4422, 6321, 8280], ["aten::add_", "[[32, 1024, 14, 14], [32, 1024, 14, 14], []]", 48, 4413, 4413, 6386, 6386], ["aten::cudnn_batch_norm_backward", "[[32, 256, 14, 14], [32, 256, 14, 14], [256], [256], [256], [256], [256], [], [0]]", 88, 4199, 4199, 30950, 46071], ["aten::threshold_", "[[32, 512, 28, 28], [], []]", 32, 4051, 4051, 1823, 1823], ["aten::cudnn_batch_norm", "[[32, 64, 112, 112], [64], [64], [64], [64], [], [], []]", 8, 3416, 3416, 74669, 76594], ["aten::threshold_", "[[32, 64, 56, 56], [], []]", 48, 3049, 3049, 2952, 2952], ["aten::threshold_", "[[32, 1024, 14, 14], [], []]", 48, 3028, 3028, 2742, 2742], ["aten::threshold_backward", "[[32, 64, 112, 112], [32, 64, 112, 112], []]", 8, 2960, 2960, 1091, 1409], ["aten::cudnn_batch_norm", "[[32, 128, 28, 28], [128], [128], [128], [128], [], [], []]", 56, 2924, 2924, 28015, 41129], ["aten::cudnn_convolution", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], []]", 8, 2814, 2814, 8350, 9574], ["aten::cudnn_batch_norm_backward", "[[32, 128, 56, 56], [32, 128, 56, 56], [128], [128], [128], [128], [128], [], [0]]", 8, 2761, 2761, 2724, 4041], ["aten::threshold_backward", "[[32, 128, 28, 28], [32, 128, 28, 28], []]", 56, 2737, 2737, 7526, 9839], ["aten::cudnn_convolution_backward_input", "[[], [32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], []]", 8, 2720, 2720, 7652, 8888], ["aten::threshold_backward", "[[32, 256, 14, 14], [32, 256, 14, 14], []]", 88, 2442, 2442, 12168, 15934], ["aten::cudnn_batch_norm_backward", "[[32, 2048, 7, 7], [32, 2048, 7, 7], [2048], [2048], [2048], [2048], [2048], [], [0]]", 32, 2355, 2355, 13377, 19182], ["aten::add_", "[[512, 512, 3, 3], [512, 512, 3, 3], []]", 66, 2354, 2354, 7102, 7102], ["aten::cudnn_batch_norm", "[[32, 256, 14, 14], [256], [256], [256], [256], [], [], []]", 88, 1999, 1999, 41824, 62024], ["aten::threshold_", "[[32, 64, 112, 112], [], []]", 8, 1996, 1996, 644, 644], ["aten::threshold_", "[[32, 128, 28, 28], [], []]", 56, 1852, 1852, 3318, 3318], ["aten::cudnn_batch_norm", "[[32, 2048, 7, 7], [2048], [2048], [2048], [2048], [], [], []]", 32, 1820, 1820, 15238, 22595], ["aten::max_pool2d_with_indices", "[[32, 64, 112, 112], [], [], [], [], []]", 8, 1783, 1783, 3302, 4686], ["aten::cudnn_batch_norm", "[[32, 128, 56, 56], [128], [128], [128], [128], [], [], []]", 8, 1593, 1593, 3822, 5708], ["aten::threshold_backward", "[[32, 128, 56, 56], [32, 128, 56, 56], []]", 8, 1475, 1475, 1107, 1426], ["aten::add_", "[[256], [256], []]", 704, 1443, 1443, 65336, 65336], ["aten::cudnn_batch_norm_backward", "[[32, 256, 28, 28], [32, 256, 28, 28], [256], [256], [256], [256], [256], [], [0]]", 8, 1321, 1321, 2749, 4135], ["aten::fill_", "[[32, 64, 112, 112], []]", 8, 1280, 1280, 446, 446], ["aten::threshold_backward", "[[32, 2048, 7, 7], [32, 2048, 7, 7], []]", 24, 1202, 1202, 3241, 4309], ["aten::add_", "[[32, 2048, 7, 7], [32, 2048, 7, 7], []]", 24, 1124, 1124, 3231, 3231], ["aten::threshold_", "[[32, 256, 14, 14], [], []]", 88, 1031, 1031, 5206, 5206], ["aten::threshold_", "[[32, 128, 56, 56], [], []]", 8, 1006, 1006, 465, 465], ["aten::add_", "[[512], [512], []]", 484, 979, 979, 48134, 48134], ["aten::cudnn_batch_norm_backward", "[[32, 512, 7, 7], [32, 512, 7, 7], [512], [512], [512], [512], [512], [], [0]]", 40, 917, 917, 16911, 24921], ["aten::add_", "[[256, 256, 3, 3], [256, 256, 3, 3], []]", 132, 908, 908, 12303, 12303], ["aten::add_", "[[2048, 512, 1, 1], [2048, 512, 1, 1], []]", 66, 908, 908, 6315, 6315], ["aten::add", "[[512, 512, 3, 3], [512, 512, 3, 3], []]", 24, 841, 841, 3910, 5009], ["aten::cudnn_batch_norm", "[[32, 256, 28, 28], [256], [256], [256], [256], [], [], []]", 8, 828, 828, 3710, 5517], ["aten::threshold_", "[[32, 2048, 7, 7], [], []]", 24, 796, 796, 1338, 1338], ["aten::threshold_backward", "[[32, 256, 28, 28], [32, 256, 28, 28], []]", 8, 757, 757, 1059, 1379], ["aten::cudnn_batch_norm_backward", "[[32, 512, 14, 14], [32, 512, 14, 14], [512], [512], [512], [512], [512], [], [0]]", 8, 739, 739, 2788, 4130], ["aten::add_", "[[128], [128], []]", 352, 730, 730, 33049, 33049], ["aten::add_", "[[2048, 1024, 1, 1], [2048, 1024, 1, 1], []]", 22, 707, 707, 2006, 2006], ["aten::add_", "[[1000, 2048], [1000, 2048], []]", 22, 674, 674, 2242, 2242], ["aten::add_", "[[512, 2048, 1, 1], [512, 2048, 1, 1], []]", 44, 645, 645, 4271, 4271], ["aten::threshold_backward", "[[32, 512, 7, 7], [32, 512, 7, 7], []]", 40, 640, 640, 6512, 8256], ["aten::cudnn_batch_norm", "[[32, 512, 7, 7], [512], [512], [512], [512], [], [], []]", 40, 637, 637, 19389, 28540], ["aten::add_", "[[1024], [1024], []]", 308, 635, 635, 28845, 28845], ["aten::add_", "[[64], [64], []]", 308, 604, 604, 28876, 28876], ["aten::threshold_", "[[32, 256, 28, 28], [], []]", 8, 506, 506, 460, 460], ["aten::mul_", "[[512, 512, 3, 3], []]", 21, 504, 504, 2479, 2479], ["aten::add", "[[256, 256, 3, 3], [256, 256, 3, 3], []]", 48, 484, 484, 6325, 8367], ["aten::add_", "[[1024, 256, 1, 1], [1024, 256, 1, 1], []]", 132, 471, 471, 12264, 12264], ["aten::add", "[[], [], []]", 424, 455, 455, 57672, 74141], ["aten::add_", "[[256, 1024, 1, 1], [256, 1024, 1, 1], []]", 110, 450, 450, 10288, 10288], ["aten::copy_", "[[], [], []]", 1192, 424, 424, 70514, 70514], ["aten::copy_", "[[256], [256], []]", 320, 422, 422, 27847, 27847], ["aten::threshold_backward", "[[32, 512, 14, 14], [32, 512, 14, 14], []]", 8, 410, 410, 1060, 1394], ["aten::_cat", "[[], []]", 24, 394, 394, 4210564, 4219527], ["aten::add", "[[2048, 512, 1, 1], [2048, 512, 1, 1], []]", 24, 383, 383, 3255, 4259], ["aten::cudnn_batch_norm", "[[32, 512, 14, 14], [512], [512], [512], [512], [], [], []]", 8, 370, 370, 3823, 5817], ["aten::add_", "[[2048], [2048], []]", 176, 354, 354, 19021, 19021], ["aten::mean", "[[32, 2048, 7, 7], [], [], []]", 8, 345, 345, 4636, 4967], ["aten::fill_", "[[512, 512, 3, 3], []]", 21, 315, 315, 1003, 1003], ["aten::threshold_", "[[32, 512, 7, 7], [], []]", 40, 276, 276, 2353, 2353], ["aten::add_", "[[128, 128, 3, 3], [128, 128, 3, 3], []]", 88, 276, 276, 8200, 8200], ["aten::addmm", "[[1000], [32, 2048], [2048, 1000], [], []]", 8, 272, 272, 856337, 859710], ["aten::copy_", "[[512], [512], []]", 220, 270, 270, 19241, 19241], ["aten::add", "[[256], [256], []]", 256, 256, 256, 33573, 43701], ["aten::add", "[[512, 2048, 1, 1], [512, 2048, 1, 1], []]", 16, 256, 256, 2082, 2743], ["aten::mul_", "[[256, 256, 3, 3], []]", 42, 256, 256, 4525, 4525], ["aten::add", "[[2048, 1024, 1, 1], [2048, 1024, 1, 1], []]", 8, 249, 249, 1040, 1363], ["aten::threshold_", "[[32, 512, 14, 14], [], []]", 8, 244, 244, 491, 491], ["aten::add", "[[1000, 2048], [1000, 2048], []]", 8, 240, 240, 1097, 1664], ["aten::mul_", "[[2048, 512, 1, 1], []]", 21, 231, 231, 2248, 2248], ["aten::div", "[[32, 2048, 7, 7], []]", 8, 230, 230, 1843, 2319], ["aten::add", "[[1024, 256, 1, 1], [1024, 256, 1, 1], []]", 48, 226, 226, 6332, 8330], ["aten::mm", "[[32, 1000], [1000, 2048]]", 8, 226, 226, 2310, 2805], ["aten::mul_", "[[256], []]", 224, 224, 224, 23316, 23316], ["aten::copy_", "[[128], [128], []]", 160, 217, 217, 14137, 14137], ["aten::add_", "[[512, 128, 1, 1], [512, 128, 1, 1], []]", 88, 197, 197, 8296, 8296], ["aten::copy_", "[[1024], [1024], []]", 140, 196, 196, 12222, 12222], ["aten::add", "[[512], [512], []]", 176, 176, 176, 23132, 30126], ["aten::add", "[[256, 1024, 1, 1], [256, 1024, 1, 1], []]", 40, 175, 175, 5297, 6947], ["aten::add_", "[[256, 64, 1, 1], [256, 64, 1, 1], []]", 88, 172, 172, 8447, 8447], ["aten::copy_", "[[512, 512, 3, 3], [512, 512, 3, 3], []]", 6, 169, 169, 519, 519], ["aten::fill_", "[[256, 256, 3, 3], []]", 42, 168, 168, 2105, 2105], ["aten::copy_", "[[64], [64], []]", 140, 161, 161, 12977, 12977], ["aten::add_", "[[512, 1024, 1, 1], [512, 1024, 1, 1], []]", 22, 158, 158, 2037, 2037], ["aten::mul_", "[[512], []]", 154, 154, 154, 17275, 17275], ["aten::mul_", "[[512, 2048, 1, 1], []]", 14, 153, 153, 1503, 1503], ["aten::mm", "[[1000, 32], [32, 2048]]", 8, 153, 153, 1395, 1871], ["aten::mul_", "[[2048, 1024, 1, 1], []]", 7, 149, 149, 841, 841], ["aten::fill_", "[[2048, 512, 1, 1], []]", 21, 147, 147, 976, 976], ["aten::mul_", "[[1000, 2048], []]", 7, 147, 147, 873, 873], ["aten::add_", "[[128, 512, 1, 1], [128, 512, 1, 1], []]", 66, 145, 145, 6069, 6069], ["aten::mul_", "[[1024, 256, 1, 1], []]", 42, 138, 138, 4550, 4550], ["aten::add_", "[[64, 64, 3, 3], [64, 64, 3, 3], []]", 66, 131, 131, 6128, 6128], ["aten::add", "[[128], [128], []]", 128, 128, 128, 16843, 21894], ["aten::add_", "[[1024, 512, 1, 1], [1024, 512, 1, 1], []]", 22, 123, 123, 2001, 2001], ["aten::add", "[[64], [64], []]", 112, 112, 112, 14921, 19491], ["aten::add", "[[1024], [1024], []]", 112, 112, 112, 15277, 20017], ["aten::mul_", "[[128], []]", 112, 112, 112, 12235, 12235], ["aten::mul_", "[[256, 1024, 1, 1], []]", 35, 108, 108, 3804, 3804], ["aten::fill_", "[[512, 2048, 1, 1], []]", 14, 98, 98, 679, 679], ["aten::mul_", "[[64], []]", 98, 98, 98, 10870, 10870], ["aten::mul_", "[[1024], []]", 98, 98, 98, 11041, 11041], ["aten::fill_", "[[256], []]", 224, 96, 96, 11134, 11134], ["aten::copy_", "[[2048], [2048], []]", 80, 94, 94, 6905, 6905], ["aten::fill_", "[[2048, 1024, 1, 1], []]", 7, 91, 91, 326, 326], ["aten::fill_", "[[1000, 2048], []]", 7, 91, 91, 412, 412], ["aten::add_", "[[64, 256, 1, 1], [64, 256, 1, 1], []]", 44, 88, 88, 4021, 4021], ["aten::add", "[[128, 128, 3, 3], [128, 128, 3, 3], []]", 32, 88, 88, 4436, 5774], ["aten::fill_", "[[512], []]", 154, 87, 87, 7313, 7313], ["aten::_log_softmax_backward_data", "[[32, 1000], [32, 1000], [], [32, 1000]]", 8, 85, 85, 1173, 2042], ["aten::fill_", "[[1024, 256, 1, 1], []]", 42, 84, 84, 2130, 2130], ["aten::add_", "[[256, 512, 1, 1], [256, 512, 1, 1], []]", 22, 81, 81, 2070, 2070], ["aten::_log_softmax", "[[32, 1000], [], []]", 8, 80, 80, 1839, 2626], ["aten::fill_", "[[128], []]", 112, 76, 76, 5414, 5414], ["aten::copy_", "[[256, 256, 3, 3], [256, 256, 3, 3], []]", 12, 74, 74, 1014, 1014], ["aten::add", "[[512, 1024, 1, 1], [512, 1024, 1, 1], []]", 8, 73, 73, 1094, 1448], ["aten::add", "[[1024, 512, 1, 1], [1024, 512, 1, 1], []]", 8, 72, 72, 1054, 1390], ["aten::fill_", "[[256, 1024, 1, 1], []]", 35, 70, 70, 1715, 1715], ["aten::copy_", "[[2048, 512, 1, 1], [2048, 512, 1, 1], []]", 6, 65, 65, 572, 572], ["aten::add", "[[2048], [2048], []]", 64, 65, 65, 8850, 11400], ["aten::add", "[[512, 128, 1, 1], [512, 128, 1, 1], []]", 32, 64, 64, 4308, 5649], ["aten::add_", "[[512, 256, 1, 1], [512, 256, 1, 1], []]", 22, 63, 63, 2172, 2172], ["aten::fill_", "[[1024], []]", 98, 57, 57, 4808, 4808], ["aten::mul_", "[[128, 128, 3, 3], []]", 28, 56, 56, 3003, 3003], ["aten::mul_", "[[2048], []]", 56, 56, 56, 5924, 5924], ["aten::fill_", "[[64], []]", 98, 55, 55, 4775, 4775], ["aten::copy_", "[[1024, 256, 1, 1], [1024, 256, 1, 1], []]", 12, 54, 54, 1058, 1058], ["aten::copy_", "[[512, 2048, 1, 1], [512, 2048, 1, 1], []]", 4, 54, 54, 362, 362], ["aten::add", "[[128, 512, 1, 1], [128, 512, 1, 1], []]", 24, 48, 48, 3301, 4364], ["aten::copy_", "[[2048, 1024, 1, 1], [2048, 1024, 1, 1], []]", 2, 48, 48, 177, 177], ["aten::copy_", "[[256, 1024, 1, 1], [256, 1024, 1, 1], []]", 10, 47, 47, 877, 877], ["aten::add_", "[[64, 3, 7, 7], [64, 3, 7, 7], []]", 22, 45, 45, 2297, 2297], ["aten::copy_", "[[1000, 2048], [1000, 2048], []]", 2, 45, 45, 191, 191], ["aten::add_", "[[128, 256, 1, 1], [128, 256, 1, 1], []]", 22, 44, 44, 2058, 2058], ["aten::add_", "[[64, 64, 1, 1], [64, 64, 1, 1], []]", 22, 43, 43, 2053, 2053], ["aten::mul_", "[[1024, 512, 1, 1], []]", 7, 38, 38, 754, 754], ["aten::mul_", "[[512, 1024, 1, 1], []]", 7, 38, 38, 1163, 1163], ["aten::nll_loss_forward", "[[32, 1000], [32], [], [], []]", 8, 32, 32, 1884, 1884], ["aten::add", "[[256, 64, 1, 1], [256, 64, 1, 1], []]", 32, 32, 32, 4231, 5568], ["aten::fill_", "[[256, 64, 1, 1], []]", 28, 28, 28, 1314, 1314], ["aten::fill_", "[[128, 128, 3, 3], []]", 28, 28, 28, 1347, 1347], ["aten::fill_", "[[512, 128, 1, 1], []]", 28, 28, 28, 1316, 1316], ["aten::fill_", "[[1024, 512, 1, 1], []]", 7, 28, 28, 459, 459], ["aten::fill_", "[[512, 1024, 1, 1], []]", 7, 28, 28, 345, 345], ["aten::mul_", "[[256, 64, 1, 1], []]", 28, 28, 28, 3131, 3131], ["aten::mul_", "[[512, 128, 1, 1], []]", 28, 28, 28, 3052, 3052], ["aten::copy_", "[[32], [32], []]", 16, 25, 25, 1465, 1465], ["aten::add", "[[64, 64, 3, 3], [64, 64, 3, 3], []]", 24, 24, 24, 3116, 4145], ["aten::add", "[[512, 256, 1, 1], [512, 256, 1, 1], []]", 8, 24, 24, 1168, 1537], ["aten::nll_loss_backward", "[[], [32, 1000], [32], [], [], [], []]", 8, 24, 24, 1406, 1406], ["aten::add", "[[256, 512, 1, 1], [256, 512, 1, 1], []]", 8, 22, 22, 1077, 1401], ["aten::add_", "[[1000], [1000], []]", 22, 22, 22, 2289, 2289], ["aten::copy_", "[[128, 128, 3, 3], [128, 128, 3, 3], []]", 8, 21, 21, 726, 726], ["aten::fill_", "[[64, 64, 3, 3], []]", 21, 21, 21, 990, 990], ["aten::fill_", "[[128, 512, 1, 1], []]", 21, 21, 21, 981, 981], ["aten::mul_", "[[64, 64, 3, 3], []]", 21, 21, 21, 2258, 2258], ["aten::mul_", "[[128, 512, 1, 1], []]", 21, 21, 21, 2330, 2330], ["aten::fill_", "[[2048], []]", 56, 20, 20, 2724, 2724], ["aten::add", "[[64, 256, 1, 1], [64, 256, 1, 1], []]", 16, 16, 16, 2176, 2827], ["aten::fill_", "[[64, 256, 1, 1], []]", 14, 14, 14, 652, 652], ["aten::mul_", "[[64, 256, 1, 1], []]", 14, 14, 14, 1533, 1533], ["aten::mul_", "[[512, 256, 1, 1], []]", 7, 14, 14, 796, 796], ["aten::mul_", "[[256, 512, 1, 1], []]", 7, 14, 14, 755, 755], ["aten::_local_scalar_dense", "[[]]", 1497, 13, 13, 31540, 31540], ["aten::copy_", "[[1024, 512, 1, 1], [1024, 512, 1, 1], []]", 2, 11, 11, 173, 173], ["aten::copy_", "[[512, 1024, 1, 1], [512, 1024, 1, 1], []]", 2, 10, 10, 172, 172], ["aten::copy_", "[[512, 128, 1, 1], [512, 128, 1, 1], []]", 8, 9, 9, 697, 697], ["aten::copy_", "[[128, 512, 1, 1], [128, 512, 1, 1], []]", 6, 9, 9, 511, 511], ["aten::add", "[[1000], [1000], []]", 8, 9, 9, 1107, 1563], ["aten::fill_", "[[], []]", 8, 8, 8, 447, 447], ["aten::add", "[[64, 3, 7, 7], [64, 3, 7, 7], []]", 8, 8, 8, 1163, 1512], ["aten::add", "[[64, 64, 1, 1], [64, 64, 1, 1], []]", 8, 8, 8, 1047, 1382], ["aten::copy_", "[[256, 64, 1, 1], [256, 64, 1, 1], []]", 8, 8, 8, 690, 690], ["aten::add", "[[128, 256, 1, 1], [128, 256, 1, 1], []]", 8, 8, 8, 1056, 1389], ["aten::copy_", "[[128, 256, 1, 1], [128, 256, 1, 1], []]", 2, 7, 7, 175, 175], ["aten::fill_", "[[64, 3, 7, 7], []]", 7, 7, 7, 399, 399], ["aten::fill_", "[[128, 256, 1, 1], []]", 7, 7, 7, 327, 327], ["aten::fill_", "[[512, 256, 1, 1], []]", 7, 7, 7, 323, 323], ["aten::fill_", "[[256, 512, 1, 1], []]", 7, 7, 7, 323, 323], ["aten::fill_", "[[1000], []]", 7, 7, 7, 327, 327], ["aten::mul_", "[[64, 3, 7, 7], []]", 7, 7, 7, 808, 808], ["aten::mul_", "[[64, 64, 1, 1], []]", 7, 7, 7, 746, 746], ["aten::mul_", "[[128, 256, 1, 1], []]", 7, 7, 7, 848, 848], ["aten::mul_", "[[1000], []]", 7, 7, 7, 936, 936], ["aten::copy_", "[[64, 64, 3, 3], [64, 64, 3, 3], []]", 6, 6, 6, 518, 518], ["aten::copy_", "[[64, 256, 1, 1], [64, 256, 1, 1], []]", 4, 5, 5, 337, 337], ["aten::copy_", "[[256, 512, 1, 1], [256, 512, 1, 1], []]", 2, 5, 5, 169, 169], ["aten::copy_", "[[64, 64, 1, 1], [64, 64, 1, 1], []]", 2, 3, 3, 191, 191], ["aten::copy_", "[[512, 256, 1, 1], [512, 256, 1, 1], []]", 2, 3, 3, 197, 197], ["aten::copy_", "[[162], [162], []]", 2, 3, 3, 28229, 28229], ["aten::copy_", "[[5], [5], []]", 2, 3, 3, 230, 230], ["aten::copy_", "[[64, 3, 7, 7], [64, 3, 7, 7], []]", 2, 2, 2, 174, 174], ["aten::copy_", "[[1000], [1000], []]", 2, 2, 2, 192, 192], ["aten::fill_", "[[64, 64, 1, 1], []]", 7, 1, 1, 355, 355], ["aten::empty", "[[], [], [], [], [], []]", 13266, 0, 0, 458342, 458342], ["aten::random_", "[[], []]", 1, 0, 0, 121, 121], ["aten::is_floating_point", "[[]]", 9, 0, 0, 131, 131], ["aten::item", "[[]]", 1497, 0, 13, 33233, 64773], ["aten::fill_", "[[1], []]", 288, 0, 0, 4990, 4990], ["aten::zero_", "[[1]]", 32, 0, 0, 1052, 1599], ["aten::zeros", "[[], [], [], [], []]", 32, 0, 0, 2261, 4527], ["aten::uniform_", "[[1], [], [], []]", 976, 0, 0, 56898, 56898], ["aten::is_floating_point", "[[1]]", 1232, 0, 0, 13051, 13051], ["aten::_local_scalar_dense", "[[1]]", 1488, 0, 0, 43799, 43799], ["aten::item", "[[1]]", 1488, 0, 0, 29196, 72995], ["aten::to", "[[2], [], [], [], [], []]", 360, 0, 0, 5429, 5429], ["detach_", "[[2]]", 360, 0, 0, 4691, 4691], ["aten::detach_", "[[2]]", 360, 0, 0, 6449, 11140], ["aten::log", "[[2]]", 360, 0, 0, 33642, 40627], ["aten::as_strided", "[[2], [], [], []]", 720, 0, 0, 9919, 9919], ["aten::select", "[[2], [], []]", 720, 0, 0, 58985, 68904], ["aten::resize_", "[[0], [], []]", 1176, 0, 0, 24049, 24049], ["aten::exp", "[[0], [1]]", 360, 0, 0, 24502, 30460], ["aten::exp", "[[1]]", 360, 0, 0, 31708, 68577], ["aten::random_", "[[1], [], [], []]", 512, 0, 0, 15826, 15826], ["aten::randint", "[[], [], [], [], [], [], [], []]", 512, 0, 0, 39627, 65058], ["aten::rand", "[[], [], [], [], []]", 256, 0, 0, 17684, 32532], ["aten::empty_strided", "[[], [], [], [], [], []]", 1626, 0, 0, 306944, 306944], ["aten::to", "[[], [], [], [], []]", 768, 0, 0, 52584, 101676], ["aten::lt", "[[0], [1], []]", 256, 0, 0, 26569, 71476], ["aten::lt", "[[1], []]", 256, 0, 0, 26814, 102158], ["aten::is_nonzero", "[[1]]", 256, 0, 0, 5909, 18580], ["aten::set_", "[[], []]", 256, 0, 0, 18337, 18337], ["aten::view", "[[150528], []]", 256, 0, 0, 17870, 17870], ["aten::as_strided", "[[224, 224, 3], [], [], []]", 256, 0, 0, 4223, 4223], ["aten::permute", "[[224, 224, 3], []]", 256, 0, 0, 22261, 26484], ["aten::empty_like", "[[3, 224, 224], [], [], [], [], []]", 256, 0, 0, 11162, 16336], ["aten::copy_", "[[3, 224, 224], [3, 224, 224], []]", 768, 0, 0, 4279740, 4279740], ["aten::contiguous", "[[3, 224, 224], []]", 256, 0, 0, 16127, 1252772], ["aten::to", "[[3, 224, 224], [], [], [], []]", 256, 0, 0, 22142, 2058888], ["aten::div", "[[3, 224, 224], []]", 256, 0, 0, 1035539, 1077151], ["aten::clone", "[[3, 224, 224], []]", 256, 0, 0, 39120, 1075822], ["aten::to", "[[3], [], [], [], [], []]", 512, 0, 0, 8976, 8976], ["aten::eq", "[[0], [3], []]", 256, 0, 0, 26085, 73070], ["aten::eq", "[[3], []]", 256, 0, 0, 24571, 101299], ["aten::as_strided", "[[], [], [], []]", 256, 0, 0, 3920, 3920], ["aten::any", "[[3]]", 256, 0, 0, 44223, 60951], ["aten::is_nonzero", "[[]]", 256, 0, 0, 5563, 17311], ["aten::view", "[[3], []]", 512, 0, 0, 35240, 35240], ["aten::sub_", "[[3, 224, 224], [3, 1, 1], []]", 256, 0, 0, 947087, 947087], ["aten::div_", "[[3, 224, 224], [3, 1, 1]]", 256, 0, 0, 1152229, 1152229], ["aten::as_strided", "[[3, 224, 224], [], [], []]", 256, 0, 0, 3156, 3156], ["aten::unsqueeze", "[[3, 224, 224], []]", 256, 0, 0, 8270, 11426], ["aten::as_strided", "[[32, 3, 224, 224], [], [], []]", 8, 0, 0, 115, 115], ["aten::slice", "[[32, 3, 224, 224], [], [], [], []]", 8, 0, 0, 333, 448], ["aten::narrow", "[[32, 3, 224, 224], [], [], []]", 8, 0, 0, 207, 655], ["aten::stride", "[[32, 3, 224, 224], []]", 72, 0, 0, 503, 503], ["aten::cat", "[[], []]", 24, 0, 394, 3242, 4222769], ["aten::stack", "[[], []]", 8, 0, 0, 4813, 1076465], ["aten::to", "[[32], [], [], [], [], []]", 8, 0, 0, 214, 214], ["detach_", "[[32]]", 8, 0, 0, 188, 188], ["aten::detach_", "[[32]]", 8, 0, 0, 157, 345], ["aten::is_pinned", "[[32, 3, 224, 224]]", 8, 0, 0, 753, 753], ["aten::set_", "[[0], [], [], [], []]", 16, 0, 0, 934, 934], ["aten::pin_memory", "[[32, 3, 224, 224]]", 8, 0, 0, 18151, 112348], ["aten::is_pinned", "[[32]]", 8, 0, 0, 367, 367], ["aten::pin_memory", "[[32]]", 8, 0, 0, 1464, 3115], ["aten::to", "[[32, 3, 224, 224], [], [], [], [], [], [], []]", 16, 0, 13482, 876, 2782], ["aten::to", "[[32], [], [], [], [], [], [], []]", 8, 0, 25, 571, 1773], ["aten::contiguous", "[[64], []]", 336, 0, 0, 3853, 3853], ["aten::view", "[[64], []]", 336, 0, 0, 15066, 15066], ["aten::contiguous", "[[256], []]", 768, 0, 0, 9261, 9261], ["aten::view", "[[256], []]", 768, 0, 0, 34092, 34092], ["aten::contiguous", "[[128], []]", 384, 0, 0, 4316, 4316], ["aten::view", "[[128], []]", 384, 0, 0, 16842, 16842], ["aten::contiguous", "[[512], []]", 528, 0, 0, 5907, 5907], ["aten::view", "[[512], []]", 528, 0, 0, 24580, 24580], ["aten::contiguous", "[[1024], []]", 336, 0, 0, 3925, 3925], ["aten::view", "[[1024], []]", 336, 0, 0, 14455, 14455], ["aten::contiguous", "[[2048], []]", 192, 0, 0, 2450, 2450], ["aten::view", "[[2048], []]", 192, 0, 0, 8356, 8356], ["aten::stride", "[[64], []]", 112, 0, 0, 609, 609], ["aten::stride", "[[256], []]", 256, 0, 0, 1314, 1314], ["aten::stride", "[[128], []]", 128, 0, 0, 664, 664], ["aten::stride", "[[512], []]", 176, 0, 0, 890, 890], ["aten::stride", "[[1024], []]", 112, 0, 0, 546, 546], ["aten::stride", "[[2048], []]", 64, 0, 0, 318, 318], ["aten::stride", "[[53120], []]", 16, 0, 0, 86, 86], ["nccl:broadcast", "[]", 18, 0, 0, 555, 555], ["aten::contiguous", "[[], []]", 424, 0, 0, 5915, 5915], ["aten::view", "[[], []]", 424, 0, 0, 22539, 22539], ["aten::stride", "[[1], []]", 424, 0, 0, 2251, 2251], ["aten::stride", "[[53], []]", 16, 0, 0, 89, 89], ["aten::as_strided", "[[53120], [], [], []]", 848, 0, 0, 10502, 10502], ["aten::slice", "[[53120], [], [], [], []]", 848, 0, 0, 62980, 73482], ["aten::narrow", "[[53120], [], [], []]", 848, 0, 0, 21564, 95046], ["aten::as_strided", "[[53], [], [], []]", 424, 0, 0, 5750, 5750], ["aten::slice", "[[53], [], [], [], []]", 424, 0, 0, 27850, 33600], ["aten::narrow", "[[53], [], [], []]", 424, 0, 0, 11636, 45236], ["aten::view", "[[1], []]", 424, 0, 0, 23021, 23021], ["aten::contiguous", "[[32, 3, 224, 224], []]", 24, 0, 0, 281, 281], ["aten::contiguous", "[[64, 3, 7, 7], []]", 8, 0, 0, 136, 136], ["aten::resize_", "[[64, 3, 7, 7], [], []]", 8, 0, 0, 98, 98], ["aten::resize_", "[[32, 3, 224, 224], [], []]", 16, 0, 0, 153, 153], ["aten::_convolution", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 15638, 847, 2356063], ["aten::convolution", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], []]", 8, 0, 15638, 378, 2356441], ["aten::conv2d", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], []]", 8, 0, 15638, 449, 2356890], ["aten::contiguous", "[[32, 64, 112, 112], []]", 56, 0, 0, 860, 860], ["aten::empty_like", "[[32, 64, 112, 112], [], [], [], [], []]", 16, 0, 0, 734, 1384], ["aten::_batch_norm_impl_index", "[[32, 64, 112, 112], [64], [64], [64], [64], [], [], [], []]", 8, 0, 3416, 1105, 78091], ["aten::batch_norm", "[[32, 64, 112, 112], [64], [64], [64], [64], [], [], [], []]", 8, 0, 3416, 433, 78524], ["aten::relu_", "[[32, 64, 112, 112]]", 8, 0, 1996, 1076, 1720], ["aten::stride", "[[32, 64, 112, 112], []]", 64, 0, 0, 368, 368], ["aten::max_pool2d", "[[32, 64, 112, 112], [], [], [], [], []]", 8, 0, 1783, 450, 5136], ["aten::contiguous", "[[32, 64, 56, 56], []]", 488, 0, 0, 6147, 6147], ["aten::contiguous", "[[64, 64, 1, 1], []]", 16, 0, 0, 223, 223], ["aten::resize_", "[[64, 64, 1, 1], [], []]", 16, 0, 0, 187, 187], ["aten::resize_", "[[32, 64, 56, 56], [], []]", 224, 0, 0, 2267, 2267], ["aten::stride", "[[32, 64, 56, 56], []]", 792, 0, 0, 5422, 5422], ["aten::_convolution", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 2814, 777, 10476], ["aten::convolution", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], []]", 8, 0, 2814, 336, 10812], ["aten::conv2d", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], []]", 8, 0, 2814, 404, 11216], ["aten::empty_like", "[[32, 64, 56, 56], [], [], [], [], []]", 48, 0, 0, 2346, 4376], ["aten::_batch_norm_impl_index", "[[32, 64, 56, 56], [64], [64], [64], [64], [], [], [], []]", 48, 0, 5326, 6207, 43099], ["aten::batch_norm", "[[32, 64, 56, 56], [64], [64], [64], [64], [], [], [], []]", 48, 0, 5326, 2308, 45407], ["aten::relu_", "[[32, 64, 56, 56]]", 48, 0, 3049, 6016, 8968], ["aten::contiguous", "[[64, 64, 3, 3], []]", 48, 0, 0, 686, 686], ["aten::resize_", "[[64, 64, 3, 3], [], []]", 48, 0, 0, 548, 548], ["aten::_convolution", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 24, 0, 15313, 2233, 27706], ["aten::convolution", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], []]", 24, 0, 15313, 1043, 28749], ["aten::conv2d", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], []]", 24, 0, 15313, 1215, 29964], ["aten::contiguous", "[[256, 64, 1, 1], []]", 64, 0, 0, 919, 919], ["aten::resize_", "[[256, 64, 1, 1], [], []]", 64, 0, 0, 922, 922], ["aten::_convolution", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 32, 0, 15955, 3401, 35987], ["aten::convolution", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], []]", 32, 0, 15955, 1559, 37546], ["aten::conv2d", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], []]", 32, 0, 15955, 1764, 39310], ["aten::contiguous", "[[32, 256, 56, 56], []]", 288, 0, 0, 3323, 3323], ["aten::empty_like", "[[32, 256, 56, 56], [], [], [], [], []]", 32, 0, 0, 1905, 3227], ["aten::_batch_norm_impl_index", "[[32, 256, 56, 56], [256], [256], [256], [256], [], [], [], []]", 32, 0, 12820, 4773, 31785], ["aten::batch_norm", "[[32, 256, 56, 56], [256], [256], [256], [256], [], [], [], []]", 32, 0, 12820, 1782, 33567], ["aten::relu_", "[[32, 256, 56, 56]]", 24, 0, 6013, 3178, 4692], ["aten::contiguous", "[[64, 256, 1, 1], []]", 32, 0, 0, 450, 450], ["aten::resize_", "[[64, 256, 1, 1], [], []]", 32, 0, 0, 389, 389], ["aten::resize_", "[[32, 256, 56, 56], [], []]", 128, 0, 0, 1284, 1284], ["aten::stride", "[[32, 256, 56, 56], []]", 384, 0, 0, 2430, 2430], ["aten::_convolution", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 16, 0, 10661, 1467, 21589], ["aten::convolution", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], []]", 16, 0, 10661, 729, 22318], ["aten::conv2d", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], []]", 16, 0, 10661, 884, 23202], ["aten::contiguous", "[[128, 256, 1, 1], []]", 16, 0, 0, 221, 221], ["aten::resize_", "[[128, 256, 1, 1], [], []]", 16, 0, 0, 191, 191], ["aten::_convolution", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 14352, 758, 23364], ["aten::convolution", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], []]", 8, 0, 14352, 356, 23720], ["aten::conv2d", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], []]", 8, 0, 14352, 450, 24170], ["aten::contiguous", "[[32, 128, 56, 56], []]", 72, 0, 0, 838, 838], ["aten::empty_like", "[[32, 128, 56, 56], [], [], [], [], []]", 8, 0, 0, 404, 731], ["aten::_batch_norm_impl_index", "[[32, 128, 56, 56], [128], [128], [128], [128], [], [], [], []]", 8, 0, 1593, 985, 7089], ["aten::batch_norm", "[[32, 128, 56, 56], [128], [128], [128], [128], [], [], [], []]", 8, 0, 1593, 374, 7463], ["aten::relu_", "[[32, 128, 56, 56]]", 8, 0, 1006, 1074, 1539], ["aten::contiguous", "[[128, 128, 3, 3], []]", 64, 0, 0, 974, 974], ["aten::resize_", "[[128, 128, 3, 3], [], []]", 64, 0, 0, 786, 786], ["aten::resize_", "[[32, 128, 56, 56], [], []]", 32, 0, 0, 309, 309], ["aten::stride", "[[32, 128, 56, 56], []]", 96, 0, 0, 617, 617], ["aten::_convolution", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 9767, 725, 19769], ["aten::convolution", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], [], [], []]", 8, 0, 9767, 353, 20122], ["aten::conv2d", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], []]", 8, 0, 9767, 405, 20527], ["aten::contiguous", "[[32, 128, 28, 28], []]", 504, 0, 0, 5915, 5915], ["aten::empty_like", "[[32, 128, 28, 28], [], [], [], [], []]", 56, 0, 0, 2724, 5197], ["aten::_batch_norm_impl_index", "[[32, 128, 28, 28], [128], [128], [128], [128], [], [], [], []]", 56, 0, 2924, 7221, 51070], ["aten::batch_norm", "[[32, 128, 28, 28], [128], [128], [128], [128], [], [], [], []]", 56, 0, 2924, 2706, 53776], ["aten::relu_", "[[32, 128, 28, 28]]", 56, 0, 1852, 6867, 10185], ["aten::contiguous", "[[512, 128, 1, 1], []]", 64, 0, 0, 909, 909], ["aten::resize_", "[[512, 128, 1, 1], [], []]", 64, 0, 0, 770, 770], ["aten::resize_", "[[32, 128, 28, 28], [], []]", 224, 0, 0, 2246, 2246], ["aten::stride", "[[32, 128, 28, 28], []]", 672, 0, 0, 4326, 4326], ["aten::_convolution", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 32, 0, 17502, 2915, 161404], ["aten::convolution", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], []]", 32, 0, 17502, 1411, 162815], ["aten::conv2d", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], []]", 32, 0, 17502, 1567, 164382], ["aten::contiguous", "[[32, 512, 28, 28], []]", 360, 0, 0, 4260, 4260], ["aten::empty_like", "[[32, 512, 28, 28], [], [], [], [], []]", 40, 0, 0, 1872, 4540], ["aten::_batch_norm_impl_index", "[[32, 512, 28, 28], [512], [512], [512], [512], [], [], [], []]", 40, 0, 8352, 5039, 36220], ["aten::batch_norm", "[[32, 512, 28, 28], [512], [512], [512], [512], [], [], [], []]", 40, 0, 8352, 1902, 38122], ["aten::contiguous", "[[512, 256, 1, 1], []]", 16, 0, 0, 227, 227], ["aten::resize_", "[[512, 256, 1, 1], [], []]", 16, 0, 0, 181, 181], ["aten::_convolution", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 7426, 766, 13579], ["aten::convolution", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], [], [], []]", 8, 0, 7426, 356, 13935], ["aten::conv2d", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], []]", 8, 0, 7426, 415, 14350], ["aten::relu_", "[[32, 512, 28, 28]]", 32, 0, 4051, 3793, 5616], ["aten::contiguous", "[[128, 512, 1, 1], []]", 48, 0, 0, 866, 866], ["aten::resize_", "[[128, 512, 1, 1], [], []]", 48, 0, 0, 737, 737], ["aten::resize_", "[[32, 512, 28, 28], [], []]", 160, 0, 0, 1683, 1683], ["aten::stride", "[[32, 512, 28, 28], []]", 480, 0, 0, 3140, 3140], ["aten::_convolution", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 24, 0, 13315, 2204, 27011], ["aten::convolution", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], []]", 24, 0, 13315, 1080, 28091], ["aten::conv2d", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], []]", 24, 0, 13315, 1225, 29316], ["aten::_convolution", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 24, 0, 11702, 2359, 28404], ["aten::convolution", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], []]", 24, 0, 11702, 1048, 29452], ["aten::conv2d", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], []]", 24, 0, 11702, 1238, 30690], ["aten::contiguous", "[[256, 512, 1, 1], []]", 16, 0, 0, 224, 224], ["aten::resize_", "[[256, 512, 1, 1], [], []]", 16, 0, 0, 184, 184], ["aten::_convolution", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 12624, 768, 17269], ["aten::convolution", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], []]", 8, 0, 12624, 338, 17607], ["aten::conv2d", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], []]", 8, 0, 12624, 394, 18001], ["aten::contiguous", "[[32, 256, 28, 28], []]", 72, 0, 0, 828, 828], ["aten::empty_like", "[[32, 256, 28, 28], [], [], [], [], []]", 8, 0, 0, 382, 703], ["aten::_batch_norm_impl_index", "[[32, 256, 28, 28], [256], [256], [256], [256], [], [], [], []]", 8, 0, 828, 995, 6895], ["aten::batch_norm", "[[32, 256, 28, 28], [256], [256], [256], [256], [], [], [], []]", 8, 0, 828, 397, 7292], ["aten::relu_", "[[32, 256, 28, 28]]", 8, 0, 506, 956, 1416], ["aten::contiguous", "[[256, 256, 3, 3], []]", 96, 0, 0, 1470, 1470], ["aten::resize_", "[[256, 256, 3, 3], [], []]", 96, 0, 0, 1110, 1110], ["aten::resize_", "[[32, 256, 28, 28], [], []]", 32, 0, 0, 309, 309], ["aten::stride", "[[32, 256, 28, 28], []]", 96, 0, 0, 581, 581], ["aten::_convolution", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 11226, 715, 12147], ["aten::convolution", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], [], [], []]", 8, 0, 11226, 343, 12490], ["aten::conv2d", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], []]", 8, 0, 11226, 430, 12920], ["aten::contiguous", "[[32, 256, 14, 14], []]", 792, 0, 0, 9144, 9144], ["aten::empty_like", "[[32, 256, 14, 14], [], [], [], [], []]", 88, 0, 0, 4258, 7895], ["aten::_batch_norm_impl_index", "[[32, 256, 14, 14], [256], [256], [256], [256], [], [], [], []]", 88, 0, 1999, 11912, 78694], ["aten::batch_norm", "[[32, 256, 14, 14], [256], [256], [256], [256], [], [], [], []]", 88, 0, 1999, 4207, 82901], ["aten::relu_", "[[32, 256, 14, 14]]", 88, 0, 1031, 10634, 15840], ["aten::contiguous", "[[1024, 256, 1, 1], []]", 96, 0, 0, 1349, 1349], ["aten::resize_", "[[1024, 256, 1, 1], [], []]", 96, 0, 0, 1170, 1170], ["aten::resize_", "[[32, 256, 14, 14], [], []]", 352, 0, 0, 3892, 3892], ["aten::stride", "[[32, 256, 14, 14], []]", 1056, 0, 0, 6696, 6696], ["aten::_convolution", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 48, 0, 23302, 4411, 41393], ["aten::convolution", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], []]", 48, 0, 23302, 2028, 43421], ["aten::conv2d", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], []]", 48, 0, 23302, 2390, 45811], ["aten::contiguous", "[[32, 1024, 14, 14], []]", 504, 0, 0, 5765, 5765], ["aten::empty_like", "[[32, 1024, 14, 14], [], [], [], [], []]", 56, 0, 0, 2724, 6109], ["aten::_batch_norm_impl_index", "[[32, 1024, 14, 14], [1024], [1024], [1024], [1024], [], [], [], []]", 56, 0, 4740, 7148, 56393], ["aten::batch_norm", "[[32, 1024, 14, 14], [1024], [1024], [1024], [1024], [], [], [], []]", 56, 0, 4740, 2657, 59050], ["aten::contiguous", "[[1024, 512, 1, 1], []]", 16, 0, 0, 224, 224], ["aten::resize_", "[[1024, 512, 1, 1], [], []]", 16, 0, 0, 191, 191], ["aten::_convolution", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 8995, 759, 10542], ["aten::convolution", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], [], [], []]", 8, 0, 8995, 333, 10875], ["aten::conv2d", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], []]", 8, 0, 8995, 396, 11271], ["aten::relu_", "[[32, 1024, 14, 14]]", 48, 0, 3028, 5768, 8510], ["aten::contiguous", "[[256, 1024, 1, 1], []]", 80, 0, 0, 1118, 1118], ["aten::resize_", "[[256, 1024, 1, 1], [], []]", 80, 0, 0, 1002, 1002], ["aten::resize_", "[[32, 1024, 14, 14], [], []]", 224, 0, 0, 2246, 2246], ["aten::stride", "[[32, 1024, 14, 14], []]", 672, 0, 0, 4261, 4261], ["aten::_convolution", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 40, 0, 20393, 3691, 34808], ["aten::convolution", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], []]", 40, 0, 20393, 1779, 36587], ["aten::conv2d", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], []]", 40, 0, 20393, 1998, 38585], ["aten::_convolution", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 40, 0, 16978, 3658, 81594], ["aten::convolution", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], []]", 40, 0, 16978, 1827, 83421], ["aten::conv2d", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], []]", 40, 0, 16978, 2255, 85676], ["aten::contiguous", "[[512, 1024, 1, 1], []]", 16, 0, 0, 223, 223], ["aten::resize_", "[[512, 1024, 1, 1], [], []]", 16, 0, 0, 187, 187], ["aten::_convolution", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 14405, 747, 21812], ["aten::convolution", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 0, 14405, 334, 22146], ["aten::conv2d", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], []]", 8, 0, 14405, 396, 22542], ["aten::contiguous", "[[32, 512, 14, 14], []]", 72, 0, 0, 829, 829], ["aten::empty_like", "[[32, 512, 14, 14], [], [], [], [], []]", 8, 0, 0, 377, 918], ["aten::_batch_norm_impl_index", "[[32, 512, 14, 14], [512], [512], [512], [512], [], [], [], []]", 8, 0, 370, 1002, 7206], ["aten::batch_norm", "[[32, 512, 14, 14], [512], [512], [512], [512], [], [], [], []]", 8, 0, 370, 392, 7598], ["aten::relu_", "[[32, 512, 14, 14]]", 8, 0, 244, 992, 1483], ["aten::contiguous", "[[512, 512, 3, 3], []]", 48, 0, 0, 699, 699], ["aten::resize_", "[[512, 512, 3, 3], [], []]", 48, 0, 0, 587, 587], ["aten::resize_", "[[32, 512, 14, 14], [], []]", 32, 0, 0, 307, 307], ["aten::stride", "[[32, 512, 14, 14], []]", 96, 0, 0, 616, 616], ["aten::_convolution", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 15023, 714, 135749], ["aten::convolution", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], [], [], []]", 8, 0, 15023, 342, 136091], ["aten::conv2d", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], []]", 8, 0, 15023, 392, 136483], ["aten::contiguous", "[[32, 512, 7, 7], []]", 360, 0, 0, 4419, 4419], ["aten::empty_like", "[[32, 512, 7, 7], [], [], [], [], []]", 40, 0, 0, 1892, 3591], ["aten::_batch_norm_impl_index", "[[32, 512, 7, 7], [512], [512], [512], [512], [], [], [], []]", 40, 0, 637, 4968, 35460], ["aten::batch_norm", "[[32, 512, 7, 7], [512], [512], [512], [512], [], [], [], []]", 40, 0, 637, 1909, 37369], ["aten::relu_", "[[32, 512, 7, 7]]", 40, 0, 276, 4765, 7118], ["aten::contiguous", "[[2048, 512, 1, 1], []]", 48, 0, 0, 687, 687], ["aten::resize_", "[[2048, 512, 1, 1], [], []]", 48, 0, 0, 560, 560], ["aten::resize_", "[[32, 512, 7, 7], [], []]", 160, 0, 0, 1708, 1708], ["aten::stride", "[[32, 512, 7, 7], []]", 480, 0, 0, 3181, 3181], ["aten::_convolution", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 24, 0, 20275, 2206, 34518], ["aten::convolution", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], []]", 24, 0, 20275, 1018, 35536], ["aten::conv2d", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], []]", 24, 0, 20275, 1194, 36730], ["aten::contiguous", "[[32, 2048, 7, 7], []]", 240, 0, 0, 2989, 2989], ["aten::empty_like", "[[32, 2048, 7, 7], [], [], [], [], []]", 32, 0, 0, 1452, 3014], ["aten::_batch_norm_impl_index", "[[32, 2048, 7, 7], [2048], [2048], [2048], [2048], [], [], [], []]", 32, 0, 1820, 4165, 28406], ["aten::batch_norm", "[[32, 2048, 7, 7], [2048], [2048], [2048], [2048], [], [], [], []]", 32, 0, 1820, 1517, 29923], ["aten::contiguous", "[[2048, 1024, 1, 1], []]", 16, 0, 0, 231, 231], ["aten::resize_", "[[2048, 1024, 1, 1], [], []]", 16, 0, 0, 201, 201], ["aten::_convolution", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 9195, 849, 13261], ["aten::convolution", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 0, 9195, 374, 13635], ["aten::conv2d", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], []]", 8, 0, 9195, 431, 14066], ["aten::relu_", "[[32, 2048, 7, 7]]", 24, 0, 796, 2847, 4185], ["aten::contiguous", "[[512, 2048, 1, 1], []]", 32, 0, 0, 533, 533], ["aten::resize_", "[[512, 2048, 1, 1], [], []]", 32, 0, 0, 531, 531], ["aten::resize_", "[[32, 2048, 7, 7], [], []]", 96, 0, 0, 1059, 1059], ["aten::stride", "[[32, 2048, 7, 7], []]", 192, 0, 0, 1308, 1308], ["aten::_convolution", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 16, 0, 18174, 1486, 28785], ["aten::convolution", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], []]", 16, 0, 18174, 684, 29469], ["aten::conv2d", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], []]", 16, 0, 18174, 805, 30274], ["aten::_convolution", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 16, 0, 15700, 1506, 26310], ["aten::convolution", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], []]", 16, 0, 15700, 736, 27046], ["aten::conv2d", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], []]", 16, 0, 15700, 817, 27863], ["aten::adaptive_avg_pool2d", "[[32, 2048, 7, 7], []]", 8, 0, 345, 411, 5378], ["aten::view", "[[32, 2048, 1, 1], []]", 8, 0, 0, 884, 884], ["aten::reshape", "[[32, 2048, 1, 1], []]", 8, 0, 0, 257, 1141], ["aten::flatten", "[[32, 2048, 1, 1], [], []]", 8, 0, 0, 399, 1540], ["aten::as_strided", "[[1000, 2048], [], [], []]", 16, 0, 0, 267, 267], ["aten::transpose", "[[1000, 2048], [], []]", 16, 0, 0, 553, 820], ["aten::t", "[[1000, 2048]]", 16, 0, 0, 1238, 2058], ["aten::as_strided", "[[1000], [], [], []]", 8, 0, 0, 119, 119], ["aten::expand", "[[1000], [], []]", 8, 0, 0, 388, 507], ["aten::stride", "[[2048, 1000], []]", 8, 0, 0, 106, 106], ["aten::stride", "[[32, 2048], []]", 24, 0, 0, 171, 171], ["aten::stride", "[[32, 1000], []]", 16, 0, 0, 81, 81], ["aten::contiguous", "[[32, 1000], []]", 24, 0, 0, 281, 281], ["aten::empty_like", "[[32, 1000], [], [], [], [], []]", 16, 0, 0, 725, 1375], ["aten::log_softmax", "[[32, 1000], [], []]", 8, 0, 80, 395, 3021], ["aten::nll_loss", "[[32, 1000], [32], [], [], []]", 8, 0, 32, 373, 2257], ["aten::empty_like", "[[], [], [], [], [], []]", 8, 0, 0, 387, 784], ["aten::ones_like", "[[], [], [], [], [], []]", 8, 0, 8, 524, 1755], ["aten::clone", "[[64, 3, 7, 7], []]", 1, 0, 1, 115, 240], ["detach", "[[64, 3, 7, 7]]", 1, 0, 0, 16, 16], ["aten::detach", "[[64, 3, 7, 7]]", 1, 0, 0, 23, 39], ["aten::clone", "[[64], []]", 14, 0, 14, 1682, 3594], ["detach", "[[64]]", 14, 0, 0, 203, 203], ["aten::detach", "[[64]]", 14, 0, 0, 299, 502], ["aten::clone", "[[64, 64, 1, 1], []]", 1, 0, 1, 112, 237], ["detach", "[[64, 64, 1, 1]]", 1, 0, 0, 15, 15], ["aten::detach", "[[64, 64, 1, 1]]", 1, 0, 0, 23, 38], ["aten::clone", "[[64, 64, 3, 3], []]", 3, 0, 3, 332, 697], ["detach", "[[64, 64, 3, 3]]", 3, 0, 0, 46, 46], ["aten::detach", "[[64, 64, 3, 3]]", 3, 0, 0, 65, 111], ["aten::clone", "[[256, 64, 1, 1], []]", 4, 0, 4, 453, 922], ["detach", "[[256, 64, 1, 1]]", 4, 0, 0, 61, 61], ["aten::detach", "[[256, 64, 1, 1]]", 4, 0, 0, 87, 148], ["aten::clone", "[[256], []]", 32, 0, 32, 3508, 7220], ["detach", "[[256]]", 32, 0, 0, 471, 471], ["aten::detach", "[[256]]", 32, 0, 0, 685, 1156], ["aten::clone", "[[64, 256, 1, 1], []]", 2, 0, 2, 226, 461], ["detach", "[[64, 256, 1, 1]]", 2, 0, 0, 31, 31], ["aten::detach", "[[64, 256, 1, 1]]", 2, 0, 0, 43, 74], ["aten::clone", "[[128, 256, 1, 1], []]", 1, 0, 1, 132, 1124], ["detach", "[[128, 256, 1, 1]]", 1, 0, 0, 17, 17], ["aten::detach", "[[128, 256, 1, 1]]", 1, 0, 0, 37, 54], ["aten::clone", "[[128], []]", 16, 0, 16, 1775, 3897], ["detach", "[[128]]", 16, 0, 0, 250, 250], ["aten::detach", "[[128]]", 16, 0, 0, 360, 610], ["aten::clone", "[[128, 128, 3, 3], []]", 4, 0, 8, 444, 1328], ["detach", "[[128, 128, 3, 3]]", 4, 0, 0, 77, 77], ["aten::detach", "[[128, 128, 3, 3]]", 4, 0, 0, 90, 167], ["aten::clone", "[[512, 128, 1, 1], []]", 4, 0, 4, 471, 963], ["detach", "[[512, 128, 1, 1]]", 4, 0, 0, 60, 60], ["aten::detach", "[[512, 128, 1, 1]]", 4, 0, 0, 88, 148], ["aten::clone", "[[512], []]", 22, 0, 22, 2377, 4993], ["detach", "[[512]]", 22, 0, 0, 315, 315], ["aten::detach", "[[512]]", 22, 0, 0, 509, 824], ["aten::clone", "[[512, 256, 1, 1], []]", 1, 0, 1, 117, 525], ["detach", "[[512, 256, 1, 1]]", 1, 0, 0, 15, 15], ["aten::detach", "[[512, 256, 1, 1]]", 1, 0, 0, 23, 38], ["aten::clone", "[[128, 512, 1, 1], []]", 3, 0, 3, 352, 706], ["detach", "[[128, 512, 1, 1]]", 3, 0, 0, 46, 46], ["aten::detach", "[[128, 512, 1, 1]]", 3, 0, 0, 63, 109], ["aten::clone", "[[256, 512, 1, 1], []]", 1, 0, 2, 112, 601], ["detach", "[[256, 512, 1, 1]]", 1, 0, 0, 14, 14], ["aten::detach", "[[256, 512, 1, 1]]", 1, 0, 0, 23, 37], ["aten::clone", "[[256, 256, 3, 3], []]", 6, 0, 20, 663, 1370], ["detach", "[[256, 256, 3, 3]]", 6, 0, 0, 90, 90], ["aten::detach", "[[256, 256, 3, 3]]", 6, 0, 0, 129, 219], ["aten::clone", "[[1024, 256, 1, 1], []]", 6, 0, 13, 706, 125826], ["detach", "[[1024, 256, 1, 1]]", 6, 0, 0, 91, 91], ["aten::detach", "[[1024, 256, 1, 1]]", 6, 0, 0, 130, 221], ["aten::clone", "[[1024], []]", 14, 0, 14, 1544, 3215], ["detach", "[[1024]]", 14, 0, 0, 216, 216], ["aten::detach", "[[1024]]", 14, 0, 0, 301, 517], ["aten::clone", "[[1024, 512, 1, 1], []]", 1, 0, 3, 107, 222], ["detach", "[[1024, 512, 1, 1]]", 1, 0, 0, 15, 15], ["aten::detach", "[[1024, 512, 1, 1]]", 1, 0, 0, 22, 37], ["aten::clone", "[[256, 1024, 1, 1], []]", 5, 0, 10, 571, 1150], ["detach", "[[256, 1024, 1, 1]]", 5, 0, 0, 76, 76], ["aten::detach", "[[256, 1024, 1, 1]]", 5, 0, 0, 119, 195], ["aten::clone", "[[512, 1024, 1, 1], []]", 1, 0, 3, 105, 220], ["detach", "[[512, 1024, 1, 1]]", 1, 0, 0, 15, 15], ["aten::detach", "[[512, 1024, 1, 1]]", 1, 0, 0, 21, 36], ["aten::clone", "[[512, 512, 3, 3], []]", 3, 0, 75, 319, 667], ["detach", "[[512, 512, 3, 3]]", 3, 0, 0, 45, 45], ["aten::detach", "[[512, 512, 3, 3]]", 3, 0, 0, 64, 109], ["aten::clone", "[[2048, 512, 1, 1], []]", 3, 0, 30, 322, 693], ["detach", "[[2048, 512, 1, 1]]", 3, 0, 0, 46, 46], ["aten::detach", "[[2048, 512, 1, 1]]", 3, 0, 0, 68, 114], ["aten::clone", "[[2048], []]", 8, 0, 8, 901, 1846], ["detach", "[[2048]]", 8, 0, 0, 117, 117], ["aten::detach", "[[2048]]", 8, 0, 0, 181, 298], ["aten::clone", "[[2048, 1024, 1, 1], []]", 1, 0, 23, 108, 222], ["detach", "[[2048, 1024, 1, 1]]", 1, 0, 0, 14, 14], ["aten::detach", "[[2048, 1024, 1, 1]]", 1, 0, 0, 23, 37], ["aten::clone", "[[512, 2048, 1, 1], []]", 2, 0, 20, 213, 463], ["detach", "[[512, 2048, 1, 1]]", 2, 0, 0, 30, 30], ["aten::detach", "[[512, 2048, 1, 1]]", 2, 0, 0, 43, 73], ["aten::clone", "[[1000, 2048], []]", 1, 0, 23, 111, 252], ["detach", "[[1000, 2048]]", 1, 0, 0, 16, 16], ["aten::detach", "[[1000, 2048]]", 1, 0, 0, 48, 64], ["aten::clone", "[[1000], []]", 1, 0, 1, 111, 227], ["detach", "[[1000]]", 1, 0, 0, 14, 14], ["aten::detach", "[[1000]]", 1, 0, 0, 21, 35], ["aten::as_strided", "[[2049000], [], [], []]", 2, 0, 0, 137, 137], ["aten::as_strided", "[[7875584], [], [], []]", 15, 0, 0, 845, 845], ["aten::as_strided", "[[6563840], [], [], []]", 12, 0, 0, 684, 684], ["aten::as_strided", "[[6637568], [], [], []]", 51, 0, 0, 2832, 2832], ["aten::as_strided", "[[2431040], [], [], []]", 81, 0, 0, 4367, 4367], ["aten::zero_", "[[64, 3, 7, 7]]", 7, 0, 7, 460, 859], ["aten::zero_", "[[64]]", 98, 0, 55, 5938, 10713], ["aten::zero_", "[[64, 64, 1, 1]]", 7, 0, 1, 421, 776], ["aten::zero_", "[[64, 64, 3, 3]]", 21, 0, 21, 1277, 2267], ["aten::zero_", "[[256, 64, 1, 1]]", 28, 0, 28, 1691, 3005], ["aten::zero_", "[[256]]", 224, 0, 96, 13792, 24926], ["aten::zero_", "[[64, 256, 1, 1]]", 14, 0, 14, 855, 1507], ["aten::zero_", "[[128, 256, 1, 1]]", 7, 0, 7, 427, 754], ["aten::zero_", "[[128]]", 112, 0, 76, 6781, 12195], ["aten::zero_", "[[128, 128, 3, 3]]", 28, 0, 28, 1692, 3039], ["aten::zero_", "[[512, 128, 1, 1]]", 28, 0, 28, 1690, 3006], ["aten::zero_", "[[512]]", 154, 0, 87, 9445, 16758], ["aten::zero_", "[[512, 256, 1, 1]]", 7, 0, 7, 412, 735], ["aten::zero_", "[[128, 512, 1, 1]]", 21, 0, 21, 1307, 2288], ["aten::zero_", "[[256, 512, 1, 1]]", 7, 0, 7, 424, 747], ["aten::zero_", "[[256, 256, 3, 3]]", 42, 0, 168, 2631, 4736], ["aten::zero_", "[[1024, 256, 1, 1]]", 42, 0, 84, 3295, 5425], ["aten::zero_", "[[1024]]", 98, 0, 57, 6358, 11166], ["aten::zero_", "[[1024, 512, 1, 1]]", 7, 0, 28, 448, 907], ["aten::zero_", "[[256, 1024, 1, 1]]", 35, 0, 70, 2189, 3904], ["aten::zero_", "[[512, 1024, 1, 1]]", 7, 0, 28, 423, 768], ["aten::zero_", "[[512, 512, 3, 3]]", 21, 0, 315, 1291, 2294], ["aten::zero_", "[[2048, 512, 1, 1]]", 21, 0, 147, 1311, 2287], ["aten::zero_", "[[2048]]", 56, 0, 20, 3508, 6232], ["aten::zero_", "[[2048, 1024, 1, 1]]", 7, 0, 91, 437, 763], ["aten::zero_", "[[512, 2048, 1, 1]]", 14, 0, 98, 877, 1556], ["aten::zero_", "[[1000, 2048]]", 7, 0, 91, 418, 830], ["aten::zero_", "[[1000]]", 7, 0, 7, 460, 787], ["NllLossBackward", "[[]]", 8, 0, 24, 728, 2134], ["LogSoftmaxBackward", "[[32, 1000]]", 8, 0, 85, 525, 2567], ["aten::as_strided", "[[2048, 1000], [], [], []]", 16, 0, 0, 231, 231], ["aten::transpose", "[[2048, 1000], [], []]", 16, 0, 0, 567, 798], ["aten::t", "[[2048, 1000]]", 16, 0, 0, 876, 1674], ["aten::conj", "[[1000, 2048]]", 8, 0, 0, 176, 176], ["aten::stride", "[[1000, 2048], []]", 16, 0, 0, 126, 126], ["aten::as_strided", "[[32, 1000], [], [], []]", 8, 0, 0, 127, 127], ["aten::transpose", "[[32, 1000], [], []]", 8, 0, 0, 289, 416], ["aten::t", "[[32, 1000]]", 8, 0, 0, 476, 892], ["aten::conj", "[[32, 2048]]", 8, 0, 0, 165, 165], ["aten::stride", "[[1000, 32], []]", 8, 0, 0, 43, 43], ["AddmmBackward", "[[32, 1000]]", 8, 0, 379, 1429, 9007], ["torch::autograd::AccumulateGrad", "[[1000]]", 8, 0, 8, 410, 1233], ["TBackward", "[[2048, 1000]]", 8, 0, 0, 306, 1123], ["torch::autograd::AccumulateGrad", "[[1000, 2048]]", 8, 0, 237, 345, 1176], ["aten::view", "[[32, 2048], []]", 8, 0, 0, 505, 505], ["aten::reshape", "[[32, 2048], []]", 8, 0, 0, 246, 751], ["ViewBackward", "[[32, 2048]]", 8, 0, 0, 317, 1068], ["aten::as_strided", "[[32, 2048, 1, 1], [], [], []]", 8, 0, 0, 152, 152], ["aten::expand", "[[32, 2048, 1, 1], [], []]", 8, 0, 0, 711, 863], ["aten::to", "[[32, 2048, 7, 7], [], [], [], []]", 8, 0, 0, 127, 127], ["MeanBackward1", "[[32, 2048, 1, 1]]", 8, 0, 230, 680, 3989], ["ReluBackward1", "[[32, 2048, 7, 7]]", 24, 0, 1202, 1454, 5763], ["AddBackward0", "[[32, 2048, 7, 7]]", 24, 0, 0, 707, 707], ["CudnnBatchNormBackward", "[[32, 2048, 7, 7]]", 32, 0, 2355, 3844, 23564], ["torch::autograd::AccumulateGrad", "[[2048]]", 64, 0, 244, 2891, 9347], ["aten::cudnn_convolution_backward", "[[32, 512, 7, 7], [32, 2048, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], [], []]", 24, 0, 35505, 4610, 336556], ["CudnnConvolutionBackward", "[[32, 2048, 7, 7]]", 32, 0, 56566, 3358, 504288], ["torch::autograd::AccumulateGrad", "[[2048, 512, 1, 1]]", 24, 0, 381, 1092, 3751], ["ReluBackward1", "[[32, 512, 7, 7]]", 40, 0, 640, 2607, 10863], ["CudnnBatchNormBackward", "[[32, 512, 7, 7]]", 40, 0, 917, 5192, 30941], ["torch::autograd::AccumulateGrad", "[[512]]", 176, 0, 672, 8594, 27711], ["aten::cudnn_convolution_backward", "[[32, 512, 7, 7], [32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], [], []]", 16, 0, 24769, 3179, 88796], ["CudnnConvolutionBackward", "[[32, 512, 7, 7]]", 40, 0, 77236, 3669, 170373], ["torch::autograd::AccumulateGrad", "[[512, 512, 3, 3]]", 24, 0, 872, 1078, 3994], ["aten::cudnn_convolution_backward", "[[32, 2048, 7, 7], [32, 512, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], [], []]", 16, 0, 28274, 3532, 49358], ["torch::autograd::AccumulateGrad", "[[512, 2048, 1, 1]]", 16, 0, 301, 1035, 2658], ["aten::cudnn_convolution_backward", "[[32, 1024, 14, 14], [32, 2048, 7, 7], [2048, 1024, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 21061, 1404, 164374], ["torch::autograd::AccumulateGrad", "[[2048, 1024, 1, 1]]", 8, 0, 265, 371, 1157], ["aten::cudnn_convolution_backward", "[[32, 512, 14, 14], [32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], [], []]", 8, 0, 24193, 1425, 28550], ["ReluBackward1", "[[32, 512, 14, 14]]", 8, 0, 410, 519, 1913], ["CudnnBatchNormBackward", "[[32, 512, 14, 14]]", 8, 0, 739, 907, 5162], ["aten::cudnn_convolution_backward", "[[32, 1024, 14, 14], [32, 512, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 23638, 1359, 29584], ["CudnnConvolutionBackward", "[[32, 512, 14, 14]]", 8, 0, 23638, 668, 30252], ["torch::autograd::AccumulateGrad", "[[512, 1024, 1, 1]]", 8, 0, 97, 373, 1141], ["ReluBackward1", "[[32, 1024, 14, 14]]", 48, 0, 4613, 2988, 12073], ["AddBackward0", "[[32, 1024, 14, 14]]", 48, 0, 0, 1174, 1174], ["CudnnBatchNormBackward", "[[32, 1024, 14, 14]]", 56, 0, 10178, 6518, 36639], ["torch::autograd::AccumulateGrad", "[[1024]]", 112, 0, 474, 4900, 15880], ["aten::cudnn_convolution_backward", "[[32, 256, 14, 14], [32, 1024, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], [], []]", 48, 0, 47634, 8163, 68971], ["CudnnConvolutionBackward", "[[32, 1024, 14, 14]]", 56, 0, 66934, 4750, 98428], ["torch::autograd::AccumulateGrad", "[[1024, 256, 1, 1]]", 48, 0, 307, 2124, 137059], ["ReluBackward1", "[[32, 256, 14, 14]]", 88, 0, 2442, 5525, 21459], ["CudnnBatchNormBackward", "[[32, 256, 14, 14]]", 88, 0, 4199, 11761, 59256], ["torch::autograd::AccumulateGrad", "[[256]]", 256, 0, 1046, 11384, 36313], ["aten::cudnn_convolution_backward", "[[32, 256, 14, 14], [32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], [], []]", 40, 0, 32433, 7112, 64794], ["CudnnConvolutionBackward", "[[32, 256, 14, 14]]", 88, 0, 91064, 7333, 151610], ["torch::autograd::AccumulateGrad", "[[256, 256, 3, 3]]", 48, 0, 459, 2139, 6911], ["aten::cudnn_convolution_backward", "[[32, 1024, 14, 14], [32, 256, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], [], []]", 40, 0, 39174, 6790, 58960], ["torch::autograd::AccumulateGrad", "[[256, 1024, 1, 1]]", 40, 0, 323, 1788, 5749], ["aten::cudnn_convolution_backward", "[[32, 512, 28, 28], [32, 1024, 14, 14], [1024, 512, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 19300, 1366, 24707], ["torch::autograd::AccumulateGrad", "[[1024, 512, 1, 1]]", 8, 0, 63, 349, 1124], ["aten::cudnn_convolution_backward", "[[32, 256, 28, 28], [32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], [], []]", 8, 0, 19457, 1337, 20523], ["ReluBackward1", "[[32, 256, 28, 28]]", 8, 0, 757, 477, 1856], ["CudnnBatchNormBackward", "[[32, 256, 28, 28]]", 8, 0, 1321, 889, 5150], ["aten::cudnn_convolution_backward", "[[32, 512, 28, 28], [32, 256, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 21704, 1500, 28161], ["CudnnConvolutionBackward", "[[32, 256, 28, 28]]", 8, 0, 21704, 653, 28814], ["torch::autograd::AccumulateGrad", "[[256, 512, 1, 1]]", 8, 0, 54, 360, 1182], ["ReluBackward1", "[[32, 512, 28, 28]]", 32, 0, 5951, 2073, 7682], ["AddBackward0", "[[32, 512, 28, 28]]", 32, 0, 0, 859, 859], ["CudnnBatchNormBackward", "[[32, 512, 28, 28]]", 40, 0, 13306, 4677, 26287], ["aten::cudnn_convolution_backward", "[[32, 128, 28, 28], [32, 512, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], [], []]", 32, 0, 31611, 5543, 49218], ["CudnnConvolutionBackward", "[[32, 512, 28, 28]]", 40, 0, 52505, 3376, 73442], ["torch::autograd::AccumulateGrad", "[[512, 128, 1, 1]]", 32, 0, 142, 1390, 4545], ["ReluBackward1", "[[32, 128, 28, 28]]", 56, 0, 2737, 3532, 13371], ["CudnnBatchNormBackward", "[[32, 128, 28, 28]]", 56, 0, 5138, 6393, 36397], ["torch::autograd::AccumulateGrad", "[[128]]", 128, 0, 514, 5672, 18047], ["aten::cudnn_convolution_backward", "[[32, 128, 28, 28], [32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], [], []]", 24, 0, 23912, 4090, 43450], ["CudnnConvolutionBackward", "[[32, 128, 28, 28]]", 56, 0, 70983, 4694, 112924], ["torch::autograd::AccumulateGrad", "[[128, 128, 3, 3]]", 32, 0, 169, 1467, 5841], ["aten::cudnn_convolution_backward", "[[32, 512, 28, 28], [32, 128, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], [], []]", 24, 0, 23882, 4303, 43227], ["torch::autograd::AccumulateGrad", "[[128, 512, 1, 1]]", 24, 0, 106, 1131, 3443], ["aten::cudnn_convolution_backward", "[[32, 256, 56, 56], [32, 512, 28, 28], [512, 256, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 20894, 1357, 20848], ["torch::autograd::AccumulateGrad", "[[512, 256, 1, 1]]", 8, 0, 35, 353, 1257], ["aten::cudnn_convolution_backward", "[[32, 128, 56, 56], [32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], [], []]", 8, 0, 23189, 1390, 21553], ["ReluBackward1", "[[32, 128, 56, 56]]", 8, 0, 1475, 496, 1922], ["CudnnBatchNormBackward", "[[32, 128, 56, 56]]", 8, 0, 2761, 906, 5074], ["aten::cudnn_convolution_backward", "[[32, 256, 56, 56], [32, 128, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 28850, 1439, 41143], ["CudnnConvolutionBackward", "[[32, 128, 56, 56]]", 8, 0, 28850, 681, 41824], ["torch::autograd::AccumulateGrad", "[[128, 256, 1, 1]]", 8, 0, 35, 351, 1138], ["ReluBackward1", "[[32, 256, 56, 56]]", 24, 0, 8811, 1434, 5659], ["AddBackward0", "[[32, 256, 56, 56]]", 24, 0, 0, 596, 596], ["CudnnBatchNormBackward", "[[32, 256, 56, 56]]", 32, 0, 20666, 3628, 21729], ["aten::cudnn_convolution_backward", "[[32, 64, 56, 56], [32, 256, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], [], []]", 32, 0, 36403, 5547, 187161], ["CudnnConvolutionBackward", "[[32, 256, 56, 56]]", 32, 0, 36403, 2616, 189777], ["torch::autograd::AccumulateGrad", "[[256, 64, 1, 1]]", 32, 0, 116, 1418, 4589], ["ReluBackward1", "[[32, 64, 56, 56]]", 48, 0, 4422, 2906, 11186], ["CudnnBatchNormBackward", "[[32, 64, 56, 56]]", 48, 0, 10113, 5410, 31064], ["torch::autograd::AccumulateGrad", "[[64]]", 112, 0, 408, 5610, 16474], ["aten::cudnn_convolution_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], [], []]", 24, 0, 42043, 4236, 46563], ["CudnnConvolutionBackward", "[[32, 64, 56, 56]]", 48, 0, 78943, 3994, 105296], ["torch::autograd::AccumulateGrad", "[[64, 64, 3, 3]]", 24, 0, 89, 1067, 3416], ["aten::cudnn_convolution_backward", "[[32, 256, 56, 56], [32, 64, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], [], []]", 16, 0, 29807, 2728, 36318], ["torch::autograd::AccumulateGrad", "[[64, 256, 1, 1]]", 16, 0, 61, 721, 2247], ["aten::cudnn_convolution_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 7093, 1379, 18421], ["torch::autograd::AccumulateGrad", "[[64, 64, 1, 1]]", 8, 0, 30, 371, 1219], ["aten::zero_", "[[32, 64, 112, 112]]", 8, 0, 1280, 318, 764], ["aten::zeros_like", "[[32, 64, 112, 112], [], [], [], [], []]", 8, 0, 1280, 348, 1767], ["aten::resize_", "[[32, 64, 112, 112], [], []]", 16, 0, 0, 360, 360], ["aten::resize_as_", "[[32, 64, 112, 112], [32, 64, 112, 112], []]", 8, 0, 0, 265, 336], ["MaxPool2DWithIndicesBackward", "[[32, 64, 56, 56]]", 8, 0, 6824, 662, 5564], ["ReluBackward1", "[[32, 64, 112, 112]]", 8, 0, 2960, 470, 1879], ["CudnnBatchNormBackward", "[[32, 64, 112, 112]]", 8, 0, 6524, 941, 5130], ["aten::cudnn_convolution_backward", "[[32, 3, 224, 224], [32, 64, 112, 112], [64, 3, 7, 7], [], [], [], [], [], [], [], []]", 8, 0, 12655, 2165, 14779], ["CudnnConvolutionBackward", "[[32, 64, 112, 112]]", 8, 0, 12655, 1471, 16250], ["torch::autograd::AccumulateGrad", "[[64, 3, 7, 7]]", 8, 0, 31, 517, 1559]]}}, "kernel_op_table": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "string", "name": "Operator"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Total Duration (us)"}, {"type": "number", "name": "Mean Duration (us)"}, {"type": "number", "name": "Max Duration (us)"}, {"type": "number", "name": "Min Duration (us)"}], "rows": [["ncclAllReduceRingLLKernel_sum_f32(ncclColl)", "CallTreeRoot", 40, 1923809, 48095.225, 14203, 124306], ["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", "aten::cudnn_convolution_backward_input", 260, 142275, 547.2115384615385, 151, 1194], ["ncclBroadcastRingLLKernel_copy_i8(ncclColl)", "CallTreeRoot", 18, 135401, 7522.277777777777, 75, 55649], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 248, 123827, 499.3024193548387, 380, 1400], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", "aten::cudnn_batch_norm_backward", 352, 74945, 212.9119318181818, 43, 854], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 124, 55499, 447.5725806451613, 383, 877], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 102, 53430, 523.8235294117648, 362, 936], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", "aten::threshold_backward", 392, 36420, 92.90816326530613, 13, 394], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", "aten::cudnn_convolution_backward_weight", 76, 36207, 476.4078947368421, 328, 731], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", "aten::cudnn_batch_norm", 200, 35259, 176.295, 50, 438], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", "aten::add_", 3670, 33635, 9.164850136239782, 1, 391], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 30, 28805, 960.1666666666666, 877, 1394], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", "aten::threshold_", 392, 23848, 60.83673469387755, 6, 273], ["volta_gcgemm_32x32_nt", "aten::cudnn_convolution", 110, 21908, 199.16363636363636, 20, 2208], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", "CallTreeRoot", 128, 20787, 162.3984375, 47, 396], ["volta_gcgemm_32x32_nt", "aten::cudnn_convolution_backward_input", 29, 19352, 667.3103448275862, 70, 2208], ["volta_sgemm_128x64_nt", "aten::cudnn_convolution_backward_weight", 84, 18145, 216.01190476190476, 172, 673], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 28, 16763, 598.6785714285714, 439, 1012], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", "aten::cudnn_convolution_backward_weight", 24, 16744, 697.6666666666666, 667, 884], ["volta_scudnn_128x64_relu_interior_nn_v1", "aten::cudnn_convolution", 53, 16546, 312.188679245283, 92, 664], ["volta_cgemm_32x32_tn", "aten::cudnn_convolution", 14, 16408, 1172.0, 210, 3113], ["volta_sgemm_128x64_nt", "aten::cudnn_convolution_backward_input", 84, 16261, 193.58333333333334, 156, 211], ["volta_cgemm_32x32_tn", "aten::cudnn_convolution_backward_input", 14, 16111, 1150.7857142857142, 216, 3109], ["volta_sgemm_128x64_nn", "aten::cudnn_convolution", 84, 15974, 190.16666666666666, 157, 207], ["volta_scudnn_128x64_stridedB_interior_nn_v1", "aten::cudnn_convolution_backward_input", 47, 15818, 336.5531914893617, 259, 547], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 22, 13552, 616.0, 213, 1005], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", "aten::cudnn_convolution", 19, 12318, 648.3157894736842, 143, 876], ["volta_cgemm_32x32_tn", "aten::cudnn_convolution_backward_weight", 14, 11505, 821.7857142857143, 216, 1693], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", "aten::cudnn_convolution_backward_input", 28, 10932, 390.42857142857144, 365, 766], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", "aten::cudnn_convolution_backward_weight", 17, 10890, 640.5882352941177, 359, 1116], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", "aten::cudnn_convolution", 28, 10846, 387.35714285714283, 362, 764], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", "aten::cudnn_convolution_backward_input", 266, 10444, 39.26315789473684, 6, 162], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", "aten::cudnn_batch_norm", 224, 9566, 42.705357142857146, 14, 88], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 12, 8529, 710.75, 655, 796], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 11, 8484, 771.2727272727273, 737, 803], ["volta_scudnn_128x64_relu_medium_nn_v1", "aten::cudnn_convolution", 12, 7505, 625.4166666666666, 383, 706], ["volta_scudnn_128x128_stridedB_interior_nn_v1", "aten::cudnn_convolution_backward_input", 25, 7321, 292.84, 275, 299], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", "aten::cudnn_convolution", 11, 6699, 609.0, 305, 725], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", "CallTreeRoot", 1288, 6385, 4.957298136645963, 1, 31], ["volta_cgemm_64x32_tn", "aten::cudnn_convolution_backward_weight", 2, 6329, 3164.5, 3163, 3166], ["void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution_backward_input", 13, 6148, 472.9230769230769, 52, 1637], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", "aten::cudnn_convolution", 10, 6005, 600.5, 569, 672], ["void flip_filter<float, float>(float*, float const*, int, int, int, int)", "aten::cudnn_convolution", 16, 6002, 375.125, 8, 1637], ["volta_scudnn_128x128_stridedB_small_nn_v1", "aten::cudnn_convolution_backward_input", 10, 5823, 582.3, 528, 877], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution_backward_input", 14, 5798, 414.14285714285717, 37, 1590], ["volta_scudnn_128x64_relu_small_nn_v1", "aten::cudnn_convolution", 19, 5646, 297.1578947368421, 268, 589], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution", 14, 5605, 400.35714285714283, 30, 1583], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", "aten::max_pool2d_with_indices_backward", 8, 5544, 693.0, 691, 697], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution_backward_weight", 7, 5509, 787.0, 127, 1671], ["volta_scudnn_128x128_stridedB_medium_nn_v1", "aten::cudnn_convolution_backward_input", 17, 5435, 319.70588235294116, 308, 334], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", "aten::cudnn_convolution", 31, 5387, 173.7741935483871, 77, 447], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", "aten::cudnn_convolution_backward_weight", 15, 5066, 337.73333333333335, 102, 1349], ["volta_scudnn_128x128_relu_interior_nn_v1", "aten::cudnn_convolution", 9, 5006, 556.2222222222222, 552, 562], ["void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution", 8, 4499, 562.375, 15, 1747], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", "aten::cudnn_convolution_backward_input", 9, 4312, 479.1111111111111, 84, 1396], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", "aten::add", 1288, 4199, 3.2600931677018634, 1, 36], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", "aten::cudnn_convolution", 9, 4168, 463.1111111111111, 86, 1380], ["void flip_filter<float, float>(float*, float const*, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 16, 3934, 245.875, 27, 1119], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", "aten::cudnn_convolution_backward_input", 84, 3839, 45.70238095238095, 21, 114], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", "aten::cudnn_convolution_backward_weight", 84, 3770, 44.88095238095238, 20, 137], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", "aten::cudnn_convolution_backward_input", 84, 3653, 43.48809523809524, 19, 134], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", "aten::cudnn_convolution", 84, 3609, 42.964285714285715, 20, 111], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", "aten::cudnn_convolution_backward_weight", 84, 3596, 42.80952380952381, 17, 138], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 5, 6, 4, 3, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", "aten::cudnn_convolution_backward_input", 3, 3531, 1177.0, 1103, 1275], ["void fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)", "aten::cudnn_convolution_backward_input", 28, 3382, 120.78571428571429, 16, 291], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", "aten::cudnn_convolution", 84, 3312, 39.42857142857143, 18, 139], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", "aten::cudnn_batch_norm_backward", 72, 3266, 45.361111111111114, 17, 79], ["void cudnn::detail::dgrad_alg1_engine<float, 128, 6, 8, 3, 3, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)", "aten::cudnn_convolution_backward_input", 1, 3157, 3157.0, 3157, 3157], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution", 10, 3121, 312.1, 88, 939], ["void fft2d_c2r_32x32<float, true, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution", 87, 2997, 34.44827586206897, 23, 126], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", "aten::fill_", 1143, 2975, 2.6027996500437447, 0, 161], ["void fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)", "aten::cudnn_convolution", 16, 2947, 184.1875, 62, 303], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution_backward_input", 10, 2794, 279.4, 88, 877], ["volta_scudnn_128x64_stridedB_small_nn_v1", "aten::cudnn_convolution_backward_input", 12, 2752, 229.33333333333334, 93, 688], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", "aten::mul_", 1127, 2728, 2.4205856255545695, 1, 24], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution", 95, 2715, 28.57894736842105, 12, 205], ["volta_scudnn_128x64_stridedB_splitK_interior_nn_v1", "aten::cudnn_convolution_backward_weight", 3, 2334, 778.0, 566, 892], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", "aten::cudnn_convolution_backward_input", 84, 2109, 25.107142857142858, 4, 71], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", "aten::cudnn_convolution_backward_weight", 84, 2109, 25.107142857142858, 3, 68], ["void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution", 7, 2043, 291.85714285714283, 94, 745], ["void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)", "aten::cudnn_convolution_backward_input", 16, 1966, 122.875, 32, 236], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1", "aten::cudnn_convolution", 3, 1935, 645.0, 573, 681], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", "aten::cudnn_convolution", 84, 1856, 22.095238095238095, 5, 71], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution_backward_weight", 5, 1850, 370.0, 133, 776], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 10, 1830, 183.0, 98, 370], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", "aten::max_pool2d_with_indices", 8, 1783, 222.875, 222, 223], ["volta_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1", "aten::cudnn_convolution_backward_weight", 1, 1668, 1668.0, 1668, 1668], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution_backward_weight", 4, 1635, 408.75, 130, 703], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 4, 6, 3, 2, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", "aten::cudnn_convolution_backward_input", 1, 1606, 1606.0, 1606, 1606], ["void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)", "aten::cudnn_convolution", 16, 1490, 93.125, 36, 216], ["void fft1d_r2c_32<float, float, float2, true, false>(float2*, float const*, int, int3, int3, int2, int2)", "aten::cudnn_convolution", 12, 1465, 122.08333333333333, 20, 406], ["void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution_backward_input", 14, 1388, 99.14285714285714, 47, 193], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 4, 1331, 332.75, 140, 528], ["volta_scudnn_128x64_stridedB_splitK_small_nn_v1", "aten::cudnn_convolution_backward_weight", 2, 1276, 638.0, 635, 641], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution_backward_input", 5, 1214, 242.8, 122, 440], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 14, 1116, 79.71428571428571, 34, 155], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", "aten::cudnn_convolution_backward_input", 1, 1078, 1078.0, 1078, 1078], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution_backward_weight", 8, 1062, 132.75, 72, 236], ["void pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)", "aten::cudnn_convolution", 2, 1054, 527.0, 523, 531], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution", 5, 1011, 202.2, 124, 411], ["void pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)", "aten::cudnn_convolution_backward_input", 2, 993, 496.5, 494, 499], ["void explicit_convolve_sgemm<float, int, 512, 6, 8, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", "aten::cudnn_convolution", 1, 748, 748.0, 748, 748], ["volta_scudnn_128x128_relu_medium_nn_v1", "aten::cudnn_convolution", 2, 719, 359.5, 302, 417], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution_backward_input", 9, 712, 79.11111111111111, 34, 194], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", "aten::cudnn_convolution_backward_input", 112, 704, 6.285714285714286, 2, 14], ["void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution", 9, 701, 77.88888888888889, 50, 181], ["volta_scudnn_128x64_stridedB_medium_nn_v1", "aten::cudnn_convolution_backward_input", 1, 646, 646.0, 646, 646], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1", "aten::cudnn_convolution", 1, 579, 579.0, 579, 579], ["volta_scudnn_128x64_stridedB_splitK_medium_nn_v1", "aten::cudnn_convolution_backward_weight", 1, 543, 543.0, 543, 543], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution_backward_input", 7, 522, 74.57142857142857, 36, 137], ["void cudnn::cnn::wgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)", "aten::cudnn_convolution_backward_weight", 1, 517, 517.0, 517, 517], ["volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1", "aten::cudnn_convolution", 1, 514, 514.0, 514, 514], ["void fft2d_r2c_32x32<float, true, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution_backward_input", 6, 513, 85.5, 53, 144], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", "aten::cudnn_convolution_backward_weight", 124, 466, 3.7580645161290325, 1, 8], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution", 7, 462, 66.0, 33, 132], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", "aten::add", 424, 455, 1.0731132075471699, 1, 3], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", "aten::cudnn_convolution_backward_weight", 124, 440, 3.5483870967741935, 1, 6], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", "aten::cudnn_convolution_backward_input", 112, 431, 3.8482142857142856, 1, 8], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution_backward_input", 3, 350, 116.66666666666667, 82, 146], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", "aten::mean", 8, 345, 43.125, 42, 47], ["void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", "aten::cudnn_convolution", 10, 319, 31.9, 9, 66], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1", "aten::cudnn_convolution", 1, 310, 310.0, 310, 310], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", "aten::cudnn_convolution", 111, 292, 2.630630630630631, 2, 6], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<float, unsigned int, 1, 128, 1>(float*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<float, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", "aten::_cat", 8, 256, 32.0, 31, 35], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", "aten::div", 8, 230, 28.75, 26, 30], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", "aten::cudnn_convolution_backward_input", 28, 220, 7.857142857142857, 4, 37], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution", 2, 211, 105.5, 78, 133], ["volta_sgemm_64x32_sliced1x4_nn", "aten::mm", 8, 209, 26.125, 25, 27], ["volta_sgemm_64x32_sliced1x4_tn", "aten::addmm", 8, 196, 24.5, 24, 28], ["volta_sgemm_128x32_nt", "aten::mm", 8, 153, 19.125, 19, 20], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", "aten::cudnn_convolution", 28, 144, 5.142857142857143, 2, 45], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<long, unsigned int, 1, 128, 1>(long*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<long, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", "aten::_cat", 8, 138, 17.25, 16, 21], ["void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", "aten::cudnn_convolution", 6, 102, 17.0, 9, 36], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", "aten::_log_softmax_backward_data", 8, 85, 10.625, 10, 11], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", "aten::_log_softmax", 8, 80, 10.0, 10, 10], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", "CallTreeRoot", 8, 68, 8.5, 8, 9], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", "aten::addmm", 8, 44, 5.5, 5, 7], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", "aten::nll_loss_forward", 8, 32, 4.0, 4, 4], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", "aten::addmm", 8, 31, 3.875, 3, 4], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", "aten::nll_loss_backward", 8, 16, 2.0, 2, 2], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", "aten::mm", 8, 16, 2.0, 2, 2]]}}, "kernel_pie": {"total": {"columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["ncclAllReduceRingLLKernel_sum_f32(ncclColl)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1923809.0}], ["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 142275.0}], ["ncclBroadcastRingLLKernel_copy_i8(ncclColl)", {"py/object": "numpy.float64", "dtype": "float64", "value": 135401.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 123827.0}], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 74945.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 60268.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 58621.0}], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 55499.0}], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 53430.0}], ["volta_cgemm_32x32_tn", {"py/object": "numpy.float64", "dtype": "float64", "value": 44024.0}], ["volta_gcgemm_32x32_nt", {"py/object": "numpy.float64", "dtype": "float64", "value": 41260.0}], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 36207.0}], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 35259.0}], ["volta_sgemm_128x64_nt", {"py/object": "numpy.float64", "dtype": "float64", "value": 34406.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 28805.0}], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 21778.0}], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 16763.0}], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 16744.0}], ["volta_scudnn_128x64_relu_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 16546.0}], ["volta_sgemm_128x64_nn", {"py/object": "numpy.float64", "dtype": "float64", "value": 15974.0}], ["volta_scudnn_128x64_stridedB_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 15818.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 13552.0}], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 13546.0}], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 12519.0}], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 12318.0}], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 10890.0}], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 10444.0}], ["void flip_filter<float, float>(float*, float const*, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 9936.0}], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", {"py/object": "numpy.float64", "dtype": "float64", "value": 9566.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 9113.0}], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 8529.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 8484.0}], ["void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 8191.0}], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 7745.0}], ["volta_scudnn_128x64_relu_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 7505.0}], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 7448.0}], ["volta_scudnn_128x128_stridedB_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 7321.0}], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 6965.0}], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 6699.0}], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 6493.0}], ["volta_cgemm_64x32_tn", {"py/object": "numpy.float64", "dtype": "float64", "value": 6329.0}], ["void fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)", {"py/object": "numpy.float64", "dtype": "float64", "value": 6329.0}], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 6005.0}], ["volta_scudnn_128x128_stridedB_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 5823.0}], ["volta_scudnn_128x64_relu_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 5646.0}], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 5544.0}], ["volta_scudnn_128x128_stridedB_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 5435.0}], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 5387.0}], ["volta_scudnn_128x128_relu_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 5006.0}], ["void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 4499.0}], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 4489.0}], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 4075.0}], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3965.0}], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3770.0}], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3596.0}], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 5, 6, 4, 3, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3531.0}], ["void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3456.0}], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3266.0}], ["void cudnn::detail::dgrad_alg1_engine<float, 128, 6, 8, 3, 3, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3157.0}], ["void fft2d_c2r_32x32<float, true, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2997.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2975.0}], ["volta_scudnn_128x64_stridedB_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 2752.0}], ["volta_scudnn_128x64_stridedB_splitK_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 2334.0}], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2196.0}], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2109.0}], ["void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2089.0}], ["void pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2047.0}], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 1935.0}], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1783.0}], ["volta_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 1668.0}], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 4, 6, 3, 2, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1606.0}], ["void fft1d_r2c_32<float, float, float2, true, false>(float2*, float const*, int, int3, int3, int2, int2)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1465.0}], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1331.0}], ["volta_scudnn_128x64_stridedB_splitK_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 1276.0}], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1078.0}], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 996.0}], ["void explicit_convolve_sgemm<float, int, 512, 6, 8, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 748.0}], ["volta_scudnn_128x128_relu_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 719.0}], ["volta_scudnn_128x64_stridedB_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 646.0}], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 579.0}], ["volta_scudnn_128x64_stridedB_splitK_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 543.0}], ["void cudnn::cnn::wgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 517.0}], ["volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 514.0}], ["void fft2d_r2c_32x32<float, true, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 513.0}], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 466.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 455.0}], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 440.0}], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 431.0}], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 364.0}], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 345.0}], ["void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 319.0}], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 310.0}], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<float, unsigned int, 1, 128, 1>(float*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<float, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 256.0}], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", {"py/object": "numpy.float64", "dtype": "float64", "value": 230.0}], ["volta_sgemm_64x32_sliced1x4_nn", {"py/object": "numpy.float64", "dtype": "float64", "value": 209.0}], ["volta_sgemm_64x32_sliced1x4_tn", {"py/object": "numpy.float64", "dtype": "float64", "value": 196.0}], ["volta_sgemm_128x32_nt", {"py/object": "numpy.float64", "dtype": "float64", "value": 153.0}], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<long, unsigned int, 1, 128, 1>(long*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<long, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 138.0}], ["void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 102.0}], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 85.0}], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 80.0}], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 68.0}], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 47.0}], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", {"py/object": "numpy.float64", "dtype": "float64", "value": 44.0}], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", {"py/object": "numpy.float64", "dtype": "float64", "value": 32.0}], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", {"py/object": "numpy.float64", "dtype": "float64", "value": 16.0}]]}}, "kernel_table": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Total Duration (us)"}, {"type": "number", "name": "Mean Duration (us)"}, {"type": "number", "name": "Max Duration (us)"}, {"type": "number", "name": "Min Duration (us)"}], "rows": [["ncclAllReduceRingLLKernel_sum_f32(ncclColl)", 40, 1923809, 48095, 124306, 14203], ["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", 260, 142275, 547, 1194, 151], ["ncclBroadcastRingLLKernel_copy_i8(ncclColl)", 18, 135401, 7522, 55649, 75], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 248, 123827, 499, 1400, 380], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", 352, 74945, 213, 854, 43], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", 784, 60268, 77, 394, 6], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", 5086, 58621, 12, 396, 1], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 124, 55499, 448, 877, 383], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 102, 53430, 524, 936, 362], ["volta_cgemm_32x32_tn", 42, 44024, 1048, 3113, 210], ["volta_gcgemm_32x32_nt", 139, 41260, 297, 2208, 20], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", 76, 36207, 476, 731, 328], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", 200, 35259, 176, 438, 50], ["volta_sgemm_128x64_nt", 168, 34406, 205, 673, 156], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 30, 28805, 960, 1394, 877], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", 56, 21778, 389, 766, 362], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 28, 16763, 599, 1012, 439], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", 24, 16744, 698, 884, 667], ["volta_scudnn_128x64_relu_interior_nn_v1", 53, 16546, 312, 664, 92], ["volta_sgemm_128x64_nn", 84, 15974, 190, 207, 157], ["volta_scudnn_128x64_stridedB_interior_nn_v1", 47, 15818, 337, 547, 259], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 22, 13552, 616, 1005, 213], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", 33, 13546, 410, 1396, 84], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", 42, 12519, 298, 1590, 30], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 19, 12318, 648, 876, 143], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", 17, 10890, 641, 1116, 359], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", 266, 10444, 39, 162, 6], ["void flip_filter<float, float>(float*, float const*, int, int, int, int)", 32, 9936, 310, 1637, 8], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", 224, 9566, 43, 88, 14], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", 2415, 9113, 4, 31, 1], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 12, 8529, 711, 796, 655], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 11, 8484, 771, 803, 737], ["void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 20, 8191, 410, 1637, 52], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", 30, 7745, 258, 939, 88], ["volta_scudnn_128x64_relu_medium_nn_v1", 12, 7505, 625, 706, 383], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", 168, 7448, 44, 114, 20], ["volta_scudnn_128x128_stridedB_interior_nn_v1", 25, 7321, 293, 299, 275], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 168, 6965, 41, 139, 18], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 11, 6699, 609, 725, 305], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", 21, 6493, 309, 1671, 33], ["volta_cgemm_64x32_tn", 2, 6329, 3164, 3166, 3163], ["void fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)", 44, 6329, 144, 303, 16], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", 10, 6005, 600, 672, 569], ["volta_scudnn_128x128_stridedB_small_nn_v1", 10, 5823, 582, 877, 528], ["volta_scudnn_128x64_relu_small_nn_v1", 19, 5646, 297, 589, 268], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", 8, 5544, 693, 697, 691], ["volta_scudnn_128x128_stridedB_medium_nn_v1", 17, 5435, 320, 334, 308], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", 31, 5387, 174, 447, 77], ["volta_scudnn_128x128_relu_interior_nn_v1", 9, 5006, 556, 562, 552], ["void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 8, 4499, 562, 1747, 15], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 112, 4489, 40, 236, 12], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", 15, 4075, 272, 776, 122], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", 168, 3965, 24, 71, 4], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 84, 3770, 45, 137, 20], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", 84, 3596, 43, 138, 17], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 5, 6, 4, 3, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 3, 3531, 1177, 1275, 1103], ["void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)", 32, 3456, 108, 236, 32], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", 72, 3266, 45, 79, 17], ["void cudnn::detail::dgrad_alg1_engine<float, 128, 6, 8, 3, 3, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)", 1, 3157, 3157, 3157, 3157], ["void fft2d_c2r_32x32<float, true, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 87, 2997, 34, 126, 23], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", 1143, 2975, 3, 161, 0], ["volta_scudnn_128x64_stridedB_small_nn_v1", 12, 2752, 229, 688, 93], ["volta_scudnn_128x64_stridedB_splitK_interior_nn_v1", 3, 2334, 778, 892, 566], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 9, 2196, 244, 703, 78], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", 84, 2109, 25, 68, 3], ["void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 23, 2089, 91, 193, 47], ["void pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)", 4, 2047, 512, 531, 494], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1", 3, 1935, 645, 681, 573], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", 8, 1783, 223, 223, 222], ["volta_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1", 1, 1668, 1668, 1668, 1668], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 4, 6, 3, 2, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 1, 1606, 1606, 1606, 1606], ["void fft1d_r2c_32<float, float, float2, true, false>(float2*, float const*, int, int3, int3, int2, int2)", 12, 1465, 122, 406, 20], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 4, 1331, 333, 528, 140], ["volta_scudnn_128x64_stridedB_splitK_small_nn_v1", 2, 1276, 638, 641, 635], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 1, 1078, 1078, 1078, 1078], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", 223, 996, 4, 14, 2], ["void explicit_convolve_sgemm<float, int, 512, 6, 8, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 1, 748, 748, 748, 748], ["volta_scudnn_128x128_relu_medium_nn_v1", 2, 719, 360, 417, 302], ["volta_scudnn_128x64_stridedB_medium_nn_v1", 1, 646, 646, 646, 646], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1", 1, 579, 579, 579, 579], ["volta_scudnn_128x64_stridedB_splitK_medium_nn_v1", 1, 543, 543, 543, 543], ["void cudnn::cnn::wgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)", 1, 517, 517, 517, 517], ["volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1", 1, 514, 514, 514, 514], ["void fft2d_r2c_32x32<float, true, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 6, 513, 86, 144, 53], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", 124, 466, 4, 8, 1], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", 424, 455, 1, 3, 1], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", 124, 440, 4, 6, 1], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", 112, 431, 4, 8, 1], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", 56, 364, 6, 45, 2], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", 8, 345, 43, 47, 42], ["void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", 10, 319, 32, 66, 9], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1", 1, 310, 310, 310, 310], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<float, unsigned int, 1, 128, 1>(float*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<float, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", 8, 256, 32, 35, 31], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", 8, 230, 29, 30, 26], ["volta_sgemm_64x32_sliced1x4_nn", 8, 209, 26, 27, 25], ["volta_sgemm_64x32_sliced1x4_tn", 8, 196, 24, 28, 24], ["volta_sgemm_128x32_nt", 8, 153, 19, 20, 19], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<long, unsigned int, 1, 128, 1>(long*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<long, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", 8, 138, 17, 21, 16], ["void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", 6, 102, 17, 36, 9], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", 8, 85, 11, 11, 10], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", 8, 80, 10, 10, 10], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", 8, 68, 8, 9, 8], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", 16, 47, 3, 4, 2], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", 8, 44, 6, 7, 5], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", 8, 32, 4, 4, 4], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", 8, 16, 2, 2, 2]]}}, "trace_file_path": "./data/tracing\\resnet50_newAPI_noPred_ddp\\worker1_span1.pt.trace.json.gz"}]}]}]}}