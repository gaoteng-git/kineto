{"py/object": "tensorboard_plugin_torch_profiler.run.Run", "name": "resnet50_autogradAPI_ddp", "run_dir": "./data/tracing\\resnet50_autogradAPI_ddp", "profiles": {"py/reduce": [{"py/type": "collections.OrderedDict"}, {"py/tuple": []}, null, null, {"py/tuple": [{"py/tuple": ["worker0_span1", {"py/object": "tensorboard_plugin_torch_profiler.run.RunProfile", "worker": "worker0_span1", "views": [{"py/object": "tensorboard_plugin_torch_profiler.consts.View", "py/newargs": {"py/tuple": [1, "overall", "Overview"]}, "py/seq": [1, "overall", "Overview"]}, {"py/object": "tensorboard_plugin_torch_profiler.consts.View", "py/newargs": {"py/tuple": [2, "operator", "Operator"]}, "py/seq": [2, "operator", "Operator"]}, {"py/object": "tensorboard_plugin_torch_profiler.consts.View", "py/newargs": {"py/tuple": [3, "kernel", "Kernel"]}, "py/seq": [3, "kernel", "Kernel"]}, {"py/object": "tensorboard_plugin_torch_profiler.consts.View", "py/newargs": {"py/tuple": [4, "trace", "Trace"]}, "py/seq": [4, "trace", "Trace"]}], "is_gpu_used": true, "overview": {"steps": {"columns": [{"type": "string", "name": "Step"}, {"type": "number", "name": "Kernel"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memcpy"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memset"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Runtime"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "DataLoader"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "CPU Exec"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Other"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}], "rows": [["0", 3831633, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 20519590us<br><b>Kernel: 3831633us</b><br>Percentage: 18.67%</div>", 16463, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 20519590us<br><b>Memcpy: 16463us</b><br>Percentage: 0.08%</div>", 161, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 20519590us<br><b>Memset: 161us</b><br>Percentage: 0.0%</div>", 4370770, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 20519590us<br><b>Runtime: 4370770us</b><br>Percentage: 21.3%</div>", 10153024, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 20519590us<br><b>DataLoader: 10153024us</b><br>Percentage: 49.48%</div>", 1836433, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 20519590us<br><b>CPU Exec: 1836433us</b><br>Percentage: 8.95%</div>", 311106, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 20519590us<br><b>Other: 311106us</b><br>Percentage: 1.52%</div>"]]}, "performance": [{"name": "Average Step Time", "description": "", "value": 20519590, "extra": 100, "children": [{"name": "Kernel", "description": "", "value": 3831633, "extra": 18.67}, {"name": "Memcpy", "description": "", "value": 16463, "extra": 0.08}, {"name": "Memset", "description": "", "value": 161, "extra": 0.0}, {"name": "Runtime", "description": "", "value": 4370770, "extra": 21.3}, {"name": "DataLoader", "description": "", "value": 10153024, "extra": 49.48}, {"name": "CPU Exec", "description": "", "value": 1836433, "extra": 8.95}, {"name": "Other", "description": "", "value": 311106, "extra": 1.52}]}], "recommendations": "<ul><li>This run has high time cost on input data loading. 49.5% of the step time is in DataLoader. You could try to set num_workers on DataLoader's construction and enable multi-processes on data loading. Reference: <a href =\"https://pytorch.org/docs/stable/data.html#single-and-multi-process-data-loading\" target=\"_blank\">Single- and Multi-process Data Loading</a></li></ul>"}, "operation_pie_by_name": {"device_total_time": {"title": "Device Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward", 617814], ["CudnnConvolutionBackward", 617814], ["aten::cudnn_convolution", 319725], ["aten::_convolution", 319725], ["aten::convolution", 319725], ["aten::conv2d", 319725], ["aten::cudnn_convolution_backward_weight", 313480], ["aten::cudnn_convolution_backward_input", 304334], ["aten::cudnn_batch_norm_backward", 77902], ["CudnnBatchNormBackward", 77902], ["aten::cudnn_batch_norm", 44773], ["aten::_batch_norm_impl_index", 44773], ["aten::batch_norm", 44773], ["aten::threshold_backward", 36504], ["ReluBackward1", 36504], ["aten::add_", 33739], ["aten::threshold_", 23822], ["aten::relu_", 23822], ["aten::copy_", 15789], ["aten::to", 13531], ["torch::autograd::AccumulateGrad", 7650], ["aten::max_pool2d_with_indices_backward", 6842], ["MaxPool2DWithIndicesBackward", 6842], ["aten::add", 4672], ["aten::fill_", 2992], ["aten::zero_", 2984], ["aten::mul_", 2735], ["aten::max_pool2d_with_indices", 1790], ["aten::max_pool2d", 1790], ["aten::zeros_like", 1285], ["aten::_cat", 391], ["aten::cat", 391], ["aten::mm", 382], ["AddmmBackward", 382], ["aten::clone", 359], ["aten::mean", 346], ["aten::adaptive_avg_pool2d", 346], ["aten::addmm", 270], ["aten::div", 231], ["MeanBackward1", 231], ["aten::_log_softmax_backward_data", 83], ["LogSoftmaxBackward", 83], ["aten::_log_softmax", 82], ["aten::log_softmax", 82], ["aten::nll_loss_forward", 33], ["aten::nll_loss", 33], ["aten::nll_loss_backward", 24], ["NllLossBackward", 24], ["aten::_local_scalar_dense", 12], ["aten::item", 12], ["aten::ones_like", 8]]}, "device_self_time": {"title": "Device Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution", 319725], ["aten::cudnn_convolution_backward_weight", 313480], ["aten::cudnn_convolution_backward_input", 304334], ["aten::cudnn_batch_norm_backward", 77902], ["aten::cudnn_batch_norm", 44773], ["aten::threshold_backward", 36504], ["aten::add_", 33739], ["aten::threshold_", 23822], ["aten::copy_", 15789], ["aten::max_pool2d_with_indices_backward", 5557], ["aten::add", 4672], ["aten::fill_", 2992], ["aten::mul_", 2735], ["aten::max_pool2d_with_indices", 1790], ["aten::_cat", 391], ["aten::mm", 382], ["aten::mean", 346], ["aten::addmm", 270], ["aten::div", 231], ["aten::_log_softmax_backward_data", 83], ["aten::_log_softmax", 82], ["aten::nll_loss_forward", 33], ["aten::nll_loss_backward", 24], ["aten::_local_scalar_dense", 12]]}, "host_total_time": {"title": "Host Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 4109504], ["aten::cat", 3006475], ["aten::_cat", 3003354], ["aten::to", 2063157], ["aten::conv2d", 2047417], ["aten::convolution", 2025043], ["aten::_convolution", 2005452], ["aten::cudnn_convolution", 1957415], ["CudnnConvolutionBackward", 1139269], ["aten::contiguous", 1112329], ["aten::cudnn_convolution_backward", 1103512], ["aten::div", 1027391], ["aten::clone", 1015020], ["aten::div_", 957981], ["aten::stack", 880545], ["aten::sub_", 801857], ["aten::cudnn_convolution_backward_weight", 549921], ["aten::batch_norm", 495808], ["aten::addmm", 489483], ["aten::_batch_norm_impl_index", 474666], ["aten::cudnn_convolution_backward_input", 474390], ["aten::empty", 423852], ["aten::cudnn_batch_norm", 389945], ["aten::add_", 361332], ["aten::add", 305173], ["CudnnBatchNormBackward", 282709], ["aten::cudnn_batch_norm_backward", 227773], ["aten::view", 226828], ["torch::autograd::AccumulateGrad", 193715], ["aten::eq", 173406], ["aten::lt", 169773], ["aten::narrow", 157669], ["aten::zero_", 134607], ["aten::item", 131460], ["aten::mul_", 122526], ["aten::pin_memory", 110434], ["aten::slice", 108094], ["ReluBackward1", 92976], ["aten::exp", 85211], ["aten::relu_", 74989], ["aten::_local_scalar_dense", 71550], ["aten::threshold_backward", 69001], ["aten::select", 63904], ["aten::fill_", 63260], ["aten::any", 61781], ["aten::empty_like", 59355], ["aten::empty_strided", 58338], ["aten::randint", 56254], ["aten::as_strided", 52150], ["aten::uniform_", 51990], ["aten::resize_", 51015], ["aten::stride", 45087], ["aten::is_nonzero", 37074], ["aten::log", 36289], ["aten::rand", 31835], ["aten::permute", 26011], ["aten::threshold_", 24209], ["aten::set_", 17980], ["aten::random_", 15844], ["aten::unsqueeze", 12645], ["aten::is_floating_point", 12476], ["aten::detach_", 10569], ["AddmmBackward", 9040], ["aten::detach", 6013], ["MaxPool2DWithIndicesBackward", 5945], ["aten::adaptive_avg_pool2d", 5680], ["aten::max_pool2d_with_indices_backward", 5301], ["aten::mean", 5251], ["aten::max_pool2d", 5123], ["aten::t", 4751], ["aten::max_pool2d_with_indices", 4656], ["aten::mm", 4623], ["detach_", 4493], ["MeanBackward1", 3503], ["aten::zeros", 3263], ["AddBackward0", 3250], ["aten::log_softmax", 3083], ["aten::_log_softmax", 2665], ["LogSoftmaxBackward", 2612], ["aten::nll_loss", 2551], ["detach", 2363], ["NllLossBackward", 2286], ["aten::nll_loss_forward", 2113], ["aten::transpose", 2101], ["aten::_log_softmax_backward_data", 2095], ["aten::reshape", 2084], ["aten::ones_like", 1915], ["aten::zeros_like", 1796], ["aten::flatten", 1754], ["aten::nll_loss_backward", 1553], ["aten::expand", 1374], ["aten::is_pinned", 1230], ["TBackward", 1120], ["ViewBackward", 1073], ["nccl:broadcast", 540], ["aten::resize_as_", 355], ["aten::conj", 343]]}, "host_self_time": {"title": "Host Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 4109504], ["aten::_cat", 2992955], ["aten::cudnn_convolution", 1873820], ["aten::div", 984130], ["aten::div_", 957981], ["aten::sub_", 801857], ["aten::cudnn_convolution_backward_weight", 488248], ["aten::addmm", 486088], ["aten::empty", 423852], ["aten::cudnn_convolution_backward_input", 410786], ["aten::add_", 361332], ["aten::cudnn_batch_norm", 286837], ["aten::add", 235366], ["aten::view", 226828], ["aten::cudnn_batch_norm_backward", 153683], ["aten::mul_", 122526], ["aten::contiguous", 110145], ["aten::to", 90856], ["aten::slice", 87987], ["aten::zero_", 76183], ["aten::cudnn_convolution_backward", 74391], ["aten::_local_scalar_dense", 71550], ["aten::fill_", 63260], ["aten::_batch_norm_impl_index", 62210], ["aten::item", 59910], ["aten::empty_strided", 58338], ["torch::autograd::AccumulateGrad", 57012], ["aten::select", 54541], ["aten::threshold_backward", 52878], ["aten::eq", 52591], ["aten::lt", 52348], ["aten::as_strided", 52150], ["aten::uniform_", 51990], ["aten::resize_", 51015], ["aten::relu_", 50780], ["aten::narrow", 49575], ["aten::exp", 48496], ["CudnnBatchNormBackward", 47972], ["aten::clone", 47297], ["aten::stride", 45087], ["aten::any", 45075], ["aten::_convolution", 41845], ["CudnnConvolutionBackward", 35757], ["aten::empty_like", 33147], ["aten::randint", 31108], ["aten::log", 30100], ["aten::threshold_", 24209], ["ReluBackward1", 23975], ["aten::conv2d", 22374], ["aten::permute", 21835], ["aten::batch_norm", 21142], ["aten::pin_memory", 20643], ["aten::convolution", 19591], ["aten::set_", 17980], ["aten::rand", 17271], ["aten::random_", 15844], ["aten::is_floating_point", 12476], ["aten::is_nonzero", 11469], ["aten::unsqueeze", 9407], ["aten::stack", 6262], ["aten::detach_", 6076], ["aten::mean", 4907], ["detach_", 4493], ["aten::detach", 3650], ["aten::mm", 3640], ["aten::max_pool2d_with_indices", 3298], ["AddBackward0", 3250], ["aten::cat", 3121], ["aten::t", 2650], ["aten::max_pool2d_with_indices_backward", 2577], ["detach", 2363], ["aten::nll_loss_forward", 2113], ["aten::_log_softmax", 1828], ["aten::zeros", 1657], ["aten::nll_loss_backward", 1553], ["aten::transpose", 1458], ["AddmmBackward", 1441], ["aten::is_pinned", 1230], ["aten::_log_softmax_backward_data", 1183], ["aten::expand", 1084], ["NllLossBackward", 733], ["MeanBackward1", 663], ["MaxPool2DWithIndicesBackward", 644], ["aten::reshape", 638], ["aten::ones_like", 590], ["nccl:broadcast", 540], ["LogSoftmaxBackward", 517], ["aten::max_pool2d", 467], ["aten::nll_loss", 438], ["aten::adaptive_avg_pool2d", 429], ["aten::flatten", 425], ["aten::log_softmax", 418], ["aten::conj", 343], ["aten::zeros_like", 340], ["ViewBackward", 318], ["TBackward", 281], ["aten::resize_as_", 281]]}}, "operation_table_by_name": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Device Self Duration (us)"}, {"type": "number", "name": "Device Total Duration (us)"}, {"type": "number", "name": "Host Self Duration (us)"}, {"type": "number", "name": "Host Total Duration (us)"}], "rows": [["aten::cudnn_convolution", 424, 319725, 319725, 1873820, 1957415], ["aten::cudnn_convolution_backward_weight", 424, 313480, 313480, 488248, 549921], ["aten::cudnn_convolution_backward_input", 416, 304334, 304334, 410786, 474390], ["aten::cudnn_batch_norm_backward", 424, 77902, 77902, 153683, 227773], ["aten::cudnn_batch_norm", 424, 44773, 44773, 286837, 389945], ["aten::threshold_backward", 392, 36504, 36504, 52878, 69001], ["aten::add_", 3670, 33739, 33739, 361332, 361332], ["aten::threshold_", 392, 23822, 23822, 24209, 24209], ["aten::copy_", 3166, 15789, 15789, 4109504, 4109504], ["aten::max_pool2d_with_indices_backward", 8, 5557, 6842, 2577, 5301], ["aten::add", 1712, 4672, 4672, 235366, 305173], ["aten::fill_", 1423, 2992, 2992, 63260, 63260], ["aten::mul_", 1127, 2735, 2735, 122526, 122526], ["aten::max_pool2d_with_indices", 8, 1790, 1790, 3298, 4656], ["aten::_cat", 24, 391, 391, 2992955, 3003354], ["aten::mm", 16, 382, 382, 3640, 4623], ["aten::mean", 8, 346, 346, 4907, 5251], ["aten::addmm", 8, 270, 270, 486088, 489483], ["aten::div", 264, 231, 231, 984130, 1027391], ["aten::_log_softmax_backward_data", 8, 83, 83, 1183, 2095], ["aten::_log_softmax", 8, 82, 82, 1828, 2665], ["aten::nll_loss_forward", 8, 33, 33, 2113, 2113], ["aten::nll_loss_backward", 8, 24, 24, 1553, 1553], ["aten::_local_scalar_dense", 2873, 12, 12, 71550, 71550], ["aten::empty", 13110, 0, 0, 423852, 423852], ["aten::random_", 513, 0, 0, 15844, 15844], ["aten::is_floating_point", 1185, 0, 0, 12476, 12476], ["aten::item", 2873, 0, 12, 59910, 131460], ["aten::zero_", 1159, 0, 2984, 76183, 134607], ["aten::zeros", 24, 0, 0, 1657, 3263], ["aten::uniform_", 920, 0, 0, 51990, 51990], ["aten::to", 1908, 0, 13531, 90856, 2063157], ["detach_", 340, 0, 0, 4493, 4493], ["aten::detach_", 340, 0, 0, 6076, 10569], ["aten::log", 332, 0, 0, 30100, 36289], ["aten::as_strided", 2929, 0, 0, 52150, 52150], ["aten::select", 664, 0, 0, 54541, 63904], ["aten::resize_", 3684, 0, 0, 51015, 51015], ["aten::exp", 664, 0, 0, 48496, 85211], ["aten::randint", 512, 0, 0, 31108, 56254], ["aten::rand", 256, 0, 0, 17271, 31835], ["aten::empty_strided", 1626, 0, 0, 58338, 58338], ["aten::lt", 512, 0, 0, 52348, 169773], ["aten::is_nonzero", 512, 0, 0, 11469, 37074], ["aten::set_", 272, 0, 0, 17980, 17980], ["aten::view", 4176, 0, 0, 226828, 226828], ["aten::permute", 256, 0, 0, 21835, 26011], ["aten::empty_like", 712, 0, 0, 33147, 59355], ["aten::contiguous", 7920, 0, 0, 110145, 1112329], ["aten::clone", 417, 0, 359, 47297, 1015020], ["aten::eq", 512, 0, 0, 52591, 173406], ["aten::any", 256, 0, 0, 45075, 61781], ["aten::sub_", 256, 0, 0, 801857, 801857], ["aten::div_", 256, 0, 0, 957981, 957981], ["aten::unsqueeze", 256, 0, 0, 9407, 12645], ["aten::slice", 1280, 0, 0, 87987, 108094], ["aten::narrow", 1280, 0, 0, 49575, 157669], ["aten::stride", 6528, 0, 0, 45087, 45087], ["aten::cat", 24, 0, 391, 3121, 3006475], ["aten::stack", 8, 0, 0, 6262, 880545], ["aten::is_pinned", 16, 0, 0, 1230, 1230], ["aten::pin_memory", 16, 0, 0, 20643, 110434], ["nccl:broadcast", 18, 0, 0, 540, 540], ["aten::_convolution", 424, 0, 319725, 41845, 2005452], ["aten::convolution", 424, 0, 319725, 19591, 2025043], ["aten::conv2d", 424, 0, 319725, 22374, 2047417], ["aten::_batch_norm_impl_index", 424, 0, 44773, 62210, 474666], ["aten::batch_norm", 424, 0, 44773, 21142, 495808], ["aten::relu_", 392, 0, 23822, 50780, 74989], ["aten::max_pool2d", 8, 0, 1790, 467, 5123], ["aten::adaptive_avg_pool2d", 8, 0, 346, 429, 5680], ["aten::reshape", 16, 0, 0, 638, 2084], ["aten::flatten", 8, 0, 0, 425, 1754], ["aten::transpose", 40, 0, 0, 1458, 2101], ["aten::t", 40, 0, 0, 2650, 4751], ["aten::expand", 16, 0, 0, 1084, 1374], ["aten::log_softmax", 8, 0, 82, 418, 3083], ["aten::nll_loss", 8, 0, 33, 438, 2551], ["aten::ones_like", 8, 0, 8, 590, 1915], ["detach", 161, 0, 0, 2363, 2363], ["aten::detach", 161, 0, 0, 3650, 6013], ["NllLossBackward", 8, 0, 24, 733, 2286], ["LogSoftmaxBackward", 8, 0, 83, 517, 2612], ["aten::conj", 16, 0, 0, 343, 343], ["AddmmBackward", 8, 0, 382, 1441, 9040], ["torch::autograd::AccumulateGrad", 1288, 0, 7650, 57012, 193715], ["TBackward", 8, 0, 0, 281, 1120], ["ViewBackward", 8, 0, 0, 318, 1073], ["MeanBackward1", 8, 0, 231, 663, 3503], ["ReluBackward1", 392, 0, 36504, 23975, 92976], ["AddBackward0", 128, 0, 0, 3250, 3250], ["CudnnBatchNormBackward", 424, 0, 77902, 47972, 282709], ["aten::cudnn_convolution_backward", 424, 0, 617814, 74391, 1103512], ["CudnnConvolutionBackward", 424, 0, 617814, 35757, 1139269], ["aten::zeros_like", 8, 0, 1285, 340, 1796], ["aten::resize_as_", 8, 0, 0, 281, 355], ["MaxPool2DWithIndicesBackward", 8, 0, 6842, 644, 5945]]}}, "operation_pie_by_name_input": {"device_total_time": {"title": "Device Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["CudnnConvolutionBackward", 91276], ["CudnnConvolutionBackward", 79147], ["CudnnConvolutionBackward", 77752], ["CudnnConvolutionBackward", 69953], ["CudnnConvolutionBackward", 66945], ["CudnnConvolutionBackward", 56687], ["CudnnConvolutionBackward", 52719], ["aten::cudnn_convolution_backward", 47641], ["aten::cudnn_convolution_backward", 42214], ["aten::cudnn_convolution_backward", 39318], ["aten::cudnn_convolution_backward", 36499], ["CudnnConvolutionBackward", 36499], ["aten::cudnn_convolution_backward", 35549], ["aten::cudnn_convolution_backward", 32520], ["aten::cudnn_convolution_backward", 31782], ["aten::cudnn_convolution_backward_weight", 31716], ["aten::cudnn_convolution_backward", 29862], ["aten::cudnn_convolution_backward_input", 28987], ["aten::cudnn_convolution_backward", 28875], ["CudnnConvolutionBackward", 28875], ["aten::cudnn_convolution_backward", 28432], ["aten::cudnn_convolution_backward_input", 28092], ["aten::cudnn_convolution_backward_input", 25942], ["aten::cudnn_convolution_backward_input", 25836], ["aten::cudnn_convolution_backward", 25143], ["aten::cudnn_convolution_backward", 24177], ["aten::cudnn_convolution_backward", 23863], ["aten::cudnn_convolution_backward", 23698], ["CudnnConvolutionBackward", 23698], ["aten::cudnn_convolution", 23594], ["aten::_convolution", 23594], ["aten::convolution", 23594], ["aten::conv2d", 23594], ["aten::cudnn_convolution_backward", 23212], ["aten::cudnn_convolution_backward", 22878], ["aten::cudnn_convolution_backward_weight", 21884], ["aten::cudnn_convolution_backward_weight", 21805], ["aten::cudnn_convolution_backward", 21625], ["CudnnConvolutionBackward", 21625], ["aten::cudnn_convolution_backward", 21138], ["aten::cudnn_convolution_backward", 20937], ["aten::cudnn_convolution_backward_input", 20732], ["aten::cudnn_convolution", 20626], ["aten::_convolution", 20626], ["aten::convolution", 20626], ["aten::conv2d", 20626], ["aten::cudnn_batch_norm_backward", 20552], ["CudnnBatchNormBackward", 20552], ["aten::cudnn_convolution", 20349], ["aten::_convolution", 20349], ["aten::convolution", 20349], ["aten::conv2d", 20349], ["aten::cudnn_convolution_backward_input", 20073], ["aten::cudnn_convolution_backward", 19438], ["aten::cudnn_convolution_backward", 19304], ["aten::cudnn_convolution_backward_weight", 18586], ["aten::cudnn_convolution_backward_weight", 18546], ["aten::cudnn_convolution", 18181], ["aten::_convolution", 18181], ["aten::convolution", 18181], ["aten::conv2d", 18181], ["aten::cudnn_convolution", 17239], ["aten::_convolution", 17239], ["aten::convolution", 17239], ["aten::conv2d", 17239], ["aten::cudnn_convolution_backward_weight", 16617], ["aten::cudnn_convolution", 15957], ["aten::_convolution", 15957], ["aten::convolution", 15957], ["aten::conv2d", 15957], ["aten::cudnn_convolution_backward_weight", 15720], ["aten::cudnn_convolution", 15714], ["aten::_convolution", 15714], ["aten::convolution", 15714], ["aten::conv2d", 15714], ["aten::cudnn_convolution", 15628], ["aten::_convolution", 15628], ["aten::convolution", 15628], ["aten::conv2d", 15628], ["aten::cudnn_convolution_backward_input", 15577], ["aten::cudnn_convolution_backward_weight", 15476], ["aten::cudnn_convolution_backward_weight", 15392], ["aten::cudnn_convolution", 15358], ["aten::_convolution", 15358], ["aten::convolution", 15358], ["aten::conv2d", 15358], ["aten::cudnn_convolution_backward_input", 15165], ["aten::cudnn_convolution", 15072], ["aten::_convolution", 15072], ["aten::convolution", 15072], ["aten::conv2d", 15072], ["aten::cudnn_convolution", 15006], ["aten::_convolution", 15006], ["aten::convolution", 15006], ["aten::conv2d", 15006], ["aten::cudnn_convolution_backward_input", 14833], ["aten::cudnn_convolution_backward_input", 14615], ["aten::cudnn_convolution", 14329], ["aten::_convolution", 14329], ["aten::convolution", 14329], ["aten::conv2d", 14329], ["aten::cudnn_convolution", 13507], ["aten::_convolution", 13507], ["aten::convolution", 13507], ["aten::conv2d", 13507], ["aten::copy_", 13506], ["aten::to", 13506], ["aten::cudnn_convolution_backward_input", 13483], ["aten::cudnn_convolution", 13367], ["aten::_convolution", 13367], ["aten::convolution", 13367], ["aten::conv2d", 13367], ["aten::cudnn_batch_norm_backward", 13207], ["CudnnBatchNormBackward", 13207], ["aten::cudnn_convolution_backward_weight", 13202], ["aten::cudnn_convolution_backward_input", 12967], ["aten::cudnn_convolution_backward_weight", 12855], ["aten::cudnn_batch_norm", 12805], ["aten::_batch_norm_impl_index", 12805], ["aten::batch_norm", 12805], ["aten::cudnn_convolution", 12705], ["aten::_convolution", 12705], ["aten::convolution", 12705], ["aten::conv2d", 12705], ["aten::cudnn_convolution_backward_weight", 12638], ["aten::cudnn_convolution_backward", 12638], ["CudnnConvolutionBackward", 12638], ["aten::cudnn_convolution", 11931], ["aten::_convolution", 11931], ["aten::convolution", 11931], ["aten::conv2d", 11931], ["aten::cudnn_convolution_backward_weight", 11667], ["aten::cudnn_convolution_backward_input", 11621], ["aten::cudnn_convolution_backward_weight", 11599], ["aten::cudnn_convolution", 11339], ["aten::_convolution", 11339], ["aten::convolution", 11339], ["aten::conv2d", 11339], ["aten::cudnn_convolution_backward_input", 11316], ["aten::cudnn_convolution_backward_input", 10993], ["aten::cudnn_convolution_backward_weight", 10731], ["aten::cudnn_convolution", 10726], ["aten::_convolution", 10726], ["aten::convolution", 10726], ["aten::conv2d", 10726], ["aten::cudnn_convolution_backward_weight", 10720], ["aten::cudnn_convolution_backward_input", 10679], ["aten::cudnn_convolution_backward_input", 10661], ["aten::cudnn_convolution", 10411], ["aten::_convolution", 10411], ["aten::convolution", 10411], ["aten::conv2d", 10411], ["aten::cudnn_batch_norm_backward", 10161], ["CudnnBatchNormBackward", 10161], ["aten::cudnn_convolution_backward_weight", 10145], ["aten::cudnn_batch_norm_backward", 10075], ["CudnnBatchNormBackward", 10075], ["aten::cudnn_convolution_backward_input", 10026], ["aten::cudnn_convolution_backward_weight", 9613], ["aten::cudnn_convolution_backward_weight", 9316], ["aten::cudnn_convolution", 9178], ["aten::_convolution", 9178], ["aten::convolution", 9178], ["aten::conv2d", 9178], ["aten::cudnn_convolution", 9007], ["aten::_convolution", 9007], ["aten::convolution", 9007], ["aten::conv2d", 9007], ["aten::threshold_backward", 8820], ["ReluBackward1", 8820], ["aten::add_", 8748], ["aten::cudnn_convolution_backward_weight", 8625], ["aten::cudnn_convolution_backward_weight", 8481], ["aten::cudnn_batch_norm", 8307], ["aten::_batch_norm_impl_index", 8307], ["aten::batch_norm", 8307], ["aten::cudnn_convolution_backward_weight", 8146], ["aten::cudnn_convolution", 7675], ["aten::_convolution", 7675], ["aten::convolution", 7675], ["aten::conv2d", 7675], ["aten::cudnn_convolution_backward", 7071], ["aten::max_pool2d_with_indices_backward", 6842], ["MaxPool2DWithIndicesBackward", 6842], ["aten::cudnn_batch_norm_backward", 6500], ["CudnnBatchNormBackward", 6500], ["aten::threshold_", 6014], ["aten::relu_", 6014], ["aten::threshold_backward", 5943], ["ReluBackward1", 5943], ["aten::add_", 5895], ["aten::cudnn_batch_norm", 5335], ["aten::_batch_norm_impl_index", 5335], ["aten::batch_norm", 5335], ["aten::cudnn_batch_norm_backward", 5106], ["CudnnBatchNormBackward", 5106], ["aten::cudnn_batch_norm", 4755], ["aten::_batch_norm_impl_index", 4755], ["aten::batch_norm", 4755], ["aten::threshold_backward", 4614], ["ReluBackward1", 4614], ["aten::threshold_backward", 4448], ["ReluBackward1", 4448], ["aten::add_", 4411], ["aten::cudnn_batch_norm_backward", 4197], ["CudnnBatchNormBackward", 4197], ["aten::threshold_", 4043], ["aten::relu_", 4043], ["aten::cudnn_batch_norm", 3407], ["aten::_batch_norm_impl_index", 3407], ["aten::batch_norm", 3407], ["aten::threshold_", 3035], ["aten::relu_", 3035], ["aten::threshold_", 3034], ["aten::relu_", 3034], ["aten::threshold_backward", 2965], ["ReluBackward1", 2965], ["aten::cudnn_batch_norm", 2929], ["aten::_batch_norm_impl_index", 2929], ["aten::batch_norm", 2929], ["aten::cudnn_convolution", 2826], ["aten::_convolution", 2826], ["aten::convolution", 2826], ["aten::conv2d", 2826], ["aten::cudnn_batch_norm_backward", 2749], ["CudnnBatchNormBackward", 2749], ["aten::cudnn_convolution_backward_input", 2736], ["aten::threshold_backward", 2733], ["ReluBackward1", 2733], ["aten::threshold_backward", 2460], ["ReluBackward1", 2460], ["aten::add_", 2386], ["aten::cudnn_batch_norm_backward", 2364], ["CudnnBatchNormBackward", 2364], ["aten::threshold_", 1998], ["aten::relu_", 1998], ["aten::cudnn_batch_norm", 1986], ["aten::_batch_norm_impl_index", 1986], ["aten::batch_norm", 1986], ["aten::threshold_", 1852], ["aten::relu_", 1852], ["aten::cudnn_batch_norm", 1821], ["aten::_batch_norm_impl_index", 1821], ["aten::batch_norm", 1821], ["aten::max_pool2d_with_indices", 1790], ["aten::max_pool2d", 1790], ["aten::cudnn_batch_norm", 1592], ["aten::_batch_norm_impl_index", 1592], ["aten::batch_norm", 1592], ["aten::threshold_backward", 1478], ["ReluBackward1", 1478], ["aten::add_", 1441], ["aten::cudnn_batch_norm_backward", 1310], ["CudnnBatchNormBackward", 1310], ["aten::fill_", 1285], ["aten::zero_", 1285], ["aten::zeros_like", 1285], ["aten::threshold_backward", 1212], ["ReluBackward1", 1212], ["aten::add_", 1132], ["torch::autograd::AccumulateGrad", 1050], ["aten::threshold_", 1021], ["aten::relu_", 1021], ["aten::threshold_", 1005], ["aten::relu_", 1005], ["aten::add_", 975], ["aten::cudnn_batch_norm_backward", 938], ["CudnnBatchNormBackward", 938], ["aten::add_", 925], ["aten::add_", 911], ["torch::autograd::AccumulateGrad", 905], ["aten::add", 840], ["aten::cudnn_batch_norm", 831], ["aten::_batch_norm_impl_index", 831], ["aten::batch_norm", 831], ["aten::threshold_", 797], ["aten::relu_", 797], ["aten::threshold_backward", 764], ["ReluBackward1", 764], ["aten::cudnn_batch_norm_backward", 743], ["CudnnBatchNormBackward", 743], ["aten::add_", 708], ["aten::add_", 684], ["aten::add_", 675], ["torch::autograd::AccumulateGrad", 667], ["aten::threshold_backward", 660], ["ReluBackward1", 660], ["aten::add_", 655], ["aten::add_", 639], ["aten::cudnn_batch_norm", 635], ["aten::_batch_norm_impl_index", 635], ["aten::batch_norm", 635], ["aten::add_", 592], ["aten::threshold_", 505], ["aten::relu_", 505], ["aten::mul_", 505], ["aten::add_", 485], ["aten::add", 483], ["torch::autograd::AccumulateGrad", 478], ["torch::autograd::AccumulateGrad", 466], ["torch::autograd::AccumulateGrad", 466], ["aten::add_", 458], ["aten::add", 455], ["aten::copy_", 426], ["aten::threshold_backward", 407], ["ReluBackward1", 407], ["torch::autograd::AccumulateGrad", 401], ["torch::autograd::AccumulateGrad", 392], ["aten::_cat", 391], ["aten::cat", 391], ["aten::add", 385], ["AddmmBackward", 382], ["aten::copy_", 377], ["aten::cudnn_batch_norm", 370], ["aten::_batch_norm_impl_index", 370], ["aten::batch_norm", 370], ["aten::add_", 355], ["aten::mean", 346], ["aten::adaptive_avg_pool2d", 346], ["torch::autograd::AccumulateGrad", 328], ["torch::autograd::AccumulateGrad", 325], ["aten::fill_", 315], ["aten::zero_", 315], ["torch::autograd::AccumulateGrad", 312], ["aten::threshold_", 274], ["aten::relu_", 274], ["aten::addmm", 270], ["aten::add_", 266], ["torch::autograd::AccumulateGrad", 266], ["aten::mul_", 262], ["aten::add", 256], ["aten::add", 256], ["aten::add", 248], ["aten::threshold_", 244], ["aten::relu_", 244], ["aten::add", 244], ["torch::autograd::AccumulateGrad", 244], ["aten::add", 239], ["torch::autograd::AccumulateGrad", 238], ["aten::mul_", 232], ["aten::div", 231], ["MeanBackward1", 231], ["aten::mm", 229], ["aten::mul_", 224], ["aten::copy_", 221], ["aten::add_", 200], ["aten::add_", 196], ["aten::add", 176], ["aten::copy_", 175], ["aten::add", 174], ["aten::copy_", 171], ["aten::fill_", 168], ["aten::zero_", 168], ["aten::copy_", 166], ["aten::add_", 161], ["torch::autograd::AccumulateGrad", 158], ["aten::add_", 156], ["aten::mul_", 154], ["aten::mul_", 154], ["aten::mm", 153], ["aten::add_", 151], ["aten::mul_", 150], ["aten::fill_", 147], ["aten::zero_", 147], ["aten::mul_", 147], ["torch::autograd::AccumulateGrad", 146], ["aten::copy_", 145], ["torch::autograd::AccumulateGrad", 142], ["aten::mul_", 136], ["aten::add", 128], ["aten::add_", 128], ["torch::autograd::AccumulateGrad", 117], ["aten::add", 112], ["aten::add", 112], ["aten::mul_", 112], ["torch::autograd::AccumulateGrad", 110], ["aten::fill_", 107], ["aten::zero_", 107], ["aten::mul_", 105], ["torch::autograd::AccumulateGrad", 99], ["aten::fill_", 98], ["aten::zero_", 98], ["aten::mul_", 98], ["aten::mul_", 98], ["aten::add_", 95], ["aten::fill_", 91], ["aten::zero_", 91], ["aten::fill_", 91], ["aten::zero_", 91], ["aten::add", 88], ["aten::fill_", 86], ["aten::zero_", 86], ["aten::fill_", 84], ["aten::zero_", 84], ["aten::_log_softmax_backward_data", 83], ["LogSoftmaxBackward", 83], ["aten::_log_softmax", 82], ["aten::log_softmax", 82], ["aten::copy_", 81], ["aten::add_", 77], ["aten::clone", 77], ["aten::copy_", 76], ["aten::fill_", 76], ["aten::zero_", 76], ["aten::add", 75], ["aten::add", 72], ["aten::fill_", 70], ["aten::zero_", 70], ["aten::add_", 69], ["torch::autograd::AccumulateGrad", 69], ["torch::autograd::AccumulateGrad", 68], ["aten::add", 64], ["aten::copy_", 64], ["aten::add", 64], ["aten::fill_", 58], ["aten::zero_", 58], ["aten::mul_", 57], ["aten::copy_", 56], ["aten::mul_", 56], ["aten::copy_", 54], ["aten::fill_", 54], ["aten::zero_", 54], ["aten::add_", 52], ["torch::autograd::AccumulateGrad", 50], ["aten::copy_", 49], ["aten::add", 48], ["aten::add_", 46], ["aten::copy_", 46], ["aten::add_", 45], ["aten::copy_", 45], ["torch::autograd::AccumulateGrad", 41], ["torch::autograd::AccumulateGrad", 41], ["aten::mul_", 39], ["aten::mul_", 38], ["aten::nll_loss_forward", 33], ["aten::nll_loss", 33], ["aten::add", 32], ["aten::clone", 32], ["torch::autograd::AccumulateGrad", 32], ["torch::autograd::AccumulateGrad", 31], ["aten::clone", 30], ["aten::fill_", 28], ["aten::zero_", 28], ["aten::fill_", 28], ["aten::zero_", 28], ["aten::fill_", 28], ["aten::zero_", 28], ["aten::fill_", 28], ["aten::zero_", 28], ["aten::fill_", 28], ["aten::zero_", 28], ["aten::mul_", 28], ["aten::mul_", 28], ["aten::copy_", 25], ["aten::to", 25], ["aten::add", 25], ["aten::add", 24], ["aten::add", 24], ["aten::nll_loss_backward", 24], ["NllLossBackward", 24], ["aten::clone", 23], ["aten::clone", 23], ["aten::clone", 22], ["aten::add_", 22], ["aten::fill_", 21], ["aten::zero_", 21], ["aten::fill_", 21], ["aten::zero_", 21], ["aten::mul_", 21], ["aten::mul_", 21], ["aten::copy_", 20], ["aten::clone", 20], ["aten::clone", 20], ["aten::fill_", 20], ["aten::zero_", 20], ["aten::add", 16], ["aten::clone", 16], ["aten::clone", 14], ["aten::clone", 14], ["aten::fill_", 14], ["aten::zero_", 14], ["aten::mul_", 14], ["aten::mul_", 14], ["aten::mul_", 14], ["aten::clone", 13], ["aten::_local_scalar_dense", 12], ["aten::item", 12], ["aten::copy_", 12], ["aten::copy_", 10], ["aten::copy_", 10], ["aten::clone", 10], ["aten::copy_", 10], ["aten::copy_", 9], ["aten::fill_", 8], ["aten::ones_like", 8], ["aten::add", 8], ["aten::add", 8], ["aten::add", 8], ["aten::clone", 8], ["aten::clone", 8], ["aten::add", 8], ["torch::autograd::AccumulateGrad", 8], ["aten::copy_", 7], ["aten::fill_", 7], ["aten::zero_", 7], ["aten::fill_", 7], ["aten::zero_", 7], ["aten::fill_", 7], ["aten::zero_", 7], ["aten::fill_", 7], ["aten::zero_", 7], ["aten::fill_", 7], ["aten::zero_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::copy_", 5], ["aten::copy_", 5], ["aten::copy_", 5], ["aten::clone", 4], ["aten::clone", 4], ["aten::clone", 3], ["aten::copy_", 3], ["aten::clone", 3], ["aten::clone", 3], ["aten::clone", 3], ["aten::fill_", 3], ["aten::zero_", 3], ["aten::copy_", 2], ["aten::copy_", 2], ["aten::clone", 2], ["aten::clone", 2], ["aten::copy_", 2], ["aten::copy_", 2], ["aten::copy_", 2], ["aten::clone", 1], ["aten::clone", 1], ["aten::clone", 1], ["aten::clone", 1], ["aten::clone", 1]]}, "device_self_time": {"title": "Device Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward_weight", 31716], ["aten::cudnn_convolution_backward_input", 28987], ["aten::cudnn_convolution_backward_input", 28092], ["aten::cudnn_convolution_backward_input", 25942], ["aten::cudnn_convolution_backward_input", 25836], ["aten::cudnn_convolution", 23594], ["aten::cudnn_convolution_backward_weight", 21884], ["aten::cudnn_convolution_backward_weight", 21805], ["aten::cudnn_convolution_backward_input", 20732], ["aten::cudnn_convolution", 20626], ["aten::cudnn_batch_norm_backward", 20552], ["aten::cudnn_convolution", 20349], ["aten::cudnn_convolution_backward_input", 20073], ["aten::cudnn_convolution_backward_weight", 18586], ["aten::cudnn_convolution_backward_weight", 18546], ["aten::cudnn_convolution", 18181], ["aten::cudnn_convolution", 17239], ["aten::cudnn_convolution_backward_weight", 16617], ["aten::cudnn_convolution", 15957], ["aten::cudnn_convolution_backward_weight", 15720], ["aten::cudnn_convolution", 15714], ["aten::cudnn_convolution", 15628], ["aten::cudnn_convolution_backward_input", 15577], ["aten::cudnn_convolution_backward_weight", 15476], ["aten::cudnn_convolution_backward_weight", 15392], ["aten::cudnn_convolution", 15358], ["aten::cudnn_convolution_backward_input", 15165], ["aten::cudnn_convolution", 15072], ["aten::cudnn_convolution", 15006], ["aten::cudnn_convolution_backward_input", 14833], ["aten::cudnn_convolution_backward_input", 14615], ["aten::cudnn_convolution", 14329], ["aten::cudnn_convolution", 13507], ["aten::copy_", 13506], ["aten::cudnn_convolution_backward_input", 13483], ["aten::cudnn_convolution", 13367], ["aten::cudnn_batch_norm_backward", 13207], ["aten::cudnn_convolution_backward_weight", 13202], ["aten::cudnn_convolution_backward_input", 12967], ["aten::cudnn_convolution_backward_weight", 12855], ["aten::cudnn_batch_norm", 12805], ["aten::cudnn_convolution", 12705], ["aten::cudnn_convolution_backward_weight", 12638], ["aten::cudnn_convolution", 11931], ["aten::cudnn_convolution_backward_weight", 11667], ["aten::cudnn_convolution_backward_input", 11621], ["aten::cudnn_convolution_backward_weight", 11599], ["aten::cudnn_convolution", 11339], ["aten::cudnn_convolution_backward_input", 11316], ["aten::cudnn_convolution_backward_input", 10993], ["aten::cudnn_convolution_backward_weight", 10731], ["aten::cudnn_convolution", 10726], ["aten::cudnn_convolution_backward_weight", 10720], ["aten::cudnn_convolution_backward_input", 10679], ["aten::cudnn_convolution_backward_input", 10661], ["aten::cudnn_convolution", 10411], ["aten::cudnn_batch_norm_backward", 10161], ["aten::cudnn_convolution_backward_weight", 10145], ["aten::cudnn_batch_norm_backward", 10075], ["aten::cudnn_convolution_backward_input", 10026], ["aten::cudnn_convolution_backward_weight", 9613], ["aten::cudnn_convolution_backward_weight", 9316], ["aten::cudnn_convolution", 9178], ["aten::cudnn_convolution", 9007], ["aten::threshold_backward", 8820], ["aten::add_", 8748], ["aten::cudnn_convolution_backward_weight", 8625], ["aten::cudnn_convolution_backward_weight", 8481], ["aten::cudnn_batch_norm", 8307], ["aten::cudnn_convolution_backward_weight", 8146], ["aten::cudnn_convolution", 7675], ["aten::cudnn_batch_norm_backward", 6500], ["aten::threshold_", 6014], ["aten::threshold_backward", 5943], ["aten::add_", 5895], ["aten::max_pool2d_with_indices_backward", 5557], ["aten::cudnn_batch_norm", 5335], ["aten::cudnn_batch_norm_backward", 5106], ["aten::cudnn_batch_norm", 4755], ["aten::threshold_backward", 4614], ["aten::threshold_backward", 4448], ["aten::add_", 4411], ["aten::cudnn_batch_norm_backward", 4197], ["aten::threshold_", 4043], ["aten::cudnn_batch_norm", 3407], ["aten::threshold_", 3035], ["aten::threshold_", 3034], ["aten::threshold_backward", 2965], ["aten::cudnn_batch_norm", 2929], ["aten::cudnn_convolution", 2826], ["aten::cudnn_batch_norm_backward", 2749], ["aten::cudnn_convolution_backward_input", 2736], ["aten::threshold_backward", 2733], ["aten::threshold_backward", 2460], ["aten::add_", 2386], ["aten::cudnn_batch_norm_backward", 2364], ["aten::threshold_", 1998], ["aten::cudnn_batch_norm", 1986], ["aten::threshold_", 1852], ["aten::cudnn_batch_norm", 1821], ["aten::max_pool2d_with_indices", 1790], ["aten::cudnn_batch_norm", 1592], ["aten::threshold_backward", 1478], ["aten::add_", 1441], ["aten::cudnn_batch_norm_backward", 1310], ["aten::fill_", 1285], ["aten::threshold_backward", 1212], ["aten::add_", 1132], ["aten::threshold_", 1021], ["aten::threshold_", 1005], ["aten::add_", 975], ["aten::cudnn_batch_norm_backward", 938], ["aten::add_", 925], ["aten::add_", 911], ["aten::add", 840], ["aten::cudnn_batch_norm", 831], ["aten::threshold_", 797], ["aten::threshold_backward", 764], ["aten::cudnn_batch_norm_backward", 743], ["aten::add_", 708], ["aten::add_", 684], ["aten::add_", 675], ["aten::threshold_backward", 660], ["aten::add_", 655], ["aten::add_", 639], ["aten::cudnn_batch_norm", 635], ["aten::add_", 592], ["aten::threshold_", 505], ["aten::mul_", 505], ["aten::add_", 485], ["aten::add", 483], ["aten::add_", 458], ["aten::add", 455], ["aten::copy_", 426], ["aten::threshold_backward", 407], ["aten::_cat", 391], ["aten::add", 385], ["aten::copy_", 377], ["aten::cudnn_batch_norm", 370], ["aten::add_", 355], ["aten::mean", 346], ["aten::fill_", 315], ["aten::threshold_", 274], ["aten::addmm", 270], ["aten::add_", 266], ["aten::mul_", 262], ["aten::add", 256], ["aten::add", 256], ["aten::add", 248], ["aten::threshold_", 244], ["aten::add", 244], ["aten::add", 239], ["aten::mul_", 232], ["aten::div", 231], ["aten::mm", 229], ["aten::mul_", 224], ["aten::copy_", 221], ["aten::add_", 200], ["aten::add_", 196], ["aten::add", 176], ["aten::copy_", 175], ["aten::add", 174], ["aten::copy_", 171], ["aten::fill_", 168], ["aten::copy_", 166], ["aten::add_", 161], ["aten::add_", 156], ["aten::mul_", 154], ["aten::mul_", 154], ["aten::mm", 153], ["aten::add_", 151], ["aten::mul_", 150], ["aten::fill_", 147], ["aten::mul_", 147], ["aten::copy_", 145], ["aten::mul_", 136], ["aten::add", 128], ["aten::add_", 128], ["aten::add", 112], ["aten::add", 112], ["aten::mul_", 112], ["aten::fill_", 107], ["aten::mul_", 105], ["aten::fill_", 98], ["aten::mul_", 98], ["aten::mul_", 98], ["aten::add_", 95], ["aten::fill_", 91], ["aten::fill_", 91], ["aten::add", 88], ["aten::fill_", 86], ["aten::fill_", 84], ["aten::_log_softmax_backward_data", 83], ["aten::_log_softmax", 82], ["aten::copy_", 81], ["aten::add_", 77], ["aten::copy_", 76], ["aten::fill_", 76], ["aten::add", 75], ["aten::add", 72], ["aten::fill_", 70], ["aten::add_", 69], ["aten::add", 64], ["aten::copy_", 64], ["aten::add", 64], ["aten::fill_", 58], ["aten::mul_", 57], ["aten::copy_", 56], ["aten::mul_", 56], ["aten::copy_", 54], ["aten::fill_", 54], ["aten::add_", 52], ["aten::copy_", 49], ["aten::add", 48], ["aten::add_", 46], ["aten::copy_", 46], ["aten::add_", 45], ["aten::copy_", 45], ["aten::mul_", 39], ["aten::mul_", 38], ["aten::nll_loss_forward", 33], ["aten::add", 32], ["aten::fill_", 28], ["aten::fill_", 28], ["aten::fill_", 28], ["aten::fill_", 28], ["aten::fill_", 28], ["aten::mul_", 28], ["aten::mul_", 28], ["aten::copy_", 25], ["aten::add", 25], ["aten::add", 24], ["aten::add", 24], ["aten::nll_loss_backward", 24], ["aten::add_", 22], ["aten::fill_", 21], ["aten::fill_", 21], ["aten::mul_", 21], ["aten::mul_", 21], ["aten::copy_", 20], ["aten::fill_", 20], ["aten::add", 16], ["aten::fill_", 14], ["aten::mul_", 14], ["aten::mul_", 14], ["aten::mul_", 14], ["aten::_local_scalar_dense", 12], ["aten::copy_", 12], ["aten::copy_", 10], ["aten::copy_", 10], ["aten::copy_", 10], ["aten::copy_", 9], ["aten::fill_", 8], ["aten::add", 8], ["aten::add", 8], ["aten::add", 8], ["aten::add", 8], ["aten::copy_", 7], ["aten::fill_", 7], ["aten::fill_", 7], ["aten::fill_", 7], ["aten::fill_", 7], ["aten::fill_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::copy_", 5], ["aten::copy_", 5], ["aten::copy_", 5], ["aten::copy_", 3], ["aten::fill_", 3], ["aten::copy_", 2], ["aten::copy_", 2], ["aten::copy_", 2], ["aten::copy_", 2], ["aten::copy_", 2]]}, "host_total_time": {"title": "Host Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 3840507], ["aten::cat", 3006475], ["aten::_cat", 3003354], ["aten::to", 1943054], ["aten::conv2d", 1437924], ["aten::convolution", 1437463], ["aten::_convolution", 1437061], ["aten::cudnn_convolution", 1436042], ["aten::div", 1025519], ["aten::contiguous", 1015106], ["aten::clone", 975599], ["aten::div_", 957981], ["aten::stack", 880545], ["aten::sub_", 801857], ["aten::addmm", 489483], ["aten::empty", 423852], ["CudnnConvolutionBackward", 291314], ["aten::cudnn_convolution_backward", 207920], ["aten::cudnn_convolution_backward_weight", 180663], ["CudnnConvolutionBackward", 150549], ["CudnnConvolutionBackward", 130797], ["CudnnConvolutionBackward", 114262], ["CudnnConvolutionBackward", 110677], ["aten::pin_memory", 107175], ["CudnnConvolutionBackward", 103207], ["aten::eq", 101704], ["aten::to", 101217], ["aten::lt", 100260], ["aten::narrow", 97215], ["aten::copy_", 87576], ["aten::batch_norm", 86610], ["aten::batch_norm", 84729], ["aten::_batch_norm_impl_index", 84303], ["aten::cudnn_batch_norm", 82696], ["aten::_batch_norm_impl_index", 82244], ["aten::cudnn_convolution_backward", 80642], ["aten::cudnn_convolution_backward", 78232], ["CudnnConvolutionBackward", 77423], ["aten::add", 77286], ["aten::slice", 72884], ["aten::eq", 71702], ["aten::lt", 69513], ["aten::copy_", 68986], ["aten::item", 68696], ["aten::cudnn_convolution_backward_input", 68695], ["aten::add_", 68572], ["aten::cudnn_batch_norm", 65478], ["aten::cudnn_convolution_backward", 64037], ["aten::select", 63904], ["aten::item", 62764], ["aten::any", 61781], ["CudnnBatchNormBackward", 60539], ["aten::exp", 59964], ["aten::narrow", 59842], ["aten::empty_strided", 58338], ["aten::cudnn_convolution_backward", 58291], ["CudnnConvolutionBackward", 56990], ["aten::randint", 56254], ["aten::batch_norm", 54713], ["aten::batch_norm", 54602], ["aten::cudnn_convolution_backward", 54358], ["aten::cudnn_convolution_backward", 53353], ["aten::cudnn_convolution_backward", 52331], ["aten::uniform_", 51990], ["aten::_batch_norm_impl_index", 51938], ["aten::_batch_norm_impl_index", 51848], ["aten::cudnn_convolution_backward", 51084], ["aten::cudnn_batch_norm_backward", 48954], ["aten::conv2d", 47370], ["aten::conv2d", 46898], ["aten::add_", 46445], ["aten::batch_norm", 46389], ["aten::add", 45985], ["aten::convolution", 44864], ["aten::convolution", 44796], ["aten::cudnn_convolution_backward", 44179], ["aten::cudnn_convolution_backward", 44061], ["aten::_batch_norm_impl_index", 43989], ["aten::cudnn_convolution_backward", 43524], ["aten::conv2d", 43462], ["aten::_convolution", 42968], ["aten::_convolution", 42632], ["aten::convolution", 42211], ["aten::cudnn_batch_norm", 41509], ["aten::cudnn_batch_norm", 41299], ["aten::conv2d", 41245], ["aten::_convolution", 41140], ["aten::conv2d", 40643], ["aten::cudnn_convolution_backward_input", 39662], ["aten::batch_norm", 39651], ["aten::_local_scalar_dense", 39608], ["aten::convolution", 39560], ["aten::view", 38958], ["aten::batch_norm", 38840], ["aten::convolution", 38567], ["aten::cudnn_convolution", 38461], ["aten::cudnn_convolution", 38304], ["aten::_convolution", 38047], ["aten::conv2d", 37743], ["aten::_batch_norm_impl_index", 37608], ["aten::cudnn_convolution_backward_input", 37281], ["aten::cudnn_convolution", 37268], ["aten::conv2d", 37125], ["aten::_batch_norm_impl_index", 36871], ["CudnnBatchNormBackward", 36857], ["torch::autograd::AccumulateGrad", 36855], ["aten::_convolution", 36698], ["aten::log", 36289], ["CudnnBatchNormBackward", 36285], ["aten::cudnn_convolution_backward_input", 36210], ["aten::convolution", 36012], ["aten::convolution", 35886], ["aten::batch_norm", 35440], ["aten::cudnn_batch_norm", 35021], ["aten::cudnn_convolution_backward", 34972], ["aten::slice", 34820], ["aten::_convolution", 34805], ["aten::_convolution", 34506], ["aten::cudnn_convolution", 34489], ["CudnnConvolutionBackward", 33853], ["aten::_batch_norm_impl_index", 33849], ["aten::add_", 33723], ["aten::cudnn_convolution_backward_weight", 33473], ["aten::view", 33469], ["aten::cudnn_convolution_backward", 33134], ["CudnnBatchNormBackward", 32778], ["aten::conv2d", 32356], ["aten::cudnn_convolution", 32209], ["aten::cudnn_convolution", 32187], ["aten::_local_scalar_dense", 31942], ["aten::rand", 31835], ["aten::batch_norm", 31668], ["aten::convolution", 31021], ["aten::cudnn_convolution_backward", 31000], ["aten::cudnn_convolution", 30969], ["aten::add", 30967], ["aten::cudnn_convolution_backward_input", 30895], ["aten::cudnn_batch_norm", 30058], ["aten::add_", 30034], ["aten::_batch_norm_impl_index", 30013], ["aten::conv2d", 29961], ["aten::copy_", 29878], ["aten::_convolution", 29866], ["aten::cudnn_batch_norm_backward", 29553], ["CudnnConvolutionBackward", 29323], ["aten::add_", 29292], ["aten::cudnn_batch_norm_backward", 29195], ["aten::convolution", 29123], ["aten::conv2d", 29107], ["CudnnConvolutionBackward", 29080], ["aten::cudnn_batch_norm", 29053], ["aten::conv2d", 28983], ["aten::cudnn_convolution_backward", 28640], ["aten::cudnn_convolution_backward_weight", 28441], ["aten::_convolution", 28403], ["aten::cudnn_convolution_backward", 28400], ["aten::cudnn_convolution_backward_weight", 28306], ["aten::convolution", 28166], ["aten::convolution", 27766], ["aten::_convolution", 27423], ["aten::cudnn_convolution", 27162], ["aten::cudnn_convolution_backward_weight", 27138], ["aten::cudnn_convolution_backward_input", 27010], ["aten::_convolution", 26675], ["aten::cudnn_convolution", 26628], ["aten::zero_", 26617], ["aten::cudnn_batch_norm_backward", 26559], ["CudnnBatchNormBackward", 26230], ["aten::permute", 26011], ["CudnnBatchNormBackward", 25822], ["aten::cudnn_convolution", 25646], ["aten::view", 25555], ["aten::cudnn_convolution_backward_input", 25545], ["torch::autograd::AccumulateGrad", 25341], ["aten::exp", 25247], ["aten::view", 24895], ["aten::cudnn_convolution_backward_input", 24817], ["aten::view", 24794], ["aten::cudnn_convolution_backward_weight", 24730], ["aten::cudnn_convolution_backward_weight", 24693], ["aten::conv2d", 24145], ["aten::cudnn_convolution", 23960], ["aten::conv2d", 23939], ["aten::cudnn_batch_norm", 23814], ["aten::mul_", 23789], ["aten::convolution", 23720], ["aten::cudnn_convolution_backward_weight", 23672], ["aten::cudnn_batch_norm", 23535], ["aten::_convolution", 23363], ["aten::cudnn_convolution_backward_input", 23343], ["aten::convolution", 23118], ["aten::cudnn_convolution_backward_input", 22983], ["aten::cudnn_convolution_backward_input", 22817], ["aten::resize_", 22679], ["aten::cudnn_convolution", 22493], ["CudnnBatchNormBackward", 22480], ["aten::_convolution", 22398], ["aten::add", 22360], ["aten::cudnn_convolution_backward", 21761], ["aten::cudnn_convolution_backward_input", 21685], ["ReluBackward1", 21300], ["aten::cudnn_batch_norm_backward", 21133], ["aten::cudnn_convolution_backward", 20813], ["CudnnBatchNormBackward", 20760], ["aten::cudnn_convolution_backward", 20697], ["aten::cudnn_batch_norm_backward", 20667], ["aten::cudnn_convolution_backward", 20603], ["aten::cudnn_convolution", 20555], ["aten::copy_", 20503], ["aten::cudnn_convolution_backward", 20346], ["aten::conv2d", 20052], ["aten::convolution", 19638], ["aten::is_nonzero", 19616], ["aten::conv2d", 19525], ["aten::add", 19475], ["aten::add", 19310], ["aten::_convolution", 19252], ["torch::autograd::AccumulateGrad", 19164], ["aten::conv2d", 19158], ["aten::convolution", 19103], ["aten::convolution", 18752], ["aten::_convolution", 18742], ["aten::view", 18517], ["aten::cudnn_convolution_backward_weight", 18404], ["aten::_convolution", 18392], ["aten::cudnn_batch_norm_backward", 18381], ["aten::cudnn_convolution", 18366], ["aten::conv2d", 18163], ["aten::zero_", 18046], ["aten::conv2d", 17951], ["aten::cudnn_convolution", 17833], ["aten::cudnn_convolution_backward_weight", 17824], ["aten::convolution", 17755], ["aten::convolution", 17534], ["aten::cudnn_convolution", 17530], ["aten::is_nonzero", 17458], ["aten::cudnn_convolution_backward_weight", 17413], ["aten::_convolution", 17380], ["aten::cudnn_convolution_backward_input", 17330], ["aten::relu_", 17200], ["aten::view", 17198], ["aten::_convolution", 17145], ["aten::set_", 17013], ["aten::view", 16975], ["aten::mul_", 16944], ["aten::add_", 16710], ["aten::cudnn_batch_norm_backward", 16605], ["aten::cudnn_convolution", 16483], ["aten::cudnn_convolution_backward_weight", 16396], ["aten::cudnn_convolution", 16265], ["torch::autograd::AccumulateGrad", 16128], ["aten::view", 16043], ["aten::threshold_backward", 15979], ["torch::autograd::AccumulateGrad", 15921], ["aten::random_", 15758], ["aten::cudnn_convolution_backward_input", 15678], ["aten::empty_like", 15541], ["aten::cudnn_convolution_backward_input", 15440], ["aten::copy_", 15215], ["aten::cudnn_convolution_backward_input", 15133], ["aten::cudnn_convolution_backward_weight", 14353], ["aten::as_strided", 14108], ["aten::conv2d", 14059], ["aten::conv2d", 13829], ["aten::convolution", 13630], ["aten::convolution", 13407], ["aten::add_", 13342], ["aten::copy_", 13301], ["aten::cudnn_convolution_backward_weight", 13290], ["aten::_convolution", 13265], ["ReluBackward1", 13192], ["aten::zero_", 13157], ["aten::add_", 13099], ["aten::_convolution", 13053], ["aten::copy_", 12975], ["aten::unsqueeze", 12645], ["aten::is_floating_point", 12354], ["aten::cudnn_convolution", 12346], ["torch::autograd::AccumulateGrad", 12240], ["aten::conv2d", 12198], ["aten::mul_", 11845], ["CudnnConvolutionBackward", 11794], ["aten::cudnn_convolution", 11791], ["aten::convolution", 11782], ["aten::cudnn_convolution_backward_weight", 11777], ["aten::cudnn_convolution_backward_weight", 11770], ["aten::zero_", 11710], ["aten::fill_", 11657], ["aten::conv2d", 11581], ["aten::zero_", 11486], ["aten::_convolution", 11428], ["ReluBackward1", 11355], ["ReluBackward1", 11329], ["aten::add", 11223], ["aten::convolution", 11169], ["aten::cudnn_convolution_backward", 11134], ["aten::_convolution", 10810], ["aten::cudnn_convolution_backward_weight", 10532], ["aten::cudnn_convolution", 10495], ["aten::cudnn_convolution_backward_input", 10474], ["aten::relu_", 10472], ["aten::add_", 10441], ["aten::cudnn_convolution_backward_input", 10422], ["aten::mul_", 10402], ["aten::mul_", 10268], ["aten::detach_", 10224], ["aten::cudnn_convolution_backward_weight", 10087], ["aten::cudnn_convolution", 9933], ["aten::threshold_backward", 9784], ["aten::cudnn_convolution_backward_weight", 9674], ["aten::contiguous", 9601], ["aten::contiguous", 9599], ["ReluBackward1", 9415], ["aten::cudnn_convolution_backward_weight", 9399], ["aten::as_strided", 9363], ["aten::relu_", 9317], ["torch::autograd::AccumulateGrad", 9166], ["aten::cudnn_convolution_backward_weight", 9132], ["aten::relu_", 9067], ["AddmmBackward", 9040], ["aten::view", 8978], ["aten::cudnn_convolution_backward_input", 8970], ["aten::cudnn_convolution_backward_weight", 8754], ["aten::add_", 8690], ["aten::add_", 8588], ["aten::add", 8494], ["aten::add_", 8432], ["aten::threshold_backward", 8413], ["aten::add", 8389], ["aten::threshold_backward", 8323], ["aten::empty_like", 8249], ["aten::fill_", 7845], ["aten::stride", 7777], ["aten::batch_norm", 7732], ["aten::batch_norm", 7722], ["aten::batch_norm", 7712], ["ReluBackward1", 7608], ["aten::relu_", 7561], ["aten::copy_", 7553], ["aten::to", 7450], ["aten::_batch_norm_impl_index", 7340], ["aten::_batch_norm_impl_index", 7336], ["aten::_batch_norm_impl_index", 7327], ["aten::clone", 7226], ["aten::add", 7091], ["aten::threshold_backward", 6988], ["torch::autograd::AccumulateGrad", 6907], ["aten::add_", 6830], ["aten::add_", 6685], ["aten::zero_", 6590], ["aten::add_", 6461], ["aten::contiguous", 6414], ["aten::add_", 6403], ["aten::add", 6381], ["aten::contiguous", 6335], ["aten::add_", 6319], ["aten::contiguous", 6125], ["torch::autograd::AccumulateGrad", 6121], ["aten::contiguous", 5945], ["MaxPool2DWithIndicesBackward", 5945], ["aten::mul_", 5924], ["aten::as_strided", 5884], ["aten::relu_", 5879], ["aten::as_strided", 5878], ["aten::contiguous", 5869], ["aten::empty_like", 5850], ["aten::cudnn_batch_norm", 5848], ["aten::cudnn_batch_norm", 5826], ["aten::cudnn_batch_norm", 5808], ["torch::autograd::AccumulateGrad", 5783], ["aten::fill_", 5750], ["aten::add", 5706], ["ReluBackward1", 5683], ["aten::adaptive_avg_pool2d", 5680], ["aten::threshold_backward", 5645], ["aten::add", 5629], ["ReluBackward1", 5599], ["aten::stride", 5525], ["aten::threshold_", 5468], ["CudnnBatchNormBackward", 5417], ["aten::max_pool2d_with_indices_backward", 5301], ["aten::mean", 5251], ["CudnnBatchNormBackward", 5243], ["CudnnBatchNormBackward", 5175], ["aten::empty_like", 5154], ["aten::max_pool2d", 5123], ["CudnnBatchNormBackward", 5123], ["aten::fill_", 5082], ["aten::to", 5013], ["aten::fill_", 4974], ["aten::clone", 4932], ["aten::zero_", 4924], ["aten::zero_", 4919], ["torch::autograd::AccumulateGrad", 4877], ["aten::contiguous", 4726], ["aten::mul_", 4721], ["aten::stride", 4715], ["aten::fill_", 4706], ["aten::mul_", 4659], ["aten::max_pool2d_with_indices", 4656], ["torch::autograd::AccumulateGrad", 4656], ["aten::stride", 4636], ["aten::relu_", 4579], ["aten::add_", 4507], ["aten::empty_like", 4495], ["aten::empty_like", 4434], ["aten::relu_", 4401], ["aten::cudnn_batch_norm_backward", 4387], ["aten::contiguous", 4362], ["aten::contiguous", 4326], ["detach_", 4323], ["aten::contiguous", 4311], ["aten::add", 4295], ["aten::add", 4263], ["aten::add", 4253], ["aten::add_", 4188], ["aten::as_strided", 4176], ["aten::threshold_backward", 4176], ["aten::add", 4158], ["aten::threshold_backward", 4153], ["aten::add_", 4149], ["aten::contiguous", 4125], ["aten::cudnn_batch_norm_backward", 4123], ["aten::cudnn_batch_norm_backward", 4119], ["aten::zero_", 4111], ["aten::cudnn_batch_norm_backward", 4097], ["aten::as_strided", 4022], ["aten::mul_", 3918], ["aten::add_", 3832], ["aten::resize_", 3676], ["torch::autograd::AccumulateGrad", 3631], ["aten::clone", 3626], ["aten::empty_like", 3611], ["torch::autograd::AccumulateGrad", 3507], ["MeanBackward1", 3503], ["torch::autograd::AccumulateGrad", 3465], ["torch::autograd::AccumulateGrad", 3458], ["aten::contiguous", 3435], ["aten::mul_", 3398], ["aten::threshold_", 3371], ["aten::add_", 3359], ["aten::stride", 3343], ["aten::stride", 3302], ["aten::zero_", 3281], ["aten::zero_", 3266], ["aten::zeros", 3263], ["aten::pin_memory", 3259], ["aten::zero_", 3247], ["aten::as_strided", 3238], ["aten::threshold_", 3212], ["aten::clone", 3189], ["aten::clone", 3174], ["aten::mul_", 3151], ["aten::empty_like", 3141], ["aten::log_softmax", 3083], ["aten::mul_", 3052], ["aten::threshold_", 2948], ["aten::to", 2942], ["aten::empty_like", 2938], ["aten::fill_", 2850], ["aten::contiguous", 2837], ["aten::add", 2825], ["aten::stride", 2801], ["aten::clone", 2787], ["aten::add", 2782], ["aten::as_strided", 2758], ["aten::mm", 2744], ["aten::_log_softmax", 2665], ["aten::stride", 2652], ["LogSoftmaxBackward", 2612], ["aten::nll_loss", 2551], ["aten::mul_", 2509], ["aten::zero_", 2478], ["aten::resize_", 2472], ["aten::zero_", 2465], ["aten::zero_", 2458], ["aten::mul_", 2429], ["aten::threshold_", 2427], ["aten::zero_", 2425], ["torch::autograd::AccumulateGrad", 2410], ["aten::mul_", 2316], ["aten::contiguous", 2307], ["torch::autograd::AccumulateGrad", 2302], ["aten::resize_", 2294], ["aten::mul_", 2289], ["NllLossBackward", 2286], ["aten::resize_", 2258], ["aten::add_", 2190], ["aten::add_", 2174], ["aten::fill_", 2130], ["aten::add_", 2128], ["aten::add_", 2123], ["aten::add_", 2122], ["aten::t", 2117], ["aten::add_", 2114], ["aten::nll_loss_forward", 2113], ["aten::fill_", 2107], ["aten::add_", 2106], ["aten::add_", 2099], ["aten::_log_softmax_backward_data", 2095], ["aten::add_", 2088], ["aten::add_", 2087], ["aten::to", 2010], ["ReluBackward1", 1955], ["aten::relu_", 1946], ["aten::ones_like", 1915], ["aten::threshold_", 1899], ["aten::mm", 1879], ["aten::div", 1872], ["ReluBackward1", 1866], ["ReluBackward1", 1842], ["ReluBackward1", 1832], ["aten::zeros_like", 1796], ["aten::clone", 1794], ["aten::t", 1763], ["aten::flatten", 1754], ["aten::fill_", 1740], ["aten::resize_", 1669], ["aten::resize_", 1656], ["aten::zero_", 1650], ["aten::copy_", 1642], ["aten::zero_", 1620], ["aten::stride", 1579], ["aten::add", 1572], ["aten::relu_", 1557], ["aten::nll_loss_backward", 1553], ["aten::mul_", 1534], ["aten::mul_", 1511], ["aten::relu_", 1510], ["aten::relu_", 1500], ["aten::add", 1497], ["aten::contiguous", 1460], ["aten::empty_like", 1459], ["aten::contiguous", 1456], ["aten::add", 1453], ["aten::add", 1444], ["aten::threshold_", 1437], ["aten::empty_like", 1434], ["aten::fill_", 1429], ["aten::threshold_backward", 1422], ["aten::fill_", 1418], ["aten::threshold_", 1404], ["aten::add", 1401], ["aten::add", 1399], ["aten::add", 1394], ["aten::add", 1394], ["aten::fill_", 1394], ["aten::clone", 1387], ["aten::threshold_backward", 1381], ["aten::add", 1376], ["aten::threshold_backward", 1372], ["aten::add", 1371], ["aten::threshold_backward", 1365], ["aten::resize_", 1353], ["aten::to", 1352], ["aten::reshape", 1329], ["torch::autograd::AccumulateGrad", 1307], ["aten::stride", 1301], ["aten::resize_", 1272], ["aten::copy_", 1214], ["torch::autograd::AccumulateGrad", 1209], ["aten::contiguous", 1197], ["AddBackward0", 1196], ["torch::autograd::AccumulateGrad", 1183], ["torch::autograd::AccumulateGrad", 1177], ["torch::autograd::AccumulateGrad", 1177], ["torch::autograd::AccumulateGrad", 1172], ["aten::detach", 1167], ["torch::autograd::AccumulateGrad", 1165], ["aten::resize_", 1164], ["torch::autograd::AccumulateGrad", 1164], ["aten::clone", 1161], ["torch::autograd::AccumulateGrad", 1143], ["aten::clone", 1131], ["TBackward", 1120], ["aten::copy_", 1094], ["torch::autograd::AccumulateGrad", 1086], ["aten::fill_", 1076], ["aten::fill_", 1076], ["ViewBackward", 1073], ["aten::zero_", 1064], ["aten::copy_", 1055], ["aten::fill_", 1053], ["aten::fill_", 1049], ["aten::stride", 1047], ["aten::resize_", 1018], ["aten::resize_", 1017], ["aten::clone", 998], ["aten::contiguous", 986], ["aten::contiguous", 972], ["aten::set_", 967], ["aten::contiguous", 948], ["aten::contiguous", 947], ["aten::view", 937], ["aten::contiguous", 936], ["aten::zero_", 929], ["aten::clone", 922], ["aten::zero_", 920], ["aten::copy_", 918], ["aten::clone", 910], ["aten::contiguous", 878], ["AddBackward0", 875], ["aten::contiguous", 874], ["aten::t", 871], ["aten::as_strided", 868], ["aten::copy_", 861], ["aten::transpose", 855], ["aten::mul_", 851], ["aten::expand", 849], ["aten::empty_like", 839], ["aten::transpose", 834], ["aten::resize_", 832], ["aten::resize_", 831], ["aten::resize_", 828], ["aten::zero_", 824], ["aten::is_pinned", 822], ["aten::zero_", 820], ["aten::detach", 815], ["aten::zero_", 815], ["aten::mul_", 814], ["aten::zero_", 813], ["aten::mul_", 809], ["aten::zero_", 804], ["aten::zero_", 804], ["aten::mul_", 804], ["aten::zero_", 803], ["aten::zero_", 801], ["aten::mul_", 790], ["aten::mul_", 780], ["aten::mul_", 774], ["aten::mul_", 763], ["aten::empty_like", 762], ["aten::zero_", 760], ["aten::contiguous", 759], ["aten::stride", 756], ["aten::copy_", 755], ["aten::reshape", 755], ["aten::mul_", 751], ["aten::stride", 746], ["aten::mul_", 731], ["aten::empty_like", 728], ["aten::contiguous", 723], ["aten::stride", 720], ["aten::empty_like", 720], ["aten::fill_", 706], ["aten::contiguous", 701], ["aten::contiguous", 700], ["aten::clone", 697], ["aten::clone", 692], ["aten::fill_", 692], ["aten::clone", 690], ["aten::stride", 687], ["aten::stride", 683], ["aten::clone", 676], ["aten::copy_", 671], ["aten::stride", 669], ["aten::as_strided", 655], ["aten::resize_", 621], ["aten::narrow", 612], ["aten::resize_", 610], ["aten::detach", 610], ["aten::threshold_", 606], ["AddBackward0", 602], ["aten::resize_", 586], ["aten::resize_", 583], ["AddBackward0", 577], ["aten::copy_", 567], ["aten::stride", 557], ["nccl:broadcast", 540], ["aten::copy_", 537], ["aten::detach", 528], ["aten::expand", 525], ["aten::copy_", 523], ["aten::view", 509], ["aten::detach", 507], ["aten::copy_", 504], ["aten::fill_", 486], ["aten::threshold_", 481], ["aten::threshold_", 479], ["aten::threshold_", 477], ["aten::contiguous", 475], ["aten::contiguous", 470], ["aten::clone", 468], ["aten::clone", 460], ["aten::clone", 456], ["detach", 454], ["aten::clone", 450], ["aten::fill_", 443], ["aten::fill_", 434], ["aten::stride", 428], ["aten::transpose", 412], ["aten::is_pinned", 408], ["aten::slice", 390], ["aten::resize_", 387], ["aten::resize_", 386], ["aten::stride", 372], ["aten::resize_", 360], ["aten::fill_", 360], ["aten::fill_", 359], ["aten::fill_", 359], ["aten::resize_as_", 355], ["aten::fill_", 351], ["aten::fill_", 349], ["aten::fill_", 348], ["aten::fill_", 348], ["aten::detach_", 345], ["aten::fill_", 345], ["aten::fill_", 344], ["aten::copy_", 339], ["aten::copy_", 338], ["detach", 326], ["aten::resize_", 322], ["aten::resize_", 320], ["aten::contiguous", 313], ["aten::detach", 292], ["aten::contiguous", 290], ["aten::as_strided", 263], ["aten::contiguous", 251], ["aten::contiguous", 249], ["aten::contiguous", 247], ["aten::contiguous", 247], ["aten::as_strided", 243], ["aten::clone", 238], ["aten::clone", 237], ["aten::contiguous", 235], ["aten::contiguous", 233], ["aten::contiguous", 233], ["aten::clone", 233], ["detach", 229], ["aten::clone", 225], ["aten::detach", 222], ["aten::clone", 222], ["aten::clone", 222], ["aten::detach", 220], ["aten::clone", 218], ["aten::resize_", 209], ["aten::copy_", 208], ["aten::resize_", 203], ["aten::resize_", 201], ["aten::copy_", 201], ["detach", 201], ["detach", 200], ["aten::copy_", 197], ["aten::resize_", 195], ["aten::resize_", 195], ["aten::resize_", 194], ["aten::resize_", 191], ["aten::stride", 188], ["aten::conj", 184], ["aten::detach", 183], ["aten::copy_", 181], ["aten::copy_", 177], ["aten::copy_", 175], ["aten::copy_", 173], ["aten::copy_", 172], ["aten::copy_", 171], ["aten::copy_", 171], ["detach_", 170], ["aten::copy_", 166], ["aten::resize_", 165], ["aten::resize_", 163], ["aten::conj", 159], ["aten::as_strided", 158], ["aten::detach", 156], ["aten::detach", 153], ["aten::as_strided", 152], ["aten::detach", 151], ["aten::as_strided", 137], ["aten::as_strided", 132], ["aten::stride", 129], ["aten::contiguous", 126], ["aten::detach", 126], ["aten::is_floating_point", 122], ["aten::to", 119], ["aten::as_strided", 115], ["aten::stride", 115], ["aten::detach", 114], ["detach", 113], ["aten::detach", 111], ["aten::detach", 109], ["aten::stride", 106], ["aten::stride", 106], ["aten::resize_", 105], ["aten::stride", 100], ["aten::detach", 90], ["detach", 90], ["detach", 89], ["aten::random_", 86], ["detach", 74], ["aten::detach", 72], ["detach", 61], ["detach", 61], ["detach", 61], ["detach", 60], ["aten::stride", 47], ["detach", 45], ["detach", 45], ["detach", 44], ["aten::detach", 44], ["aten::detach", 41], ["aten::detach", 40], ["aten::detach", 39], ["aten::detach", 38], ["aten::detach", 38], ["aten::detach", 38], ["aten::detach", 37], ["aten::detach", 36], ["aten::detach", 36], ["detach", 31], ["detach", 29], ["detach", 16], ["detach", 16], ["detach", 15], ["detach", 15], ["detach", 15], ["detach", 15], ["detach", 15], ["detach", 15], ["detach", 14], ["detach", 14]]}, "host_self_time": {"title": "Host Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 3840507], ["aten::_cat", 2992955], ["aten::cudnn_convolution", 1433941], ["aten::div", 982592], ["aten::div_", 957981], ["aten::sub_", 801857], ["aten::addmm", 486088], ["aten::empty", 423852], ["aten::cudnn_convolution_backward_weight", 176989], ["aten::copy_", 87576], ["aten::cudnn_batch_norm", 80775], ["aten::copy_", 68986], ["aten::add_", 68572], ["aten::cudnn_convolution_backward_input", 67502], ["aten::add", 60066], ["aten::slice", 58776], ["aten::empty_strided", 58338], ["aten::to", 55918], ["aten::select", 54541], ["aten::uniform_", 51990], ["aten::add_", 46445], ["aten::any", 45075], ["aten::cudnn_batch_norm", 44191], ["aten::_local_scalar_dense", 39608], ["aten::view", 38958], ["aten::add", 35628], ["aten::cudnn_batch_norm_backward", 33905], ["aten::add_", 33723], ["aten::view", 33469], ["aten::cudnn_convolution_backward_input", 33433], ["aten::cudnn_convolution_backward_input", 32313], ["aten::_local_scalar_dense", 31942], ["aten::randint", 31108], ["aten::cudnn_convolution", 30991], ["aten::item", 30822], ["aten::log", 30100], ["aten::add_", 30034], ["aten::cudnn_convolution", 29982], ["aten::copy_", 29878], ["aten::clone", 29615], ["aten::add_", 29292], ["aten::cudnn_convolution", 29209], ["aten::cudnn_convolution_backward_input", 29138], ["aten::item", 29088], ["aten::slice", 28936], ["aten::exp", 28622], ["aten::cudnn_convolution", 28562], ["aten::cudnn_batch_norm", 27688], ["aten::cudnn_batch_norm", 27445], ["aten::lt", 26862], ["aten::cudnn_convolution_backward_weight", 26846], ["aten::eq", 26363], ["aten::eq", 26228], ["aten::cudnn_convolution", 26188], ["aten::cudnn_convolution_backward_input", 26051], ["aten::cudnn_convolution_backward_weight", 26009], ["aten::cudnn_convolution", 25689], ["aten::view", 25555], ["aten::lt", 25486], ["aten::narrow", 25022], ["aten::view", 24895], ["aten::view", 24794], ["aten::narrow", 24331], ["aten::cudnn_convolution", 24210], ["aten::add", 23877], ["aten::mul_", 23789], ["aten::cudnn_batch_norm", 23617], ["aten::cudnn_convolution_backward_weight", 23516], ["aten::cudnn_convolution_backward_input", 23377], ["aten::cudnn_convolution", 23244], ["aten::cudnn_convolution", 23226], ["aten::resize_", 22679], ["aten::cudnn_convolution", 22559], ["aten::permute", 21835], ["aten::cudnn_convolution", 21172], ["aten::cudnn_convolution_backward_weight", 21056], ["aten::cudnn_convolution_backward_input", 20821], ["aten::copy_", 20503], ["aten::cudnn_convolution", 20366], ["aten::cudnn_convolution_backward_weight", 20334], ["aten::cudnn_convolution_backward_input", 20015], ["aten::exp", 19874], ["aten::cudnn_batch_norm", 19729], ["aten::cudnn_batch_norm_backward", 19677], ["aten::cudnn_batch_norm_backward", 19661], ["aten::cudnn_batch_norm", 19630], ["aten::to", 19503], ["aten::cudnn_convolution_backward_input", 19456], ["aten::cudnn_convolution_backward_weight", 19216], ["aten::cudnn_convolution_backward_weight", 19195], ["aten::pin_memory", 19128], ["aten::cudnn_convolution_backward_input", 18631], ["aten::view", 18517], ["aten::cudnn_convolution_backward_input", 18435], ["aten::cudnn_convolution", 17947], ["aten::cudnn_convolution_backward_input", 17758], ["aten::cudnn_batch_norm_backward", 17357], ["aten::rand", 17271], ["aten::add", 17249], ["aten::view", 17198], ["aten::set_", 17013], ["aten::view", 16975], ["aten::mul_", 16944], ["aten::cudnn_convolution", 16856], ["aten::add_", 16710], ["aten::cudnn_convolution", 16316], ["aten::cudnn_batch_norm", 16230], ["aten::cudnn_convolution_backward_input", 16116], ["aten::view", 16043], ["aten::random_", 15758], ["aten::cudnn_batch_norm", 15752], ["aten::cudnn_convolution_backward_weight", 15432], ["aten::cudnn_convolution", 15304], ["aten::copy_", 15215], ["aten::add", 14967], ["aten::zero_", 14960], ["aten::add", 14891], ["aten::cudnn_convolution_backward_weight", 14812], ["aten::cudnn_convolution_backward_input", 14329], ["aten::cudnn_convolution", 14259], ["aten::cudnn_convolution", 14159], ["aten::as_strided", 14108], ["aten::cudnn_convolution_backward_weight", 14104], ["aten::cudnn_batch_norm_backward", 13941], ["aten::cudnn_batch_norm_backward", 13902], ["aten::cudnn_convolution_backward_weight", 13899], ["aten::cudnn_convolution_backward_input", 13830], ["aten::add_", 13342], ["aten::copy_", 13301], ["aten::cudnn_convolution_backward_input", 13271], ["aten::cudnn_convolution_backward_weight", 13248], ["aten::add_", 13099], ["aten::copy_", 12975], ["aten::cudnn_batch_norm_backward", 12923], ["aten::contiguous", 12922], ["aten::threshold_backward", 12366], ["aten::is_floating_point", 12354], ["aten::cudnn_convolution_backward_weight", 12056], ["aten::_batch_norm_impl_index", 12019], ["aten::mul_", 11845], ["aten::relu_", 11732], ["aten::fill_", 11657], ["aten::cudnn_batch_norm_backward", 11184], ["aten::cudnn_convolution", 11166], ["torch::autograd::AccumulateGrad", 11023], ["aten::empty_like", 10613], ["aten::cudnn_convolution_backward_weight", 10580], ["aten::cudnn_convolution", 10543], ["aten::cudnn_convolution_backward_weight", 10536], ["aten::add_", 10441], ["aten::mul_", 10402], ["aten::mul_", 10268], ["aten::zero_", 10201], ["CudnnBatchNormBackward", 10134], ["aten::contiguous", 9601], ["aten::contiguous", 9599], ["aten::unsqueeze", 9407], ["aten::as_strided", 9363], ["aten::cudnn_convolution_backward_weight", 9335], ["aten::cudnn_convolution_backward_input", 9273], ["aten::cudnn_convolution_backward_input", 9201], ["aten::cudnn_convolution", 9193], ["aten::cudnn_convolution_backward_weight", 8997], ["aten::view", 8978], ["aten::cudnn_convolution", 8738], ["aten::add_", 8690], ["aten::_batch_norm_impl_index", 8659], ["aten::add_", 8588], ["aten::add", 8566], ["aten::add_", 8432], ["aten::cudnn_convolution_backward_weight", 8427], ["aten::cudnn_convolution_backward_weight", 8188], ["aten::cudnn_convolution_backward", 8020], ["aten::fill_", 7845], ["aten::cudnn_convolution_backward_input", 7836], ["aten::cudnn_convolution_backward_weight", 7831], ["aten::stride", 7777], ["torch::autograd::AccumulateGrad", 7750], ["aten::cudnn_convolution_backward_weight", 7642], ["aten::_batch_norm_impl_index", 7630], ["aten::cudnn_convolution_backward", 7571], ["aten::copy_", 7553], ["aten::to", 7450], ["aten::_batch_norm_impl_index", 7450], ["aten::threshold_backward", 7430], ["CudnnConvolutionBackward", 7408], ["aten::zero_", 7407], ["aten::relu_", 7101], ["aten::cudnn_convolution_backward", 6988], ["aten::add_", 6830], ["aten::add_", 6685], ["aten::zero_", 6628], ["aten::zero_", 6512], ["aten::threshold_backward", 6463], ["aten::add_", 6461], ["aten::add", 6428], ["aten::add", 6416], ["aten::contiguous", 6414], ["aten::_batch_norm_impl_index", 6409], ["aten::add_", 6403], ["aten::threshold_backward", 6355], ["CudnnBatchNormBackward", 6355], ["aten::contiguous", 6335], ["aten::add_", 6319], ["aten::stack", 6262], ["CudnnBatchNormBackward", 6192], ["aten::contiguous", 6125], ["aten::relu_", 6119], ["aten::relu_", 6105], ["aten::contiguous", 5945], ["aten::mul_", 5924], ["aten::detach_", 5901], ["aten::as_strided", 5884], ["aten::as_strided", 5878], ["aten::contiguous", 5869], ["aten::is_nonzero", 5803], ["aten::fill_", 5750], ["torch::autograd::AccumulateGrad", 5732], ["aten::_batch_norm_impl_index", 5714], ["aten::is_nonzero", 5666], ["aten::stride", 5525], ["aten::cudnn_convolution_backward", 5511], ["aten::threshold_", 5468], ["aten::_batch_norm_impl_index", 5465], ["CudnnBatchNormBackward", 5426], ["aten::add", 5419], ["aten::threshold_backward", 5356], ["aten::cudnn_convolution_backward", 5323], ["ReluBackward1", 5321], ["aten::cudnn_convolution_backward", 5178], ["aten::relu_", 5134], ["aten::fill_", 5082], ["aten::add", 5066], ["aten::to", 5013], ["aten::fill_", 4974], ["aten::mean", 4907], ["torch::autograd::AccumulateGrad", 4874], ["torch::autograd::AccumulateGrad", 4852], ["CudnnConvolutionBackward", 4798], ["aten::contiguous", 4726], ["aten::mul_", 4721], ["aten::stride", 4715], ["aten::fill_", 4706], ["aten::_convolution", 4699], ["aten::mul_", 4659], ["aten::stride", 4636], ["CudnnConvolutionBackward", 4629], ["CudnnBatchNormBackward", 4512], ["aten::add_", 4507], ["CudnnBatchNormBackward", 4448], ["aten::empty_like", 4434], ["aten::_batch_norm_impl_index", 4433], ["aten::batch_norm", 4366], ["aten::contiguous", 4362], ["aten::add", 4340], ["aten::contiguous", 4326], ["detach_", 4323], ["aten::contiguous", 4311], ["aten::threshold_backward", 4309], ["aten::add", 4307], ["aten::add_", 4188], ["aten::as_strided", 4176], ["aten::cudnn_convolution_backward", 4163], ["aten::cudnn_convolution_backward", 4159], ["aten::add_", 4149], ["aten::contiguous", 4125], ["aten::cudnn_convolution_backward", 4113], ["aten::as_strided", 4022], ["CudnnConvolutionBackward", 4018], ["aten::_convolution", 3989], ["aten::relu_", 3980], ["aten::_convolution", 3955], ["aten::cudnn_batch_norm", 3928], ["aten::cudnn_batch_norm", 3927], ["aten::cudnn_batch_norm", 3925], ["aten::mul_", 3918], ["aten::add_", 3832], ["aten::zero_", 3740], ["aten::resize_", 3676], ["CudnnBatchNormBackward", 3635], ["CudnnBatchNormBackward", 3584], ["aten::clone", 3489], ["aten::contiguous", 3435], ["ReluBackward1", 3408], ["CudnnConvolutionBackward", 3405], ["aten::mul_", 3398], ["CudnnConvolutionBackward", 3373], ["aten::threshold_", 3371], ["aten::add_", 3359], ["aten::stride", 3343], ["aten::stride", 3302], ["aten::max_pool2d_with_indices", 3298], ["aten::add", 3268], ["aten::add", 3265], ["aten::as_strided", 3238], ["aten::threshold_", 3212], ["aten::threshold_backward", 3201], ["aten::add", 3189], ["aten::threshold_backward", 3180], ["aten::add", 3164], ["aten::mul_", 3151], ["aten::relu_", 3142], ["aten::cat", 3121], ["aten::_convolution", 3103], ["aten::_convolution", 3096], ["aten::mul_", 3052], ["ReluBackward1", 3032], ["aten::relu_", 2997], ["aten::threshold_", 2948], ["ReluBackward1", 2916], ["aten::cudnn_batch_norm_backward", 2876], ["aten::fill_", 2850], ["aten::contiguous", 2837], ["aten::zero_", 2817], ["aten::stride", 2801], ["torch::autograd::AccumulateGrad", 2797], ["aten::zero_", 2789], ["aten::cudnn_batch_norm_backward", 2777], ["aten::batch_norm", 2775], ["aten::empty_like", 2759], ["aten::as_strided", 2758], ["aten::batch_norm", 2754], ["CudnnConvolutionBackward", 2752], ["aten::cudnn_batch_norm_backward", 2743], ["aten::cudnn_convolution_backward", 2737], ["aten::cudnn_batch_norm_backward", 2737], ["aten::empty_like", 2734], ["aten::cudnn_convolution_backward", 2720], ["aten::cudnn_convolution_backward", 2717], ["aten::stride", 2652], ["CudnnConvolutionBackward", 2632], ["aten::max_pool2d_with_indices_backward", 2577], ["aten::mul_", 2509], ["aten::conv2d", 2506], ["aten::resize_", 2472], ["aten::mul_", 2429], ["aten::threshold_", 2427], ["ReluBackward1", 2427], ["aten::batch_norm", 2400], ["aten::clone", 2381], ["aten::_convolution", 2373], ["aten::zero_", 2371], ["aten::empty_like", 2354], ["aten::_convolution", 2353], ["aten::_convolution", 2348], ["aten::mul_", 2316], ["aten::contiguous", 2307], ["aten::resize_", 2294], ["aten::mul_", 2289], ["aten::_convolution", 2272], ["aten::resize_", 2258], ["aten::mm", 2249], ["aten::convolution", 2232], ["aten::add_", 2190], ["aten::add_", 2174], ["aten::add", 2166], ["torch::autograd::AccumulateGrad", 2160], ["aten::add", 2132], ["aten::fill_", 2130], ["aten::add_", 2128], ["torch::autograd::AccumulateGrad", 2125], ["aten::add_", 2123], ["aten::add_", 2122], ["aten::add_", 2114], ["aten::nll_loss_forward", 2113], ["aten::fill_", 2107], ["aten::add_", 2106], ["aten::conv2d", 2102], ["aten::add_", 2099], ["aten::add_", 2088], ["aten::add_", 2087], ["aten::conv2d", 2076], ["aten::batch_norm", 2043], ["aten::empty_like", 1985], ["aten::batch_norm", 1969], ["ReluBackward1", 1963], ["aten::empty_like", 1953], ["aten::threshold_", 1899], ["aten::cudnn_convolution_backward", 1886], ["aten::convolution", 1869], ["aten::zero_", 1853], ["aten::zero_", 1852], ["aten::zero_", 1848], ["aten::convolution", 1828], ["aten::_log_softmax", 1828], ["torch::autograd::AccumulateGrad", 1809], ["aten::clone", 1741], ["aten::fill_", 1740], ["aten::conv2d", 1731], ["aten::conv2d", 1685], ["aten::resize_", 1669], ["aten::zeros", 1657], ["aten::resize_", 1656], ["aten::batch_norm", 1655], ["aten::copy_", 1642], ["aten::_convolution", 1622], ["aten::empty_like", 1594], ["aten::batch_norm", 1591], ["aten::stride", 1579], ["aten::empty_like", 1574], ["aten::clone", 1563], ["aten::_convolution", 1559], ["aten::nll_loss_backward", 1553], ["aten::_convolution", 1545], ["aten::div", 1538], ["aten::mul_", 1534], ["aten::clone", 1516], ["aten::pin_memory", 1515], ["aten::convolution", 1513], ["torch::autograd::AccumulateGrad", 1513], ["aten::mul_", 1511], ["ReluBackward1", 1507], ["aten::convolution", 1506], ["aten::cudnn_convolution_backward", 1465], ["aten::contiguous", 1460], ["aten::contiguous", 1456], ["ReluBackward1", 1446], ["torch::autograd::AccumulateGrad", 1445], ["AddmmBackward", 1441], ["aten::threshold_", 1437], ["aten::fill_", 1429], ["torch::autograd::AccumulateGrad", 1429], ["aten::fill_", 1418], ["aten::zero_", 1416], ["aten::threshold_", 1404], ["aten::zero_", 1402], ["aten::cudnn_convolution_backward", 1396], ["aten::fill_", 1394], ["aten::cudnn_convolution_backward", 1393], ["aten::mm", 1391], ["aten::zero_", 1382], ["aten::cudnn_convolution_backward", 1379], ["aten::zero_", 1372], ["aten::cudnn_convolution_backward", 1372], ["aten::cudnn_convolution_backward", 1361], ["aten::resize_", 1353], ["aten::to", 1352], ["aten::conv2d", 1341], ["aten::cudnn_convolution_backward", 1341], ["aten::relu_", 1340], ["aten::conv2d", 1335], ["aten::cudnn_convolution_backward", 1327], ["aten::cudnn_convolution_backward", 1312], ["aten::stride", 1301], ["aten::t", 1283], ["aten::resize_", 1272], ["aten::conv2d", 1251], ["aten::conv2d", 1239], ["aten::copy_", 1214], ["aten::add", 1208], ["aten::contiguous", 1197], ["AddBackward0", 1196], ["aten::_batch_norm_impl_index", 1192], ["aten::_log_softmax_backward_data", 1183], ["torch::autograd::AccumulateGrad", 1166], ["aten::resize_", 1164], ["aten::add", 1163], ["aten::convolution", 1155], ["aten::add", 1108], ["aten::threshold_backward", 1102], ["aten::copy_", 1094], ["aten::convolution", 1091], ["aten::add", 1091], ["aten::_batch_norm_impl_index", 1086], ["aten::_batch_norm_impl_index", 1084], ["aten::convolution", 1081], ["aten::add", 1081], ["aten::relu_", 1078], ["aten::fill_", 1076], ["aten::fill_", 1076], ["aten::add", 1072], ["torch::autograd::AccumulateGrad", 1072], ["aten::convolution", 1071], ["aten::add", 1070], ["aten::_batch_norm_impl_index", 1069], ["aten::add", 1068], ["aten::copy_", 1055], ["aten::fill_", 1053], ["aten::add", 1051], ["aten::add", 1050], ["aten::fill_", 1049], ["aten::stride", 1047], ["aten::threshold_backward", 1044], ["torch::autograd::AccumulateGrad", 1043], ["torch::autograd::AccumulateGrad", 1041], ["aten::threshold_backward", 1039], ["aten::threshold_backward", 1033], ["aten::relu_", 1029], ["aten::_convolution", 1024], ["aten::relu_", 1023], ["aten::resize_", 1018], ["aten::resize_", 1017], ["CudnnBatchNormBackward", 996], ["aten::contiguous", 986], ["aten::contiguous", 972], ["aten::set_", 967], ["aten::cudnn_convolution_backward", 959], ["aten::contiguous", 948], ["aten::contiguous", 947], ["aten::zero_", 944], ["aten::view", 937], ["aten::contiguous", 936], ["aten::zero_", 928], ["CudnnBatchNormBackward", 920], ["aten::copy_", 918], ["aten::t", 908], ["aten::_convolution", 902], ["aten::to", 891], ["CudnnBatchNormBackward", 885], ["CudnnBatchNormBackward", 885], ["aten::contiguous", 878], ["AddBackward0", 875], ["aten::contiguous", 874], ["aten::as_strided", 868], ["aten::copy_", 861], ["aten::mul_", 851], ["aten::clone", 848], ["aten::conv2d", 838], ["aten::resize_", 832], ["aten::resize_", 831], ["aten::resize_", 828], ["aten::is_pinned", 822], ["aten::conv2d", 821], ["aten::conv2d", 817], ["aten::mul_", 814], ["aten::mul_", 809], ["aten::_convolution", 808], ["aten::mul_", 804], ["aten::_convolution", 797], ["aten::mul_", 790], ["torch::autograd::AccumulateGrad", 790], ["aten::_convolution", 785], ["aten::empty_like", 782], ["aten::mul_", 780], ["aten::_convolution", 778], ["aten::_convolution", 778], ["aten::mul_", 774], ["aten::_convolution", 773], ["aten::_convolution", 769], ["aten::_convolution", 765], ["aten::mul_", 763], ["aten::contiguous", 759], ["aten::stride", 756], ["aten::copy_", 755], ["aten::_convolution", 752], ["aten::empty_like", 751], ["aten::mul_", 751], ["aten::stride", 746], ["aten::convolution", 743], ["torch::autograd::AccumulateGrad", 734], ["NllLossBackward", 733], ["aten::mul_", 731], ["aten::contiguous", 723], ["aten::stride", 720], ["aten::convolution", 720], ["aten::convolution", 720], ["CudnnConvolutionBackward", 719], ["aten::detach", 713], ["aten::zero_", 708], ["aten::fill_", 706], ["aten::contiguous", 701], ["aten::contiguous", 700], ["aten::fill_", 692], ["aten::expand", 691], ["aten::stride", 687], ["aten::clone", 684], ["aten::stride", 683], ["CudnnConvolutionBackward", 683], ["CudnnConvolutionBackward", 680], ["aten::copy_", 671], ["aten::stride", 669], ["MeanBackward1", 663], ["aten::clone", 660], ["CudnnConvolutionBackward", 660], ["aten::as_strided", 655], ["MaxPool2DWithIndicesBackward", 644], ["aten::resize_", 621], ["aten::transpose", 612], ["aten::to", 610], ["aten::resize_", 610], ["aten::threshold_", 606], ["AddBackward0", 602], ["aten::ones_like", 590], ["aten::resize_", 586], ["aten::resize_", 583], ["AddBackward0", 577], ["aten::transpose", 571], ["aten::copy_", 567], ["aten::zero_", 561], ["aten::stride", 557], ["aten::clone", 556], ["nccl:broadcast", 540], ["aten::copy_", 537], ["ReluBackward1", 533], ["aten::copy_", 523], ["LogSoftmaxBackward", 517], ["aten::view", 509], ["aten::copy_", 504], ["aten::zero_", 495], ["aten::detach", 489], ["aten::fill_", 486], ["ReluBackward1", 485], ["aten::threshold_", 481], ["aten::threshold_", 479], ["aten::threshold_", 477], ["ReluBackward1", 477], ["aten::contiguous", 475], ["aten::zero_", 473], ["aten::zero_", 471], ["aten::contiguous", 470], ["aten::max_pool2d", 467], ["aten::conv2d", 461], ["aten::zero_", 460], ["ReluBackward1", 460], ["aten::t", 459], ["torch::autograd::AccumulateGrad", 457], ["aten::zero_", 456], ["aten::zero_", 456], ["aten::clone", 455], ["aten::clone", 455], ["aten::zero_", 455], ["aten::zero_", 455], ["detach", 454], ["aten::zero_", 454], ["aten::clone", 445], ["aten::fill_", 443], ["aten::nll_loss", 438], ["aten::fill_", 434], ["aten::empty_like", 430], ["aten::conv2d", 429], ["aten::adaptive_avg_pool2d", 429], ["aten::stride", 428], ["aten::batch_norm", 426], ["aten::conv2d", 425], ["aten::flatten", 425], ["aten::conv2d", 422], ["aten::conv2d", 422], ["aten::log_softmax", 418], ["aten::conv2d", 417], ["aten::conv2d", 416], ["aten::conv2d", 414], ["aten::conv2d", 412], ["aten::empty_like", 411], ["aten::is_pinned", 408], ["aten::conv2d", 408], ["aten::conv2d", 406], ["aten::convolution", 402], ["aten::expand", 393], ["aten::batch_norm", 392], ["aten::reshape", 392], ["aten::empty_like", 389], ["aten::convolution", 389], ["aten::resize_", 387], ["aten::resize_", 386], ["aten::convolution", 386], ["aten::batch_norm", 386], ["aten::batch_norm", 385], ["aten::empty_like", 384], ["aten::detach", 381], ["aten::convolution", 375], ["aten::stride", 372], ["torch::autograd::AccumulateGrad", 367], ["torch::autograd::AccumulateGrad", 366], ["aten::convolution", 365], ["torch::autograd::AccumulateGrad", 365], ["torch::autograd::AccumulateGrad", 365], ["torch::autograd::AccumulateGrad", 363], ["aten::convolution", 361], ["torch::autograd::AccumulateGrad", 361], ["aten::convolution", 360], ["aten::resize_", 360], ["aten::fill_", 360], ["aten::convolution", 359], ["aten::fill_", 359], ["aten::fill_", 359], ["aten::convolution", 357], ["aten::convolution", 354], ["aten::convolution", 354], ["aten::fill_", 351], ["torch::autograd::AccumulateGrad", 351], ["aten::fill_", 349], ["aten::fill_", 348], ["aten::fill_", 348], ["aten::fill_", 345], ["torch::autograd::AccumulateGrad", 345], ["aten::fill_", 344], ["aten::zeros_like", 340], ["aten::copy_", 339], ["aten::copy_", 338], ["aten::clone", 335], ["aten::clone", 332], ["aten::clone", 329], ["aten::detach", 327], ["aten::clone", 326], ["detach", 326], ["aten::resize_", 322], ["aten::resize_", 320], ["ViewBackward", 318], ["torch::autograd::AccumulateGrad", 317], ["aten::zero_", 317], ["aten::contiguous", 313], ["aten::detach", 307], ["aten::contiguous", 290], ["TBackward", 281], ["aten::resize_as_", 281], ["aten::slice", 275], ["aten::transpose", 275], ["aten::as_strided", 263], ["aten::contiguous", 251], ["aten::contiguous", 249], ["aten::contiguous", 247], ["aten::contiguous", 247], ["aten::reshape", 246], ["aten::as_strided", 243], ["aten::contiguous", 235], ["aten::contiguous", 233], ["aten::contiguous", 233], ["aten::clone", 233], ["detach", 229], ["aten::narrow", 222], ["aten::clone", 221], ["aten::resize_", 209], ["aten::copy_", 208], ["aten::resize_", 203], ["aten::resize_", 201], ["aten::copy_", 201], ["detach", 201], ["detach", 200], ["aten::copy_", 197], ["aten::resize_", 195], ["aten::resize_", 195], ["aten::resize_", 194], ["aten::resize_", 191], ["aten::stride", 188], ["aten::conj", 184], ["aten::copy_", 181], ["aten::detach", 179], ["aten::copy_", 177], ["aten::detach_", 175], ["aten::copy_", 175], ["aten::copy_", 173], ["aten::copy_", 172], ["aten::copy_", 171], ["aten::copy_", 171], ["detach_", 170], ["aten::copy_", 166], ["aten::resize_", 165], ["aten::resize_", 163], ["aten::conj", 159], ["aten::as_strided", 158], ["aten::as_strided", 152], ["aten::as_strided", 137], ["aten::as_strided", 132], ["aten::detach", 132], ["aten::detach", 131], ["aten::stride", 129], ["aten::contiguous", 126], ["aten::is_floating_point", 122], ["aten::clone", 121], ["aten::to", 119], ["aten::as_strided", 115], ["aten::stride", 115], ["aten::clone", 115], ["aten::clone", 113], ["aten::clone", 113], ["aten::clone", 113], ["detach", 113], ["aten::clone", 111], ["aten::clone", 111], ["aten::detach", 109], ["aten::clone", 107], ["aten::stride", 106], ["aten::stride", 106], ["aten::resize_", 105], ["aten::clone", 105], ["aten::clone", 104], ["aten::stride", 100], ["aten::detach", 95], ["aten::detach", 92], ["aten::detach", 91], ["detach", 90], ["detach", 89], ["aten::random_", 86], ["detach", 74], ["aten::detach", 69], ["aten::detach", 66], ["aten::detach", 65], ["aten::detach", 65], ["detach", 61], ["detach", 61], ["detach", 61], ["detach", 60], ["aten::detach", 59], ["aten::stride", 47], ["detach", 45], ["detach", 45], ["detach", 44], ["aten::detach", 43], ["detach", 31], ["aten::detach", 29], ["detach", 29], ["aten::detach", 25], ["aten::detach", 25], ["aten::detach", 24], ["aten::detach", 23], ["aten::detach", 23], ["aten::detach", 22], ["aten::detach", 22], ["aten::detach", 22], ["aten::detach", 22], ["detach", 16], ["detach", 16], ["detach", 15], ["detach", 15], ["detach", 15], ["detach", 15], ["detach", 15], ["detach", 15], ["detach", 14], ["detach", 14]]}}, "operation_table_by_name_input": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "string", "name": "Input Shape"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Device Self Duration (us)"}, {"type": "number", "name": "Device Total Duration (us)"}, {"type": "number", "name": "Host Self Duration (us)"}, {"type": "number", "name": "Host Total Duration (us)"}], "rows": [["aten::cudnn_convolution_backward_weight", "[[], [32, 64, 56, 56], [32, 64, 56, 56], [], [], [], [], [], [], []]", 32, 31716, 31716, 23516, 28306], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], []]", 24, 28987, 28987, 33433, 37281], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], []]", 48, 28092, 28092, 32313, 39662], ["aten::cudnn_convolution_backward_input", "[[], [32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], []]", 32, 25942, 25942, 26051, 30895], ["aten::cudnn_convolution_backward_input", "[[], [32, 1024, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], []]", 48, 25836, 25836, 29138, 36210], ["aten::cudnn_convolution", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], []]", 48, 23594, 23594, 29982, 37268], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 56, 56], [32, 64, 56, 56], [], [], [], [], [], [], []]", 32, 21884, 21884, 19216, 23672], ["aten::cudnn_convolution_backward_weight", "[[], [32, 1024, 14, 14], [32, 256, 14, 14], [], [], [], [], [], [], []]", 48, 21805, 21805, 26846, 33473], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], []]", 40, 20732, 20732, 20015, 25545], ["aten::cudnn_convolution", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], []]", 40, 20626, 20626, 26188, 32187], ["aten::cudnn_batch_norm_backward", "[[32, 256, 56, 56], [32, 256, 56, 56], [256], [256], [256], [256], [256], [], [0]]", 32, 20552, 20552, 11184, 16605], ["aten::cudnn_convolution", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], []]", 24, 20349, 20349, 28562, 32209], ["aten::cudnn_convolution_backward_input", "[[], [32, 2048, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], []]", 24, 20073, 20073, 19456, 22817], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 14, 14], [32, 1024, 14, 14], [], [], [], [], [], [], []]", 40, 18586, 18586, 19195, 24730], ["aten::cudnn_convolution_backward_weight", "[[], [32, 64, 56, 56], [32, 256, 56, 56], [], [], [], [], [], [], []]", 16, 18546, 18546, 14104, 16396], ["aten::cudnn_convolution", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], []]", 16, 18181, 18181, 24210, 26628], ["aten::cudnn_convolution", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], []]", 40, 17239, 17239, 30991, 38304], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 28, 28], [32, 128, 28, 28], [], [], [], [], [], [], []]", 32, 16617, 16617, 20334, 24693], ["aten::cudnn_convolution", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], []]", 32, 15957, 15957, 25689, 30969], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 14, 14], [32, 256, 14, 14], [], [], [], [], [], [], []]", 40, 15720, 15720, 21056, 27138], ["aten::cudnn_convolution", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], []]", 16, 15714, 15714, 22559, 25646], ["aten::cudnn_convolution", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], []]", 8, 15628, 15628, 1433941, 1436042], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], []]", 16, 15577, 15577, 20821, 23343], ["aten::cudnn_convolution_backward_weight", "[[], [32, 2048, 7, 7], [32, 512, 7, 7], [], [], [], [], [], [], []]", 24, 15476, 15476, 176989, 180663], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 56, 56], [32, 256, 56, 56], [], [], [], [], [], [], []]", 8, 15392, 15392, 13248, 14353], ["aten::cudnn_convolution", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], []]", 24, 15358, 15358, 23244, 27162], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], []]", 32, 15165, 15165, 18435, 22983], ["aten::cudnn_convolution", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 15072, 15072, 16856, 18366], ["aten::cudnn_convolution", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], [], [], []]", 8, 15006, 15006, 16316, 17833], ["aten::cudnn_convolution_backward_input", "[[], [32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], []]", 24, 14833, 14833, 23377, 27010], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], []]", 32, 14615, 14615, 18631, 24817], ["aten::cudnn_convolution", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], []]", 8, 14329, 14329, 21172, 22493], ["aten::cudnn_convolution", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], []]", 24, 13507, 13507, 20366, 23960], ["aten::copy_", "[[32, 3, 224, 224], [32, 3, 224, 224], []]", 16, 13506, 13506, 87576, 87576], ["aten::cudnn_convolution_backward_input", "[[], [32, 128, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], []]", 8, 13483, 13483, 16116, 17330], ["aten::cudnn_convolution", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], []]", 32, 13367, 13367, 29209, 34489], ["aten::cudnn_batch_norm_backward", "[[32, 512, 28, 28], [32, 512, 28, 28], [512], [512], [512], [512], [512], [], [0]]", 40, 13207, 13207, 13941, 21133], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 28, 28], [32, 512, 28, 28], [], [], [], [], [], [], []]", 24, 13202, 13202, 13899, 17413], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 12967, 12967, 14329, 15440], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 7, 7], [32, 2048, 7, 7], [], [], [], [], [], [], []]", 16, 12855, 12855, 15432, 17824], ["aten::cudnn_batch_norm", "[[32, 256, 56, 56], [256], [256], [256], [256], [], [], []]", 32, 12805, 12805, 16230, 23814], ["aten::cudnn_convolution", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], []]", 8, 12705, 12705, 15304, 16483], ["aten::cudnn_convolution_backward_weight", "[[], [32, 64, 112, 112], [32, 3, 224, 224], [], [], [], [], [], [], []]", 8, 12638, 12638, 8997, 10087], ["aten::cudnn_convolution", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], []]", 24, 11931, 11931, 23226, 38461], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 28, 28], [32, 128, 28, 28], [], [], [], [], [], [], []]", 24, 11667, 11667, 14812, 18404], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 28, 28], [512, 256, 1, 1], [], [], [], [], [], [], []]", 8, 11621, 11621, 9273, 10474], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 28, 28], [32, 512, 28, 28], [], [], [], [], [], [], []]", 8, 11599, 11599, 10536, 11777], ["aten::cudnn_convolution", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], [], [], []]", 8, 11339, 11339, 10543, 11791], ["aten::cudnn_convolution_backward_input", "[[], [32, 64, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], []]", 16, 11316, 11316, 13271, 15678], ["aten::cudnn_convolution_backward_input", "[[], [32, 2048, 7, 7], [2048, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 10993, 10993, 67502, 68695], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 14, 14], [32, 1024, 14, 14], [], [], [], [], [], [], []]", 8, 10731, 10731, 10580, 11770], ["aten::cudnn_convolution", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], []]", 16, 10726, 10726, 17947, 20555], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 7, 7], [32, 512, 7, 7], [], [], [], [], [], [], []]", 16, 10720, 10720, 26009, 28441], ["aten::cudnn_convolution_backward_input", "[[], [32, 1024, 14, 14], [1024, 512, 1, 1], [], [], [], [], [], [], []]", 8, 10679, 10679, 7836, 8970], ["aten::cudnn_convolution_backward_input", "[[], [32, 128, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], []]", 24, 10661, 10661, 17758, 21685], ["aten::cudnn_convolution", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], [], [], []]", 8, 10411, 10411, 14159, 17530], ["aten::cudnn_batch_norm_backward", "[[32, 1024, 14, 14], [32, 1024, 14, 14], [1024], [1024], [1024], [1024], [1024], [], [0]]", 56, 10161, 10161, 19661, 29195], ["aten::cudnn_convolution_backward_weight", "[[], [32, 2048, 7, 7], [32, 1024, 14, 14], [], [], [], [], [], [], []]", 8, 10145, 10145, 9335, 10532], ["aten::cudnn_batch_norm_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], [64], [64], [64], [64], [64], [], [0]]", 48, 10075, 10075, 17357, 26559], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], []]", 8, 10026, 10026, 13830, 15133], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 7, 7], [32, 512, 14, 14], [], [], [], [], [], [], []]", 8, 9613, 9613, 12056, 13290], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 28, 28], [32, 256, 56, 56], [], [], [], [], [], [], []]", 8, 9316, 9316, 7642, 8754], ["aten::cudnn_convolution", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], [], [], []]", 8, 9178, 9178, 8738, 9933], ["aten::cudnn_convolution", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 9007, 9007, 11166, 12346], ["aten::threshold_backward", "[[32, 256, 56, 56], [32, 256, 56, 56], []]", 24, 8820, 8820, 3201, 4176], ["aten::add_", "[[32, 256, 56, 56], [32, 256, 56, 56], []]", 24, 8748, 8748, 3832, 3832], ["aten::cudnn_convolution_backward_weight", "[[], [32, 1024, 14, 14], [32, 512, 28, 28], [], [], [], [], [], [], []]", 8, 8625, 8625, 8188, 9399], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 28, 28], [32, 128, 56, 56], [], [], [], [], [], [], []]", 8, 8481, 8481, 8427, 9674], ["aten::cudnn_batch_norm", "[[32, 512, 28, 28], [512], [512], [512], [512], [], [], []]", 40, 8307, 8307, 19729, 30058], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 14, 14], [32, 256, 28, 28], [], [], [], [], [], [], []]", 8, 8146, 8146, 7831, 9132], ["aten::cudnn_convolution", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], [], [], []]", 8, 7675, 7675, 14259, 16265], ["aten::cudnn_batch_norm_backward", "[[32, 64, 112, 112], [32, 64, 112, 112], [64], [64], [64], [64], [64], [], [0]]", 8, 6500, 6500, 2743, 4119], ["aten::threshold_", "[[32, 256, 56, 56], [], []]", 24, 6014, 6014, 1437, 1437], ["aten::threshold_backward", "[[32, 512, 28, 28], [32, 512, 28, 28], []]", 32, 5943, 5943, 4309, 5645], ["aten::add_", "[[32, 512, 28, 28], [32, 512, 28, 28], []]", 32, 5895, 5895, 4507, 4507], ["aten::max_pool2d_with_indices_backward", "[[32, 64, 56, 56], [32, 64, 112, 112], [], [], [], [], [], [32, 64, 56, 56]]", 8, 5557, 6842, 2577, 5301], ["aten::cudnn_batch_norm", "[[32, 64, 56, 56], [64], [64], [64], [64], [], [], []]", 48, 5335, 5335, 23617, 35021], ["aten::cudnn_batch_norm_backward", "[[32, 128, 28, 28], [32, 128, 28, 28], [128], [128], [128], [128], [128], [], [0]]", 56, 5106, 5106, 19677, 29553], ["aten::cudnn_batch_norm", "[[32, 1024, 14, 14], [1024], [1024], [1024], [1024], [], [], []]", 56, 4755, 4755, 27445, 41509], ["aten::threshold_backward", "[[32, 1024, 14, 14], [32, 1024, 14, 14], []]", 48, 4614, 4614, 6355, 8323], ["aten::threshold_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], []]", 48, 4448, 4448, 6463, 8413], ["aten::add_", "[[32, 1024, 14, 14], [32, 1024, 14, 14], []]", 48, 4411, 4411, 6685, 6685], ["aten::cudnn_batch_norm_backward", "[[32, 256, 14, 14], [32, 256, 14, 14], [256], [256], [256], [256], [256], [], [0]]", 88, 4197, 4197, 33905, 48954], ["aten::threshold_", "[[32, 512, 28, 28], [], []]", 32, 4043, 4043, 1899, 1899], ["aten::cudnn_batch_norm", "[[32, 64, 112, 112], [64], [64], [64], [64], [], [], []]", 8, 3407, 3407, 80775, 82696], ["aten::threshold_", "[[32, 1024, 14, 14], [], []]", 48, 3035, 3035, 3212, 3212], ["aten::threshold_", "[[32, 64, 56, 56], [], []]", 48, 3034, 3034, 2948, 2948], ["aten::threshold_backward", "[[32, 64, 112, 112], [32, 64, 112, 112], []]", 8, 2965, 2965, 1033, 1372], ["aten::cudnn_batch_norm", "[[32, 128, 28, 28], [128], [128], [128], [128], [], [], []]", 56, 2929, 2929, 27688, 41299], ["aten::cudnn_convolution", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], []]", 8, 2826, 2826, 9193, 10495], ["aten::cudnn_batch_norm_backward", "[[32, 128, 56, 56], [32, 128, 56, 56], [128], [128], [128], [128], [128], [], [0]]", 8, 2749, 2749, 2737, 4097], ["aten::cudnn_convolution_backward_input", "[[], [32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], []]", 8, 2736, 2736, 9201, 10422], ["aten::threshold_backward", "[[32, 128, 28, 28], [32, 128, 28, 28], []]", 56, 2733, 2733, 7430, 9784], ["aten::threshold_backward", "[[32, 256, 14, 14], [32, 256, 14, 14], []]", 88, 2460, 2460, 12366, 15979], ["aten::add_", "[[512, 512, 3, 3], [512, 512, 3, 3], []]", 66, 2386, 2386, 6319, 6319], ["aten::cudnn_batch_norm_backward", "[[32, 2048, 7, 7], [32, 2048, 7, 7], [2048], [2048], [2048], [2048], [2048], [], [0]]", 32, 2364, 2364, 12923, 18381], ["aten::threshold_", "[[32, 64, 112, 112], [], []]", 8, 1998, 1998, 606, 606], ["aten::cudnn_batch_norm", "[[32, 256, 14, 14], [256], [256], [256], [256], [], [], []]", 88, 1986, 1986, 44191, 65478], ["aten::threshold_", "[[32, 128, 28, 28], [], []]", 56, 1852, 1852, 3371, 3371], ["aten::cudnn_batch_norm", "[[32, 2048, 7, 7], [2048], [2048], [2048], [2048], [], [], []]", 32, 1821, 1821, 15752, 23535], ["aten::max_pool2d_with_indices", "[[32, 64, 112, 112], [], [], [], [], []]", 8, 1790, 1790, 3298, 4656], ["aten::cudnn_batch_norm", "[[32, 128, 56, 56], [128], [128], [128], [128], [], [], []]", 8, 1592, 1592, 3927, 5808], ["aten::threshold_backward", "[[32, 128, 56, 56], [32, 128, 56, 56], []]", 8, 1478, 1478, 1039, 1365], ["aten::add_", "[[256], [256], []]", 704, 1441, 1441, 68572, 68572], ["aten::cudnn_batch_norm_backward", "[[32, 256, 28, 28], [32, 256, 28, 28], [256], [256], [256], [256], [256], [], [0]]", 8, 1310, 1310, 2876, 4387], ["aten::fill_", "[[32, 64, 112, 112], []]", 8, 1285, 1285, 443, 443], ["aten::threshold_backward", "[[32, 2048, 7, 7], [32, 2048, 7, 7], []]", 24, 1212, 1212, 3180, 4153], ["aten::add_", "[[32, 2048, 7, 7], [32, 2048, 7, 7], []]", 24, 1132, 1132, 3359, 3359], ["aten::threshold_", "[[32, 256, 14, 14], [], []]", 88, 1021, 1021, 5468, 5468], ["aten::threshold_", "[[32, 128, 56, 56], [], []]", 8, 1005, 1005, 481, 481], ["aten::add_", "[[512], [512], []]", 484, 975, 975, 46445, 46445], ["aten::cudnn_batch_norm_backward", "[[32, 512, 7, 7], [32, 512, 7, 7], [512], [512], [512], [512], [512], [], [0]]", 40, 938, 938, 13902, 20667], ["aten::add_", "[[2048, 512, 1, 1], [2048, 512, 1, 1], []]", 66, 925, 925, 6461, 6461], ["aten::add_", "[[256, 256, 3, 3], [256, 256, 3, 3], []]", 132, 911, 911, 13099, 13099], ["aten::add", "[[512, 512, 3, 3], [512, 512, 3, 3], []]", 24, 840, 840, 3189, 4253], ["aten::cudnn_batch_norm", "[[32, 256, 28, 28], [256], [256], [256], [256], [], [], []]", 8, 831, 831, 3928, 5826], ["aten::threshold_", "[[32, 2048, 7, 7], [], []]", 24, 797, 797, 1404, 1404], ["aten::threshold_backward", "[[32, 256, 28, 28], [32, 256, 28, 28], []]", 8, 764, 764, 1102, 1422], ["aten::cudnn_batch_norm_backward", "[[32, 512, 14, 14], [32, 512, 14, 14], [512], [512], [512], [512], [512], [], [0]]", 8, 743, 743, 2777, 4123], ["aten::add_", "[[2048, 1024, 1, 1], [2048, 1024, 1, 1], []]", 22, 708, 708, 2099, 2099], ["aten::add_", "[[128], [128], []]", 352, 684, 684, 33723, 33723], ["aten::add_", "[[1000, 2048], [1000, 2048], []]", 22, 675, 675, 2123, 2123], ["aten::threshold_backward", "[[32, 512, 7, 7], [32, 512, 7, 7], []]", 40, 660, 660, 5356, 6988], ["aten::add_", "[[512, 2048, 1, 1], [512, 2048, 1, 1], []]", 44, 655, 655, 4149, 4149], ["aten::add_", "[[1024], [1024], []]", 308, 639, 639, 30034, 30034], ["aten::cudnn_batch_norm", "[[32, 512, 7, 7], [512], [512], [512], [512], [], [], []]", 40, 635, 635, 19630, 29053], ["aten::add_", "[[64], [64], []]", 308, 592, 592, 29292, 29292], ["aten::threshold_", "[[32, 256, 28, 28], [], []]", 8, 505, 505, 477, 477], ["aten::mul_", "[[512, 512, 3, 3], []]", 21, 505, 505, 2429, 2429], ["aten::add_", "[[1024, 256, 1, 1], [1024, 256, 1, 1], []]", 132, 485, 485, 13342, 13342], ["aten::add", "[[256, 256, 3, 3], [256, 256, 3, 3], []]", 48, 483, 483, 6428, 8494], ["aten::add_", "[[256, 1024, 1, 1], [256, 1024, 1, 1], []]", 110, 458, 458, 10441, 10441], ["aten::add", "[[], [], []]", 424, 455, 455, 60066, 77286], ["aten::copy_", "[[], [], []]", 1192, 426, 426, 68986, 68986], ["aten::threshold_backward", "[[32, 512, 14, 14], [32, 512, 14, 14], []]", 8, 407, 407, 1044, 1381], ["aten::_cat", "[[], []]", 24, 391, 391, 2992955, 3003354], ["aten::add", "[[2048, 512, 1, 1], [2048, 512, 1, 1], []]", 24, 385, 385, 3164, 4158], ["aten::copy_", "[[256], [256], []]", 320, 377, 377, 29878, 29878], ["aten::cudnn_batch_norm", "[[32, 512, 14, 14], [512], [512], [512], [512], [], [], []]", 8, 370, 370, 3925, 5848], ["aten::add_", "[[2048], [2048], []]", 176, 355, 355, 16710, 16710], ["aten::mean", "[[32, 2048, 7, 7], [], [], []]", 8, 346, 346, 4907, 5251], ["aten::fill_", "[[512, 512, 3, 3], []]", 21, 315, 315, 1076, 1076], ["aten::threshold_", "[[32, 512, 7, 7], [], []]", 40, 274, 274, 2427, 2427], ["aten::addmm", "[[1000], [32, 2048], [2048, 1000], [], []]", 8, 270, 270, 486088, 489483], ["aten::add_", "[[128, 128, 3, 3], [128, 128, 3, 3], []]", 88, 266, 266, 8588, 8588], ["aten::mul_", "[[256, 256, 3, 3], []]", 42, 262, 262, 4659, 4659], ["aten::add", "[[256], [256], []]", 256, 256, 256, 35628, 45985], ["aten::add", "[[512, 2048, 1, 1], [512, 2048, 1, 1], []]", 16, 256, 256, 2132, 2782], ["aten::add", "[[2048, 1024, 1, 1], [2048, 1024, 1, 1], []]", 8, 248, 248, 1072, 1401], ["aten::threshold_", "[[32, 512, 14, 14], [], []]", 8, 244, 244, 479, 479], ["aten::add", "[[1000, 2048], [1000, 2048], []]", 8, 244, 244, 1051, 1371], ["aten::add", "[[1024, 256, 1, 1], [1024, 256, 1, 1], []]", 48, 239, 239, 6416, 8389], ["aten::mul_", "[[2048, 512, 1, 1], []]", 21, 232, 232, 2509, 2509], ["aten::div", "[[32, 2048, 7, 7], []]", 8, 231, 231, 1538, 1872], ["aten::mm", "[[32, 1000], [1000, 2048]]", 8, 229, 229, 2249, 2744], ["aten::mul_", "[[256], []]", 224, 224, 224, 23789, 23789], ["aten::copy_", "[[512], [512], []]", 220, 221, 221, 20503, 20503], ["aten::add_", "[[512, 128, 1, 1], [512, 128, 1, 1], []]", 88, 200, 200, 8432, 8432], ["aten::add_", "[[256, 64, 1, 1], [256, 64, 1, 1], []]", 88, 196, 196, 8690, 8690], ["aten::add", "[[512], [512], []]", 176, 176, 176, 23877, 30967], ["aten::copy_", "[[1024], [1024], []]", 140, 175, 175, 12975, 12975], ["aten::add", "[[256, 1024, 1, 1], [256, 1024, 1, 1], []]", 40, 174, 174, 5419, 7091], ["aten::copy_", "[[512, 512, 3, 3], [512, 512, 3, 3], []]", 6, 171, 171, 537, 537], ["aten::fill_", "[[256, 256, 3, 3], []]", 42, 168, 168, 2130, 2130], ["aten::copy_", "[[128], [128], []]", 160, 166, 166, 15215, 15215], ["aten::add_", "[[512, 1024, 1, 1], [512, 1024, 1, 1], []]", 22, 161, 161, 2087, 2087], ["aten::add_", "[[128, 512, 1, 1], [128, 512, 1, 1], []]", 66, 156, 156, 6403, 6403], ["aten::mul_", "[[512], []]", 154, 154, 154, 16944, 16944], ["aten::mul_", "[[512, 2048, 1, 1], []]", 14, 154, 154, 1511, 1511], ["aten::mm", "[[1000, 32], [32, 2048]]", 8, 153, 153, 1391, 1879], ["aten::add_", "[[64, 64, 3, 3], [64, 64, 3, 3], []]", 66, 151, 151, 6830, 6830], ["aten::mul_", "[[2048, 1024, 1, 1], []]", 7, 150, 150, 814, 814], ["aten::fill_", "[[2048, 512, 1, 1], []]", 21, 147, 147, 1049, 1049], ["aten::mul_", "[[1000, 2048], []]", 7, 147, 147, 751, 751], ["aten::copy_", "[[64], [64], []]", 140, 145, 145, 13301, 13301], ["aten::mul_", "[[1024, 256, 1, 1], []]", 42, 136, 136, 4721, 4721], ["aten::add", "[[128], [128], []]", 128, 128, 128, 17249, 22360], ["aten::add_", "[[1024, 512, 1, 1], [1024, 512, 1, 1], []]", 22, 128, 128, 2106, 2106], ["aten::add", "[[64], [64], []]", 112, 112, 112, 14891, 19310], ["aten::add", "[[1024], [1024], []]", 112, 112, 112, 14967, 19475], ["aten::mul_", "[[128], []]", 112, 112, 112, 11845, 11845], ["aten::fill_", "[[256], []]", 224, 107, 107, 11657, 11657], ["aten::mul_", "[[256, 1024, 1, 1], []]", 35, 105, 105, 3918, 3918], ["aten::fill_", "[[512, 2048, 1, 1], []]", 14, 98, 98, 692, 692], ["aten::mul_", "[[64], []]", 98, 98, 98, 10402, 10402], ["aten::mul_", "[[1024], []]", 98, 98, 98, 10268, 10268], ["aten::add_", "[[64, 256, 1, 1], [64, 256, 1, 1], []]", 44, 95, 95, 4188, 4188], ["aten::fill_", "[[2048, 1024, 1, 1], []]", 7, 91, 91, 351, 351], ["aten::fill_", "[[1000, 2048], []]", 7, 91, 91, 348, 348], ["aten::add", "[[128, 128, 3, 3], [128, 128, 3, 3], []]", 32, 88, 88, 4307, 5629], ["aten::fill_", "[[512], []]", 154, 86, 86, 7845, 7845], ["aten::fill_", "[[1024, 256, 1, 1], []]", 42, 84, 84, 2107, 2107], ["aten::_log_softmax_backward_data", "[[32, 1000], [32, 1000], [], [32, 1000]]", 8, 83, 83, 1183, 2095], ["aten::_log_softmax", "[[32, 1000], [], []]", 8, 82, 82, 1828, 2665], ["aten::copy_", "[[2048], [2048], []]", 80, 81, 81, 7553, 7553], ["aten::add_", "[[256, 512, 1, 1], [256, 512, 1, 1], []]", 22, 77, 77, 2122, 2122], ["aten::copy_", "[[256, 256, 3, 3], [256, 256, 3, 3], []]", 12, 76, 76, 1055, 1055], ["aten::fill_", "[[128], []]", 112, 76, 76, 5750, 5750], ["aten::add", "[[512, 1024, 1, 1], [512, 1024, 1, 1], []]", 8, 75, 75, 1068, 1394], ["aten::add", "[[1024, 512, 1, 1], [1024, 512, 1, 1], []]", 8, 72, 72, 1091, 1444], ["aten::fill_", "[[256, 1024, 1, 1], []]", 35, 70, 70, 1740, 1740], ["aten::add_", "[[512, 256, 1, 1], [512, 256, 1, 1], []]", 22, 69, 69, 2174, 2174], ["aten::add", "[[512, 128, 1, 1], [512, 128, 1, 1], []]", 32, 64, 64, 5066, 6381], ["aten::copy_", "[[2048, 512, 1, 1], [2048, 512, 1, 1], []]", 6, 64, 64, 567, 567], ["aten::add", "[[2048], [2048], []]", 64, 64, 64, 8566, 11223], ["aten::fill_", "[[1024], []]", 98, 58, 58, 4974, 4974], ["aten::mul_", "[[128, 128, 3, 3], []]", 28, 57, 57, 3052, 3052], ["aten::copy_", "[[512, 2048, 1, 1], [512, 2048, 1, 1], []]", 4, 56, 56, 338, 338], ["aten::mul_", "[[2048], []]", 56, 56, 56, 5924, 5924], ["aten::copy_", "[[1024, 256, 1, 1], [1024, 256, 1, 1], []]", 12, 54, 54, 1094, 1094], ["aten::fill_", "[[64], []]", 98, 54, 54, 5082, 5082], ["aten::add_", "[[128, 256, 1, 1], [128, 256, 1, 1], []]", 22, 52, 52, 2114, 2114], ["aten::copy_", "[[2048, 1024, 1, 1], [2048, 1024, 1, 1], []]", 2, 49, 49, 171, 171], ["aten::add", "[[128, 512, 1, 1], [128, 512, 1, 1], []]", 24, 48, 48, 3265, 4263], ["aten::add_", "[[64, 3, 7, 7], [64, 3, 7, 7], []]", 22, 46, 46, 2190, 2190], ["aten::copy_", "[[1000, 2048], [1000, 2048], []]", 2, 46, 46, 166, 166], ["aten::add_", "[[64, 64, 1, 1], [64, 64, 1, 1], []]", 22, 45, 45, 2088, 2088], ["aten::copy_", "[[256, 1024, 1, 1], [256, 1024, 1, 1], []]", 10, 45, 45, 861, 861], ["aten::mul_", "[[512, 1024, 1, 1], []]", 7, 39, 39, 780, 780], ["aten::mul_", "[[1024, 512, 1, 1], []]", 7, 38, 38, 790, 790], ["aten::nll_loss_forward", "[[32, 1000], [32], [], [], []]", 8, 33, 33, 2113, 2113], ["aten::add", "[[256, 64, 1, 1], [256, 64, 1, 1], []]", 32, 32, 32, 4340, 5706], ["aten::fill_", "[[256, 64, 1, 1], []]", 28, 28, 28, 1418, 1418], ["aten::fill_", "[[128, 128, 3, 3], []]", 28, 28, 28, 1394, 1394], ["aten::fill_", "[[512, 128, 1, 1], []]", 28, 28, 28, 1429, 1429], ["aten::fill_", "[[1024, 512, 1, 1], []]", 7, 28, 28, 348, 348], ["aten::fill_", "[[512, 1024, 1, 1], []]", 7, 28, 28, 360, 360], ["aten::mul_", "[[256, 64, 1, 1], []]", 28, 28, 28, 3151, 3151], ["aten::mul_", "[[512, 128, 1, 1], []]", 28, 28, 28, 3398, 3398], ["aten::copy_", "[[32], [32], []]", 16, 25, 25, 1642, 1642], ["aten::add", "[[64, 64, 3, 3], [64, 64, 3, 3], []]", 24, 25, 25, 3268, 4295], ["aten::add", "[[512, 256, 1, 1], [512, 256, 1, 1], []]", 8, 24, 24, 1070, 1399], ["aten::add", "[[256, 512, 1, 1], [256, 512, 1, 1], []]", 8, 24, 24, 1050, 1376], ["aten::nll_loss_backward", "[[], [32, 1000], [32], [], [], [], []]", 8, 24, 24, 1553, 1553], ["aten::add_", "[[1000], [1000], []]", 22, 22, 22, 2128, 2128], ["aten::fill_", "[[64, 64, 3, 3], []]", 21, 21, 21, 1053, 1053], ["aten::fill_", "[[128, 512, 1, 1], []]", 21, 21, 21, 1076, 1076], ["aten::mul_", "[[64, 64, 3, 3], []]", 21, 21, 21, 2289, 2289], ["aten::mul_", "[[128, 512, 1, 1], []]", 21, 21, 21, 2316, 2316], ["aten::copy_", "[[128, 128, 3, 3], [128, 128, 3, 3], []]", 8, 20, 20, 755, 755], ["aten::fill_", "[[2048], []]", 56, 20, 20, 2850, 2850], ["aten::add", "[[64, 256, 1, 1], [64, 256, 1, 1], []]", 16, 16, 16, 2166, 2825], ["aten::fill_", "[[64, 256, 1, 1], []]", 14, 14, 14, 706, 706], ["aten::mul_", "[[64, 256, 1, 1], []]", 14, 14, 14, 1534, 1534], ["aten::mul_", "[[512, 256, 1, 1], []]", 7, 14, 14, 763, 763], ["aten::mul_", "[[256, 512, 1, 1], []]", 7, 14, 14, 809, 809], ["aten::_local_scalar_dense", "[[]]", 1441, 12, 12, 31942, 31942], ["aten::copy_", "[[1024, 512, 1, 1], [1024, 512, 1, 1], []]", 2, 12, 12, 173, 173], ["aten::copy_", "[[256, 64, 1, 1], [256, 64, 1, 1], []]", 8, 10, 10, 671, 671], ["aten::copy_", "[[512, 128, 1, 1], [512, 128, 1, 1], []]", 8, 10, 10, 918, 918], ["aten::copy_", "[[512, 1024, 1, 1], [512, 1024, 1, 1], []]", 2, 10, 10, 177, 177], ["aten::copy_", "[[128, 512, 1, 1], [128, 512, 1, 1], []]", 6, 9, 9, 504, 504], ["aten::fill_", "[[], []]", 8, 8, 8, 486, 486], ["aten::add", "[[64, 3, 7, 7], [64, 3, 7, 7], []]", 8, 8, 8, 1208, 1572], ["aten::add", "[[64, 64, 1, 1], [64, 64, 1, 1], []]", 8, 8, 8, 1108, 1453], ["aten::add", "[[128, 256, 1, 1], [128, 256, 1, 1], []]", 8, 8, 8, 1163, 1497], ["aten::add", "[[1000], [1000], []]", 8, 8, 8, 1081, 1394], ["aten::copy_", "[[64, 64, 3, 3], [64, 64, 3, 3], []]", 6, 7, 7, 523, 523], ["aten::fill_", "[[64, 3, 7, 7], []]", 7, 7, 7, 434, 434], ["aten::fill_", "[[128, 256, 1, 1], []]", 7, 7, 7, 345, 345], ["aten::fill_", "[[512, 256, 1, 1], []]", 7, 7, 7, 359, 359], ["aten::fill_", "[[256, 512, 1, 1], []]", 7, 7, 7, 344, 344], ["aten::fill_", "[[1000], []]", 7, 7, 7, 349, 349], ["aten::mul_", "[[64, 3, 7, 7], []]", 7, 7, 7, 851, 851], ["aten::mul_", "[[64, 64, 1, 1], []]", 7, 7, 7, 804, 804], ["aten::mul_", "[[128, 256, 1, 1], []]", 7, 7, 7, 774, 774], ["aten::mul_", "[[1000], []]", 7, 7, 7, 731, 731], ["aten::copy_", "[[64, 256, 1, 1], [64, 256, 1, 1], []]", 4, 5, 5, 339, 339], ["aten::copy_", "[[128, 256, 1, 1], [128, 256, 1, 1], []]", 2, 5, 5, 201, 201], ["aten::copy_", "[[256, 512, 1, 1], [256, 512, 1, 1], []]", 2, 5, 5, 197, 197], ["aten::copy_", "[[512, 256, 1, 1], [512, 256, 1, 1], []]", 2, 3, 3, 171, 171], ["aten::fill_", "[[64, 64, 1, 1], []]", 7, 3, 3, 359, 359], ["aten::copy_", "[[64, 3, 7, 7], [64, 3, 7, 7], []]", 2, 2, 2, 175, 175], ["aten::copy_", "[[64, 64, 1, 1], [64, 64, 1, 1], []]", 2, 2, 2, 172, 172], ["aten::copy_", "[[1000], [1000], []]", 2, 2, 2, 181, 181], ["aten::copy_", "[[162], [162], []]", 2, 2, 2, 1214, 1214], ["aten::copy_", "[[5], [5], []]", 2, 2, 2, 208, 208], ["aten::empty", "[[], [], [], [], [], []]", 13110, 0, 0, 423852, 423852], ["aten::random_", "[[], []]", 1, 0, 0, 86, 86], ["aten::is_floating_point", "[[]]", 9, 0, 0, 122, 122], ["aten::item", "[[]]", 1441, 0, 12, 30822, 62764], ["aten::fill_", "[[1], []]", 280, 0, 0, 4706, 4706], ["aten::zero_", "[[1]]", 24, 0, 0, 708, 1064], ["aten::zeros", "[[], [], [], [], []]", 24, 0, 0, 1657, 3263], ["aten::uniform_", "[[1], [], [], []]", 920, 0, 0, 51990, 51990], ["aten::is_floating_point", "[[1]]", 1176, 0, 0, 12354, 12354], ["aten::_local_scalar_dense", "[[1]]", 1432, 0, 0, 39608, 39608], ["aten::item", "[[1]]", 1432, 0, 0, 29088, 68696], ["aten::to", "[[2], [], [], [], [], []]", 332, 0, 0, 5013, 5013], ["detach_", "[[2]]", 332, 0, 0, 4323, 4323], ["aten::detach_", "[[2]]", 332, 0, 0, 5901, 10224], ["aten::log", "[[2]]", 332, 0, 0, 30100, 36289], ["aten::as_strided", "[[2], [], [], []]", 664, 0, 0, 9363, 9363], ["aten::select", "[[2], [], []]", 664, 0, 0, 54541, 63904], ["aten::resize_", "[[0], [], []]", 1148, 0, 0, 22679, 22679], ["aten::exp", "[[0], [1]]", 332, 0, 0, 19874, 25247], ["aten::exp", "[[1]]", 332, 0, 0, 28622, 59964], ["aten::random_", "[[1], [], [], []]", 512, 0, 0, 15758, 15758], ["aten::randint", "[[], [], [], [], [], [], [], []]", 512, 0, 0, 31108, 56254], ["aten::rand", "[[], [], [], [], []]", 256, 0, 0, 17271, 31835], ["aten::empty_strided", "[[], [], [], [], [], []]", 1626, 0, 0, 58338, 58338], ["aten::to", "[[], [], [], [], []]", 768, 0, 0, 55918, 101217], ["aten::lt", "[[0], [1], []]", 256, 0, 0, 25486, 69513], ["aten::lt", "[[1], []]", 256, 0, 0, 26862, 100260], ["aten::is_nonzero", "[[1]]", 256, 0, 0, 5666, 17458], ["aten::set_", "[[], []]", 256, 0, 0, 17013, 17013], ["aten::view", "[[150528], []]", 256, 0, 0, 16975, 16975], ["aten::as_strided", "[[224, 224, 3], [], [], []]", 256, 0, 0, 4176, 4176], ["aten::permute", "[[224, 224, 3], []]", 256, 0, 0, 21835, 26011], ["aten::empty_like", "[[3, 224, 224], [], [], [], [], []]", 256, 0, 0, 10613, 15541], ["aten::copy_", "[[3, 224, 224], [3, 224, 224], []]", 768, 0, 0, 3840507, 3840507], ["aten::contiguous", "[[3, 224, 224], []]", 256, 0, 0, 12922, 1015106], ["aten::to", "[[3, 224, 224], [], [], [], []]", 256, 0, 0, 19503, 1943054], ["aten::div", "[[3, 224, 224], []]", 256, 0, 0, 982592, 1025519], ["aten::clone", "[[3, 224, 224], []]", 256, 0, 0, 29615, 975599], ["aten::to", "[[3], [], [], [], [], []]", 512, 0, 0, 7450, 7450], ["aten::eq", "[[0], [3], []]", 256, 0, 0, 26228, 71702], ["aten::eq", "[[3], []]", 256, 0, 0, 26363, 101704], ["aten::as_strided", "[[], [], [], []]", 256, 0, 0, 4022, 4022], ["aten::any", "[[3]]", 256, 0, 0, 45075, 61781], ["aten::is_nonzero", "[[]]", 256, 0, 0, 5803, 19616], ["aten::view", "[[3], []]", 512, 0, 0, 33469, 33469], ["aten::sub_", "[[3, 224, 224], [3, 1, 1], []]", 256, 0, 0, 801857, 801857], ["aten::div_", "[[3, 224, 224], [3, 1, 1]]", 256, 0, 0, 957981, 957981], ["aten::as_strided", "[[3, 224, 224], [], [], []]", 256, 0, 0, 3238, 3238], ["aten::unsqueeze", "[[3, 224, 224], []]", 256, 0, 0, 9407, 12645], ["aten::as_strided", "[[32, 3, 224, 224], [], [], []]", 8, 0, 0, 115, 115], ["aten::slice", "[[32, 3, 224, 224], [], [], [], []]", 8, 0, 0, 275, 390], ["aten::narrow", "[[32, 3, 224, 224], [], [], []]", 8, 0, 0, 222, 612], ["aten::stride", "[[32, 3, 224, 224], []]", 72, 0, 0, 557, 557], ["aten::cat", "[[], []]", 24, 0, 391, 3121, 3006475], ["aten::stack", "[[], []]", 8, 0, 0, 6262, 880545], ["aten::to", "[[32], [], [], [], [], []]", 8, 0, 0, 1352, 1352], ["detach_", "[[32]]", 8, 0, 0, 170, 170], ["aten::detach_", "[[32]]", 8, 0, 0, 175, 345], ["aten::is_pinned", "[[32, 3, 224, 224]]", 8, 0, 0, 822, 822], ["aten::set_", "[[0], [], [], [], []]", 16, 0, 0, 967, 967], ["aten::pin_memory", "[[32, 3, 224, 224]]", 8, 0, 0, 19128, 107175], ["aten::is_pinned", "[[32]]", 8, 0, 0, 408, 408], ["aten::pin_memory", "[[32]]", 8, 0, 0, 1515, 3259], ["aten::to", "[[32, 3, 224, 224], [], [], [], [], [], [], []]", 16, 0, 13506, 891, 2942], ["aten::to", "[[32], [], [], [], [], [], [], []]", 8, 0, 25, 610, 2010], ["aten::contiguous", "[[64], []]", 336, 0, 0, 4311, 4311], ["aten::view", "[[64], []]", 336, 0, 0, 17198, 17198], ["aten::contiguous", "[[256], []]", 768, 0, 0, 9601, 9601], ["aten::view", "[[256], []]", 768, 0, 0, 38958, 38958], ["aten::contiguous", "[[128], []]", 384, 0, 0, 4726, 4726], ["aten::view", "[[128], []]", 384, 0, 0, 18517, 18517], ["aten::contiguous", "[[512], []]", 528, 0, 0, 6414, 6414], ["aten::view", "[[512], []]", 528, 0, 0, 25555, 25555], ["aten::contiguous", "[[1024], []]", 336, 0, 0, 4125, 4125], ["aten::view", "[[1024], []]", 336, 0, 0, 16043, 16043], ["aten::contiguous", "[[2048], []]", 192, 0, 0, 2307, 2307], ["aten::view", "[[2048], []]", 192, 0, 0, 8978, 8978], ["aten::stride", "[[64], []]", 112, 0, 0, 720, 720], ["aten::stride", "[[256], []]", 256, 0, 0, 1579, 1579], ["aten::stride", "[[128], []]", 128, 0, 0, 756, 756], ["aten::stride", "[[512], []]", 176, 0, 0, 1047, 1047], ["aten::stride", "[[1024], []]", 112, 0, 0, 669, 669], ["aten::stride", "[[2048], []]", 64, 0, 0, 372, 372], ["aten::stride", "[[53120], []]", 16, 0, 0, 106, 106], ["nccl:broadcast", "[]", 18, 0, 0, 540, 540], ["aten::contiguous", "[[], []]", 424, 0, 0, 6335, 6335], ["aten::view", "[[], []]", 424, 0, 0, 24895, 24895], ["aten::stride", "[[1], []]", 424, 0, 0, 2801, 2801], ["aten::stride", "[[53], []]", 16, 0, 0, 106, 106], ["aten::as_strided", "[[53120], [], [], []]", 848, 0, 0, 14108, 14108], ["aten::slice", "[[53120], [], [], [], []]", 848, 0, 0, 58776, 72884], ["aten::narrow", "[[53120], [], [], []]", 848, 0, 0, 24331, 97215], ["aten::as_strided", "[[53], [], [], []]", 424, 0, 0, 5884, 5884], ["aten::slice", "[[53], [], [], [], []]", 424, 0, 0, 28936, 34820], ["aten::narrow", "[[53], [], [], []]", 424, 0, 0, 25022, 59842], ["aten::view", "[[1], []]", 424, 0, 0, 24794, 24794], ["aten::contiguous", "[[32, 3, 224, 224], []]", 24, 0, 0, 313, 313], ["aten::contiguous", "[[64, 3, 7, 7], []]", 8, 0, 0, 126, 126], ["aten::resize_", "[[64, 3, 7, 7], [], []]", 8, 0, 0, 105, 105], ["aten::resize_", "[[32, 3, 224, 224], [], []]", 16, 0, 0, 163, 163], ["aten::_convolution", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 15628, 902, 1437061], ["aten::convolution", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], []]", 8, 0, 15628, 402, 1437463], ["aten::conv2d", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], []]", 8, 0, 15628, 461, 1437924], ["aten::contiguous", "[[32, 64, 112, 112], []]", 56, 0, 0, 723, 723], ["aten::empty_like", "[[32, 64, 112, 112], [], [], [], [], []]", 16, 0, 0, 751, 1434], ["aten::_batch_norm_impl_index", "[[32, 64, 112, 112], [64], [64], [64], [64], [], [], [], []]", 8, 0, 3407, 1192, 84303], ["aten::batch_norm", "[[32, 64, 112, 112], [64], [64], [64], [64], [], [], [], []]", 8, 0, 3407, 426, 84729], ["aten::relu_", "[[32, 64, 112, 112]]", 8, 0, 1998, 1340, 1946], ["aten::stride", "[[32, 64, 112, 112], []]", 64, 0, 0, 428, 428], ["aten::max_pool2d", "[[32, 64, 112, 112], [], [], [], [], []]", 8, 0, 1790, 467, 5123], ["aten::contiguous", "[[32, 64, 56, 56], []]", 488, 0, 0, 5869, 5869], ["aten::contiguous", "[[64, 64, 1, 1], []]", 16, 0, 0, 233, 233], ["aten::resize_", "[[64, 64, 1, 1], [], []]", 16, 0, 0, 191, 191], ["aten::resize_", "[[32, 64, 56, 56], [], []]", 224, 0, 0, 2472, 2472], ["aten::stride", "[[32, 64, 56, 56], []]", 792, 0, 0, 5525, 5525], ["aten::_convolution", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 2826, 808, 11428], ["aten::convolution", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], []]", 8, 0, 2826, 354, 11782], ["aten::conv2d", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], []]", 8, 0, 2826, 416, 12198], ["aten::empty_like", "[[32, 64, 56, 56], [], [], [], [], []]", 48, 0, 0, 2354, 4434], ["aten::_batch_norm_impl_index", "[[32, 64, 56, 56], [64], [64], [64], [64], [], [], [], []]", 48, 0, 5335, 6409, 43989], ["aten::batch_norm", "[[32, 64, 56, 56], [64], [64], [64], [64], [], [], [], []]", 48, 0, 5335, 2400, 46389], ["aten::relu_", "[[32, 64, 56, 56]]", 48, 0, 3034, 6119, 9067], ["aten::contiguous", "[[64, 64, 3, 3], []]", 48, 0, 0, 759, 759], ["aten::resize_", "[[64, 64, 3, 3], [], []]", 48, 0, 0, 586, 586], ["aten::_convolution", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 24, 0, 15358, 2373, 29866], ["aten::convolution", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], []]", 24, 0, 15358, 1155, 31021], ["aten::conv2d", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], []]", 24, 0, 15358, 1335, 32356], ["aten::contiguous", "[[256, 64, 1, 1], []]", 64, 0, 0, 947, 947], ["aten::resize_", "[[256, 64, 1, 1], [], []]", 64, 0, 0, 828, 828], ["aten::_convolution", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 32, 0, 15957, 3096, 34506], ["aten::convolution", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], []]", 32, 0, 15957, 1506, 36012], ["aten::conv2d", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], []]", 32, 0, 15957, 1731, 37743], ["aten::contiguous", "[[32, 256, 56, 56], []]", 288, 0, 0, 3435, 3435], ["aten::empty_like", "[[32, 256, 56, 56], [], [], [], [], []]", 32, 0, 0, 1594, 2938], ["aten::_batch_norm_impl_index", "[[32, 256, 56, 56], [256], [256], [256], [256], [], [], [], []]", 32, 0, 12805, 4433, 30013], ["aten::batch_norm", "[[32, 256, 56, 56], [256], [256], [256], [256], [], [], [], []]", 32, 0, 12805, 1655, 31668], ["aten::relu_", "[[32, 256, 56, 56]]", 24, 0, 6014, 3142, 4579], ["aten::contiguous", "[[64, 256, 1, 1], []]", 32, 0, 0, 475, 475], ["aten::resize_", "[[64, 256, 1, 1], [], []]", 32, 0, 0, 386, 386], ["aten::resize_", "[[32, 256, 56, 56], [], []]", 128, 0, 0, 1353, 1353], ["aten::stride", "[[32, 256, 56, 56], []]", 384, 0, 0, 2652, 2652], ["aten::_convolution", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 16, 0, 10726, 1622, 22398], ["aten::convolution", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], []]", 16, 0, 10726, 720, 23118], ["aten::conv2d", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], []]", 16, 0, 10726, 821, 23939], ["aten::contiguous", "[[128, 256, 1, 1], []]", 16, 0, 0, 247, 247], ["aten::resize_", "[[128, 256, 1, 1], [], []]", 16, 0, 0, 209, 209], ["aten::_convolution", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 14329, 765, 23363], ["aten::convolution", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], []]", 8, 0, 14329, 357, 23720], ["aten::conv2d", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], []]", 8, 0, 14329, 425, 24145], ["aten::contiguous", "[[32, 128, 56, 56], []]", 72, 0, 0, 874, 874], ["aten::empty_like", "[[32, 128, 56, 56], [], [], [], [], []]", 8, 0, 0, 389, 728], ["aten::_batch_norm_impl_index", "[[32, 128, 56, 56], [128], [128], [128], [128], [], [], [], []]", 8, 0, 1592, 1084, 7340], ["aten::batch_norm", "[[32, 128, 56, 56], [128], [128], [128], [128], [], [], [], []]", 8, 0, 1592, 392, 7732], ["aten::relu_", "[[32, 128, 56, 56]]", 8, 0, 1005, 1029, 1510], ["aten::contiguous", "[[128, 128, 3, 3], []]", 64, 0, 0, 948, 948], ["aten::resize_", "[[128, 128, 3, 3], [], []]", 64, 0, 0, 832, 832], ["aten::resize_", "[[32, 128, 56, 56], [], []]", 32, 0, 0, 322, 322], ["aten::stride", "[[32, 128, 56, 56], []]", 96, 0, 0, 687, 687], ["aten::_convolution", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 10411, 752, 18392], ["aten::convolution", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], [], [], []]", 8, 0, 10411, 360, 18752], ["aten::conv2d", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], []]", 8, 0, 10411, 406, 19158], ["aten::contiguous", "[[32, 128, 28, 28], []]", 504, 0, 0, 6125, 6125], ["aten::empty_like", "[[32, 128, 28, 28], [], [], [], [], []]", 56, 0, 0, 2734, 5154], ["aten::_batch_norm_impl_index", "[[32, 128, 28, 28], [128], [128], [128], [128], [], [], [], []]", 56, 0, 2929, 7630, 51848], ["aten::batch_norm", "[[32, 128, 28, 28], [128], [128], [128], [128], [], [], [], []]", 56, 0, 2929, 2754, 54602], ["aten::relu_", "[[32, 128, 28, 28]]", 56, 0, 1852, 7101, 10472], ["aten::contiguous", "[[512, 128, 1, 1], []]", 64, 0, 0, 972, 972], ["aten::resize_", "[[512, 128, 1, 1], [], []]", 64, 0, 0, 831, 831], ["aten::resize_", "[[32, 128, 28, 28], [], []]", 224, 0, 0, 2294, 2294], ["aten::stride", "[[32, 128, 28, 28], []]", 672, 0, 0, 4636, 4636], ["aten::_convolution", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 32, 0, 13367, 3103, 38047], ["aten::convolution", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], []]", 32, 0, 13367, 1513, 39560], ["aten::conv2d", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], []]", 32, 0, 13367, 1685, 41245], ["aten::contiguous", "[[32, 512, 28, 28], []]", 360, 0, 0, 4362, 4362], ["aten::empty_like", "[[32, 512, 28, 28], [], [], [], [], []]", 40, 0, 0, 1985, 4495], ["aten::_batch_norm_impl_index", "[[32, 512, 28, 28], [512], [512], [512], [512], [], [], [], []]", 40, 0, 8307, 5465, 37608], ["aten::batch_norm", "[[32, 512, 28, 28], [512], [512], [512], [512], [], [], [], []]", 40, 0, 8307, 2043, 39651], ["aten::contiguous", "[[512, 256, 1, 1], []]", 16, 0, 0, 251, 251], ["aten::resize_", "[[512, 256, 1, 1], [], []]", 16, 0, 0, 203, 203], ["aten::_convolution", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 7675, 773, 17145], ["aten::convolution", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], [], [], []]", 8, 0, 7675, 389, 17534], ["aten::conv2d", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], []]", 8, 0, 7675, 417, 17951], ["aten::relu_", "[[32, 512, 28, 28]]", 32, 0, 4043, 3980, 5879], ["aten::contiguous", "[[128, 512, 1, 1], []]", 48, 0, 0, 936, 936], ["aten::resize_", "[[128, 512, 1, 1], [], []]", 48, 0, 0, 621, 621], ["aten::resize_", "[[32, 512, 28, 28], [], []]", 160, 0, 0, 1669, 1669], ["aten::stride", "[[32, 512, 28, 28], []]", 480, 0, 0, 3343, 3343], ["aten::_convolution", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 24, 0, 13507, 2353, 26675], ["aten::convolution", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], []]", 24, 0, 13507, 1091, 27766], ["aten::conv2d", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], []]", 24, 0, 13507, 1341, 29107], ["aten::_convolution", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 24, 0, 11931, 2348, 41140], ["aten::convolution", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], []]", 24, 0, 11931, 1071, 42211], ["aten::conv2d", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], []]", 24, 0, 11931, 1251, 43462], ["aten::contiguous", "[[256, 512, 1, 1], []]", 16, 0, 0, 235, 235], ["aten::resize_", "[[256, 512, 1, 1], [], []]", 16, 0, 0, 195, 195], ["aten::_convolution", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 12705, 785, 17380], ["aten::convolution", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], []]", 8, 0, 12705, 375, 17755], ["aten::conv2d", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], []]", 8, 0, 12705, 408, 18163], ["aten::contiguous", "[[32, 256, 28, 28], []]", 72, 0, 0, 986, 986], ["aten::empty_like", "[[32, 256, 28, 28], [], [], [], [], []]", 8, 0, 0, 384, 720], ["aten::_batch_norm_impl_index", "[[32, 256, 28, 28], [256], [256], [256], [256], [], [], [], []]", 8, 0, 831, 1086, 7327], ["aten::batch_norm", "[[32, 256, 28, 28], [256], [256], [256], [256], [], [], [], []]", 8, 0, 831, 385, 7712], ["aten::relu_", "[[32, 256, 28, 28]]", 8, 0, 505, 1023, 1500], ["aten::contiguous", "[[256, 256, 3, 3], []]", 96, 0, 0, 1456, 1456], ["aten::resize_", "[[256, 256, 3, 3], [], []]", 96, 0, 0, 1164, 1164], ["aten::resize_", "[[32, 256, 28, 28], [], []]", 32, 0, 0, 360, 360], ["aten::stride", "[[32, 256, 28, 28], []]", 96, 0, 0, 746, 746], ["aten::_convolution", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 11339, 1024, 13053], ["aten::convolution", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], [], [], []]", 8, 0, 11339, 354, 13407], ["aten::conv2d", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], []]", 8, 0, 11339, 422, 13829], ["aten::contiguous", "[[32, 256, 14, 14], []]", 792, 0, 0, 9599, 9599], ["aten::empty_like", "[[32, 256, 14, 14], [], [], [], [], []]", 88, 0, 0, 4434, 8249], ["aten::_batch_norm_impl_index", "[[32, 256, 14, 14], [256], [256], [256], [256], [], [], [], []]", 88, 0, 1986, 12019, 82244], ["aten::batch_norm", "[[32, 256, 14, 14], [256], [256], [256], [256], [], [], [], []]", 88, 0, 1986, 4366, 86610], ["aten::relu_", "[[32, 256, 14, 14]]", 88, 0, 1021, 11732, 17200], ["aten::contiguous", "[[1024, 256, 1, 1], []]", 96, 0, 0, 1460, 1460], ["aten::resize_", "[[1024, 256, 1, 1], [], []]", 96, 0, 0, 1272, 1272], ["aten::resize_", "[[32, 256, 14, 14], [], []]", 352, 0, 0, 3676, 3676], ["aten::stride", "[[32, 256, 14, 14], []]", 1056, 0, 0, 7777, 7777], ["aten::_convolution", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 48, 0, 23594, 4699, 42632], ["aten::convolution", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], []]", 48, 0, 23594, 2232, 44864], ["aten::conv2d", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], []]", 48, 0, 23594, 2506, 47370], ["aten::contiguous", "[[32, 1024, 14, 14], []]", 504, 0, 0, 5945, 5945], ["aten::empty_like", "[[32, 1024, 14, 14], [], [], [], [], []]", 56, 0, 0, 2759, 5850], ["aten::_batch_norm_impl_index", "[[32, 1024, 14, 14], [1024], [1024], [1024], [1024], [], [], [], []]", 56, 0, 4755, 7450, 51938], ["aten::batch_norm", "[[32, 1024, 14, 14], [1024], [1024], [1024], [1024], [], [], [], []]", 56, 0, 4755, 2775, 54713], ["aten::contiguous", "[[1024, 512, 1, 1], []]", 16, 0, 0, 247, 247], ["aten::resize_", "[[1024, 512, 1, 1], [], []]", 16, 0, 0, 194, 194], ["aten::_convolution", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 9178, 769, 10810], ["aten::convolution", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], [], [], []]", 8, 0, 9178, 359, 11169], ["aten::conv2d", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], []]", 8, 0, 9178, 412, 11581], ["aten::relu_", "[[32, 1024, 14, 14]]", 48, 0, 3035, 6105, 9317], ["aten::contiguous", "[[256, 1024, 1, 1], []]", 80, 0, 0, 1197, 1197], ["aten::resize_", "[[256, 1024, 1, 1], [], []]", 80, 0, 0, 1018, 1018], ["aten::resize_", "[[32, 1024, 14, 14], [], []]", 224, 0, 0, 2258, 2258], ["aten::stride", "[[32, 1024, 14, 14], []]", 672, 0, 0, 4715, 4715], ["aten::_convolution", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 40, 0, 20626, 3955, 36698], ["aten::convolution", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], []]", 40, 0, 20626, 1869, 38567], ["aten::conv2d", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], []]", 40, 0, 20626, 2076, 40643], ["aten::_convolution", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 40, 0, 17239, 3989, 42968], ["aten::convolution", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], []]", 40, 0, 17239, 1828, 44796], ["aten::conv2d", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], []]", 40, 0, 17239, 2102, 46898], ["aten::contiguous", "[[512, 1024, 1, 1], []]", 16, 0, 0, 233, 233], ["aten::resize_", "[[512, 1024, 1, 1], [], []]", 16, 0, 0, 195, 195], ["aten::_convolution", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 15072, 778, 19252], ["aten::convolution", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 0, 15072, 386, 19638], ["aten::conv2d", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], []]", 8, 0, 15072, 414, 20052], ["aten::contiguous", "[[32, 512, 14, 14], []]", 72, 0, 0, 878, 878], ["aten::empty_like", "[[32, 512, 14, 14], [], [], [], [], []]", 8, 0, 0, 430, 762], ["aten::_batch_norm_impl_index", "[[32, 512, 14, 14], [512], [512], [512], [512], [], [], [], []]", 8, 0, 370, 1069, 7336], ["aten::batch_norm", "[[32, 512, 14, 14], [512], [512], [512], [512], [], [], [], []]", 8, 0, 370, 386, 7722], ["aten::relu_", "[[32, 512, 14, 14]]", 8, 0, 244, 1078, 1557], ["aten::contiguous", "[[512, 512, 3, 3], []]", 48, 0, 0, 700, 700], ["aten::resize_", "[[512, 512, 3, 3], [], []]", 48, 0, 0, 583, 583], ["aten::resize_", "[[32, 512, 14, 14], [], []]", 32, 0, 0, 320, 320], ["aten::stride", "[[32, 512, 14, 14], []]", 96, 0, 0, 683, 683], ["aten::_convolution", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 15006, 778, 18742], ["aten::convolution", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], [], [], []]", 8, 0, 15006, 361, 19103], ["aten::conv2d", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], []]", 8, 0, 15006, 422, 19525], ["aten::contiguous", "[[32, 512, 7, 7], []]", 360, 0, 0, 4326, 4326], ["aten::empty_like", "[[32, 512, 7, 7], [], [], [], [], []]", 40, 0, 0, 1953, 3611], ["aten::_batch_norm_impl_index", "[[32, 512, 7, 7], [512], [512], [512], [512], [], [], [], []]", 40, 0, 635, 5714, 36871], ["aten::batch_norm", "[[32, 512, 7, 7], [512], [512], [512], [512], [], [], [], []]", 40, 0, 635, 1969, 38840], ["aten::relu_", "[[32, 512, 7, 7]]", 40, 0, 274, 5134, 7561], ["aten::contiguous", "[[2048, 512, 1, 1], []]", 48, 0, 0, 701, 701], ["aten::resize_", "[[2048, 512, 1, 1], [], []]", 48, 0, 0, 610, 610], ["aten::resize_", "[[32, 512, 7, 7], [], []]", 160, 0, 0, 1656, 1656], ["aten::stride", "[[32, 512, 7, 7], []]", 480, 0, 0, 3302, 3302], ["aten::_convolution", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 24, 0, 20349, 2272, 34805], ["aten::convolution", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], []]", 24, 0, 20349, 1081, 35886], ["aten::conv2d", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], []]", 24, 0, 20349, 1239, 37125], ["aten::contiguous", "[[32, 2048, 7, 7], []]", 240, 0, 0, 2837, 2837], ["aten::empty_like", "[[32, 2048, 7, 7], [], [], [], [], []]", 32, 0, 0, 1574, 3141], ["aten::_batch_norm_impl_index", "[[32, 2048, 7, 7], [2048], [2048], [2048], [2048], [], [], [], []]", 32, 0, 1821, 8659, 33849], ["aten::batch_norm", "[[32, 2048, 7, 7], [2048], [2048], [2048], [2048], [], [], [], []]", 32, 0, 1821, 1591, 35440], ["aten::contiguous", "[[2048, 1024, 1, 1], []]", 16, 0, 0, 249, 249], ["aten::resize_", "[[2048, 1024, 1, 1], [], []]", 16, 0, 0, 201, 201], ["aten::_convolution", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 9007, 797, 13265], ["aten::convolution", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 0, 9007, 365, 13630], ["aten::conv2d", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], []]", 8, 0, 9007, 429, 14059], ["aten::relu_", "[[32, 2048, 7, 7]]", 24, 0, 797, 2997, 4401], ["aten::contiguous", "[[512, 2048, 1, 1], []]", 32, 0, 0, 470, 470], ["aten::resize_", "[[512, 2048, 1, 1], [], []]", 32, 0, 0, 387, 387], ["aten::resize_", "[[32, 2048, 7, 7], [], []]", 96, 0, 0, 1017, 1017], ["aten::stride", "[[32, 2048, 7, 7], []]", 192, 0, 0, 1301, 1301], ["aten::_convolution", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 16, 0, 18181, 1559, 28403], ["aten::convolution", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], []]", 16, 0, 18181, 720, 29123], ["aten::conv2d", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], []]", 16, 0, 18181, 838, 29961], ["aten::_convolution", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 16, 0, 15714, 1545, 27423], ["aten::convolution", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], []]", 16, 0, 15714, 743, 28166], ["aten::conv2d", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], []]", 16, 0, 15714, 817, 28983], ["aten::adaptive_avg_pool2d", "[[32, 2048, 7, 7], []]", 8, 0, 346, 429, 5680], ["aten::view", "[[32, 2048, 1, 1], []]", 8, 0, 0, 937, 937], ["aten::reshape", "[[32, 2048, 1, 1], []]", 8, 0, 0, 392, 1329], ["aten::flatten", "[[32, 2048, 1, 1], [], []]", 8, 0, 0, 425, 1754], ["aten::as_strided", "[[1000, 2048], [], [], []]", 16, 0, 0, 263, 263], ["aten::transpose", "[[1000, 2048], [], []]", 16, 0, 0, 571, 834], ["aten::t", "[[1000, 2048]]", 16, 0, 0, 1283, 2117], ["aten::as_strided", "[[1000], [], [], []]", 8, 0, 0, 132, 132], ["aten::expand", "[[1000], [], []]", 8, 0, 0, 393, 525], ["aten::stride", "[[2048, 1000], []]", 8, 0, 0, 115, 115], ["aten::stride", "[[32, 2048], []]", 24, 0, 0, 188, 188], ["aten::stride", "[[32, 1000], []]", 16, 0, 0, 100, 100], ["aten::contiguous", "[[32, 1000], []]", 24, 0, 0, 290, 290], ["aten::empty_like", "[[32, 1000], [], [], [], [], []]", 16, 0, 0, 782, 1459], ["aten::log_softmax", "[[32, 1000], [], []]", 8, 0, 82, 418, 3083], ["aten::nll_loss", "[[32, 1000], [32], [], [], []]", 8, 0, 33, 438, 2551], ["aten::empty_like", "[[], [], [], [], [], []]", 8, 0, 0, 411, 839], ["aten::ones_like", "[[], [], [], [], [], []]", 8, 0, 8, 590, 1915], ["aten::clone", "[[64, 3, 7, 7], []]", 1, 0, 1, 113, 237], ["detach", "[[64, 3, 7, 7]]", 1, 0, 0, 15, 15], ["aten::detach", "[[64, 3, 7, 7]]", 1, 0, 0, 24, 39], ["aten::clone", "[[64], []]", 14, 0, 14, 1563, 3189], ["detach", "[[64]]", 14, 0, 0, 200, 200], ["aten::detach", "[[64]]", 14, 0, 0, 307, 507], ["aten::clone", "[[64, 64, 1, 1], []]", 1, 0, 1, 115, 233], ["detach", "[[64, 64, 1, 1]]", 1, 0, 0, 16, 16], ["aten::detach", "[[64, 64, 1, 1]]", 1, 0, 0, 22, 38], ["aten::clone", "[[64, 64, 3, 3], []]", 3, 0, 3, 326, 690], ["detach", "[[64, 64, 3, 3]]", 3, 0, 0, 44, 44], ["aten::detach", "[[64, 64, 3, 3]]", 3, 0, 0, 65, 109], ["aten::clone", "[[256, 64, 1, 1], []]", 4, 0, 4, 455, 922], ["detach", "[[256, 64, 1, 1]]", 4, 0, 0, 60, 60], ["aten::detach", "[[256, 64, 1, 1]]", 4, 0, 0, 91, 151], ["aten::clone", "[[256], []]", 32, 0, 32, 3489, 7226], ["detach", "[[256]]", 32, 0, 0, 454, 454], ["aten::detach", "[[256]]", 32, 0, 0, 713, 1167], ["aten::clone", "[[64, 256, 1, 1], []]", 2, 0, 2, 221, 456], ["detach", "[[64, 256, 1, 1]]", 2, 0, 0, 31, 31], ["aten::detach", "[[64, 256, 1, 1]]", 2, 0, 0, 59, 90], ["aten::clone", "[[128, 256, 1, 1], []]", 1, 0, 1, 113, 998], ["detach", "[[128, 256, 1, 1]]", 1, 0, 0, 15, 15], ["aten::detach", "[[128, 256, 1, 1]]", 1, 0, 0, 23, 38], ["aten::clone", "[[128], []]", 16, 0, 16, 1741, 3626], ["detach", "[[128]]", 16, 0, 0, 229, 229], ["aten::detach", "[[128]]", 16, 0, 0, 381, 610], ["aten::clone", "[[128, 128, 3, 3], []]", 4, 0, 8, 455, 1161], ["detach", "[[128, 128, 3, 3]]", 4, 0, 0, 61, 61], ["aten::detach", "[[128, 128, 3, 3]]", 4, 0, 0, 95, 156], ["aten::clone", "[[512, 128, 1, 1], []]", 4, 0, 4, 445, 910], ["detach", "[[512, 128, 1, 1]]", 4, 0, 0, 61, 61], ["aten::detach", "[[512, 128, 1, 1]]", 4, 0, 0, 92, 153], ["aten::clone", "[[512], []]", 22, 0, 22, 2381, 4932], ["detach", "[[512]]", 22, 0, 0, 326, 326], ["aten::detach", "[[512]]", 22, 0, 0, 489, 815], ["aten::clone", "[[512, 256, 1, 1], []]", 1, 0, 1, 113, 468], ["detach", "[[512, 256, 1, 1]]", 1, 0, 0, 16, 16], ["aten::detach", "[[512, 256, 1, 1]]", 1, 0, 0, 25, 41], ["aten::clone", "[[128, 512, 1, 1], []]", 3, 0, 3, 329, 692], ["detach", "[[128, 512, 1, 1]]", 3, 0, 0, 61, 61], ["aten::detach", "[[128, 512, 1, 1]]", 3, 0, 0, 65, 126], ["aten::clone", "[[256, 512, 1, 1], []]", 1, 0, 2, 111, 450], ["detach", "[[256, 512, 1, 1]]", 1, 0, 0, 15, 15], ["aten::detach", "[[256, 512, 1, 1]]", 1, 0, 0, 23, 38], ["aten::clone", "[[256, 256, 3, 3], []]", 6, 0, 20, 660, 1387], ["detach", "[[256, 256, 3, 3]]", 6, 0, 0, 89, 89], ["aten::detach", "[[256, 256, 3, 3]]", 6, 0, 0, 131, 220], ["aten::clone", "[[1024, 256, 1, 1], []]", 6, 0, 13, 684, 2787], ["detach", "[[1024, 256, 1, 1]]", 6, 0, 0, 90, 90], ["aten::detach", "[[1024, 256, 1, 1]]", 6, 0, 0, 132, 222], ["aten::clone", "[[1024], []]", 14, 0, 14, 1516, 3174], ["detach", "[[1024]]", 14, 0, 0, 201, 201], ["aten::detach", "[[1024]]", 14, 0, 0, 327, 528], ["aten::clone", "[[1024, 512, 1, 1], []]", 1, 0, 3, 107, 222], ["detach", "[[1024, 512, 1, 1]]", 1, 0, 0, 15, 15], ["aten::detach", "[[1024, 512, 1, 1]]", 1, 0, 0, 25, 40], ["aten::clone", "[[256, 1024, 1, 1], []]", 5, 0, 10, 556, 1131], ["detach", "[[256, 1024, 1, 1]]", 5, 0, 0, 74, 74], ["aten::detach", "[[256, 1024, 1, 1]]", 5, 0, 0, 109, 183], ["aten::clone", "[[512, 1024, 1, 1], []]", 1, 0, 3, 104, 218], ["detach", "[[512, 1024, 1, 1]]", 1, 0, 0, 15, 15], ["aten::detach", "[[512, 1024, 1, 1]]", 1, 0, 0, 29, 44], ["aten::clone", "[[512, 512, 3, 3], []]", 3, 0, 77, 335, 697], ["detach", "[[512, 512, 3, 3]]", 3, 0, 0, 45, 45], ["aten::detach", "[[512, 512, 3, 3]]", 3, 0, 0, 66, 111], ["aten::clone", "[[2048, 512, 1, 1], []]", 3, 0, 30, 332, 676], ["detach", "[[2048, 512, 1, 1]]", 3, 0, 0, 45, 45], ["aten::detach", "[[2048, 512, 1, 1]]", 3, 0, 0, 69, 114], ["aten::clone", "[[2048], []]", 8, 0, 8, 848, 1794], ["detach", "[[2048]]", 8, 0, 0, 113, 113], ["aten::detach", "[[2048]]", 8, 0, 0, 179, 292], ["aten::clone", "[[2048, 1024, 1, 1], []]", 1, 0, 23, 105, 222], ["detach", "[[2048, 1024, 1, 1]]", 1, 0, 0, 15, 15], ["aten::detach", "[[2048, 1024, 1, 1]]", 1, 0, 0, 22, 37], ["aten::clone", "[[512, 2048, 1, 1], []]", 2, 0, 20, 233, 460], ["detach", "[[512, 2048, 1, 1]]", 2, 0, 0, 29, 29], ["aten::detach", "[[512, 2048, 1, 1]]", 2, 0, 0, 43, 72], ["aten::clone", "[[1000, 2048], []]", 1, 0, 23, 121, 238], ["detach", "[[1000, 2048]]", 1, 0, 0, 14, 14], ["aten::detach", "[[1000, 2048]]", 1, 0, 0, 22, 36], ["aten::clone", "[[1000], []]", 1, 0, 1, 111, 225], ["detach", "[[1000]]", 1, 0, 0, 14, 14], ["aten::detach", "[[1000]]", 1, 0, 0, 22, 36], ["aten::as_strided", "[[2049000], [], [], []]", 2, 0, 0, 152, 152], ["aten::as_strided", "[[7875584], [], [], []]", 15, 0, 0, 868, 868], ["aten::as_strided", "[[6563840], [], [], []]", 12, 0, 0, 655, 655], ["aten::as_strided", "[[6637568], [], [], []]", 51, 0, 0, 2758, 2758], ["aten::as_strided", "[[2431040], [], [], []]", 81, 0, 0, 5878, 5878], ["aten::zero_", "[[64, 3, 7, 7]]", 7, 0, 7, 495, 929], ["aten::zero_", "[[64]]", 98, 0, 54, 6628, 11710], ["aten::zero_", "[[64, 64, 1, 1]]", 7, 0, 3, 561, 920], ["aten::zero_", "[[64, 64, 3, 3]]", 21, 0, 21, 1372, 2425], ["aten::zero_", "[[256, 64, 1, 1]]", 28, 0, 28, 1848, 3266], ["aten::zero_", "[[256]]", 224, 0, 107, 14960, 26617], ["aten::zero_", "[[64, 256, 1, 1]]", 14, 0, 14, 944, 1650], ["aten::zero_", "[[128, 256, 1, 1]]", 7, 0, 7, 456, 801], ["aten::zero_", "[[128]]", 112, 0, 76, 7407, 13157], ["aten::zero_", "[[128, 128, 3, 3]]", 28, 0, 28, 1853, 3247], ["aten::zero_", "[[512, 128, 1, 1]]", 28, 0, 28, 1852, 3281], ["aten::zero_", "[[512]]", 154, 0, 86, 10201, 18046], ["aten::zero_", "[[512, 256, 1, 1]]", 7, 0, 7, 454, 813], ["aten::zero_", "[[128, 512, 1, 1]]", 21, 0, 21, 1402, 2478], ["aten::zero_", "[[256, 512, 1, 1]]", 7, 0, 7, 471, 815], ["aten::zero_", "[[256, 256, 3, 3]]", 42, 0, 168, 2789, 4919], ["aten::zero_", "[[1024, 256, 1, 1]]", 42, 0, 84, 2817, 4924], ["aten::zero_", "[[1024]]", 98, 0, 58, 6512, 11486], ["aten::zero_", "[[1024, 512, 1, 1]]", 7, 0, 28, 455, 803], ["aten::zero_", "[[256, 1024, 1, 1]]", 35, 0, 70, 2371, 4111], ["aten::zero_", "[[512, 1024, 1, 1]]", 7, 0, 28, 460, 820], ["aten::zero_", "[[512, 512, 3, 3]]", 21, 0, 315, 1382, 2458], ["aten::zero_", "[[2048, 512, 1, 1]]", 21, 0, 147, 1416, 2465], ["aten::zero_", "[[2048]]", 56, 0, 20, 3740, 6590], ["aten::zero_", "[[2048, 1024, 1, 1]]", 7, 0, 91, 473, 824], ["aten::zero_", "[[512, 2048, 1, 1]]", 14, 0, 98, 928, 1620], ["aten::zero_", "[[1000, 2048]]", 7, 0, 91, 456, 804], ["aten::zero_", "[[1000]]", 7, 0, 7, 455, 804], ["NllLossBackward", "[[]]", 8, 0, 24, 733, 2286], ["LogSoftmaxBackward", "[[32, 1000]]", 8, 0, 83, 517, 2612], ["aten::as_strided", "[[2048, 1000], [], [], []]", 16, 0, 0, 243, 243], ["aten::transpose", "[[2048, 1000], [], []]", 16, 0, 0, 612, 855], ["aten::t", "[[2048, 1000]]", 16, 0, 0, 908, 1763], ["aten::conj", "[[1000, 2048]]", 8, 0, 0, 159, 159], ["aten::stride", "[[1000, 2048], []]", 16, 0, 0, 129, 129], ["aten::as_strided", "[[32, 1000], [], [], []]", 8, 0, 0, 137, 137], ["aten::transpose", "[[32, 1000], [], []]", 8, 0, 0, 275, 412], ["aten::t", "[[32, 1000]]", 8, 0, 0, 459, 871], ["aten::conj", "[[32, 2048]]", 8, 0, 0, 184, 184], ["aten::stride", "[[1000, 32], []]", 8, 0, 0, 47, 47], ["AddmmBackward", "[[32, 1000]]", 8, 0, 382, 1441, 9040], ["torch::autograd::AccumulateGrad", "[[1000]]", 8, 0, 8, 365, 1209], ["TBackward", "[[2048, 1000]]", 8, 0, 0, 281, 1120], ["torch::autograd::AccumulateGrad", "[[1000, 2048]]", 8, 0, 238, 317, 1086], ["aten::view", "[[32, 2048], []]", 8, 0, 0, 509, 509], ["aten::reshape", "[[32, 2048], []]", 8, 0, 0, 246, 755], ["ViewBackward", "[[32, 2048]]", 8, 0, 0, 318, 1073], ["aten::as_strided", "[[32, 2048, 1, 1], [], [], []]", 8, 0, 0, 158, 158], ["aten::expand", "[[32, 2048, 1, 1], [], []]", 8, 0, 0, 691, 849], ["aten::to", "[[32, 2048, 7, 7], [], [], [], []]", 8, 0, 0, 119, 119], ["MeanBackward1", "[[32, 2048, 1, 1]]", 8, 0, 231, 663, 3503], ["ReluBackward1", "[[32, 2048, 7, 7]]", 24, 0, 1212, 1446, 5599], ["AddBackward0", "[[32, 2048, 7, 7]]", 24, 0, 0, 602, 602], ["CudnnBatchNormBackward", "[[32, 2048, 7, 7]]", 32, 0, 2364, 3584, 22480], ["torch::autograd::AccumulateGrad", "[[2048]]", 64, 0, 244, 2797, 9166], ["aten::cudnn_convolution_backward", "[[32, 512, 7, 7], [32, 2048, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], [], []]", 24, 0, 35549, 4159, 207920], ["CudnnConvolutionBackward", "[[32, 2048, 7, 7]]", 32, 0, 56687, 2752, 291314], ["torch::autograd::AccumulateGrad", "[[2048, 512, 1, 1]]", 24, 0, 392, 1166, 3631], ["ReluBackward1", "[[32, 512, 7, 7]]", 40, 0, 660, 2427, 9415], ["CudnnBatchNormBackward", "[[32, 512, 7, 7]]", 40, 0, 938, 4512, 25822], ["torch::autograd::AccumulateGrad", "[[512]]", 176, 0, 667, 7750, 25341], ["aten::cudnn_convolution_backward", "[[32, 512, 7, 7], [32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], [], []]", 16, 0, 25143, 2737, 52331], ["CudnnConvolutionBackward", "[[32, 512, 7, 7]]", 40, 0, 77752, 3405, 130797], ["torch::autograd::AccumulateGrad", "[[512, 512, 3, 3]]", 24, 0, 905, 1041, 3465], ["aten::cudnn_convolution_backward", "[[32, 2048, 7, 7], [32, 512, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], [], []]", 16, 0, 28432, 2717, 44061], ["torch::autograd::AccumulateGrad", "[[512, 2048, 1, 1]]", 16, 0, 312, 734, 2302], ["aten::cudnn_convolution_backward", "[[32, 1024, 14, 14], [32, 2048, 7, 7], [2048, 1024, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 21138, 1327, 80642], ["torch::autograd::AccumulateGrad", "[[2048, 1024, 1, 1]]", 8, 0, 266, 365, 1164], ["aten::cudnn_convolution_backward", "[[32, 512, 14, 14], [32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], [], []]", 8, 0, 24177, 1312, 31000], ["ReluBackward1", "[[32, 512, 14, 14]]", 8, 0, 407, 485, 1866], ["CudnnBatchNormBackward", "[[32, 512, 14, 14]]", 8, 0, 743, 920, 5175], ["aten::cudnn_convolution_backward", "[[32, 1024, 14, 14], [32, 512, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 23698, 1341, 28640], ["CudnnConvolutionBackward", "[[32, 512, 14, 14]]", 8, 0, 23698, 683, 29323], ["torch::autograd::AccumulateGrad", "[[512, 1024, 1, 1]]", 8, 0, 99, 367, 1183], ["ReluBackward1", "[[32, 1024, 14, 14]]", 48, 0, 4614, 3032, 11355], ["AddBackward0", "[[32, 1024, 14, 14]]", 48, 0, 0, 1196, 1196], ["CudnnBatchNormBackward", "[[32, 1024, 14, 14]]", 56, 0, 10161, 6192, 36285], ["torch::autograd::AccumulateGrad", "[[1024]]", 112, 0, 478, 4874, 16128], ["aten::cudnn_convolution_backward", "[[32, 256, 14, 14], [32, 1024, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], [], []]", 48, 0, 47641, 8020, 78232], ["CudnnConvolutionBackward", "[[32, 1024, 14, 14]]", 56, 0, 66945, 4629, 103207], ["torch::autograd::AccumulateGrad", "[[1024, 256, 1, 1]]", 48, 0, 325, 2160, 12240], ["ReluBackward1", "[[32, 256, 14, 14]]", 88, 0, 2460, 5321, 21300], ["CudnnBatchNormBackward", "[[32, 256, 14, 14]]", 88, 0, 4197, 10134, 60539], ["torch::autograd::AccumulateGrad", "[[256]]", 256, 0, 1050, 11023, 36855], ["aten::cudnn_convolution_backward", "[[32, 256, 14, 14], [32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], [], []]", 40, 0, 32520, 6988, 64037], ["CudnnConvolutionBackward", "[[32, 256, 14, 14]]", 88, 0, 91276, 7408, 150549], ["torch::autograd::AccumulateGrad", "[[256, 256, 3, 3]]", 48, 0, 466, 2125, 6907], ["aten::cudnn_convolution_backward", "[[32, 1024, 14, 14], [32, 256, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], [], []]", 40, 0, 39318, 7571, 58291], ["torch::autograd::AccumulateGrad", "[[256, 1024, 1, 1]]", 40, 0, 328, 1809, 5783], ["aten::cudnn_convolution_backward", "[[32, 512, 28, 28], [32, 1024, 14, 14], [1024, 512, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 19304, 1886, 20346], ["torch::autograd::AccumulateGrad", "[[1024, 512, 1, 1]]", 8, 0, 69, 345, 1165], ["aten::cudnn_convolution_backward", "[[32, 256, 28, 28], [32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], [], []]", 8, 0, 19438, 1372, 20813], ["ReluBackward1", "[[32, 256, 28, 28]]", 8, 0, 764, 533, 1955], ["CudnnBatchNormBackward", "[[32, 256, 28, 28]]", 8, 0, 1310, 885, 5417], ["aten::cudnn_convolution_backward", "[[32, 512, 28, 28], [32, 256, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 21625, 1396, 28400], ["CudnnConvolutionBackward", "[[32, 256, 28, 28]]", 8, 0, 21625, 680, 29080], ["torch::autograd::AccumulateGrad", "[[256, 512, 1, 1]]", 8, 0, 50, 457, 1307], ["ReluBackward1", "[[32, 512, 28, 28]]", 32, 0, 5943, 1963, 7608], ["AddBackward0", "[[32, 512, 28, 28]]", 32, 0, 0, 875, 875], ["CudnnBatchNormBackward", "[[32, 512, 28, 28]]", 40, 0, 13207, 4448, 26230], ["aten::cudnn_convolution_backward", "[[32, 128, 28, 28], [32, 512, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], [], []]", 32, 0, 31782, 5323, 53353], ["CudnnConvolutionBackward", "[[32, 512, 28, 28]]", 40, 0, 52719, 3373, 77423], ["torch::autograd::AccumulateGrad", "[[512, 128, 1, 1]]", 32, 0, 146, 1429, 4877], ["ReluBackward1", "[[32, 128, 28, 28]]", 56, 0, 2733, 3408, 13192], ["CudnnBatchNormBackward", "[[32, 128, 28, 28]]", 56, 0, 5106, 6355, 36857], ["torch::autograd::AccumulateGrad", "[[128]]", 128, 0, 466, 5732, 19164], ["aten::cudnn_convolution_backward", "[[32, 128, 28, 28], [32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], [], []]", 24, 0, 22878, 5178, 44179], ["CudnnConvolutionBackward", "[[32, 128, 28, 28]]", 56, 0, 69953, 4798, 114262], ["torch::autograd::AccumulateGrad", "[[128, 128, 3, 3]]", 32, 0, 158, 1513, 6121], ["aten::cudnn_convolution_backward", "[[32, 512, 28, 28], [32, 128, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], [], []]", 24, 0, 23863, 4163, 43524], ["torch::autograd::AccumulateGrad", "[[128, 512, 1, 1]]", 24, 0, 117, 1072, 3507], ["aten::cudnn_convolution_backward", "[[32, 256, 56, 56], [32, 512, 28, 28], [512, 256, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 20937, 1379, 20697], ["torch::autograd::AccumulateGrad", "[[512, 256, 1, 1]]", 8, 0, 41, 361, 1177], ["aten::cudnn_convolution_backward", "[[32, 128, 56, 56], [32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], [], []]", 8, 0, 23212, 1393, 21761], ["ReluBackward1", "[[32, 128, 56, 56]]", 8, 0, 1478, 477, 1842], ["CudnnBatchNormBackward", "[[32, 128, 56, 56]]", 8, 0, 2749, 885, 5123], ["aten::cudnn_convolution_backward", "[[32, 256, 56, 56], [32, 128, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 28875, 1361, 33134], ["CudnnConvolutionBackward", "[[32, 128, 56, 56]]", 8, 0, 28875, 719, 33853], ["torch::autograd::AccumulateGrad", "[[128, 256, 1, 1]]", 8, 0, 41, 363, 1172], ["ReluBackward1", "[[32, 256, 56, 56]]", 24, 0, 8820, 1507, 5683], ["AddBackward0", "[[32, 256, 56, 56]]", 24, 0, 0, 577, 577], ["CudnnBatchNormBackward", "[[32, 256, 56, 56]]", 32, 0, 20552, 3635, 20760], ["aten::cudnn_convolution_backward", "[[32, 64, 56, 56], [32, 256, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], [], []]", 32, 0, 36499, 5511, 54358], ["CudnnConvolutionBackward", "[[32, 256, 56, 56]]", 32, 0, 36499, 2632, 56990], ["torch::autograd::AccumulateGrad", "[[256, 64, 1, 1]]", 32, 0, 142, 1445, 4656], ["ReluBackward1", "[[32, 64, 56, 56]]", 48, 0, 4448, 2916, 11329], ["CudnnBatchNormBackward", "[[32, 64, 56, 56]]", 48, 0, 10075, 5426, 32778], ["torch::autograd::AccumulateGrad", "[[64]]", 112, 0, 401, 4852, 15921], ["aten::cudnn_convolution_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], [], []]", 24, 0, 42214, 4113, 51084], ["CudnnConvolutionBackward", "[[32, 64, 56, 56]]", 48, 0, 79147, 4018, 110677], ["torch::autograd::AccumulateGrad", "[[64, 64, 3, 3]]", 24, 0, 110, 1043, 3458], ["aten::cudnn_convolution_backward", "[[32, 256, 56, 56], [32, 64, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], [], []]", 16, 0, 29862, 2720, 34972], ["torch::autograd::AccumulateGrad", "[[64, 256, 1, 1]]", 16, 0, 68, 790, 2410], ["aten::cudnn_convolution_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 7071, 1465, 20603], ["torch::autograd::AccumulateGrad", "[[64, 64, 1, 1]]", 8, 0, 31, 366, 1143], ["aten::zero_", "[[32, 64, 112, 112]]", 8, 0, 1285, 317, 760], ["aten::zeros_like", "[[32, 64, 112, 112], [], [], [], [], []]", 8, 0, 1285, 340, 1796], ["aten::resize_", "[[32, 64, 112, 112], [], []]", 16, 0, 0, 165, 165], ["aten::resize_as_", "[[32, 64, 112, 112], [32, 64, 112, 112], []]", 8, 0, 0, 281, 355], ["MaxPool2DWithIndicesBackward", "[[32, 64, 56, 56]]", 8, 0, 6842, 644, 5945], ["ReluBackward1", "[[32, 64, 112, 112]]", 8, 0, 2965, 460, 1832], ["CudnnBatchNormBackward", "[[32, 64, 112, 112]]", 8, 0, 6500, 996, 5243], ["aten::cudnn_convolution_backward", "[[32, 3, 224, 224], [32, 64, 112, 112], [64, 3, 7, 7], [], [], [], [], [], [], [], []]", 8, 0, 12638, 959, 11134], ["CudnnConvolutionBackward", "[[32, 64, 112, 112]]", 8, 0, 12638, 660, 11794], ["torch::autograd::AccumulateGrad", "[[64, 3, 7, 7]]", 8, 0, 32, 351, 1177]]}}, "kernel_op_table": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "string", "name": "Operator"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Total Duration (us)"}, {"type": "number", "name": "Mean Duration (us)"}, {"type": "number", "name": "Max Duration (us)"}, {"type": "number", "name": "Min Duration (us)"}], "rows": [["ncclAllReduceRingLLKernel_sum_f32(ncclColl)", "CallTreeRoot", 38, 3202562, 84277.94736842105, 3620, 385453], ["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", "aten::cudnn_convolution_backward_input", 260, 142493, 548.05, 150, 1206], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 248, 124024, 500.0967741935484, 381, 1439], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", "aten::cudnn_batch_norm_backward", 352, 74600, 211.9318181818182, 44, 859], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 94, 47861, 509.1595744680851, 361, 939], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 92, 42464, 461.5652173913044, 384, 904], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", "aten::threshold_backward", 392, 36504, 93.12244897959184, 14, 393], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", "aten::cudnn_convolution_backward_weight", 76, 36368, 478.5263157894737, 330, 737], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", "aten::cudnn_batch_norm", 200, 35206, 176.03, 50, 438], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", "aten::add_", 3670, 33739, 9.193188010899183, 1, 391], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 30, 28780, 959.3333333333334, 884, 1394], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", "aten::threshold_", 392, 23822, 60.77040816326531, 6, 273], ["volta_gcgemm_32x32_nt", "aten::cudnn_convolution", 110, 22147, 201.33636363636364, 21, 2208], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", "CallTreeRoot", 128, 20764, 162.21875, 50, 396], ["volta_gcgemm_32x32_nt", "aten::cudnn_convolution_backward_input", 29, 19326, 666.4137931034483, 73, 2213], ["volta_sgemm_128x64_nt", "aten::cudnn_convolution_backward_weight", 84, 17256, 205.42857142857142, 173, 676], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 28, 16817, 600.6071428571429, 444, 1013], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", "aten::cudnn_convolution_backward_weight", 24, 16743, 697.625, 669, 887], ["volta_cgemm_32x32_tn", "aten::cudnn_convolution", 14, 16644, 1188.857142857143, 221, 3113], ["volta_scudnn_128x64_relu_interior_nn_v1", "aten::cudnn_convolution", 53, 16602, 313.24528301886795, 92, 692], ["volta_sgemm_128x64_nt", "aten::cudnn_convolution_backward_input", 84, 16244, 193.38095238095238, 157, 213], ["volta_cgemm_32x32_tn", "aten::cudnn_convolution_backward_input", 14, 16202, 1157.2857142857142, 213, 3107], ["volta_sgemm_128x64_nn", "aten::cudnn_convolution", 84, 16044, 191.0, 157, 212], ["volta_scudnn_128x64_stridedB_interior_nn_v1", "aten::cudnn_convolution_backward_input", 47, 15871, 337.6808510638298, 269, 545], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 22, 13522, 614.6363636363636, 212, 1006], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", "aten::cudnn_convolution", 19, 12340, 649.4736842105264, 142, 874], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", "aten::cudnn_convolution", 19, 11791, 620.578947368421, 320, 801], ["volta_cgemm_32x32_tn", "aten::cudnn_convolution_backward_weight", 14, 11522, 823.0, 216, 1685], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", "aten::cudnn_convolution_backward_input", 28, 10943, 390.82142857142856, 365, 768], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", "aten::cudnn_convolution_backward_weight", 17, 10924, 642.5882352941177, 362, 1114], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", "aten::cudnn_convolution", 28, 10869, 388.17857142857144, 362, 764], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", "aten::cudnn_convolution_backward_input", 266, 10505, 39.49248120300752, 6, 163], ["volta_scudnn_128x128_relu_medium_nn_v1", "aten::cudnn_convolution", 34, 9734, 286.29411764705884, 268, 425], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", "aten::cudnn_batch_norm", 224, 9567, 42.70982142857143, 14, 89], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 12, 8791, 732.5833333333334, 656, 880], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 11, 8560, 778.1818181818181, 751, 799], ["volta_scudnn_128x64_relu_medium_nn_v1", "aten::cudnn_convolution", 12, 7523, 626.9166666666666, 381, 704], ["volta_scudnn_128x128_stridedB_interior_nn_v1", "aten::cudnn_convolution_backward_input", 25, 7294, 291.76, 270, 300], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", "aten::cudnn_convolution", 39, 6919, 177.4102564102564, 77, 453], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", "aten::cudnn_convolution", 10, 6572, 657.2, 570, 742], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", "CallTreeRoot", 1288, 6449, 5.006987577639752, 1, 30], ["volta_cgemm_64x32_tn", "aten::cudnn_convolution_backward_weight", 2, 6330, 3165.0, 3164, 3166], ["void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution_backward_input", 13, 6160, 473.84615384615387, 55, 1640], ["void flip_filter<float, float>(float*, float const*, int, int, int, int)", "aten::cudnn_convolution", 16, 6069, 379.3125, 8, 1638], ["volta_scudnn_128x128_stridedB_small_nn_v1", "aten::cudnn_convolution_backward_input", 10, 5913, 591.3, 546, 933], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution_backward_input", 14, 5782, 413.0, 36, 1585], ["volta_scudnn_128x64_relu_small_nn_v1", "aten::cudnn_convolution", 19, 5702, 300.10526315789474, 269, 608], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution", 14, 5612, 400.85714285714283, 29, 1582], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", "aten::max_pool2d_with_indices_backward", 8, 5557, 694.625, 692, 698], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution_backward_weight", 7, 5495, 785.0, 124, 1672], ["volta_scudnn_128x128_stridedB_medium_nn_v1", "aten::cudnn_convolution_backward_input", 17, 5461, 321.2352941176471, 310, 330], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", "aten::cudnn_convolution_backward_weight", 15, 5086, 339.06666666666666, 103, 1351], ["volta_scudnn_128x128_relu_interior_nn_v1", "aten::cudnn_convolution", 9, 5042, 560.2222222222222, 552, 584], ["void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution", 8, 4516, 564.5, 15, 1755], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", "aten::cudnn_convolution_backward_input", 9, 4328, 480.8888888888889, 89, 1395], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", "aten::add", 1288, 4217, 3.2740683229813663, 1, 35], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", "aten::cudnn_convolution", 9, 4172, 463.55555555555554, 85, 1379], ["void flip_filter<float, float>(float*, float const*, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 16, 3951, 246.9375, 28, 1126], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", "aten::cudnn_convolution_backward_input", 84, 3915, 46.607142857142854, 23, 119], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", "aten::cudnn_convolution_backward_weight", 84, 3747, 44.607142857142854, 22, 138], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", "aten::cudnn_convolution_backward_input", 84, 3682, 43.833333333333336, 22, 140], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", "aten::cudnn_convolution_backward_weight", 84, 3653, 43.48809523809524, 19, 140], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", "aten::cudnn_convolution", 84, 3602, 42.88095238095238, 19, 112], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 5, 6, 4, 3, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", "aten::cudnn_convolution_backward_input", 3, 3556, 1185.3333333333333, 1102, 1272], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", "aten::cudnn_convolution", 84, 3396, 40.42857142857143, 17, 136], ["void fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)", "aten::cudnn_convolution_backward_input", 28, 3394, 121.21428571428571, 15, 295], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", "aten::cudnn_batch_norm_backward", 72, 3297, 45.791666666666664, 20, 79], ["void cudnn::detail::dgrad_alg1_engine<float, 128, 6, 8, 3, 3, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)", "aten::cudnn_convolution_backward_input", 1, 3161, 3161.0, 3161, 3161], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution", 10, 3124, 312.4, 89, 937], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", "aten::fill_", 1143, 2992, 2.6176727909011372, 0, 162], ["void fft2d_c2r_32x32<float, true, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution", 87, 2984, 34.298850574712645, 24, 123], ["void fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)", "aten::cudnn_convolution", 16, 2941, 183.8125, 61, 303], ["volta_scudnn_128x64_stridedB_small_nn_v1", "aten::cudnn_convolution_backward_input", 12, 2818, 234.83333333333334, 95, 690], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution_backward_input", 10, 2812, 281.2, 88, 876], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", "aten::mul_", 1127, 2735, 2.4267968056787934, 1, 25], ["ncclBroadcastRingLLKernel_copy_i8(ncclColl)", "CallTreeRoot", 18, 2732, 151.77777777777777, 70, 274], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution", 95, 2714, 28.568421052631578, 13, 205], ["volta_scudnn_128x64_stridedB_splitK_interior_nn_v1", "aten::cudnn_convolution_backward_weight", 3, 2341, 780.3333333333334, 567, 893], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", "aten::cudnn_convolution_backward_input", 84, 2129, 25.345238095238095, 4, 71], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", "aten::cudnn_convolution_backward_weight", 84, 2121, 25.25, 3, 69], ["void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution", 7, 2099, 299.85714285714283, 93, 749], ["void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)", "aten::cudnn_convolution_backward_input", 16, 1960, 122.5, 33, 251], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1", "aten::cudnn_convolution", 3, 1957, 652.3333333333334, 593, 682], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution_backward_weight", 5, 1855, 371.0, 131, 773], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 10, 1850, 185.0, 97, 370], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", "aten::cudnn_convolution", 84, 1834, 21.833333333333332, 4, 72], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", "aten::max_pool2d_with_indices", 8, 1790, 223.75, 223, 225], ["volta_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1", "aten::cudnn_convolution_backward_weight", 1, 1648, 1648.0, 1648, 1648], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution_backward_weight", 4, 1625, 406.25, 134, 700], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 4, 6, 3, 2, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", "aten::cudnn_convolution_backward_input", 1, 1606, 1606.0, 1606, 1606], ["void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)", "aten::cudnn_convolution", 16, 1530, 95.625, 36, 208], ["void fft1d_r2c_32<float, float, float2, true, false>(float2*, float const*, int, int3, int3, int2, int2)", "aten::cudnn_convolution", 12, 1475, 122.91666666666667, 20, 405], ["void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution_backward_input", 14, 1408, 100.57142857142857, 39, 196], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 4, 1334, 333.5, 142, 526], ["volta_scudnn_128x64_stridedB_splitK_small_nn_v1", "aten::cudnn_convolution_backward_weight", 2, 1290, 645.0, 640, 650], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution_backward_input", 5, 1220, 244.0, 124, 439], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 14, 1100, 78.57142857142857, 36, 163], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", "aten::cudnn_convolution_backward_input", 1, 1082, 1082.0, 1082, 1082], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution_backward_weight", 8, 1067, 133.375, 71, 229], ["void pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)", "aten::cudnn_convolution", 2, 1047, 523.5, 523, 524], ["void pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)", "aten::cudnn_convolution_backward_input", 2, 1019, 509.5, 496, 523], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution", 5, 997, 199.4, 123, 405], ["void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution", 9, 733, 81.44444444444444, 47, 197], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution_backward_input", 9, 709, 78.77777777777777, 42, 194], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", "aten::cudnn_convolution_backward_input", 112, 694, 6.196428571428571, 2, 12], ["void explicit_convolve_sgemm<float, int, 512, 6, 8, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", "aten::cudnn_convolution", 1, 671, 671.0, 671, 671], ["volta_scudnn_128x64_stridedB_medium_nn_v1", "aten::cudnn_convolution_backward_input", 1, 652, 652.0, 652, 652], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1", "aten::cudnn_convolution", 1, 595, 595.0, 595, 595], ["volta_scudnn_128x64_stridedB_splitK_medium_nn_v1", "aten::cudnn_convolution_backward_weight", 1, 541, 541.0, 541, 541], ["volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1", "aten::cudnn_convolution", 1, 531, 531.0, 531, 531], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution_backward_input", 7, 531, 75.85714285714286, 35, 139], ["void cudnn::cnn::wgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)", "aten::cudnn_convolution_backward_weight", 1, 509, 509.0, 509, 509], ["void fft2d_r2c_32x32<float, true, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution_backward_input", 6, 495, 82.5, 54, 144], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution", 7, 467, 66.71428571428571, 35, 132], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", "aten::add", 424, 455, 1.0731132075471699, 1, 3], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", "aten::cudnn_convolution_backward_weight", 124, 451, 3.6370967741935485, 1, 7], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", "aten::cudnn_convolution_backward_weight", 124, 448, 3.6129032258064515, 1, 7], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", "aten::cudnn_convolution_backward_input", 112, 396, 3.5357142857142856, 1, 7], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", "aten::cudnn_convolution", 143, 381, 2.664335664335664, 2, 6], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution_backward_input", 3, 349, 116.33333333333333, 81, 143], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", "aten::mean", 8, 346, 43.25, 42, 46], ["void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", "aten::cudnn_convolution", 10, 321, 32.1, 9, 66], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1", "aten::cudnn_convolution", 1, 311, 311.0, 311, 311], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<float, unsigned int, 1, 128, 1>(float*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<float, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", "aten::_cat", 8, 259, 32.375, 32, 35], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", "aten::div", 8, 231, 28.875, 27, 30], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", "aten::cudnn_convolution_backward_input", 28, 224, 8.0, 4, 37], ["volta_sgemm_64x32_sliced1x4_nn", "aten::mm", 8, 212, 26.5, 26, 27], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution", 2, 210, 105.0, 78, 132], ["volta_sgemm_64x32_sliced1x4_tn", "aten::addmm", 8, 199, 24.875, 24, 27], ["volta_sgemm_128x32_nt", "aten::mm", 8, 153, 19.125, 19, 20], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", "aten::cudnn_convolution", 28, 133, 4.75, 2, 45], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<long, unsigned int, 1, 128, 1>(long*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<long, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", "aten::_cat", 8, 132, 16.5, 16, 18], ["void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", "aten::cudnn_convolution", 6, 102, 17.0, 9, 35], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", "aten::_log_softmax_backward_data", 8, 83, 10.375, 10, 11], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", "aten::_log_softmax", 8, 82, 10.25, 10, 11], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", "CallTreeRoot", 8, 67, 8.375, 8, 9], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", "aten::addmm", 8, 41, 5.125, 5, 6], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", "aten::nll_loss_forward", 8, 33, 4.125, 4, 5], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", "aten::addmm", 8, 29, 3.625, 3, 4], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", "aten::nll_loss_backward", 8, 16, 2.0, 2, 2], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", "aten::mm", 8, 16, 2.0, 2, 2]]}}, "kernel_pie": {"total": {"columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["ncclAllReduceRingLLKernel_sum_f32(ncclColl)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3202562.0}], ["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 142493.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 124024.0}], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 74600.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 60326.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 58720.0}], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 47861.0}], ["volta_cgemm_32x32_tn", {"py/object": "numpy.float64", "dtype": "float64", "value": 44368.0}], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 42464.0}], ["volta_gcgemm_32x32_nt", {"py/object": "numpy.float64", "dtype": "float64", "value": 41473.0}], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 36368.0}], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 35206.0}], ["volta_sgemm_128x64_nt", {"py/object": "numpy.float64", "dtype": "float64", "value": 33500.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 28780.0}], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 21812.0}], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 16817.0}], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 16743.0}], ["volta_scudnn_128x64_relu_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 16602.0}], ["volta_sgemm_128x64_nn", {"py/object": "numpy.float64", "dtype": "float64", "value": 16044.0}], ["volta_scudnn_128x64_stridedB_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 15871.0}], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 13586.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 13522.0}], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 12494.0}], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 12340.0}], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 11791.0}], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 10924.0}], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 10505.0}], ["void flip_filter<float, float>(float*, float const*, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 10020.0}], ["volta_scudnn_128x128_relu_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 9734.0}], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", {"py/object": "numpy.float64", "dtype": "float64", "value": 9567.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 9184.0}], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 8791.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 8560.0}], ["void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 8259.0}], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 7786.0}], ["volta_scudnn_128x64_relu_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 7523.0}], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 7517.0}], ["volta_scudnn_128x128_stridedB_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 7294.0}], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 7078.0}], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 6919.0}], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 6572.0}], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 6493.0}], ["void fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)", {"py/object": "numpy.float64", "dtype": "float64", "value": 6335.0}], ["volta_cgemm_64x32_tn", {"py/object": "numpy.float64", "dtype": "float64", "value": 6330.0}], ["volta_scudnn_128x128_stridedB_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 5913.0}], ["volta_scudnn_128x64_relu_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 5702.0}], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 5557.0}], ["volta_scudnn_128x128_stridedB_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 5461.0}], ["volta_scudnn_128x128_relu_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 5042.0}], ["void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 4516.0}], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 4490.0}], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 4072.0}], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3963.0}], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3747.0}], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3653.0}], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 5, 6, 4, 3, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3556.0}], ["void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3490.0}], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3297.0}], ["void cudnn::detail::dgrad_alg1_engine<float, 128, 6, 8, 3, 3, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3161.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2992.0}], ["void fft2d_c2r_32x32<float, true, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2984.0}], ["volta_scudnn_128x64_stridedB_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 2818.0}], ["ncclBroadcastRingLLKernel_copy_i8(ncclColl)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2732.0}], ["volta_scudnn_128x64_stridedB_splitK_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 2341.0}], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2184.0}], ["void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2141.0}], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2121.0}], ["void pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2066.0}], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 1957.0}], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1790.0}], ["volta_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 1648.0}], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 4, 6, 3, 2, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1606.0}], ["void fft1d_r2c_32<float, float, float2, true, false>(float2*, float const*, int, int3, int3, int2, int2)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1475.0}], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1334.0}], ["volta_scudnn_128x64_stridedB_splitK_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 1290.0}], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1082.0}], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1075.0}], ["void explicit_convolve_sgemm<float, int, 512, 6, 8, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 671.0}], ["volta_scudnn_128x64_stridedB_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 652.0}], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 595.0}], ["volta_scudnn_128x64_stridedB_splitK_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 541.0}], ["volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 531.0}], ["void cudnn::cnn::wgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 509.0}], ["void fft2d_r2c_32x32<float, true, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 495.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 455.0}], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 451.0}], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 448.0}], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 396.0}], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 357.0}], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 346.0}], ["void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 321.0}], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 311.0}], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<float, unsigned int, 1, 128, 1>(float*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<float, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 259.0}], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", {"py/object": "numpy.float64", "dtype": "float64", "value": 231.0}], ["volta_sgemm_64x32_sliced1x4_nn", {"py/object": "numpy.float64", "dtype": "float64", "value": 212.0}], ["volta_sgemm_64x32_sliced1x4_tn", {"py/object": "numpy.float64", "dtype": "float64", "value": 199.0}], ["volta_sgemm_128x32_nt", {"py/object": "numpy.float64", "dtype": "float64", "value": 153.0}], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<long, unsigned int, 1, 128, 1>(long*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<long, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 132.0}], ["void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 102.0}], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 83.0}], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 82.0}], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 67.0}], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 45.0}], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", {"py/object": "numpy.float64", "dtype": "float64", "value": 41.0}], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", {"py/object": "numpy.float64", "dtype": "float64", "value": 33.0}], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", {"py/object": "numpy.float64", "dtype": "float64", "value": 16.0}]]}}, "kernel_table": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Total Duration (us)"}, {"type": "number", "name": "Mean Duration (us)"}, {"type": "number", "name": "Max Duration (us)"}, {"type": "number", "name": "Min Duration (us)"}], "rows": [["ncclAllReduceRingLLKernel_sum_f32(ncclColl)", 38, 3202562, 84278, 385453, 3620], ["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", 260, 142493, 548, 1206, 150], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 248, 124024, 500, 1439, 381], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", 352, 74600, 212, 859, 44], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", 784, 60326, 77, 393, 6], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", 5086, 58720, 12, 396, 1], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 94, 47861, 509, 939, 361], ["volta_cgemm_32x32_tn", 42, 44368, 1056, 3113, 213], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 92, 42464, 462, 904, 384], ["volta_gcgemm_32x32_nt", 139, 41473, 298, 2213, 21], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", 76, 36368, 479, 737, 330], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", 200, 35206, 176, 438, 50], ["volta_sgemm_128x64_nt", 168, 33500, 199, 676, 157], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 30, 28780, 959, 1394, 884], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", 56, 21812, 390, 768, 362], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 28, 16817, 601, 1013, 444], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", 24, 16743, 698, 887, 669], ["volta_scudnn_128x64_relu_interior_nn_v1", 53, 16602, 313, 692, 92], ["volta_sgemm_128x64_nn", 84, 16044, 191, 212, 157], ["volta_scudnn_128x64_stridedB_interior_nn_v1", 47, 15871, 338, 545, 269], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", 33, 13586, 412, 1395, 85], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 22, 13522, 615, 1006, 212], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", 42, 12494, 297, 1585, 29], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 19, 12340, 649, 874, 142], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 19, 11791, 621, 801, 320], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", 17, 10924, 643, 1114, 362], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", 266, 10505, 39, 163, 6], ["void flip_filter<float, float>(float*, float const*, int, int, int, int)", 32, 10020, 313, 1638, 8], ["volta_scudnn_128x128_relu_medium_nn_v1", 34, 9734, 286, 425, 268], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", 224, 9567, 43, 89, 14], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", 2415, 9184, 4, 30, 1], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 12, 8791, 733, 880, 656], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 11, 8560, 778, 799, 751], ["void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 20, 8259, 413, 1640, 55], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", 30, 7786, 260, 937, 88], ["volta_scudnn_128x64_relu_medium_nn_v1", 12, 7523, 627, 704, 381], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", 168, 7517, 45, 119, 19], ["volta_scudnn_128x128_stridedB_interior_nn_v1", 25, 7294, 292, 300, 270], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 168, 7078, 42, 140, 17], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", 39, 6919, 177, 453, 77], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", 10, 6572, 657, 742, 570], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", 21, 6493, 309, 1672, 35], ["void fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)", 44, 6335, 144, 303, 15], ["volta_cgemm_64x32_tn", 2, 6330, 3165, 3166, 3164], ["volta_scudnn_128x128_stridedB_small_nn_v1", 10, 5913, 591, 933, 546], ["volta_scudnn_128x64_relu_small_nn_v1", 19, 5702, 300, 608, 269], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", 8, 5557, 695, 698, 692], ["volta_scudnn_128x128_stridedB_medium_nn_v1", 17, 5461, 321, 330, 310], ["volta_scudnn_128x128_relu_interior_nn_v1", 9, 5042, 560, 584, 552], ["void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 8, 4516, 564, 1755, 15], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 112, 4490, 40, 229, 13], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", 15, 4072, 271, 773, 123], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", 168, 3963, 24, 72, 4], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 84, 3747, 45, 138, 22], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", 84, 3653, 43, 140, 19], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 5, 6, 4, 3, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 3, 3556, 1185, 1272, 1102], ["void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)", 32, 3490, 109, 251, 33], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", 72, 3297, 46, 79, 20], ["void cudnn::detail::dgrad_alg1_engine<float, 128, 6, 8, 3, 3, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)", 1, 3161, 3161, 3161, 3161], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", 1143, 2992, 3, 162, 0], ["void fft2d_c2r_32x32<float, true, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 87, 2984, 34, 123, 24], ["volta_scudnn_128x64_stridedB_small_nn_v1", 12, 2818, 235, 690, 95], ["ncclBroadcastRingLLKernel_copy_i8(ncclColl)", 18, 2732, 152, 274, 70], ["volta_scudnn_128x64_stridedB_splitK_interior_nn_v1", 3, 2341, 780, 893, 567], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 9, 2184, 243, 700, 78], ["void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 23, 2141, 93, 197, 39], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", 84, 2121, 25, 69, 3], ["void pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)", 4, 2066, 516, 524, 496], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1", 3, 1957, 652, 682, 593], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", 8, 1790, 224, 225, 223], ["volta_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1", 1, 1648, 1648, 1648, 1648], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 4, 6, 3, 2, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 1, 1606, 1606, 1606, 1606], ["void fft1d_r2c_32<float, float, float2, true, false>(float2*, float const*, int, int3, int3, int2, int2)", 12, 1475, 123, 405, 20], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 4, 1334, 334, 526, 142], ["volta_scudnn_128x64_stridedB_splitK_small_nn_v1", 2, 1290, 645, 650, 640], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 1, 1082, 1082, 1082, 1082], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", 255, 1075, 4, 12, 2], ["void explicit_convolve_sgemm<float, int, 512, 6, 8, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 1, 671, 671, 671, 671], ["volta_scudnn_128x64_stridedB_medium_nn_v1", 1, 652, 652, 652, 652], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1", 1, 595, 595, 595, 595], ["volta_scudnn_128x64_stridedB_splitK_medium_nn_v1", 1, 541, 541, 541, 541], ["volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1", 1, 531, 531, 531, 531], ["void cudnn::cnn::wgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)", 1, 509, 509, 509, 509], ["void fft2d_r2c_32x32<float, true, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 6, 495, 82, 144, 54], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", 424, 455, 1, 3, 1], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", 124, 451, 4, 7, 1], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", 124, 448, 4, 7, 1], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", 112, 396, 4, 7, 1], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", 56, 357, 6, 45, 2], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", 8, 346, 43, 46, 42], ["void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", 10, 321, 32, 66, 9], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1", 1, 311, 311, 311, 311], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<float, unsigned int, 1, 128, 1>(float*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<float, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", 8, 259, 32, 35, 32], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", 8, 231, 29, 30, 27], ["volta_sgemm_64x32_sliced1x4_nn", 8, 212, 26, 27, 26], ["volta_sgemm_64x32_sliced1x4_tn", 8, 199, 25, 27, 24], ["volta_sgemm_128x32_nt", 8, 153, 19, 20, 19], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<long, unsigned int, 1, 128, 1>(long*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<long, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", 8, 132, 16, 18, 16], ["void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", 6, 102, 17, 35, 9], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", 8, 83, 10, 11, 10], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", 8, 82, 10, 11, 10], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", 8, 67, 8, 9, 8], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", 16, 45, 3, 4, 2], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", 8, 41, 5, 6, 5], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", 8, 33, 4, 5, 4], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", 8, 16, 2, 2, 2]]}}, "trace_file_path": "./data/tracing\\resnet50_autogradAPI_ddp\\worker0_span1.pt.trace.json.gz"}]}, {"py/tuple": ["worker1_span1", {"py/object": "tensorboard_plugin_torch_profiler.run.RunProfile", "worker": "worker1_span1", "views": [{"py/id": 4}, {"py/id": 5}, {"py/id": 6}, {"py/id": 7}], "is_gpu_used": true, "overview": {"steps": {"columns": [{"type": "string", "name": "Step"}, {"type": "number", "name": "Kernel"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memcpy"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memset"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Runtime"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "DataLoader"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "CPU Exec"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Other"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}], "rows": [["0", 2562971, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 20598873us<br><b>Kernel: 2562971us</b><br>Percentage: 12.44%</div>", 16300, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 20598873us<br><b>Memcpy: 16300us</b><br>Percentage: 0.08%</div>", 162, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 20598873us<br><b>Memset: 162us</b><br>Percentage: 0.0%</div>", 4339670, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 20598873us<br><b>Runtime: 4339670us</b><br>Percentage: 21.07%</div>", 11117394, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 20598873us<br><b>DataLoader: 11117394us</b><br>Percentage: 53.97%</div>", 2334934, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 20598873us<br><b>CPU Exec: 2334934us</b><br>Percentage: 11.34%</div>", 227442, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 20598873us<br><b>Other: 227442us</b><br>Percentage: 1.1%</div>"]]}, "performance": [{"name": "Average Step Time", "description": "", "value": 20598873, "extra": 100, "children": [{"name": "Kernel", "description": "", "value": 2562971, "extra": 12.44}, {"name": "Memcpy", "description": "", "value": 16300, "extra": 0.08}, {"name": "Memset", "description": "", "value": 162, "extra": 0.0}, {"name": "Runtime", "description": "", "value": 4339670, "extra": 21.07}, {"name": "DataLoader", "description": "", "value": 11117394, "extra": 53.97}, {"name": "CPU Exec", "description": "", "value": 2334934, "extra": 11.34}, {"name": "Other", "description": "", "value": 227442, "extra": 1.1}]}], "recommendations": "<ul><li>This run has high time cost on input data loading. 54.0% of the step time is in DataLoader. You could try to set num_workers on DataLoader's construction and enable multi-processes on data loading. Reference: <a href =\"https://pytorch.org/docs/stable/data.html#single-and-multi-process-data-loading\" target=\"_blank\">Single- and Multi-process Data Loading</a></li></ul>"}, "operation_pie_by_name": {"device_total_time": {"title": "Device Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward", 621026], ["CudnnConvolutionBackward", 621026], ["aten::cudnn_convolution", 321646], ["aten::_convolution", 321646], ["aten::convolution", 321646], ["aten::conv2d", 321646], ["aten::cudnn_convolution_backward_weight", 315723], ["aten::cudnn_convolution_backward_input", 305303], ["aten::cudnn_batch_norm_backward", 78220], ["CudnnBatchNormBackward", 78220], ["aten::cudnn_batch_norm", 44717], ["aten::_batch_norm_impl_index", 44717], ["aten::batch_norm", 44717], ["aten::threshold_backward", 36540], ["ReluBackward1", 36540], ["aten::add_", 33900], ["aten::threshold_", 23847], ["aten::relu_", 23847], ["aten::copy_", 16018], ["aten::to", 13566], ["torch::autograd::AccumulateGrad", 7789], ["aten::max_pool2d_with_indices_backward", 6851], ["MaxPool2DWithIndicesBackward", 6851], ["aten::add", 4669], ["aten::fill_", 3005], ["aten::zero_", 2997], ["aten::mul_", 2723], ["aten::max_pool2d_with_indices", 1788], ["aten::max_pool2d", 1788], ["aten::zeros_like", 1285], ["aten::_cat", 392], ["aten::cat", 392], ["aten::mm", 386], ["AddmmBackward", 386], ["aten::clone", 359], ["aten::mean", 345], ["aten::adaptive_avg_pool2d", 345], ["aten::addmm", 275], ["aten::div", 234], ["MeanBackward1", 234], ["aten::_log_softmax_backward_data", 83], ["LogSoftmaxBackward", 83], ["aten::_log_softmax", 81], ["aten::log_softmax", 81], ["aten::nll_loss_forward", 33], ["aten::nll_loss", 33], ["aten::nll_loss_backward", 24], ["NllLossBackward", 24], ["aten::_local_scalar_dense", 12], ["aten::item", 12], ["aten::ones_like", 8]]}, "device_self_time": {"title": "Device Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution", 321646], ["aten::cudnn_convolution_backward_weight", 315723], ["aten::cudnn_convolution_backward_input", 305303], ["aten::cudnn_batch_norm_backward", 78220], ["aten::cudnn_batch_norm", 44717], ["aten::threshold_backward", 36540], ["aten::add_", 33900], ["aten::threshold_", 23847], ["aten::copy_", 16018], ["aten::max_pool2d_with_indices_backward", 5566], ["aten::add", 4669], ["aten::fill_", 3005], ["aten::mul_", 2723], ["aten::max_pool2d_with_indices", 1788], ["aten::_cat", 392], ["aten::mm", 386], ["aten::mean", 345], ["aten::addmm", 275], ["aten::div", 234], ["aten::_log_softmax_backward_data", 83], ["aten::_log_softmax", 81], ["aten::nll_loss_forward", 33], ["aten::nll_loss_backward", 24], ["aten::_local_scalar_dense", 12]]}, "host_total_time": {"title": "Host Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 4144866], ["aten::cat", 2889397], ["aten::_cat", 2886103], ["aten::conv2d", 2073763], ["aten::to", 2062694], ["aten::convolution", 2050737], ["aten::_convolution", 2030410], ["aten::cudnn_convolution", 1980305], ["CudnnConvolutionBackward", 1218710], ["aten::cudnn_convolution_backward", 1182696], ["aten::contiguous", 1164958], ["aten::clone", 996033], ["aten::div", 994616], ["aten::div_", 966065], ["aten::stack", 804276], ["aten::sub_", 796119], ["aten::cudnn_convolution_backward_weight", 630944], ["aten::batch_norm", 507955], ["aten::addmm", 486833], ["aten::_batch_norm_impl_index", 485949], ["aten::cudnn_convolution_backward_input", 472731], ["aten::empty", 434482], ["aten::cudnn_batch_norm", 396690], ["aten::add_", 356466], ["aten::add", 308876], ["CudnnBatchNormBackward", 288172], ["aten::cudnn_batch_norm_backward", 232602], ["aten::view", 228853], ["torch::autograd::AccumulateGrad", 199603], ["aten::eq", 190521], ["aten::lt", 177847], ["aten::narrow", 159581], ["aten::item", 144811], ["aten::zero_", 135697], ["aten::slice", 123223], ["aten::pin_memory", 120157], ["aten::mul_", 117846], ["ReluBackward1", 94713], ["aten::exp", 91835], ["aten::select", 79129], ["aten::_local_scalar_dense", 77280], ["aten::relu_", 74442], ["aten::threshold_backward", 70404], ["aten::any", 64036], ["aten::fill_", 63115], ["aten::empty_like", 62700], ["aten::randint", 61402], ["aten::empty_strided", 58780], ["aten::uniform_", 57045], ["aten::as_strided", 55144], ["aten::resize_", 55010], ["aten::stride", 46659], ["aten::log", 41501], ["aten::is_nonzero", 40116], ["aten::rand", 33177], ["aten::permute", 27392], ["aten::threshold_", 23790], ["aten::set_", 19301], ["aten::random_", 16674], ["aten::is_floating_point", 14562], ["aten::unsqueeze", 13209], ["aten::detach_", 11560], ["AddmmBackward", 9196], ["aten::detach", 7458], ["aten::adaptive_avg_pool2d", 5932], ["MaxPool2DWithIndicesBackward", 5800], ["aten::mean", 5519], ["aten::max_pool2d", 5260], ["aten::max_pool2d_with_indices_backward", 5145], ["aten::mm", 4810], ["aten::t", 4778], ["aten::max_pool2d_with_indices", 4772], ["detach_", 4729], ["MeanBackward1", 3646], ["aten::zeros", 3369], ["AddBackward0", 3341], ["aten::log_softmax", 3171], ["detach", 2936], ["aten::_log_softmax", 2731], ["LogSoftmaxBackward", 2689], ["aten::nll_loss", 2427], ["aten::_log_softmax_backward_data", 2171], ["aten::transpose", 2104], ["NllLossBackward", 2085], ["aten::reshape", 2001], ["aten::nll_loss_forward", 1977], ["aten::zeros_like", 1975], ["aten::ones_like", 1912], ["aten::flatten", 1637], ["aten::expand", 1408], ["aten::nll_loss_backward", 1398], ["aten::is_pinned", 1134], ["TBackward", 1120], ["ViewBackward", 1115], ["nccl:broadcast", 547], ["aten::resize_as_", 359], ["aten::conj", 317]]}, "host_self_time": {"title": "Host Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 4144866], ["aten::_cat", 2875436], ["aten::cudnn_convolution", 1903545], ["aten::div_", 966065], ["aten::div", 953106], ["aten::sub_", 796119], ["aten::cudnn_convolution_backward_weight", 567642], ["aten::addmm", 483411], ["aten::empty", 434482], ["aten::cudnn_convolution_backward_input", 409044], ["aten::add_", 356466], ["aten::cudnn_batch_norm", 289122], ["aten::add", 236741], ["aten::view", 228853], ["aten::cudnn_batch_norm_backward", 156263], ["aten::mul_", 117846], ["aten::contiguous", 114051], ["aten::slice", 103229], ["aten::to", 92032], ["aten::zero_", 77800], ["aten::_local_scalar_dense", 77280], ["aten::cudnn_convolution_backward", 73946], ["aten::select", 68648], ["aten::item", 67531], ["aten::_batch_norm_impl_index", 65055], ["aten::fill_", 63115], ["torch::autograd::AccumulateGrad", 59896], ["aten::empty_strided", 58780], ["aten::clone", 58309], ["aten::uniform_", 57045], ["aten::eq", 55564], ["aten::as_strided", 55144], ["aten::resize_", 55010], ["aten::lt", 54667], ["aten::threshold_backward", 53379], ["aten::exp", 52551], ["aten::relu_", 50652], ["CudnnBatchNormBackward", 48285], ["aten::stride", 46659], ["aten::_convolution", 43809], ["aten::any", 43695], ["aten::narrow", 36358], ["CudnnConvolutionBackward", 36014], ["aten::empty_like", 35295], ["aten::log", 34721], ["aten::randint", 33156], ["ReluBackward1", 24309], ["aten::threshold_", 23790], ["aten::conv2d", 23026], ["aten::permute", 23020], ["aten::batch_norm", 22006], ["aten::convolution", 20327], ["aten::pin_memory", 19532], ["aten::set_", 19301], ["aten::rand", 18218], ["aten::random_", 16674], ["aten::is_floating_point", 14562], ["aten::is_nonzero", 12855], ["aten::unsqueeze", 9977], ["aten::detach_", 6831], ["aten::mean", 5157], ["detach_", 4729], ["aten::stack", 4630], ["aten::detach", 4522], ["aten::mm", 3821], ["aten::max_pool2d_with_indices", 3373], ["AddBackward0", 3341], ["aten::cat", 3294], ["detach", 2936], ["aten::t", 2674], ["aten::max_pool2d_with_indices_backward", 2267], ["aten::nll_loss_forward", 1977], ["aten::_log_softmax", 1877], ["aten::zeros", 1712], ["aten::transpose", 1447], ["AddmmBackward", 1410], ["aten::nll_loss_backward", 1398], ["aten::_log_softmax_backward_data", 1210], ["aten::is_pinned", 1134], ["aten::expand", 1121], ["MeanBackward1", 703], ["NllLossBackward", 687], ["MaxPool2DWithIndicesBackward", 655], ["aten::ones_like", 572], ["nccl:broadcast", 547], ["aten::reshape", 538], ["LogSoftmaxBackward", 518], ["aten::max_pool2d", 488], ["aten::nll_loss", 450], ["aten::log_softmax", 440], ["aten::flatten", 427], ["aten::adaptive_avg_pool2d", 413], ["aten::zeros_like", 382], ["ViewBackward", 324], ["aten::conj", 317], ["TBackward", 288], ["aten::resize_as_", 284]]}}, "operation_table_by_name": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Device Self Duration (us)"}, {"type": "number", "name": "Device Total Duration (us)"}, {"type": "number", "name": "Host Self Duration (us)"}, {"type": "number", "name": "Host Total Duration (us)"}], "rows": [["aten::cudnn_convolution", 424, 321646, 321646, 1903545, 1980305], ["aten::cudnn_convolution_backward_weight", 424, 315723, 315723, 567642, 630944], ["aten::cudnn_convolution_backward_input", 416, 305303, 305303, 409044, 472731], ["aten::cudnn_batch_norm_backward", 424, 78220, 78220, 156263, 232602], ["aten::cudnn_batch_norm", 424, 44717, 44717, 289122, 396690], ["aten::threshold_backward", 392, 36540, 36540, 53379, 70404], ["aten::add_", 3670, 33900, 33900, 356466, 356466], ["aten::threshold_", 392, 23847, 23847, 23790, 23790], ["aten::copy_", 3166, 16018, 16018, 4144866, 4144866], ["aten::max_pool2d_with_indices_backward", 8, 5566, 6851, 2267, 5145], ["aten::add", 1712, 4669, 4669, 236741, 308876], ["aten::fill_", 1423, 3005, 3005, 63115, 63115], ["aten::mul_", 1127, 2723, 2723, 117846, 117846], ["aten::max_pool2d_with_indices", 8, 1788, 1788, 3373, 4772], ["aten::_cat", 24, 392, 392, 2875436, 2886103], ["aten::mm", 16, 386, 386, 3821, 4810], ["aten::mean", 8, 345, 345, 5157, 5519], ["aten::addmm", 8, 275, 275, 483411, 486833], ["aten::div", 264, 234, 234, 953106, 994616], ["aten::_log_softmax_backward_data", 8, 83, 83, 1210, 2171], ["aten::_log_softmax", 8, 81, 81, 1877, 2731], ["aten::nll_loss_forward", 8, 33, 33, 1977, 1977], ["aten::nll_loss_backward", 8, 24, 24, 1398, 1398], ["aten::_local_scalar_dense", 2961, 12, 12, 77280, 77280], ["aten::empty", 13220, 0, 0, 434482, 434482], ["aten::random_", 513, 0, 0, 16674, 16674], ["aten::is_floating_point", 1229, 0, 0, 14562, 14562], ["aten::item", 2961, 0, 12, 67531, 144811], ["aten::zero_", 1159, 0, 2997, 77800, 135697], ["aten::zeros", 24, 0, 0, 1712, 3369], ["aten::uniform_", 964, 0, 0, 57045, 57045], ["aten::to", 1930, 0, 13566, 92032, 2062694], ["detach_", 362, 0, 0, 4729, 4729], ["aten::detach_", 362, 0, 0, 6831, 11560], ["aten::log", 354, 0, 0, 34721, 41501], ["aten::as_strided", 2973, 0, 0, 55144, 55144], ["aten::select", 708, 0, 0, 68648, 79129], ["aten::resize_", 3706, 0, 0, 55010, 55010], ["aten::exp", 708, 0, 0, 52551, 91835], ["aten::randint", 512, 0, 0, 33156, 61402], ["aten::rand", 256, 0, 0, 18218, 33177], ["aten::empty_strided", 1626, 0, 0, 58780, 58780], ["aten::lt", 512, 0, 0, 54667, 177847], ["aten::is_nonzero", 512, 0, 0, 12855, 40116], ["aten::set_", 272, 0, 0, 19301, 19301], ["aten::view", 4176, 0, 0, 228853, 228853], ["aten::permute", 256, 0, 0, 23020, 27392], ["aten::empty_like", 712, 0, 0, 35295, 62700], ["aten::contiguous", 7920, 0, 0, 114051, 1164958], ["aten::clone", 417, 0, 359, 58309, 996033], ["aten::eq", 512, 0, 0, 55564, 190521], ["aten::any", 256, 0, 0, 43695, 64036], ["aten::sub_", 256, 0, 0, 796119, 796119], ["aten::div_", 256, 0, 0, 966065, 966065], ["aten::unsqueeze", 256, 0, 0, 9977, 13209], ["aten::slice", 1280, 0, 0, 103229, 123223], ["aten::narrow", 1280, 0, 0, 36358, 159581], ["aten::stride", 6528, 0, 0, 46659, 46659], ["aten::cat", 24, 0, 392, 3294, 2889397], ["aten::stack", 8, 0, 0, 4630, 804276], ["aten::is_pinned", 16, 0, 0, 1134, 1134], ["aten::pin_memory", 16, 0, 0, 19532, 120157], ["nccl:broadcast", 18, 0, 0, 547, 547], ["aten::_convolution", 424, 0, 321646, 43809, 2030410], ["aten::convolution", 424, 0, 321646, 20327, 2050737], ["aten::conv2d", 424, 0, 321646, 23026, 2073763], ["aten::_batch_norm_impl_index", 424, 0, 44717, 65055, 485949], ["aten::batch_norm", 424, 0, 44717, 22006, 507955], ["aten::relu_", 392, 0, 23847, 50652, 74442], ["aten::max_pool2d", 8, 0, 1788, 488, 5260], ["aten::adaptive_avg_pool2d", 8, 0, 345, 413, 5932], ["aten::reshape", 16, 0, 0, 538, 2001], ["aten::flatten", 8, 0, 0, 427, 1637], ["aten::transpose", 40, 0, 0, 1447, 2104], ["aten::t", 40, 0, 0, 2674, 4778], ["aten::expand", 16, 0, 0, 1121, 1408], ["aten::log_softmax", 8, 0, 81, 440, 3171], ["aten::nll_loss", 8, 0, 33, 450, 2427], ["aten::ones_like", 8, 0, 8, 572, 1912], ["detach", 161, 0, 0, 2936, 2936], ["aten::detach", 161, 0, 0, 4522, 7458], ["NllLossBackward", 8, 0, 24, 687, 2085], ["LogSoftmaxBackward", 8, 0, 83, 518, 2689], ["aten::conj", 16, 0, 0, 317, 317], ["AddmmBackward", 8, 0, 386, 1410, 9196], ["torch::autograd::AccumulateGrad", 1288, 0, 7789, 59896, 199603], ["TBackward", 8, 0, 0, 288, 1120], ["ViewBackward", 8, 0, 0, 324, 1115], ["MeanBackward1", 8, 0, 234, 703, 3646], ["ReluBackward1", 392, 0, 36540, 24309, 94713], ["AddBackward0", 128, 0, 0, 3341, 3341], ["CudnnBatchNormBackward", 424, 0, 78220, 48285, 288172], ["aten::cudnn_convolution_backward", 424, 0, 621026, 73946, 1182696], ["CudnnConvolutionBackward", 424, 0, 621026, 36014, 1218710], ["aten::zeros_like", 8, 0, 1285, 382, 1975], ["aten::resize_as_", 8, 0, 0, 284, 359], ["MaxPool2DWithIndicesBackward", 8, 0, 6851, 655, 5800]]}}, "operation_pie_by_name_input": {"device_total_time": {"title": "Device Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["CudnnConvolutionBackward", 91559], ["CudnnConvolutionBackward", 79457], ["CudnnConvolutionBackward", 77576], ["CudnnConvolutionBackward", 71511], ["CudnnConvolutionBackward", 67147], ["CudnnConvolutionBackward", 57174], ["CudnnConvolutionBackward", 52822], ["aten::cudnn_convolution_backward", 47750], ["aten::cudnn_convolution_backward", 42389], ["aten::cudnn_convolution_backward", 39429], ["aten::cudnn_convolution_backward", 36726], ["CudnnConvolutionBackward", 36726], ["aten::cudnn_convolution_backward", 35776], ["aten::cudnn_convolution_backward", 32574], ["aten::cudnn_convolution_backward_weight", 31905], ["aten::cudnn_convolution_backward", 31808], ["aten::cudnn_convolution_backward", 29911], ["aten::cudnn_convolution_backward", 28851], ["CudnnConvolutionBackward", 28851], ["aten::cudnn_convolution_backward_input", 28843], ["aten::cudnn_convolution_backward", 28497], ["aten::cudnn_convolution_backward_input", 28166], ["aten::cudnn_convolution_backward_input", 26148], ["aten::cudnn_convolution_backward_input", 25852], ["aten::cudnn_convolution_backward", 24818], ["aten::cudnn_convolution_backward", 24261], ["aten::cudnn_convolution_backward", 24231], ["aten::cudnn_convolution_backward", 23922], ["aten::cudnn_convolution_backward", 23731], ["CudnnConvolutionBackward", 23731], ["aten::cudnn_convolution", 23416], ["aten::_convolution", 23416], ["aten::convolution", 23416], ["aten::conv2d", 23416], ["aten::cudnn_convolution_backward", 23358], ["aten::cudnn_convolution_backward_weight", 21973], ["aten::cudnn_convolution_backward_weight", 21898], ["aten::cudnn_convolution_backward", 21787], ["CudnnConvolutionBackward", 21787], ["aten::cudnn_convolution_backward", 21398], ["aten::cudnn_convolution_backward", 21014], ["aten::cudnn_convolution_backward_input", 20781], ["aten::cudnn_batch_norm_backward", 20675], ["CudnnBatchNormBackward", 20675], ["aten::cudnn_convolution", 20489], ["aten::_convolution", 20489], ["aten::convolution", 20489], ["aten::conv2d", 20489], ["aten::cudnn_convolution", 20407], ["aten::_convolution", 20407], ["aten::convolution", 20407], ["aten::conv2d", 20407], ["aten::cudnn_convolution_backward_input", 20251], ["aten::cudnn_convolution_backward", 19556], ["aten::cudnn_convolution_backward", 19397], ["aten::cudnn_convolution_backward_weight", 18648], ["aten::cudnn_convolution_backward_weight", 18623], ["aten::cudnn_convolution", 18225], ["aten::_convolution", 18225], ["aten::convolution", 18225], ["aten::conv2d", 18225], ["aten::cudnn_convolution", 17626], ["aten::_convolution", 17626], ["aten::convolution", 17626], ["aten::conv2d", 17626], ["aten::cudnn_convolution", 17078], ["aten::_convolution", 17078], ["aten::convolution", 17078], ["aten::conv2d", 17078], ["aten::cudnn_convolution_backward_weight", 16649], ["aten::cudnn_convolution", 15748], ["aten::_convolution", 15748], ["aten::convolution", 15748], ["aten::conv2d", 15748], ["aten::cudnn_convolution_backward_weight", 15740], ["aten::cudnn_convolution", 15713], ["aten::_convolution", 15713], ["aten::convolution", 15713], ["aten::conv2d", 15713], ["aten::cudnn_convolution_backward_input", 15630], ["aten::cudnn_convolution_backward_weight", 15525], ["aten::cudnn_convolution_backward_weight", 15387], ["aten::cudnn_convolution", 15283], ["aten::_convolution", 15283], ["aten::convolution", 15283], ["aten::conv2d", 15283], ["aten::cudnn_convolution_backward_input", 15159], ["aten::cudnn_convolution", 15106], ["aten::_convolution", 15106], ["aten::convolution", 15106], ["aten::conv2d", 15106], ["aten::cudnn_convolution", 15055], ["aten::_convolution", 15055], ["aten::convolution", 15055], ["aten::conv2d", 15055], ["aten::cudnn_convolution_backward_input", 14912], ["aten::cudnn_convolution", 14848], ["aten::_convolution", 14848], ["aten::convolution", 14848], ["aten::conv2d", 14848], ["aten::cudnn_convolution", 14809], ["aten::_convolution", 14809], ["aten::convolution", 14809], ["aten::conv2d", 14809], ["aten::cudnn_convolution_backward_input", 14753], ["aten::copy_", 13541], ["aten::to", 13541], ["aten::cudnn_convolution_backward_input", 13464], ["aten::cudnn_convolution", 13429], ["aten::_convolution", 13429], ["aten::convolution", 13429], ["aten::conv2d", 13429], ["aten::cudnn_convolution_backward_weight", 13272], ["aten::cudnn_batch_norm_backward", 13249], ["CudnnBatchNormBackward", 13249], ["aten::cudnn_convolution_backward_input", 13000], ["aten::cudnn_convolution_backward_weight", 12927], ["aten::cudnn_convolution_backward_weight", 12867], ["aten::cudnn_batch_norm", 12813], ["aten::_batch_norm_impl_index", 12813], ["aten::batch_norm", 12813], ["aten::cudnn_convolution", 12689], ["aten::_convolution", 12689], ["aten::convolution", 12689], ["aten::conv2d", 12689], ["aten::cudnn_convolution_backward_weight", 12685], ["aten::cudnn_convolution_backward", 12685], ["CudnnConvolutionBackward", 12685], ["aten::cudnn_convolution", 11815], ["aten::_convolution", 11815], ["aten::convolution", 11815], ["aten::conv2d", 11815], ["aten::cudnn_convolution_backward_weight", 11723], ["aten::cudnn_convolution_backward_input", 11684], ["aten::cudnn_convolution_backward_input", 11288], ["aten::cudnn_convolution", 11264], ["aten::_convolution", 11264], ["aten::convolution", 11264], ["aten::conv2d", 11264], ["aten::cudnn_convolution_backward_input", 11224], ["aten::cudnn_convolution_backward_weight", 10731], ["aten::cudnn_convolution_backward_input", 10705], ["aten::cudnn_convolution_backward_input", 10650], ["aten::cudnn_convolution_backward_weight", 10583], ["aten::cudnn_convolution", 10361], ["aten::_convolution", 10361], ["aten::convolution", 10361], ["aten::conv2d", 10361], ["aten::cudnn_convolution_backward_weight", 10174], ["aten::cudnn_batch_norm_backward", 10163], ["CudnnBatchNormBackward", 10163], ["aten::cudnn_batch_norm_backward", 10151], ["CudnnBatchNormBackward", 10151], ["aten::cudnn_convolution_backward_input", 10064], ["aten::cudnn_convolution_backward_weight", 9653], ["aten::cudnn_convolution", 9524], ["aten::_convolution", 9524], ["aten::convolution", 9524], ["aten::conv2d", 9524], ["aten::cudnn_convolution_backward_weight", 9330], ["aten::cudnn_convolution", 9055], ["aten::_convolution", 9055], ["aten::convolution", 9055], ["aten::conv2d", 9055], ["aten::cudnn_convolution", 9034], ["aten::_convolution", 9034], ["aten::convolution", 9034], ["aten::conv2d", 9034], ["aten::threshold_backward", 8808], ["ReluBackward1", 8808], ["aten::add_", 8748], ["aten::cudnn_convolution_backward_weight", 8692], ["aten::cudnn_convolution_backward_weight", 8514], ["aten::cudnn_batch_norm", 8307], ["aten::_batch_norm_impl_index", 8307], ["aten::batch_norm", 8307], ["aten::cudnn_convolution_backward_weight", 8224], ["aten::cudnn_convolution", 7551], ["aten::_convolution", 7551], ["aten::convolution", 7551], ["aten::conv2d", 7551], ["aten::cudnn_convolution_backward", 7157], ["aten::max_pool2d_with_indices_backward", 6851], ["MaxPool2DWithIndicesBackward", 6851], ["aten::cudnn_batch_norm_backward", 6523], ["CudnnBatchNormBackward", 6523], ["aten::threshold_", 6017], ["aten::relu_", 6017], ["aten::threshold_backward", 5947], ["ReluBackward1", 5947], ["aten::add_", 5907], ["aten::cudnn_batch_norm", 5318], ["aten::_batch_norm_impl_index", 5318], ["aten::batch_norm", 5318], ["aten::cudnn_batch_norm_backward", 5143], ["CudnnBatchNormBackward", 5143], ["aten::cudnn_batch_norm", 4745], ["aten::_batch_norm_impl_index", 4745], ["aten::batch_norm", 4745], ["aten::threshold_backward", 4618], ["ReluBackward1", 4618], ["aten::threshold_backward", 4472], ["ReluBackward1", 4472], ["aten::add_", 4416], ["aten::cudnn_batch_norm_backward", 4201], ["CudnnBatchNormBackward", 4201], ["aten::threshold_", 4061], ["aten::relu_", 4061], ["aten::cudnn_batch_norm", 3412], ["aten::_batch_norm_impl_index", 3412], ["aten::batch_norm", 3412], ["aten::cudnn_convolution", 3121], ["aten::_convolution", 3121], ["aten::convolution", 3121], ["aten::conv2d", 3121], ["aten::threshold_", 3034], ["aten::relu_", 3034], ["aten::threshold_", 3031], ["aten::relu_", 3031], ["aten::threshold_backward", 2963], ["ReluBackward1", 2963], ["aten::cudnn_batch_norm", 2922], ["aten::_batch_norm_impl_index", 2922], ["aten::batch_norm", 2922], ["aten::cudnn_batch_norm_backward", 2764], ["CudnnBatchNormBackward", 2764], ["aten::threshold_backward", 2753], ["ReluBackward1", 2753], ["aten::cudnn_convolution_backward_input", 2729], ["aten::threshold_backward", 2461], ["ReluBackward1", 2461], ["aten::add_", 2357], ["aten::cudnn_batch_norm_backward", 2351], ["CudnnBatchNormBackward", 2351], ["aten::cudnn_batch_norm", 1995], ["aten::_batch_norm_impl_index", 1995], ["aten::batch_norm", 1995], ["aten::threshold_", 1993], ["aten::relu_", 1993], ["aten::threshold_", 1852], ["aten::relu_", 1852], ["aten::cudnn_batch_norm", 1797], ["aten::_batch_norm_impl_index", 1797], ["aten::batch_norm", 1797], ["aten::max_pool2d_with_indices", 1788], ["aten::max_pool2d", 1788], ["aten::cudnn_batch_norm", 1580], ["aten::_batch_norm_impl_index", 1580], ["aten::batch_norm", 1580], ["aten::add_", 1496], ["aten::threshold_backward", 1478], ["ReluBackward1", 1478], ["aten::cudnn_batch_norm_backward", 1329], ["CudnnBatchNormBackward", 1329], ["aten::fill_", 1285], ["aten::zero_", 1285], ["aten::zeros_like", 1285], ["aten::threshold_backward", 1213], ["ReluBackward1", 1213], ["aten::add_", 1136], ["torch::autograd::AccumulateGrad", 1105], ["aten::threshold_", 1037], ["aten::relu_", 1037], ["aten::threshold_", 1005], ["aten::relu_", 1005], ["aten::add_", 977], ["aten::add_", 925], ["aten::add_", 923], ["aten::cudnn_batch_norm_backward", 918], ["CudnnBatchNormBackward", 918], ["torch::autograd::AccumulateGrad", 878], ["aten::add", 840], ["aten::cudnn_batch_norm", 826], ["aten::_batch_norm_impl_index", 826], ["aten::batch_norm", 826], ["aten::threshold_", 797], ["aten::relu_", 797], ["aten::threshold_backward", 768], ["ReluBackward1", 768], ["aten::cudnn_batch_norm_backward", 753], ["CudnnBatchNormBackward", 753], ["aten::add_", 733], ["aten::add_", 705], ["aten::add_", 675], ["torch::autograd::AccumulateGrad", 669], ["aten::threshold_backward", 652], ["ReluBackward1", 652], ["aten::add_", 649], ["aten::add_", 645], ["aten::cudnn_batch_norm", 631], ["aten::_batch_norm_impl_index", 631], ["aten::batch_norm", 631], ["aten::add_", 628], ["torch::autograd::AccumulateGrad", 515], ["aten::threshold_", 505], ["aten::relu_", 505], ["aten::mul_", 500], ["aten::add_", 498], ["torch::autograd::AccumulateGrad", 487], ["torch::autograd::AccumulateGrad", 482], ["aten::add", 480], ["aten::add_", 478], ["aten::add", 454], ["torch::autograd::AccumulateGrad", 439], ["aten::copy_", 428], ["aten::copy_", 424], ["aten::threshold_backward", 407], ["ReluBackward1", 407], ["torch::autograd::AccumulateGrad", 397], ["aten::_cat", 392], ["aten::cat", 392], ["aten::add", 386], ["AddmmBackward", 386], ["aten::cudnn_batch_norm", 371], ["aten::_batch_norm_impl_index", 371], ["aten::batch_norm", 371], ["aten::add_", 365], ["aten::mean", 345], ["aten::adaptive_avg_pool2d", 345], ["torch::autograd::AccumulateGrad", 343], ["torch::autograd::AccumulateGrad", 329], ["aten::fill_", 315], ["aten::zero_", 315], ["torch::autograd::AccumulateGrad", 306], ["aten::add_", 290], ["aten::addmm", 275], ["aten::threshold_", 273], ["aten::relu_", 273], ["aten::copy_", 268], ["torch::autograd::AccumulateGrad", 262], ["aten::mul_", 259], ["aten::add", 256], ["aten::add", 256], ["torch::autograd::AccumulateGrad", 255], ["aten::add", 248], ["aten::add", 243], ["aten::threshold_", 242], ["aten::relu_", 242], ["aten::add", 237], ["torch::autograd::AccumulateGrad", 237], ["aten::mm", 234], ["aten::div", 234], ["MeanBackward1", 234], ["aten::mul_", 231], ["aten::mul_", 224], ["aten::copy_", 205], ["aten::copy_", 198], ["aten::add_", 198], ["aten::add_", 197], ["torch::autograd::AccumulateGrad", 181], ["aten::add", 176], ["aten::add", 174], ["aten::copy_", 174], ["aten::fill_", 168], ["aten::zero_", 168], ["aten::add_", 156], ["aten::mul_", 154], ["aten::mul_", 152], ["aten::mm", 152], ["aten::add_", 151], ["aten::mul_", 149], ["aten::copy_", 148], ["aten::fill_", 147], ["aten::zero_", 147], ["aten::mul_", 147], ["torch::autograd::AccumulateGrad", 146], ["torch::autograd::AccumulateGrad", 142], ["aten::add_", 140], ["aten::mul_", 133], ["aten::add", 128], ["aten::add_", 128], ["aten::add", 112], ["aten::add", 112], ["aten::mul_", 112], ["torch::autograd::AccumulateGrad", 112], ["aten::mul_", 108], ["aten::fill_", 106], ["aten::zero_", 106], ["aten::copy_", 98], ["aten::fill_", 98], ["aten::zero_", 98], ["aten::mul_", 98], ["aten::mul_", 98], ["torch::autograd::AccumulateGrad", 98], ["torch::autograd::AccumulateGrad", 95], ["aten::fill_", 92], ["aten::zero_", 92], ["aten::fill_", 91], ["aten::zero_", 91], ["aten::fill_", 91], ["aten::zero_", 91], ["aten::add", 88], ["aten::fill_", 84], ["aten::zero_", 84], ["aten::fill_", 83], ["aten::zero_", 83], ["aten::_log_softmax_backward_data", 83], ["LogSoftmaxBackward", 83], ["aten::_log_softmax", 81], ["aten::log_softmax", 81], ["aten::copy_", 78], ["aten::clone", 78], ["aten::add_", 75], ["aten::add_", 74], ["aten::add_", 73], ["aten::add", 73], ["aten::add", 72], ["aten::fill_", 70], ["aten::zero_", 70], ["aten::copy_", 68], ["aten::add", 66], ["torch::autograd::AccumulateGrad", 66], ["aten::add", 64], ["aten::fill_", 63], ["aten::zero_", 63], ["aten::copy_", 59], ["aten::copy_", 57], ["aten::mul_", 56], ["aten::mul_", 56], ["aten::fill_", 50], ["aten::zero_", 50], ["aten::add_", 48], ["aten::add", 48], ["aten::copy_", 48], ["torch::autograd::AccumulateGrad", 48], ["torch::autograd::AccumulateGrad", 47], ["aten::copy_", 46], ["aten::copy_", 46], ["aten::add_", 45], ["torch::autograd::AccumulateGrad", 45], ["aten::add_", 42], ["aten::mul_", 39], ["aten::mul_", 36], ["torch::autograd::AccumulateGrad", 35], ["aten::add", 34], ["torch::autograd::AccumulateGrad", 34], ["aten::nll_loss_forward", 33], ["aten::nll_loss", 33], ["aten::clone", 32], ["aten::clone", 30], ["aten::fill_", 28], ["aten::zero_", 28], ["aten::fill_", 28], ["aten::zero_", 28], ["aten::fill_", 28], ["aten::zero_", 28], ["aten::fill_", 28], ["aten::zero_", 28], ["aten::fill_", 28], ["aten::zero_", 28], ["aten::mul_", 28], ["aten::mul_", 28], ["torch::autograd::AccumulateGrad", 28], ["aten::add", 26], ["aten::copy_", 25], ["aten::to", 25], ["aten::add", 24], ["aten::add", 24], ["aten::nll_loss_backward", 24], ["NllLossBackward", 24], ["aten::clone", 23], ["aten::clone", 23], ["aten::clone", 22], ["aten::add_", 22], ["aten::fill_", 21], ["aten::zero_", 21], ["aten::fill_", 21], ["aten::zero_", 21], ["aten::mul_", 21], ["aten::mul_", 21], ["aten::clone", 20], ["aten::copy_", 19], ["aten::clone", 19], ["aten::fill_", 19], ["aten::zero_", 19], ["aten::add", 16], ["aten::clone", 16], ["aten::mul_", 16], ["aten::mul_", 15], ["aten::clone", 14], ["aten::clone", 14], ["aten::fill_", 14], ["aten::zero_", 14], ["aten::mul_", 14], ["aten::clone", 13], ["aten::_local_scalar_dense", 12], ["aten::item", 12], ["aten::copy_", 12], ["aten::copy_", 11], ["aten::copy_", 10], ["aten::clone", 10], ["aten::copy_", 9], ["aten::copy_", 9], ["aten::fill_", 8], ["aten::ones_like", 8], ["aten::add", 8], ["aten::add", 8], ["aten::add", 8], ["aten::clone", 8], ["aten::clone", 8], ["aten::add", 8], ["torch::autograd::AccumulateGrad", 8], ["aten::fill_", 7], ["aten::zero_", 7], ["aten::fill_", 7], ["aten::zero_", 7], ["aten::fill_", 7], ["aten::zero_", 7], ["aten::fill_", 7], ["aten::zero_", 7], ["aten::fill_", 7], ["aten::zero_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::copy_", 6], ["aten::copy_", 5], ["aten::copy_", 5], ["aten::copy_", 5], ["aten::clone", 4], ["aten::clone", 4], ["aten::fill_", 4], ["aten::zero_", 4], ["aten::copy_", 3], ["aten::clone", 3], ["aten::copy_", 3], ["aten::clone", 3], ["aten::clone", 3], ["aten::clone", 3], ["aten::copy_", 3], ["aten::copy_", 3], ["aten::copy_", 2], ["aten::clone", 2], ["aten::clone", 2], ["aten::copy_", 2], ["aten::clone", 1], ["aten::clone", 1], ["aten::clone", 1], ["aten::clone", 1], ["aten::clone", 1]]}, "device_self_time": {"title": "Device Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward_weight", 31905], ["aten::cudnn_convolution_backward_input", 28843], ["aten::cudnn_convolution_backward_input", 28166], ["aten::cudnn_convolution_backward_input", 26148], ["aten::cudnn_convolution_backward_input", 25852], ["aten::cudnn_convolution", 23416], ["aten::cudnn_convolution_backward_weight", 21973], ["aten::cudnn_convolution_backward_weight", 21898], ["aten::cudnn_convolution_backward_input", 20781], ["aten::cudnn_batch_norm_backward", 20675], ["aten::cudnn_convolution", 20489], ["aten::cudnn_convolution", 20407], ["aten::cudnn_convolution_backward_input", 20251], ["aten::cudnn_convolution_backward_weight", 18648], ["aten::cudnn_convolution_backward_weight", 18623], ["aten::cudnn_convolution", 18225], ["aten::cudnn_convolution", 17626], ["aten::cudnn_convolution", 17078], ["aten::cudnn_convolution_backward_weight", 16649], ["aten::cudnn_convolution", 15748], ["aten::cudnn_convolution_backward_weight", 15740], ["aten::cudnn_convolution", 15713], ["aten::cudnn_convolution_backward_input", 15630], ["aten::cudnn_convolution_backward_weight", 15525], ["aten::cudnn_convolution_backward_weight", 15387], ["aten::cudnn_convolution", 15283], ["aten::cudnn_convolution_backward_input", 15159], ["aten::cudnn_convolution", 15106], ["aten::cudnn_convolution", 15055], ["aten::cudnn_convolution_backward_input", 14912], ["aten::cudnn_convolution", 14848], ["aten::cudnn_convolution", 14809], ["aten::cudnn_convolution_backward_input", 14753], ["aten::copy_", 13541], ["aten::cudnn_convolution_backward_input", 13464], ["aten::cudnn_convolution", 13429], ["aten::cudnn_convolution_backward_weight", 13272], ["aten::cudnn_batch_norm_backward", 13249], ["aten::cudnn_convolution_backward_input", 13000], ["aten::cudnn_convolution_backward_weight", 12927], ["aten::cudnn_convolution_backward_weight", 12867], ["aten::cudnn_batch_norm", 12813], ["aten::cudnn_convolution", 12689], ["aten::cudnn_convolution_backward_weight", 12685], ["aten::cudnn_convolution", 11815], ["aten::cudnn_convolution_backward_weight", 11723], ["aten::cudnn_convolution_backward_input", 11684], ["aten::cudnn_convolution_backward_input", 11288], ["aten::cudnn_convolution", 11264], ["aten::cudnn_convolution_backward_input", 11224], ["aten::cudnn_convolution_backward_weight", 10731], ["aten::cudnn_convolution_backward_input", 10705], ["aten::cudnn_convolution_backward_input", 10650], ["aten::cudnn_convolution_backward_weight", 10583], ["aten::cudnn_convolution", 10361], ["aten::cudnn_convolution_backward_weight", 10174], ["aten::cudnn_batch_norm_backward", 10163], ["aten::cudnn_batch_norm_backward", 10151], ["aten::cudnn_convolution_backward_input", 10064], ["aten::cudnn_convolution_backward_weight", 9653], ["aten::cudnn_convolution", 9524], ["aten::cudnn_convolution_backward_weight", 9330], ["aten::cudnn_convolution", 9055], ["aten::cudnn_convolution", 9034], ["aten::threshold_backward", 8808], ["aten::add_", 8748], ["aten::cudnn_convolution_backward_weight", 8692], ["aten::cudnn_convolution_backward_weight", 8514], ["aten::cudnn_batch_norm", 8307], ["aten::cudnn_convolution_backward_weight", 8224], ["aten::cudnn_convolution", 7551], ["aten::cudnn_batch_norm_backward", 6523], ["aten::threshold_", 6017], ["aten::threshold_backward", 5947], ["aten::add_", 5907], ["aten::max_pool2d_with_indices_backward", 5566], ["aten::cudnn_batch_norm", 5318], ["aten::cudnn_batch_norm_backward", 5143], ["aten::cudnn_batch_norm", 4745], ["aten::threshold_backward", 4618], ["aten::threshold_backward", 4472], ["aten::add_", 4416], ["aten::cudnn_batch_norm_backward", 4201], ["aten::threshold_", 4061], ["aten::cudnn_batch_norm", 3412], ["aten::cudnn_convolution", 3121], ["aten::threshold_", 3034], ["aten::threshold_", 3031], ["aten::threshold_backward", 2963], ["aten::cudnn_batch_norm", 2922], ["aten::cudnn_batch_norm_backward", 2764], ["aten::threshold_backward", 2753], ["aten::cudnn_convolution_backward_input", 2729], ["aten::threshold_backward", 2461], ["aten::add_", 2357], ["aten::cudnn_batch_norm_backward", 2351], ["aten::cudnn_batch_norm", 1995], ["aten::threshold_", 1993], ["aten::threshold_", 1852], ["aten::cudnn_batch_norm", 1797], ["aten::max_pool2d_with_indices", 1788], ["aten::cudnn_batch_norm", 1580], ["aten::add_", 1496], ["aten::threshold_backward", 1478], ["aten::cudnn_batch_norm_backward", 1329], ["aten::fill_", 1285], ["aten::threshold_backward", 1213], ["aten::add_", 1136], ["aten::threshold_", 1037], ["aten::threshold_", 1005], ["aten::add_", 977], ["aten::add_", 925], ["aten::add_", 923], ["aten::cudnn_batch_norm_backward", 918], ["aten::add", 840], ["aten::cudnn_batch_norm", 826], ["aten::threshold_", 797], ["aten::threshold_backward", 768], ["aten::cudnn_batch_norm_backward", 753], ["aten::add_", 733], ["aten::add_", 705], ["aten::add_", 675], ["aten::threshold_backward", 652], ["aten::add_", 649], ["aten::add_", 645], ["aten::cudnn_batch_norm", 631], ["aten::add_", 628], ["aten::threshold_", 505], ["aten::mul_", 500], ["aten::add_", 498], ["aten::add", 480], ["aten::add_", 478], ["aten::add", 454], ["aten::copy_", 428], ["aten::copy_", 424], ["aten::threshold_backward", 407], ["aten::_cat", 392], ["aten::add", 386], ["aten::cudnn_batch_norm", 371], ["aten::add_", 365], ["aten::mean", 345], ["aten::fill_", 315], ["aten::add_", 290], ["aten::addmm", 275], ["aten::threshold_", 273], ["aten::copy_", 268], ["aten::mul_", 259], ["aten::add", 256], ["aten::add", 256], ["aten::add", 248], ["aten::add", 243], ["aten::threshold_", 242], ["aten::add", 237], ["aten::mm", 234], ["aten::div", 234], ["aten::mul_", 231], ["aten::mul_", 224], ["aten::copy_", 205], ["aten::copy_", 198], ["aten::add_", 198], ["aten::add_", 197], ["aten::add", 176], ["aten::add", 174], ["aten::copy_", 174], ["aten::fill_", 168], ["aten::add_", 156], ["aten::mul_", 154], ["aten::mul_", 152], ["aten::mm", 152], ["aten::add_", 151], ["aten::mul_", 149], ["aten::copy_", 148], ["aten::fill_", 147], ["aten::mul_", 147], ["aten::add_", 140], ["aten::mul_", 133], ["aten::add", 128], ["aten::add_", 128], ["aten::add", 112], ["aten::add", 112], ["aten::mul_", 112], ["aten::mul_", 108], ["aten::fill_", 106], ["aten::copy_", 98], ["aten::fill_", 98], ["aten::mul_", 98], ["aten::mul_", 98], ["aten::fill_", 92], ["aten::fill_", 91], ["aten::fill_", 91], ["aten::add", 88], ["aten::fill_", 84], ["aten::fill_", 83], ["aten::_log_softmax_backward_data", 83], ["aten::_log_softmax", 81], ["aten::copy_", 78], ["aten::add_", 75], ["aten::add_", 74], ["aten::add_", 73], ["aten::add", 73], ["aten::add", 72], ["aten::fill_", 70], ["aten::copy_", 68], ["aten::add", 66], ["aten::add", 64], ["aten::fill_", 63], ["aten::copy_", 59], ["aten::copy_", 57], ["aten::mul_", 56], ["aten::mul_", 56], ["aten::fill_", 50], ["aten::add_", 48], ["aten::add", 48], ["aten::copy_", 48], ["aten::copy_", 46], ["aten::copy_", 46], ["aten::add_", 45], ["aten::add_", 42], ["aten::mul_", 39], ["aten::mul_", 36], ["aten::add", 34], ["aten::nll_loss_forward", 33], ["aten::fill_", 28], ["aten::fill_", 28], ["aten::fill_", 28], ["aten::fill_", 28], ["aten::fill_", 28], ["aten::mul_", 28], ["aten::mul_", 28], ["aten::add", 26], ["aten::copy_", 25], ["aten::add", 24], ["aten::add", 24], ["aten::nll_loss_backward", 24], ["aten::add_", 22], ["aten::fill_", 21], ["aten::fill_", 21], ["aten::mul_", 21], ["aten::mul_", 21], ["aten::copy_", 19], ["aten::fill_", 19], ["aten::add", 16], ["aten::mul_", 16], ["aten::mul_", 15], ["aten::fill_", 14], ["aten::mul_", 14], ["aten::_local_scalar_dense", 12], ["aten::copy_", 12], ["aten::copy_", 11], ["aten::copy_", 10], ["aten::copy_", 9], ["aten::copy_", 9], ["aten::fill_", 8], ["aten::add", 8], ["aten::add", 8], ["aten::add", 8], ["aten::add", 8], ["aten::fill_", 7], ["aten::fill_", 7], ["aten::fill_", 7], ["aten::fill_", 7], ["aten::fill_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::mul_", 7], ["aten::copy_", 6], ["aten::copy_", 5], ["aten::copy_", 5], ["aten::copy_", 5], ["aten::fill_", 4], ["aten::copy_", 3], ["aten::copy_", 3], ["aten::copy_", 3], ["aten::copy_", 3], ["aten::copy_", 2], ["aten::copy_", 2]]}, "host_total_time": {"title": "Host Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 3853109], ["aten::cat", 2889397], ["aten::_cat", 2886103], ["aten::to", 1939754], ["aten::conv2d", 1478371], ["aten::convolution", 1477908], ["aten::_convolution", 1477506], ["aten::cudnn_convolution", 1476455], ["aten::contiguous", 1064623], ["aten::div", 992662], ["aten::div_", 966065], ["aten::clone", 948948], ["aten::stack", 804276], ["aten::sub_", 796119], ["aten::addmm", 486833], ["aten::empty", 434482], ["CudnnConvolutionBackward", 297745], ["aten::cudnn_convolution_backward", 211255], ["CudnnConvolutionBackward", 201046], ["aten::cudnn_convolution_backward_weight", 183429], ["CudnnConvolutionBackward", 154205], ["aten::cudnn_convolution_backward", 124731], ["CudnnConvolutionBackward", 118305], ["aten::pin_memory", 116908], ["CudnnConvolutionBackward", 114023], ["aten::eq", 110976], ["aten::narrow", 109153], ["aten::lt", 105124], ["aten::to", 104270], ["aten::cudnn_convolution_backward_weight", 100237], ["aten::copy_", 98537], ["CudnnConvolutionBackward", 97383], ["aten::batch_norm", 95267], ["aten::_batch_norm_impl_index", 90332], ["aten::slice", 85190], ["aten::cudnn_convolution_backward", 83745], ["aten::batch_norm", 80706], ["aten::_batch_norm_impl_index", 80235], ["aten::add", 80042], ["aten::eq", 79545], ["aten::select", 79129], ["aten::cudnn_batch_norm", 78500], ["aten::item", 76153], ["CudnnConvolutionBackward", 74258], ["aten::lt", 72723], ["aten::cudnn_convolution_backward", 71778], ["aten::copy_", 70639], ["aten::item", 68658], ["aten::cudnn_batch_norm", 67934], ["aten::cudnn_convolution_backward_input", 67841], ["aten::add_", 67611], ["aten::cudnn_convolution_backward", 66043], ["aten::exp", 65339], ["aten::any", 64036], ["aten::randint", 61402], ["aten::cudnn_convolution_backward", 59693], ["aten::cudnn_convolution_backward", 59573], ["CudnnBatchNormBackward", 59325], ["aten::empty_strided", 58780], ["aten::batch_norm", 57448], ["aten::uniform_", 57045], ["CudnnConvolutionBackward", 56146], ["aten::batch_norm", 56031], ["aten::_batch_norm_impl_index", 54654], ["aten::cudnn_convolution_backward", 53501], ["aten::_batch_norm_impl_index", 53230], ["aten::cudnn_convolution_backward", 50100], ["aten::narrow", 49805], ["aten::conv2d", 48686], ["aten::batch_norm", 48489], ["aten::cudnn_batch_norm_backward", 47691], ["aten::conv2d", 46358], ["aten::convolution", 46116], ["aten::_batch_norm_impl_index", 46035], ["aten::add", 45441], ["aten::add_", 45191], ["aten::_local_scalar_dense", 45078], ["aten::conv2d", 44219], ["aten::convolution", 44140], ["aten::cudnn_convolution_backward", 44077], ["aten::_convolution", 43832], ["aten::cudnn_convolution_backward", 43545], ["aten::cudnn_batch_norm", 43519], ["aten::cudnn_convolution_backward", 42792], ["aten::_convolution", 42243], ["aten::cudnn_batch_norm", 42081], ["aten::convolution", 42063], ["aten::log", 41501], ["aten::batch_norm", 40806], ["aten::batch_norm", 40788], ["aten::_convolution", 40117], ["aten::cudnn_convolution_backward_input", 40010], ["aten::_batch_norm_impl_index", 38810], ["aten::_batch_norm_impl_index", 38788], ["aten::view", 38447], ["torch::autograd::AccumulateGrad", 38425], ["aten::conv2d", 38268], ["aten::cudnn_convolution", 38031], ["aten::cudnn_convolution_backward_input", 38027], ["CudnnBatchNormBackward", 37791], ["aten::conv2d", 37719], ["aten::slice", 37638], ["aten::cudnn_convolution", 37532], ["CudnnBatchNormBackward", 37508], ["aten::cudnn_batch_norm", 36549], ["aten::convolution", 36549], ["aten::convolution", 36448], ["aten::conv2d", 36295], ["aten::_convolution", 35292], ["aten::cudnn_convolution", 35091], ["aten::_convolution", 35029], ["aten::cudnn_convolution_backward", 34791], ["aten::view", 34757], ["aten::convolution", 34558], ["aten::cudnn_convolution_backward_input", 34536], ["CudnnConvolutionBackward", 34324], ["aten::add_", 33907], ["aten::cudnn_convolution_backward", 33618], ["aten::conv2d", 33235], ["aten::rand", 33177], ["aten::_convolution", 33015], ["aten::cudnn_convolution_backward_weight", 32729], ["aten::cudnn_convolution", 32524], ["aten::_local_scalar_dense", 32202], ["aten::batch_norm", 32119], ["aten::batch_norm", 31996], ["aten::convolution", 31928], ["aten::conv2d", 31751], ["CudnnBatchNormBackward", 31655], ["aten::conv2d", 31527], ["aten::cudnn_convolution", 31247], ["aten::cudnn_convolution_backward_input", 31161], ["aten::cudnn_batch_norm", 30940], ["aten::convolution", 30840], ["aten::_convolution", 30796], ["aten::copy_", 30698], ["aten::cudnn_batch_norm", 30537], ["aten::cudnn_batch_norm_backward", 30520], ["aten::add", 30504], ["aten::_batch_norm_impl_index", 30421], ["aten::cudnn_batch_norm_backward", 30363], ["aten::_batch_norm_impl_index", 30347], ["aten::convolution", 30223], ["aten::cudnn_convolution_backward", 30197], ["aten::_convolution", 30105], ["aten::cudnn_convolution_backward_input", 30075], ["aten::cudnn_convolution_backward_weight", 29708], ["aten::conv2d", 29455], ["aten::conv2d", 29412], ["aten::cudnn_convolution", 29357], ["CudnnConvolutionBackward", 29356], ["aten::add_", 29177], ["aten::_convolution", 29087], ["aten::add_", 28888], ["CudnnConvolutionBackward", 28881], ["aten::cudnn_convolution_backward_weight", 28829], ["aten::cudnn_convolution_backward", 28704], ["aten::convolution", 28618], ["aten::cudnn_convolution_backward", 28148], ["aten::cudnn_convolution", 28128], ["aten::convolution", 28114], ["aten::cudnn_convolution", 28038], ["aten::_convolution", 27880], ["aten::permute", 27392], ["CudnnBatchNormBackward", 27038], ["aten::_convolution", 26881], ["aten::cudnn_convolution_backward_input", 26806], ["CudnnBatchNormBackward", 26562], ["aten::exp", 26496], ["aten::zero_", 26459], ["aten::cudnn_convolution", 26241], ["aten::cudnn_convolution", 26045], ["aten::view", 26022], ["torch::autograd::AccumulateGrad", 25792], ["aten::cudnn_batch_norm_backward", 25438], ["aten::cudnn_convolution_backward_weight", 25297], ["aten::resize_", 25215], ["aten::view", 25005], ["aten::view", 24509], ["CudnnBatchNormBackward", 24504], ["aten::cudnn_batch_norm", 24117], ["aten::cudnn_batch_norm", 24102], ["aten::cudnn_convolution", 24077], ["aten::cudnn_convolution_backward_weight", 24013], ["aten::cudnn_convolution_backward_input", 23585], ["aten::cudnn_convolution_backward_input", 23232], ["aten::conv2d", 23117], ["aten::mul_", 23038], ["aten::cudnn_convolution_backward_weight", 22876], ["aten::add", 22798], ["CudnnBatchNormBackward", 22709], ["aten::convolution", 22275], ["aten::cudnn_convolution_backward_input", 22064], ["aten::cudnn_convolution_backward", 21714], ["aten::cudnn_convolution_backward_input", 21687], ["aten::_convolution", 21522], ["aten::cudnn_batch_norm_backward", 21490], ["aten::cudnn_batch_norm_backward", 21421], ["aten::cudnn_convolution_backward_input", 21405], ["ReluBackward1", 21323], ["aten::copy_", 21068], ["aten::conv2d", 21006], ["aten::cudnn_convolution_backward", 21002], ["aten::is_nonzero", 20905], ["aten::cudnn_convolution_backward", 20843], ["aten::cudnn_convolution_backward", 20758], ["aten::conv2d", 20682], ["aten::convolution", 20561], ["aten::cudnn_batch_norm_backward", 20298], ["aten::convolution", 20251], ["aten::_convolution", 20179], ["aten::add", 19986], ["aten::_convolution", 19882], ["aten::cudnn_convolution_backward", 19733], ["aten::cudnn_convolution", 19626], ["aten::add", 19580], ["aten::conv2d", 19418], ["aten::cudnn_convolution", 19234], ["aten::is_nonzero", 19211], ["torch::autograd::AccumulateGrad", 19038], ["aten::convolution", 19002], ["aten::cudnn_convolution", 18945], ["aten::conv2d", 18868], ["aten::cudnn_convolution_backward_weight", 18781], ["aten::_convolution", 18559], ["aten::cudnn_batch_norm_backward", 18453], ["aten::convolution", 18435], ["aten::view", 18412], ["aten::set_", 18344], ["aten::zero_", 18108], ["aten::_convolution", 18061], ["aten::cudnn_convolution_backward_weight", 18038], ["aten::conv2d", 17987], ["aten::view", 17872], ["aten::cudnn_convolution", 17630], ["aten::cudnn_convolution_backward_weight", 17525], ["aten::convolution", 17456], ["aten::cudnn_convolution_backward_input", 17362], ["aten::empty_like", 17320], ["aten::cudnn_convolution", 17144], ["aten::_convolution", 17067], ["aten::add_", 17038], ["torch::autograd::AccumulateGrad", 16688], ["aten::relu_", 16611], ["aten::random_", 16595], ["aten::view", 16592], ["aten::view", 16542], ["aten::conv2d", 16346], ["torch::autograd::AccumulateGrad", 16217], ["aten::cudnn_convolution", 16168], ["aten::cudnn_convolution_backward_weight", 15988], ["aten::convolution", 15926], ["aten::threshold_backward", 15908], ["aten::mul_", 15887], ["aten::cudnn_convolution_backward_input", 15845], ["aten::_convolution", 15553], ["aten::copy_", 15147], ["aten::cudnn_convolution_backward_input", 15095], ["aten::cudnn_convolution_backward_input", 14846], ["aten::cudnn_convolution_backward_weight", 14759], ["aten::cudnn_convolution", 14651], ["aten::is_floating_point", 14437], ["aten::cudnn_convolution_backward_weight", 14367], ["aten::conv2d", 14292], ["aten::convolution", 13855], ["aten::copy_", 13732], ["ReluBackward1", 13689], ["aten::conv2d", 13621], ["aten::_convolution", 13486], ["aten::copy_", 13333], ["aten::zero_", 13262], ["aten::unsqueeze", 13209], ["aten::convolution", 13205], ["CudnnConvolutionBackward", 13038], ["aten::_convolution", 12808], ["aten::cudnn_convolution", 12574], ["aten::add_", 12531], ["torch::autograd::AccumulateGrad", 12515], ["aten::add_", 12468], ["aten::cudnn_convolution_backward", 12355], ["aten::as_strided", 12277], ["aten::conv2d", 12206], ["aten::cudnn_convolution_backward_weight", 12085], ["aten::cudnn_convolution_backward_weight", 11984], ["aten::cudnn_convolution", 11894], ["aten::convolution", 11783], ["aten::cudnn_convolution_backward_weight", 11746], ["ReluBackward1", 11693], ["aten::add", 11650], ["aten::zero_", 11648], ["aten::zero_", 11611], ["ReluBackward1", 11483], ["aten::mul_", 11420], ["aten::_convolution", 11394], ["aten::fill_", 11344], ["aten::cudnn_convolution_backward_weight", 11231], ["aten::detach_", 11222], ["aten::conv2d", 10924], ["aten::relu_", 10570], ["aten::cudnn_convolution", 10496], ["aten::convolution", 10483], ["aten::as_strided", 10481], ["aten::add_", 10443], ["aten::cudnn_convolution_backward_input", 10433], ["aten::contiguous", 10404], ["aten::mul_", 10373], ["aten::mul_", 10255], ["aten::threshold_backward", 10244], ["aten::_convolution", 10116], ["aten::contiguous", 9864], ["aten::cudnn_convolution_backward_weight", 9807], ["torch::autograd::AccumulateGrad", 9651], ["aten::cudnn_convolution_backward_input", 9558], ["ReluBackward1", 9538], ["aten::add_", 9488], ["aten::cudnn_convolution_backward_weight", 9431], ["aten::relu_", 9393], ["aten::view", 9232], ["AddmmBackward", 9196], ["aten::cudnn_convolution_backward_weight", 9195], ["aten::cudnn_convolution", 9177], ["aten::cudnn_convolution_backward_input", 9163], ["aten::relu_", 9032], ["aten::cudnn_convolution_backward_weight", 8889], ["aten::add", 8837], ["aten::clone", 8735], ["aten::threshold_backward", 8646], ["aten::empty_like", 8589], ["aten::threshold_backward", 8551], ["aten::add", 8473], ["aten::add_", 8439], ["aten::add_", 8282], ["aten::batch_norm", 8276], ["aten::batch_norm", 8142], ["aten::batch_norm", 7887], ["aten::to", 7877], ["aten::_batch_norm_impl_index", 7869], ["aten::stride", 7810], ["aten::copy_", 7810], ["aten::relu_", 7794], ["aten::_batch_norm_impl_index", 7735], ["aten::fill_", 7673], ["aten::copy_", 7668], ["ReluBackward1", 7630], ["aten::as_strided", 7601], ["aten::_batch_norm_impl_index", 7493], ["aten::add_", 7272], ["aten::add", 7200], ["torch::autograd::AccumulateGrad", 7072], ["aten::threshold_backward", 7057], ["aten::zero_", 7008], ["aten::contiguous", 6755], ["torch::autograd::AccumulateGrad", 6405], ["aten::cudnn_batch_norm", 6330], ["aten::add_", 6325], ["aten::contiguous", 6299], ["aten::add_", 6277], ["aten::contiguous", 6245], ["aten::contiguous", 6179], ["aten::cudnn_batch_norm", 6159], ["aten::add_", 6121], ["aten::add_", 6113], ["aten::as_strided", 6089], ["aten::contiguous", 5998], ["aten::clone", 5951], ["aten::adaptive_avg_pool2d", 5932], ["aten::empty_like", 5926], ["aten::cudnn_batch_norm", 5922], ["torch::autograd::AccumulateGrad", 5904], ["aten::add", 5894], ["aten::relu_", 5890], ["ReluBackward1", 5877], ["torch::autograd::AccumulateGrad", 5841], ["ReluBackward1", 5811], ["MaxPool2DWithIndicesBackward", 5800], ["aten::add", 5787], ["aten::stride", 5698], ["aten::add", 5673], ["aten::threshold_backward", 5663], ["aten::mul_", 5629], ["aten::fill_", 5627], ["aten::mean", 5519], ["aten::to", 5514], ["aten::empty_like", 5464], ["aten::threshold_", 5350], ["CudnnBatchNormBackward", 5327], ["CudnnBatchNormBackward", 5284], ["CudnnBatchNormBackward", 5261], ["aten::max_pool2d", 5260], ["CudnnBatchNormBackward", 5208], ["aten::max_pool2d_with_indices_backward", 5145], ["aten::fill_", 5104], ["aten::zero_", 4973], ["aten::fill_", 4943], ["aten::zero_", 4935], ["aten::fill_", 4927], ["torch::autograd::AccumulateGrad", 4878], ["aten::stride", 4863], ["aten::contiguous", 4862], ["aten::contiguous", 4830], ["aten::max_pool2d_with_indices", 4772], ["aten::stride", 4757], ["aten::empty_like", 4704], ["detach_", 4560], ["aten::empty_like", 4546], ["aten::add_", 4480], ["aten::relu_", 4469], ["aten::relu_", 4468], ["aten::contiguous", 4438], ["aten::mul_", 4438], ["aten::mul_", 4437], ["aten::clone", 4424], ["aten::threshold_backward", 4393], ["aten::as_strided", 4372], ["aten::contiguous", 4324], ["aten::cudnn_batch_norm_backward", 4306], ["aten::contiguous", 4268], ["aten::add", 4267], ["aten::add", 4263], ["aten::add", 4263], ["aten::cudnn_batch_norm_backward", 4239], ["aten::threshold_backward", 4238], ["aten::cudnn_batch_norm_backward", 4200], ["aten::add", 4188], ["aten::cudnn_batch_norm_backward", 4183], ["aten::add_", 4118], ["aten::zero_", 4100], ["aten::add_", 4092], ["aten::as_strided", 4063], ["aten::resize_", 3876], ["torch::autograd::AccumulateGrad", 3835], ["aten::stride", 3833], ["aten::clone", 3826], ["aten::clone", 3797], ["aten::empty_like", 3759], ["aten::mul_", 3755], ["aten::as_strided", 3745], ["MeanBackward1", 3646], ["torch::autograd::AccumulateGrad", 3574], ["torch::autograd::AccumulateGrad", 3568], ["aten::contiguous", 3528], ["torch::autograd::AccumulateGrad", 3522], ["aten::stride", 3484], ["aten::add_", 3458], ["aten::add_", 3427], ["aten::threshold_", 3373], ["aten::zeros", 3369], ["aten::zero_", 3268], ["aten::pin_memory", 3249], ["aten::zero_", 3242], ["aten::as_strided", 3232], ["aten::zero_", 3231], ["aten::empty_like", 3228], ["aten::fill_", 3181], ["aten::log_softmax", 3171], ["aten::clone", 3087], ["aten::mul_", 3058], ["aten::mul_", 3052], ["aten::mul_", 3027], ["aten::empty_like", 3022], ["aten::contiguous", 3014], ["aten::threshold_", 2944], ["aten::threshold_", 2910], ["aten::mm", 2903], ["aten::add", 2835], ["aten::to", 2830], ["aten::stride", 2786], ["aten::stride", 2785], ["aten::add", 2745], ["aten::_log_softmax", 2731], ["LogSoftmaxBackward", 2689], ["aten::zero_", 2604], ["aten::zero_", 2565], ["aten::resize_", 2488], ["aten::zero_", 2485], ["aten::threshold_", 2473], ["aten::add_", 2464], ["aten::zero_", 2462], ["aten::resize_", 2438], ["aten::nll_loss", 2427], ["aten::resize_", 2402], ["torch::autograd::AccumulateGrad", 2353], ["aten::contiguous", 2352], ["torch::autograd::AccumulateGrad", 2340], ["aten::mul_", 2292], ["aten::mul_", 2246], ["aten::mul_", 2206], ["aten::mul_", 2192], ["aten::clone", 2183], ["aten::_log_softmax_backward_data", 2171], ["aten::add_", 2159], ["aten::add_", 2156], ["aten::fill_", 2141], ["aten::t", 2140], ["aten::to", 2118], ["aten::add_", 2105], ["aten::fill_", 2096], ["aten::add_", 2094], ["aten::add_", 2093], ["NllLossBackward", 2085], ["aten::add_", 2078], ["aten::add_", 2073], ["aten::add_", 2061], ["aten::add_", 2037], ["aten::nll_loss_forward", 1977], ["aten::zeros_like", 1975], ["ReluBackward1", 1960], ["aten::div", 1954], ["aten::ones_like", 1912], ["ReluBackward1", 1908], ["aten::mm", 1907], ["ReluBackward1", 1903], ["ReluBackward1", 1898], ["aten::threshold_", 1871], ["aten::zero_", 1823], ["aten::resize_", 1758], ["aten::resize_", 1743], ["aten::fill_", 1739], ["aten::t", 1721], ["aten::relu_", 1720], ["aten::copy_", 1713], ["aten::clone", 1663], ["aten::flatten", 1637], ["aten::zero_", 1629], ["aten::stride", 1597], ["aten::add", 1592], ["aten::empty_like", 1560], ["aten::add", 1546], ["aten::detach", 1524], ["aten::relu_", 1517], ["aten::mul_", 1501], ["aten::empty_like", 1499], ["aten::relu_", 1498], ["aten::add", 1490], ["aten::relu_", 1480], ["aten::add", 1473], ["aten::threshold_backward", 1465], ["aten::contiguous", 1464], ["aten::contiguous", 1462], ["aten::mul_", 1452], ["aten::copy_", 1447], ["aten::add", 1432], ["aten::threshold_", 1427], ["aten::threshold_backward", 1422], ["aten::threshold_backward", 1420], ["aten::add", 1412], ["aten::resize_", 1410], ["aten::add", 1404], ["aten::threshold_", 1403], ["aten::resize_", 1402], ["aten::nll_loss_backward", 1398], ["aten::threshold_backward", 1397], ["aten::fill_", 1385], ["aten::fill_", 1382], ["aten::fill_", 1382], ["aten::clone", 1381], ["aten::add", 1376], ["aten::add", 1371], ["aten::add", 1354], ["aten::stride", 1352], ["aten::clone", 1333], ["torch::autograd::AccumulateGrad", 1302], ["torch::autograd::AccumulateGrad", 1264], ["AddBackward0", 1264], ["torch::autograd::AccumulateGrad", 1240], ["aten::contiguous", 1238], ["aten::resize_", 1217], ["aten::reshape", 1210], ["aten::resize_", 1209], ["torch::autograd::AccumulateGrad", 1196], ["torch::autograd::AccumulateGrad", 1192], ["aten::copy_", 1191], ["torch::autograd::AccumulateGrad", 1170], ["torch::autograd::AccumulateGrad", 1169], ["torch::autograd::AccumulateGrad", 1161], ["aten::as_strided", 1152], ["torch::autograd::AccumulateGrad", 1149], ["torch::autograd::AccumulateGrad", 1142], ["aten::clone", 1136], ["aten::fill_", 1134], ["TBackward", 1120], ["aten::zero_", 1119], ["aten::stride", 1117], ["aten::copy_", 1115], ["ViewBackward", 1115], ["aten::clone", 1106], ["aten::fill_", 1062], ["aten::resize_", 1060], ["aten::clone", 1049], ["aten::fill_", 1030], ["aten::fill_", 1028], ["aten::detach", 1004], ["aten::contiguous", 995], ["aten::contiguous", 973], ["aten::set_", 957], ["aten::contiguous", 956], ["aten::view", 925], ["aten::t", 917], ["aten::zero_", 913], ["aten::as_strided", 900], ["aten::contiguous", 893], ["aten::contiguous", 886], ["aten::mul_", 869], ["aten::zero_", 868], ["aten::contiguous", 864], ["aten::empty_like", 861], ["aten::clone", 859], ["aten::zero_", 859], ["aten::expand", 859], ["aten::zero_", 849], ["aten::transpose", 842], ["AddBackward0", 839], ["aten::clone", 837], ["aten::transpose", 834], ["aten::clone", 833], ["aten::zero_", 828], ["aten::clone", 826], ["aten::mul_", 824], ["aten::resize_", 819], ["aten::zero_", 819], ["aten::contiguous", 816], ["aten::zero_", 814], ["aten::resize_", 811], ["aten::zero_", 809], ["aten::zero_", 808], ["aten::zero_", 805], ["aten::stride", 799], ["aten::contiguous", 796], ["aten::resize_", 794], ["aten::zero_", 793], ["aten::reshape", 791], ["aten::stride", 784], ["aten::copy_", 773], ["aten::resize_", 754], ["aten::mul_", 754], ["aten::copy_", 753], ["aten::contiguous", 752], ["aten::detach", 751], ["aten::empty_like", 749], ["aten::is_pinned", 748], ["aten::mul_", 747], ["aten::mul_", 741], ["aten::mul_", 741], ["aten::copy_", 740], ["aten::mul_", 740], ["aten::empty_like", 739], ["aten::mul_", 735], ["aten::empty_like", 734], ["aten::contiguous", 725], ["aten::mul_", 721], ["aten::mul_", 716], ["aten::contiguous", 712], ["aten::stride", 705], ["aten::stride", 702], ["aten::stride", 691], ["aten::fill_", 686], ["aten::fill_", 683], ["aten::stride", 677], ["aten::copy_", 651], ["aten::detach", 644], ["aten::detach", 637], ["aten::narrow", 623], ["AddBackward0", 621], ["AddBackward0", 617], ["aten::resize_", 601], ["aten::resize_", 599], ["aten::stride", 597], ["aten::resize_", 595], ["aten::copy_", 593], ["aten::threshold_", 590], ["detach", 584], ["aten::copy_", 579], ["aten::clone", 560], ["aten::clone", 555], ["aten::expand", 549], ["nccl:broadcast", 547], ["aten::copy_", 546], ["aten::view", 538], ["aten::clone", 519], ["aten::contiguous", 512], ["aten::clone", 503], ["aten::threshold_", 492], ["aten::contiguous", 484], ["aten::threshold_", 482], ["aten::fill_", 479], ["aten::threshold_", 475], ["aten::fill_", 449], ["aten::resize_", 429], ["aten::transpose", 428], ["aten::stride", 423], ["aten::fill_", 412], ["aten::stride", 399], ["aten::resize_", 396], ["aten::slice", 395], ["aten::fill_", 395], ["detach", 393], ["aten::is_pinned", 386], ["aten::copy_", 384], ["aten::fill_", 383], ["aten::detach", 375], ["aten::resize_", 369], ["aten::resize_", 365], ["aten::copy_", 364], ["aten::fill_", 363], ["aten::resize_as_", 359], ["aten::fill_", 357], ["aten::fill_", 355], ["aten::fill_", 347], ["aten::fill_", 343], ["aten::fill_", 343], ["aten::fill_", 342], ["aten::resize_", 340], ["aten::detach_", 338], ["aten::contiguous", 316], ["aten::contiguous", 311], ["aten::clone", 293], ["detach", 288], ["aten::clone", 282], ["aten::resize_", 276], ["aten::detach", 276], ["aten::clone", 271], ["aten::clone", 271], ["aten::detach", 269], ["aten::clone", 269], ["aten::as_strided", 268], ["aten::clone", 268], ["aten::clone", 268], ["detach", 262], ["detach", 249], ["aten::contiguous", 245], ["aten::as_strided", 244], ["aten::contiguous", 242], ["aten::contiguous", 241], ["aten::contiguous", 241], ["aten::contiguous", 241], ["aten::contiguous", 240], ["aten::copy_", 238], ["aten::copy_", 238], ["aten::contiguous", 236], ["aten::detach", 234], ["aten::copy_", 225], ["aten::copy_", 223], ["aten::resize_", 211], ["aten::copy_", 202], ["aten::to", 201], ["aten::resize_", 200], ["aten::copy_", 200], ["aten::resize_", 199], ["aten::resize_", 198], ["aten::resize_", 198], ["aten::copy_", 198], ["aten::resize_", 195], ["aten::stride", 192], ["aten::copy_", 190], ["aten::copy_", 189], ["aten::detach", 188], ["aten::copy_", 187], ["aten::copy_", 186], ["aten::detach", 183], ["aten::detach", 181], ["aten::as_strided", 172], ["aten::resize_", 172], ["detach_", 169], ["aten::resize_", 166], ["aten::conj", 161], ["aten::conj", 156], ["aten::as_strided", 147], ["aten::as_strided", 145], ["detach", 143], ["aten::detach", 141], ["aten::as_strided", 140], ["aten::detach", 138], ["aten::detach", 136], ["aten::detach", 135], ["aten::contiguous", 134], ["aten::stride", 134], ["aten::to", 130], ["aten::is_floating_point", 125], ["aten::as_strided", 116], ["detach", 114], ["aten::stride", 111], ["detach", 111], ["aten::stride", 109], ["aten::stride", 107], ["aten::resize_", 105], ["aten::stride", 98], ["detach", 92], ["aten::detach", 91], ["aten::detach", 90], ["aten::random_", 79], ["detach", 75], ["detach", 74], ["detach", 72], ["detach", 57], ["detach", 55], ["detach", 55], ["detach", 55], ["aten::stride", 49], ["aten::detach", 48], ["aten::detach", 47], ["aten::detach", 47], ["aten::detach", 46], ["aten::detach", 46], ["aten::detach", 46], ["aten::detach", 46], ["aten::detach", 45], ["aten::detach", 45], ["aten::detach", 45], ["detach", 37], ["detach", 36], ["detach", 19], ["detach", 19], ["detach", 19], ["detach", 19], ["detach", 18], ["detach", 18], ["detach", 18], ["detach", 18], ["detach", 18], ["detach", 18]]}, "host_self_time": {"title": "Host Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 3853109], ["aten::_cat", 2875436], ["aten::cudnn_convolution", 1474263], ["aten::div_", 966065], ["aten::div", 951492], ["aten::sub_", 796119], ["aten::addmm", 483411], ["aten::empty", 434482], ["aten::cudnn_convolution_backward_weight", 179674], ["aten::copy_", 98537], ["aten::cudnn_convolution_backward_weight", 97703], ["aten::cudnn_batch_norm", 76508], ["aten::slice", 72913], ["aten::copy_", 70639], ["aten::select", 68648], ["aten::add_", 67611], ["aten::cudnn_convolution_backward_input", 66555], ["aten::add", 61742], ["aten::empty_strided", 58780], ["aten::to", 57406], ["aten::uniform_", 57045], ["aten::cudnn_batch_norm", 45465], ["aten::add_", 45191], ["aten::_local_scalar_dense", 45078], ["aten::any", 43695], ["aten::view", 38447], ["aten::item", 36456], ["aten::clone", 36176], ["aten::add", 34954], ["aten::view", 34757], ["aten::log", 34721], ["aten::cudnn_convolution_backward_input", 33986], ["aten::add_", 33907], ["aten::randint", 33156], ["aten::cudnn_convolution_backward_input", 32323], ["aten::_local_scalar_dense", 32202], ["aten::exp", 32076], ["aten::cudnn_batch_norm_backward", 32053], ["aten::item", 31075], ["aten::cudnn_convolution_backward_input", 30738], ["aten::copy_", 30698], ["aten::cudnn_convolution", 30526], ["aten::slice", 30037], ["aten::cudnn_convolution", 30016], ["aten::add_", 29177], ["aten::cudnn_batch_norm", 29173], ["aten::eq", 29130], ["aten::add_", 28888], ["aten::cudnn_convolution", 28872], ["aten::cudnn_convolution", 28458], ["aten::lt", 28279], ["aten::cudnn_batch_norm", 28257], ["aten::eq", 26434], ["aten::lt", 26388], ["aten::cudnn_convolution_backward_input", 26293], ["aten::view", 26022], ["aten::cudnn_convolution_backward_weight", 25909], ["aten::cudnn_convolution", 25824], ["aten::cudnn_convolution", 25230], ["aten::resize_", 25215], ["aten::cudnn_convolution_backward_weight", 25068], ["aten::view", 25005], ["aten::view", 24509], ["aten::cudnn_convolution", 24499], ["aten::cudnn_batch_norm", 24487], ["aten::narrow", 23963], ["aten::add", 23422], ["aten::cudnn_convolution_backward_input", 23129], ["aten::mul_", 23038], ["aten::permute", 23020], ["aten::cudnn_convolution", 22501], ["aten::cudnn_convolution_backward_weight", 22402], ["aten::cudnn_convolution", 22356], ["aten::cudnn_convolution", 22142], ["aten::copy_", 21068], ["aten::cudnn_convolution_backward_input", 20955], ["aten::cudnn_batch_norm", 20713], ["aten::exp", 20475], ["aten::cudnn_batch_norm_backward", 20450], ["aten::cudnn_batch_norm_backward", 20396], ["aten::cudnn_convolution", 20366], ["aten::cudnn_batch_norm", 20115], ["aten::cudnn_convolution_backward_input", 19785], ["aten::cudnn_convolution_backward_weight", 19552], ["aten::cudnn_convolution_backward_weight", 19448], ["aten::cudnn_convolution_backward_input", 19375], ["aten::to", 19366], ["aten::cudnn_convolution_backward_input", 18551], ["aten::cudnn_convolution_backward_weight", 18475], ["aten::view", 18412], ["aten::set_", 18344], ["aten::rand", 18218], ["aten::cudnn_convolution_backward_input", 18153], ["aten::pin_memory", 18014], ["aten::cudnn_convolution", 17973], ["aten::view", 17872], ["aten::cudnn_convolution", 17371], ["aten::add", 17363], ["aten::cudnn_batch_norm_backward", 17067], ["aten::add_", 17038], ["aten::_batch_norm_impl_index", 16996], ["aten::cudnn_convolution", 16894], ["aten::cudnn_convolution_backward_input", 16788], ["aten::random_", 16595], ["aten::view", 16592], ["aten::view", 16542], ["aten::cudnn_convolution", 16409], ["aten::cudnn_batch_norm", 16173], ["aten::cudnn_convolution_backward_input", 16109], ["aten::cudnn_batch_norm", 16101], ["aten::mul_", 15887], ["aten::cudnn_convolution_backward_weight", 15592], ["aten::add", 15467], ["aten::add", 15173], ["aten::copy_", 15147], ["aten::zero_", 15115], ["aten::cudnn_convolution_backward_weight", 15063], ["aten::cudnn_convolution", 14832], ["aten::cudnn_convolution", 14531], ["aten::is_floating_point", 14437], ["aten::cudnn_batch_norm_backward", 14397], ["aten::cudnn_batch_norm_backward", 14339], ["aten::cudnn_batch_norm_backward", 14331], ["aten::cudnn_convolution_backward_weight", 14069], ["aten::cudnn_convolution_backward_input", 13877], ["aten::copy_", 13732], ["aten::contiguous", 13716], ["aten::cudnn_convolution_backward_weight", 13670], ["aten::cudnn_convolution_backward_weight", 13587], ["aten::cudnn_convolution_backward_input", 13562], ["aten::copy_", 13333], ["aten::cudnn_convolution_backward_input", 13306], ["aten::cudnn_convolution_backward_weight", 13117], ["aten::add_", 12531], ["aten::add_", 12468], ["aten::as_strided", 12277], ["aten::narrow", 12167], ["aten::threshold_backward", 12074], ["torch::autograd::AccumulateGrad", 11916], ["aten::cudnn_batch_norm_backward", 11863], ["aten::empty_like", 11847], ["aten::mul_", 11420], ["aten::cudnn_convolution", 11370], ["aten::fill_", 11344], ["aten::relu_", 11261], ["aten::cudnn_convolution", 11240], ["aten::cudnn_convolution_backward_weight", 10867], ["aten::cudnn_convolution_backward_weight", 10702], ["aten::cudnn_convolution", 10674], ["aten::cudnn_convolution_backward_weight", 10595], ["aten::as_strided", 10481], ["aten::add_", 10443], ["aten::zero_", 10435], ["aten::contiguous", 10404], ["aten::mul_", 10373], ["aten::mul_", 10255], ["CudnnBatchNormBackward", 10219], ["aten::unsqueeze", 9977], ["aten::contiguous", 9864], ["aten::cudnn_convolution_backward_weight", 9846], ["aten::add_", 9488], ["aten::cudnn_convolution_backward_input", 9273], ["aten::cudnn_convolution", 9243], ["aten::view", 9232], ["aten::add", 8494], ["aten::add_", 8439], ["aten::cudnn_convolution_backward_weight", 8437], ["aten::cudnn_convolution_backward", 8415], ["aten::cudnn_convolution_backward_input", 8411], ["aten::add_", 8282], ["aten::cudnn_convolution_backward_weight", 8175], ["torch::autograd::AccumulateGrad", 8080], ["aten::_batch_norm_impl_index", 7976], ["aten::_batch_norm_impl_index", 7964], ["aten::cudnn_convolution", 7955], ["aten::cudnn_convolution_backward_weight", 7948], ["aten::to", 7877], ["aten::cudnn_convolution_backward_input", 7875], ["aten::stride", 7810], ["aten::copy_", 7810], ["aten::cudnn_convolution_backward_weight", 7743], ["aten::fill_", 7673], ["aten::copy_", 7668], ["aten::zero_", 7635], ["aten::as_strided", 7601], ["CudnnConvolutionBackward", 7587], ["aten::threshold_backward", 7511], ["aten::add_", 7272], ["aten::relu_", 7197], ["aten::cudnn_convolution_backward", 7027], ["aten::cudnn_convolution_backward", 6999], ["aten::is_nonzero", 6950], ["aten::_batch_norm_impl_index", 6858], ["aten::contiguous", 6755], ["aten::zero_", 6705], ["aten::zero_", 6684], ["aten::detach_", 6662], ["aten::add", 6546], ["aten::threshold_backward", 6542], ["aten::threshold_backward", 6527], ["aten::add", 6479], ["aten::relu_", 6449], ["CudnnBatchNormBackward", 6338], ["aten::add_", 6325], ["aten::contiguous", 6299], ["aten::add_", 6277], ["aten::contiguous", 6245], ["CudnnBatchNormBackward", 6229], ["aten::contiguous", 6179], ["aten::relu_", 6122], ["aten::add_", 6121], ["aten::add_", 6113], ["aten::as_strided", 6089], ["aten::_batch_norm_impl_index", 6001], ["aten::contiguous", 5998], ["aten::is_nonzero", 5905], ["torch::autograd::AccumulateGrad", 5905], ["aten::stride", 5698], ["aten::_batch_norm_impl_index", 5642], ["aten::mul_", 5629], ["aten::fill_", 5627], ["aten::add", 5529], ["aten::cudnn_convolution_backward", 5523], ["aten::to", 5514], ["CudnnBatchNormBackward", 5463], ["aten::cudnn_convolution_backward", 5450], ["ReluBackward1", 5415], ["aten::threshold_backward", 5403], ["aten::threshold_", 5350], ["torch::autograd::AccumulateGrad", 5341], ["aten::relu_", 5321], ["aten::mean", 5157], ["aten::fill_", 5104], ["aten::_convolution", 5086], ["torch::autograd::AccumulateGrad", 5081], ["aten::fill_", 4943], ["aten::batch_norm", 4935], ["aten::fill_", 4927], ["aten::stride", 4863], ["aten::contiguous", 4862], ["aten::contiguous", 4830], ["CudnnConvolutionBackward", 4762], ["aten::stride", 4757], ["CudnnConvolutionBackward", 4687], ["aten::empty_like", 4677], ["aten::stack", 4630], ["detach_", 4560], ["aten::add", 4532], ["aten::_batch_norm_impl_index", 4515], ["CudnnBatchNormBackward", 4504], ["aten::_batch_norm_impl_index", 4493], ["aten::add_", 4480], ["CudnnBatchNormBackward", 4479], ["aten::contiguous", 4438], ["aten::mul_", 4438], ["aten::mul_", 4437], ["aten::_convolution", 4433], ["aten::add", 4418], ["aten::clone", 4405], ["aten::as_strided", 4372], ["aten::add", 4342], ["aten::contiguous", 4324], ["aten::threshold_backward", 4312], ["aten::cudnn_convolution_backward", 4302], ["aten::contiguous", 4268], ["aten::cudnn_convolution_backward", 4255], ["aten::cudnn_convolution_backward", 4209], ["aten::cudnn_convolution_backward", 4162], ["aten::_convolution", 4138], ["aten::cudnn_batch_norm", 4130], ["aten::add_", 4118], ["aten::add_", 4092], ["CudnnConvolutionBackward", 4088], ["aten::as_strided", 4063], ["aten::cudnn_batch_norm", 4031], ["aten::relu_", 4019], ["aten::cudnn_batch_norm", 3969], ["aten::resize_", 3876], ["aten::stride", 3833], ["aten::zero_", 3827], ["aten::mul_", 3755], ["aten::as_strided", 3745], ["CudnnBatchNormBackward", 3730], ["CudnnBatchNormBackward", 3683], ["aten::contiguous", 3528], ["aten::stride", 3484], ["aten::add_", 3458], ["ReluBackward1", 3445], ["aten::add_", 3427], ["aten::threshold_backward", 3406], ["CudnnConvolutionBackward", 3400], ["aten::max_pool2d_with_indices", 3373], ["aten::threshold_", 3373], ["CudnnConvolutionBackward", 3326], ["aten::_convolution", 3322], ["aten::cat", 3294], ["aten::add", 3286], ["aten::threshold_backward", 3257], ["aten::add", 3238], ["aten::as_strided", 3232], ["aten::add", 3218], ["aten::_convolution", 3190], ["aten::fill_", 3181], ["aten::add", 3177], ["torch::autograd::AccumulateGrad", 3119], ["aten::relu_", 3066], ["aten::mul_", 3058], ["aten::mul_", 3052], ["ReluBackward1", 3047], ["aten::relu_", 3041], ["aten::mul_", 3027], ["aten::contiguous", 3014], ["aten::clone", 2987], ["aten::cudnn_convolution_backward", 2970], ["aten::threshold_", 2944], ["ReluBackward1", 2932], ["aten::threshold_", 2910], ["aten::cudnn_batch_norm_backward", 2897], ["aten::empty_like", 2896], ["aten::zero_", 2877], ["aten::cudnn_batch_norm_backward", 2857], ["aten::cudnn_convolution_backward", 2845], ["aten::empty_like", 2823], ["aten::cudnn_batch_norm_backward", 2808], ["aten::cudnn_batch_norm_backward", 2805], ["aten::batch_norm", 2801], ["aten::batch_norm", 2794], ["aten::zero_", 2794], ["aten::stride", 2786], ["aten::stride", 2785], ["aten::cudnn_convolution_backward", 2773], ["CudnnConvolutionBackward", 2745], ["CudnnConvolutionBackward", 2645], ["aten::conv2d", 2570], ["aten::_convolution", 2489], ["aten::resize_", 2488], ["ReluBackward1", 2481], ["aten::threshold_", 2473], ["aten::add_", 2464], ["aten::batch_norm", 2454], ["aten::_convolution", 2444], ["aten::resize_", 2438], ["aten::empty_like", 2417], ["aten::mm", 2412], ["aten::resize_", 2402], ["aten::_convolution", 2394], ["aten::_convolution", 2391], ["aten::zero_", 2361], ["aten::contiguous", 2352], ["aten::mul_", 2292], ["aten::convolution", 2284], ["aten::max_pool2d_with_indices_backward", 2267], ["aten::mul_", 2246], ["aten::conv2d", 2218], ["torch::autograd::AccumulateGrad", 2218], ["torch::autograd::AccumulateGrad", 2214], ["aten::mul_", 2206], ["aten::mul_", 2192], ["aten::clone", 2180], ["aten::add", 2166], ["aten::add_", 2159], ["aten::conv2d", 2156], ["aten::add_", 2156], ["aten::fill_", 2141], ["aten::add_", 2105], ["aten::fill_", 2096], ["aten::add_", 2094], ["aten::add_", 2093], ["aten::add", 2084], ["aten::empty_like", 2083], ["aten::add_", 2078], ["aten::add_", 2073], ["aten::add_", 2061], ["aten::empty_like", 2044], ["aten::add_", 2037], ["aten::batch_norm", 2000], ["aten::batch_norm", 1996], ["aten::nll_loss_forward", 1977], ["ReluBackward1", 1967], ["aten::convolution", 1946], ["aten::clone", 1932], ["aten::clone", 1906], ["aten::convolution", 1897], ["aten::zero_", 1886], ["torch::autograd::AccumulateGrad", 1879], ["aten::_log_softmax", 1877], ["aten::threshold_", 1871], ["aten::zero_", 1857], ["aten::zero_", 1849], ["aten::resize_", 1758], ["aten::resize_", 1743], ["aten::fill_", 1739], ["aten::conv2d", 1737], ["aten::conv2d", 1719], ["aten::copy_", 1713], ["aten::zeros", 1712], ["aten::_convolution", 1709], ["aten::batch_norm", 1698], ["aten::batch_norm", 1649], ["aten::_convolution", 1643], ["aten::empty_like", 1631], ["aten::empty_like", 1616], ["aten::div", 1614], ["aten::stride", 1597], ["aten::_convolution", 1597], ["ReluBackward1", 1573], ["aten::convolution", 1543], ["aten::zero_", 1542], ["aten::convolution", 1520], ["aten::pin_memory", 1518], ["torch::autograd::AccumulateGrad", 1511], ["aten::mul_", 1501], ["ReluBackward1", 1484], ["aten::cudnn_convolution_backward", 1465], ["aten::contiguous", 1464], ["aten::contiguous", 1462], ["aten::zero_", 1455], ["aten::mul_", 1452], ["aten::copy_", 1447], ["torch::autograd::AccumulateGrad", 1445], ["torch::autograd::AccumulateGrad", 1443], ["aten::zero_", 1434], ["aten::zero_", 1431], ["aten::cudnn_convolution_backward", 1431], ["aten::threshold_", 1427], ["aten::cudnn_convolution_backward", 1427], ["aten::resize_", 1410], ["AddmmBackward", 1410], ["aten::mm", 1409], ["aten::threshold_", 1403], ["aten::resize_", 1402], ["aten::cudnn_convolution_backward", 1400], ["aten::nll_loss_backward", 1398], ["aten::cudnn_convolution_backward", 1398], ["aten::cudnn_convolution_backward", 1394], ["aten::fill_", 1385], ["aten::cudnn_convolution_backward", 1384], ["aten::fill_", 1382], ["aten::fill_", 1382], ["aten::cudnn_convolution_backward", 1377], ["aten::cudnn_convolution_backward", 1363], ["aten::stride", 1352], ["aten::cudnn_convolution_backward", 1344], ["aten::conv2d", 1307], ["aten::conv2d", 1304], ["aten::conv2d", 1298], ["aten::t", 1298], ["aten::_batch_norm_impl_index", 1273], ["aten::conv2d", 1271], ["torch::autograd::AccumulateGrad", 1265], ["AddBackward0", 1264], ["aten::contiguous", 1238], ["aten::convolution", 1233], ["aten::add", 1228], ["aten::resize_", 1217], ["aten::add", 1216], ["aten::_log_softmax_backward_data", 1210], ["aten::resize_", 1209], ["aten::copy_", 1191], ["aten::convolution", 1156], ["aten::as_strided", 1152], ["aten::add", 1147], ["torch::autograd::AccumulateGrad", 1143], ["aten::zero_", 1137], ["aten::convolution", 1136], ["aten::add", 1135], ["aten::fill_", 1134], ["aten::convolution", 1132], ["aten::relu_", 1130], ["aten::_batch_norm_impl_index", 1128], ["torch::autograd::AccumulateGrad", 1125], ["aten::stride", 1117], ["aten::threshold_backward", 1117], ["aten::copy_", 1115], ["aten::_batch_norm_impl_index", 1108], ["aten::_batch_norm_impl_index", 1101], ["aten::add", 1088], ["aten::threshold_backward", 1086], ["aten::add", 1083], ["aten::add", 1076], ["torch::autograd::AccumulateGrad", 1075], ["aten::threshold_backward", 1073], ["aten::clone", 1071], ["aten::threshold_backward", 1071], ["aten::fill_", 1062], ["aten::resize_", 1060], ["aten::add", 1059], ["aten::add", 1042], ["aten::add", 1037], ["aten::cudnn_convolution_backward", 1033], ["aten::fill_", 1030], ["aten::fill_", 1028], ["aten::relu_", 1025], ["aten::relu_", 1016], ["aten::relu_", 1005], ["aten::contiguous", 995], ["aten::contiguous", 973], ["aten::set_", 957], ["aten::contiguous", 956], ["CudnnBatchNormBackward", 953], ["aten::zero_", 946], ["aten::detach", 940], ["aten::_convolution", 928], ["aten::view", 925], ["aten::conv2d", 911], ["aten::as_strided", 900], ["CudnnBatchNormBackward", 899], ["aten::to", 898], ["CudnnBatchNormBackward", 895], ["aten::contiguous", 893], ["CudnnBatchNormBackward", 893], ["aten::t", 887], ["aten::contiguous", 886], ["aten::mul_", 869], ["aten::contiguous", 864], ["aten::conv2d", 842], ["AddBackward0", 839], ["aten::conv2d", 837], ["aten::clone", 835], ["aten::_convolution", 831], ["aten::clone", 830], ["aten::_convolution", 827], ["aten::mul_", 824], ["aten::_convolution", 821], ["aten::resize_", 819], ["aten::contiguous", 816], ["aten::_convolution", 813], ["aten::resize_", 811], ["aten::_convolution", 803], ["aten::empty_like", 801], ["aten::empty_like", 801], ["aten::stride", 799], ["aten::_convolution", 798], ["aten::contiguous", 796], ["aten::resize_", 794], ["aten::_convolution", 791], ["aten::_convolution", 790], ["aten::_convolution", 787], ["aten::stride", 784], ["aten::_convolution", 784], ["aten::copy_", 773], ["aten::zero_", 754], ["aten::resize_", 754], ["aten::mul_", 754], ["aten::convolution", 753], ["aten::copy_", 753], ["aten::contiguous", 752], ["aten::is_pinned", 748], ["aten::mul_", 747], ["torch::autograd::AccumulateGrad", 747], ["aten::mul_", 741], ["aten::mul_", 741], ["aten::copy_", 740], ["aten::mul_", 740], ["aten::convolution", 738], ["aten::convolution", 735], ["aten::mul_", 735], ["CudnnConvolutionBackward", 733], ["torch::autograd::AccumulateGrad", 728], ["aten::contiguous", 725], ["aten::mul_", 721], ["aten::mul_", 716], ["aten::contiguous", 712], ["aten::clone", 712], ["aten::expand", 712], ["CudnnConvolutionBackward", 706], ["aten::stride", 705], ["MeanBackward1", 703], ["aten::stride", 702], ["aten::stride", 691], ["NllLossBackward", 687], ["aten::fill_", 686], ["aten::fill_", 683], ["CudnnConvolutionBackward", 683], ["aten::stride", 677], ["MaxPool2DWithIndicesBackward", 655], ["CudnnConvolutionBackward", 652], ["aten::copy_", 651], ["aten::to", 640], ["AddBackward0", 621], ["AddBackward0", 617], ["aten::detach", 611], ["aten::resize_", 601], ["aten::resize_", 599], ["aten::stride", 597], ["aten::resize_", 595], ["aten::copy_", 593], ["aten::threshold_", 590], ["aten::transpose", 590], ["detach", 584], ["aten::copy_", 579], ["aten::transpose", 574], ["aten::ones_like", 572], ["aten::clone", 563], ["nccl:broadcast", 547], ["aten::copy_", 546], ["aten::clone", 546], ["aten::clone", 544], ["aten::view", 538], ["aten::conv2d", 531], ["LogSoftmaxBackward", 518], ["aten::contiguous", 512], ["aten::zero_", 502], ["aten::zero_", 501], ["ReluBackward1", 501], ["ReluBackward1", 495], ["aten::threshold_", 492], ["aten::t", 489], ["aten::max_pool2d", 488], ["ReluBackward1", 488], ["aten::contiguous", 484], ["aten::threshold_", 482], ["ReluBackward1", 481], ["aten::fill_", 479], ["aten::zero_", 476], ["aten::threshold_", 475], ["aten::zero_", 473], ["aten::batch_norm", 471], ["aten::zero_", 466], ["aten::zero_", 465], ["aten::zero_", 465], ["aten::conv2d", 463], ["aten::detach", 463], ["aten::zero_", 463], ["aten::zero_", 462], ["aten::zero_", 459], ["aten::nll_loss", 450], ["aten::empty_like", 449], ["aten::fill_", 449], ["aten::conv2d", 445], ["aten::convolution", 443], ["aten::conv2d", 441], ["aten::log_softmax", 440], ["aten::clone", 439], ["aten::conv2d", 437], ["aten::conv2d", 433], ["aten::conv2d", 431], ["aten::resize_", 429], ["aten::clone", 428], ["aten::flatten", 427], ["aten::stride", 423], ["aten::conv2d", 423], ["aten::conv2d", 420], ["aten::conv2d", 416], ["aten::conv2d", 416], ["aten::clone", 416], ["aten::adaptive_avg_pool2d", 413], ["aten::clone", 413], ["aten::fill_", 412], ["aten::empty_like", 411], ["aten::expand", 409], ["aten::batch_norm", 407], ["aten::batch_norm", 407], ["aten::convolution", 402], ["aten::empty_like", 401], ["aten::stride", 399], ["aten::empty_like", 398], ["aten::convolution", 397], ["aten::resize_", 396], ["aten::fill_", 395], ["aten::batch_norm", 394], ["detach", 393], ["aten::convolution", 389], ["aten::convolution", 389], ["aten::detach", 388], ["aten::is_pinned", 386], ["aten::copy_", 384], ["aten::fill_", 383], ["aten::convolution", 382], ["aten::detach", 382], ["aten::zeros_like", 382], ["torch::autograd::AccumulateGrad", 378], ["torch::autograd::AccumulateGrad", 376], ["aten::convolution", 374], ["torch::autograd::AccumulateGrad", 374], ["aten::convolution", 373], ["aten::resize_", 369], ["aten::convolution", 369], ["aten::convolution", 369], ["aten::convolution", 367], ["torch::autograd::AccumulateGrad", 367], ["aten::resize_", 365], ["torch::autograd::AccumulateGrad", 365], ["aten::copy_", 364], ["torch::autograd::AccumulateGrad", 364], ["aten::fill_", 363], ["torch::autograd::AccumulateGrad", 363], ["torch::autograd::AccumulateGrad", 363], ["aten::fill_", 357], ["torch::autograd::AccumulateGrad", 356], ["aten::fill_", 355], ["torch::autograd::AccumulateGrad", 355], ["aten::fill_", 347], ["aten::zero_", 344], ["aten::fill_", 343], ["aten::fill_", 343], ["aten::fill_", 342], ["aten::resize_", 340], ["ViewBackward", 324], ["aten::contiguous", 316], ["aten::contiguous", 311], ["detach", 288], ["TBackward", 288], ["aten::clone", 286], ["aten::reshape", 285], ["aten::resize_as_", 284], ["aten::transpose", 283], ["aten::slice", 279], ["aten::resize_", 276], ["aten::clone", 269], ["aten::as_strided", 268], ["detach", 262], ["aten::reshape", 253], ["detach", 249], ["aten::contiguous", 245], ["aten::as_strided", 244], ["aten::contiguous", 242], ["aten::contiguous", 241], ["aten::contiguous", 241], ["aten::contiguous", 241], ["aten::contiguous", 240], ["aten::copy_", 238], ["aten::copy_", 238], ["aten::contiguous", 236], ["aten::detach", 232], ["aten::narrow", 228], ["aten::copy_", 225], ["aten::copy_", 223], ["aten::resize_", 211], ["aten::copy_", 202], ["aten::to", 201], ["aten::resize_", 200], ["aten::copy_", 200], ["aten::resize_", 199], ["aten::resize_", 198], ["aten::resize_", 198], ["aten::copy_", 198], ["aten::resize_", 195], ["aten::stride", 192], ["aten::copy_", 190], ["aten::copy_", 189], ["aten::copy_", 187], ["aten::copy_", 186], ["aten::as_strided", 172], ["aten::resize_", 172], ["detach_", 169], ["aten::detach_", 169], ["aten::resize_", 166], ["aten::detach", 162], ["aten::conj", 161], ["aten::detach", 158], ["aten::conj", 156], ["aten::as_strided", 147], ["aten::as_strided", 145], ["aten::clone", 143], ["detach", 143], ["aten::detach", 142], ["aten::as_strided", 140], ["aten::clone", 140], ["aten::clone", 139], ["aten::clone", 138], ["aten::clone", 138], ["aten::clone", 138], ["aten::clone", 135], ["aten::clone", 135], ["aten::contiguous", 134], ["aten::stride", 134], ["aten::clone", 133], ["aten::clone", 132], ["aten::to", 130], ["aten::is_floating_point", 125], ["aten::as_strided", 116], ["aten::detach", 116], ["detach", 114], ["aten::stride", 111], ["detach", 111], ["aten::stride", 109], ["aten::detach", 109], ["aten::stride", 107], ["aten::detach", 106], ["aten::resize_", 105], ["aten::stride", 98], ["detach", 92], ["aten::detach", 86], ["aten::detach", 81], ["aten::detach", 81], ["aten::detach", 80], ["aten::random_", 79], ["detach", 75], ["detach", 74], ["detach", 72], ["detach", 57], ["detach", 55], ["detach", 55], ["detach", 55], ["aten::detach", 54], ["aten::detach", 54], ["aten::stride", 49], ["detach", 37], ["detach", 36], ["aten::detach", 29], ["aten::detach", 29], ["aten::detach", 28], ["aten::detach", 28], ["aten::detach", 28], ["aten::detach", 27], ["aten::detach", 27], ["aten::detach", 27], ["aten::detach", 27], ["aten::detach", 27], ["detach", 19], ["detach", 19], ["detach", 19], ["detach", 19], ["detach", 18], ["detach", 18], ["detach", 18], ["detach", 18], ["detach", 18], ["detach", 18]]}}, "operation_table_by_name_input": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "string", "name": "Input Shape"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Device Self Duration (us)"}, {"type": "number", "name": "Device Total Duration (us)"}, {"type": "number", "name": "Host Self Duration (us)"}, {"type": "number", "name": "Host Total Duration (us)"}], "rows": [["aten::cudnn_convolution_backward_weight", "[[], [32, 64, 56, 56], [32, 64, 56, 56], [], [], [], [], [], [], []]", 32, 31905, 31905, 25068, 29708], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], []]", 24, 28843, 28843, 33986, 38027], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], []]", 48, 28166, 28166, 32323, 40010], ["aten::cudnn_convolution_backward_input", "[[], [32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], []]", 32, 26148, 26148, 26293, 31161], ["aten::cudnn_convolution_backward_input", "[[], [32, 1024, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], []]", 48, 25852, 25852, 23129, 30075], ["aten::cudnn_convolution", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], []]", 48, 23416, 23416, 30526, 38031], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 56, 56], [32, 64, 56, 56], [], [], [], [], [], [], []]", 32, 21973, 21973, 19448, 24013], ["aten::cudnn_convolution_backward_weight", "[[], [32, 1024, 14, 14], [32, 256, 14, 14], [], [], [], [], [], [], []]", 48, 21898, 21898, 25909, 32729], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], []]", 40, 20781, 20781, 20955, 26806], ["aten::cudnn_batch_norm_backward", "[[32, 256, 56, 56], [32, 256, 56, 56], [256], [256], [256], [256], [256], [], [0]]", 32, 20675, 20675, 11863, 18453], ["aten::cudnn_convolution", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], []]", 40, 20489, 20489, 28458, 35091], ["aten::cudnn_convolution", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], []]", 24, 20407, 20407, 28872, 32524], ["aten::cudnn_convolution_backward_input", "[[], [32, 2048, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], []]", 24, 20251, 20251, 19785, 23232], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 14, 14], [32, 1024, 14, 14], [], [], [], [], [], [], []]", 40, 18648, 18648, 19552, 25297], ["aten::cudnn_convolution_backward_weight", "[[], [32, 64, 56, 56], [32, 256, 56, 56], [], [], [], [], [], [], []]", 16, 18623, 18623, 13670, 15988], ["aten::cudnn_convolution", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], []]", 16, 18225, 18225, 25230, 28128], ["aten::cudnn_convolution", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], []]", 32, 17626, 17626, 24499, 29357], ["aten::cudnn_convolution", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], []]", 40, 17078, 17078, 30016, 37532], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 28, 28], [32, 128, 28, 28], [], [], [], [], [], [], []]", 32, 16649, 16649, 18475, 22876], ["aten::cudnn_convolution", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], []]", 32, 15748, 15748, 25824, 31247], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 14, 14], [32, 256, 14, 14], [], [], [], [], [], [], []]", 40, 15740, 15740, 22402, 28829], ["aten::cudnn_convolution", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], []]", 16, 15713, 15713, 22501, 26045], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], []]", 16, 15630, 15630, 19375, 21687], ["aten::cudnn_convolution_backward_weight", "[[], [32, 2048, 7, 7], [32, 512, 7, 7], [], [], [], [], [], [], []]", 24, 15525, 15525, 179674, 183429], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 56, 56], [32, 256, 56, 56], [], [], [], [], [], [], []]", 8, 15387, 15387, 13587, 14759], ["aten::cudnn_convolution", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], []]", 8, 15283, 15283, 17973, 19234], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], []]", 32, 15159, 15159, 16788, 21405], ["aten::cudnn_convolution", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], []]", 8, 15106, 15106, 1474263, 1476455], ["aten::cudnn_convolution", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], [], [], []]", 8, 15055, 15055, 14531, 16168], ["aten::cudnn_convolution_backward_input", "[[], [32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], []]", 24, 14912, 14912, 30738, 34536], ["aten::cudnn_convolution", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], []]", 24, 14848, 14848, 22142, 26241], ["aten::cudnn_convolution", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 14809, 14809, 17371, 18945], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], []]", 32, 14753, 14753, 18551, 23585], ["aten::copy_", "[[32, 3, 224, 224], [32, 3, 224, 224], []]", 16, 13541, 13541, 98537, 98537], ["aten::cudnn_convolution_backward_input", "[[], [32, 128, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], []]", 8, 13464, 13464, 16109, 17362], ["aten::cudnn_convolution", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], []]", 24, 13429, 13429, 20366, 24077], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 28, 28], [32, 512, 28, 28], [], [], [], [], [], [], []]", 24, 13272, 13272, 14069, 17525], ["aten::cudnn_batch_norm_backward", "[[32, 512, 28, 28], [32, 512, 28, 28], [512], [512], [512], [512], [512], [], [0]]", 40, 13249, 13249, 14331, 21490], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 13000, 13000, 13877, 15095], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 28, 28], [32, 128, 28, 28], [], [], [], [], [], [], []]", 24, 12927, 12927, 15063, 18781], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 7, 7], [32, 2048, 7, 7], [], [], [], [], [], [], []]", 16, 12867, 12867, 15592, 18038], ["aten::cudnn_batch_norm", "[[32, 256, 56, 56], [256], [256], [256], [256], [], [], []]", 32, 12813, 12813, 16173, 24102], ["aten::cudnn_convolution", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], []]", 8, 12689, 12689, 16409, 17630], ["aten::cudnn_convolution_backward_weight", "[[], [32, 64, 112, 112], [32, 3, 224, 224], [], [], [], [], [], [], []]", 8, 12685, 12685, 9846, 11231], ["aten::cudnn_convolution", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], []]", 24, 11815, 11815, 22356, 28038], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 28, 28], [32, 512, 28, 28], [], [], [], [], [], [], []]", 8, 11723, 11723, 10595, 11746], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 28, 28], [512, 256, 1, 1], [], [], [], [], [], [], []]", 8, 11684, 11684, 9273, 10433], ["aten::cudnn_convolution_backward_input", "[[], [32, 64, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], []]", 16, 11288, 11288, 13306, 15845], ["aten::cudnn_convolution", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], [], [], []]", 8, 11264, 11264, 10674, 11894], ["aten::cudnn_convolution_backward_input", "[[], [32, 2048, 7, 7], [2048, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 11224, 11224, 66555, 67841], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 14, 14], [32, 1024, 14, 14], [], [], [], [], [], [], []]", 8, 10731, 10731, 10867, 12085], ["aten::cudnn_convolution_backward_input", "[[], [32, 1024, 14, 14], [1024, 512, 1, 1], [], [], [], [], [], [], []]", 8, 10705, 10705, 8411, 9558], ["aten::cudnn_convolution_backward_input", "[[], [32, 128, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], []]", 24, 10650, 10650, 18153, 22064], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 7, 7], [32, 512, 7, 7], [], [], [], [], [], [], []]", 16, 10583, 10583, 97703, 100237], ["aten::cudnn_convolution", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], []]", 16, 10361, 10361, 16894, 19626], ["aten::cudnn_convolution_backward_weight", "[[], [32, 2048, 7, 7], [32, 1024, 14, 14], [], [], [], [], [], [], []]", 8, 10174, 10174, 13117, 14367], ["aten::cudnn_batch_norm_backward", "[[32, 1024, 14, 14], [32, 1024, 14, 14], [1024], [1024], [1024], [1024], [1024], [], [0]]", 56, 10163, 10163, 20396, 30363], ["aten::cudnn_batch_norm_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], [64], [64], [64], [64], [64], [], [0]]", 48, 10151, 10151, 17067, 25438], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], []]", 8, 10064, 10064, 13562, 14846], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 7, 7], [32, 512, 14, 14], [], [], [], [], [], [], []]", 8, 9653, 9653, 10702, 11984], ["aten::cudnn_convolution", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], [], [], []]", 8, 9524, 9524, 14832, 17144], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 28, 28], [32, 256, 56, 56], [], [], [], [], [], [], []]", 8, 9330, 9330, 7743, 8889], ["aten::cudnn_convolution", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 9055, 9055, 11370, 12574], ["aten::cudnn_convolution", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], [], [], []]", 8, 9034, 9034, 9243, 10496], ["aten::threshold_backward", "[[32, 256, 56, 56], [32, 256, 56, 56], []]", 24, 8808, 8808, 3257, 4238], ["aten::add_", "[[32, 256, 56, 56], [32, 256, 56, 56], []]", 24, 8748, 8748, 3458, 3458], ["aten::cudnn_convolution_backward_weight", "[[], [32, 1024, 14, 14], [32, 512, 28, 28], [], [], [], [], [], [], []]", 8, 8692, 8692, 8437, 9807], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 28, 28], [32, 128, 56, 56], [], [], [], [], [], [], []]", 8, 8514, 8514, 8175, 9431], ["aten::cudnn_batch_norm", "[[32, 512, 28, 28], [512], [512], [512], [512], [], [], []]", 40, 8307, 8307, 20115, 30940], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 14, 14], [32, 256, 28, 28], [], [], [], [], [], [], []]", 8, 8224, 8224, 7948, 9195], ["aten::cudnn_convolution", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], [], [], []]", 8, 7551, 7551, 11240, 14651], ["aten::cudnn_batch_norm_backward", "[[32, 64, 112, 112], [32, 64, 112, 112], [64], [64], [64], [64], [64], [], [0]]", 8, 6523, 6523, 2805, 4200], ["aten::threshold_", "[[32, 256, 56, 56], [], []]", 24, 6017, 6017, 1427, 1427], ["aten::threshold_backward", "[[32, 512, 28, 28], [32, 512, 28, 28], []]", 32, 5947, 5947, 4312, 5663], ["aten::add_", "[[32, 512, 28, 28], [32, 512, 28, 28], []]", 32, 5907, 5907, 4480, 4480], ["aten::max_pool2d_with_indices_backward", "[[32, 64, 56, 56], [32, 64, 112, 112], [], [], [], [], [], [32, 64, 56, 56]]", 8, 5566, 6851, 2267, 5145], ["aten::cudnn_batch_norm", "[[32, 64, 56, 56], [64], [64], [64], [64], [], [], []]", 48, 5318, 5318, 24487, 36549], ["aten::cudnn_batch_norm_backward", "[[32, 128, 28, 28], [32, 128, 28, 28], [128], [128], [128], [128], [128], [], [0]]", 56, 5143, 5143, 20450, 30520], ["aten::cudnn_batch_norm", "[[32, 1024, 14, 14], [1024], [1024], [1024], [1024], [], [], []]", 56, 4745, 4745, 29173, 43519], ["aten::threshold_backward", "[[32, 1024, 14, 14], [32, 1024, 14, 14], []]", 48, 4618, 4618, 6527, 8551], ["aten::threshold_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], []]", 48, 4472, 4472, 6542, 8646], ["aten::add_", "[[32, 1024, 14, 14], [32, 1024, 14, 14], []]", 48, 4416, 4416, 7272, 7272], ["aten::cudnn_batch_norm_backward", "[[32, 256, 14, 14], [32, 256, 14, 14], [256], [256], [256], [256], [256], [], [0]]", 88, 4201, 4201, 32053, 47691], ["aten::threshold_", "[[32, 512, 28, 28], [], []]", 32, 4061, 4061, 1871, 1871], ["aten::cudnn_batch_norm", "[[32, 64, 112, 112], [64], [64], [64], [64], [], [], []]", 8, 3412, 3412, 76508, 78500], ["aten::cudnn_convolution", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], []]", 8, 3121, 3121, 7955, 9177], ["aten::threshold_", "[[32, 1024, 14, 14], [], []]", 48, 3034, 3034, 2910, 2910], ["aten::threshold_", "[[32, 64, 56, 56], [], []]", 48, 3031, 3031, 2944, 2944], ["aten::threshold_backward", "[[32, 64, 112, 112], [32, 64, 112, 112], []]", 8, 2963, 2963, 1086, 1420], ["aten::cudnn_batch_norm", "[[32, 128, 28, 28], [128], [128], [128], [128], [], [], []]", 56, 2922, 2922, 28257, 42081], ["aten::cudnn_batch_norm_backward", "[[32, 128, 56, 56], [32, 128, 56, 56], [128], [128], [128], [128], [128], [], [0]]", 8, 2764, 2764, 2808, 4183], ["aten::threshold_backward", "[[32, 128, 28, 28], [32, 128, 28, 28], []]", 56, 2753, 2753, 7511, 10244], ["aten::cudnn_convolution_backward_input", "[[], [32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], []]", 8, 2729, 2729, 7875, 9163], ["aten::threshold_backward", "[[32, 256, 14, 14], [32, 256, 14, 14], []]", 88, 2461, 2461, 12074, 15908], ["aten::add_", "[[512, 512, 3, 3], [512, 512, 3, 3], []]", 66, 2357, 2357, 6121, 6121], ["aten::cudnn_batch_norm_backward", "[[32, 2048, 7, 7], [32, 2048, 7, 7], [2048], [2048], [2048], [2048], [2048], [], [0]]", 32, 2351, 2351, 14339, 20298], ["aten::cudnn_batch_norm", "[[32, 256, 14, 14], [256], [256], [256], [256], [], [], []]", 88, 1995, 1995, 45465, 67934], ["aten::threshold_", "[[32, 64, 112, 112], [], []]", 8, 1993, 1993, 590, 590], ["aten::threshold_", "[[32, 128, 28, 28], [], []]", 56, 1852, 1852, 3373, 3373], ["aten::cudnn_batch_norm", "[[32, 2048, 7, 7], [2048], [2048], [2048], [2048], [], [], []]", 32, 1797, 1797, 16101, 24117], ["aten::max_pool2d_with_indices", "[[32, 64, 112, 112], [], [], [], [], []]", 8, 1788, 1788, 3373, 4772], ["aten::cudnn_batch_norm", "[[32, 128, 56, 56], [128], [128], [128], [128], [], [], []]", 8, 1580, 1580, 4130, 6159], ["aten::add_", "[[256], [256], []]", 704, 1496, 1496, 67611, 67611], ["aten::threshold_backward", "[[32, 128, 56, 56], [32, 128, 56, 56], []]", 8, 1478, 1478, 1073, 1422], ["aten::cudnn_batch_norm_backward", "[[32, 256, 28, 28], [32, 256, 28, 28], [256], [256], [256], [256], [256], [], [0]]", 8, 1329, 1329, 2897, 4306], ["aten::fill_", "[[32, 64, 112, 112], []]", 8, 1285, 1285, 449, 449], ["aten::threshold_backward", "[[32, 2048, 7, 7], [32, 2048, 7, 7], []]", 24, 1213, 1213, 3406, 4393], ["aten::add_", "[[32, 2048, 7, 7], [32, 2048, 7, 7], []]", 24, 1136, 1136, 3427, 3427], ["aten::threshold_", "[[32, 256, 14, 14], [], []]", 88, 1037, 1037, 5350, 5350], ["aten::threshold_", "[[32, 128, 56, 56], [], []]", 8, 1005, 1005, 482, 482], ["aten::add_", "[[512], [512], []]", 484, 977, 977, 45191, 45191], ["aten::add_", "[[2048, 512, 1, 1], [2048, 512, 1, 1], []]", 66, 925, 925, 6113, 6113], ["aten::add_", "[[256, 256, 3, 3], [256, 256, 3, 3], []]", 132, 923, 923, 12468, 12468], ["aten::cudnn_batch_norm_backward", "[[32, 512, 7, 7], [32, 512, 7, 7], [512], [512], [512], [512], [512], [], [0]]", 40, 918, 918, 14397, 21421], ["aten::add", "[[512, 512, 3, 3], [512, 512, 3, 3], []]", 24, 840, 840, 3218, 4263], ["aten::cudnn_batch_norm", "[[32, 256, 28, 28], [256], [256], [256], [256], [], [], []]", 8, 826, 826, 3969, 5922], ["aten::threshold_", "[[32, 2048, 7, 7], [], []]", 24, 797, 797, 1403, 1403], ["aten::threshold_backward", "[[32, 256, 28, 28], [32, 256, 28, 28], []]", 8, 768, 768, 1117, 1465], ["aten::cudnn_batch_norm_backward", "[[32, 512, 14, 14], [32, 512, 14, 14], [512], [512], [512], [512], [512], [], [0]]", 8, 753, 753, 2857, 4239], ["aten::add_", "[[128], [128], []]", 352, 733, 733, 33907, 33907], ["aten::add_", "[[2048, 1024, 1, 1], [2048, 1024, 1, 1], []]", 22, 705, 705, 2159, 2159], ["aten::add_", "[[1000, 2048], [1000, 2048], []]", 22, 675, 675, 2037, 2037], ["aten::threshold_backward", "[[32, 512, 7, 7], [32, 512, 7, 7], []]", 40, 652, 652, 5403, 7057], ["aten::add_", "[[1024], [1024], []]", 308, 649, 649, 28888, 28888], ["aten::add_", "[[512, 2048, 1, 1], [512, 2048, 1, 1], []]", 44, 645, 645, 4092, 4092], ["aten::cudnn_batch_norm", "[[32, 512, 7, 7], [512], [512], [512], [512], [], [], []]", 40, 631, 631, 20713, 30537], ["aten::add_", "[[64], [64], []]", 308, 628, 628, 29177, 29177], ["aten::threshold_", "[[32, 256, 28, 28], [], []]", 8, 505, 505, 492, 492], ["aten::mul_", "[[512, 512, 3, 3], []]", 21, 500, 500, 2206, 2206], ["aten::add_", "[[1024, 256, 1, 1], [1024, 256, 1, 1], []]", 132, 498, 498, 12531, 12531], ["aten::add", "[[256, 256, 3, 3], [256, 256, 3, 3], []]", 48, 480, 480, 6546, 8837], ["aten::add_", "[[256, 1024, 1, 1], [256, 1024, 1, 1], []]", 110, 478, 478, 10443, 10443], ["aten::add", "[[], [], []]", 424, 454, 454, 61742, 80042], ["aten::copy_", "[[256], [256], []]", 320, 428, 428, 30698, 30698], ["aten::copy_", "[[], [], []]", 1192, 424, 424, 70639, 70639], ["aten::threshold_backward", "[[32, 512, 14, 14], [32, 512, 14, 14], []]", 8, 407, 407, 1071, 1397], ["aten::_cat", "[[], []]", 24, 392, 392, 2875436, 2886103], ["aten::add", "[[2048, 512, 1, 1], [2048, 512, 1, 1], []]", 24, 386, 386, 3177, 4188], ["aten::cudnn_batch_norm", "[[32, 512, 14, 14], [512], [512], [512], [512], [], [], []]", 8, 371, 371, 4031, 6330], ["aten::add_", "[[2048], [2048], []]", 176, 365, 365, 17038, 17038], ["aten::mean", "[[32, 2048, 7, 7], [], [], []]", 8, 345, 345, 5157, 5519], ["aten::fill_", "[[512, 512, 3, 3], []]", 21, 315, 315, 1062, 1062], ["aten::add_", "[[128, 128, 3, 3], [128, 128, 3, 3], []]", 88, 290, 290, 8282, 8282], ["aten::addmm", "[[1000], [32, 2048], [2048, 1000], [], []]", 8, 275, 275, 483411, 486833], ["aten::threshold_", "[[32, 512, 7, 7], [], []]", 40, 273, 273, 2473, 2473], ["aten::copy_", "[[512], [512], []]", 220, 268, 268, 21068, 21068], ["aten::mul_", "[[256, 256, 3, 3], []]", 42, 259, 259, 4437, 4437], ["aten::add", "[[256], [256], []]", 256, 256, 256, 34954, 45441], ["aten::add", "[[512, 2048, 1, 1], [512, 2048, 1, 1], []]", 16, 256, 256, 2084, 2745], ["aten::add", "[[2048, 1024, 1, 1], [2048, 1024, 1, 1], []]", 8, 248, 248, 1042, 1371], ["aten::add", "[[1000, 2048], [1000, 2048], []]", 8, 243, 243, 1037, 1354], ["aten::threshold_", "[[32, 512, 14, 14], [], []]", 8, 242, 242, 475, 475], ["aten::add", "[[1024, 256, 1, 1], [1024, 256, 1, 1], []]", 48, 237, 237, 6479, 8473], ["aten::mm", "[[32, 1000], [1000, 2048]]", 8, 234, 234, 2412, 2903], ["aten::div", "[[32, 2048, 7, 7], []]", 8, 234, 234, 1614, 1954], ["aten::mul_", "[[2048, 512, 1, 1], []]", 21, 231, 231, 2192, 2192], ["aten::mul_", "[[256], []]", 224, 224, 224, 23038, 23038], ["aten::copy_", "[[1024], [1024], []]", 140, 205, 205, 13333, 13333], ["aten::copy_", "[[128], [128], []]", 160, 198, 198, 15147, 15147], ["aten::add_", "[[256, 64, 1, 1], [256, 64, 1, 1], []]", 88, 198, 198, 9488, 9488], ["aten::add_", "[[512, 128, 1, 1], [512, 128, 1, 1], []]", 88, 197, 197, 8439, 8439], ["aten::add", "[[512], [512], []]", 176, 176, 176, 23422, 30504], ["aten::add", "[[256, 1024, 1, 1], [256, 1024, 1, 1], []]", 40, 174, 174, 5529, 7200], ["aten::copy_", "[[512, 512, 3, 3], [512, 512, 3, 3], []]", 6, 174, 174, 593, 593], ["aten::fill_", "[[256, 256, 3, 3], []]", 42, 168, 168, 2096, 2096], ["aten::add_", "[[512, 1024, 1, 1], [512, 1024, 1, 1], []]", 22, 156, 156, 2061, 2061], ["aten::mul_", "[[512], []]", 154, 154, 154, 15887, 15887], ["aten::mul_", "[[512, 2048, 1, 1], []]", 14, 152, 152, 1452, 1452], ["aten::mm", "[[1000, 32], [32, 2048]]", 8, 152, 152, 1409, 1907], ["aten::add_", "[[128, 512, 1, 1], [128, 512, 1, 1], []]", 66, 151, 151, 6277, 6277], ["aten::mul_", "[[2048, 1024, 1, 1], []]", 7, 149, 149, 740, 740], ["aten::copy_", "[[64], [64], []]", 140, 148, 148, 13732, 13732], ["aten::fill_", "[[2048, 512, 1, 1], []]", 21, 147, 147, 1030, 1030], ["aten::mul_", "[[1000, 2048], []]", 7, 147, 147, 741, 741], ["aten::add_", "[[64, 64, 3, 3], [64, 64, 3, 3], []]", 66, 140, 140, 6325, 6325], ["aten::mul_", "[[1024, 256, 1, 1], []]", 42, 133, 133, 4438, 4438], ["aten::add", "[[128], [128], []]", 128, 128, 128, 17363, 22798], ["aten::add_", "[[1024, 512, 1, 1], [1024, 512, 1, 1], []]", 22, 128, 128, 2094, 2094], ["aten::add", "[[64], [64], []]", 112, 112, 112, 15467, 19986], ["aten::add", "[[1024], [1024], []]", 112, 112, 112, 15173, 19580], ["aten::mul_", "[[128], []]", 112, 112, 112, 11420, 11420], ["aten::mul_", "[[256, 1024, 1, 1], []]", 35, 108, 108, 3755, 3755], ["aten::fill_", "[[256], []]", 224, 106, 106, 11344, 11344], ["aten::copy_", "[[2048], [2048], []]", 80, 98, 98, 7668, 7668], ["aten::fill_", "[[512, 2048, 1, 1], []]", 14, 98, 98, 683, 683], ["aten::mul_", "[[64], []]", 98, 98, 98, 10373, 10373], ["aten::mul_", "[[1024], []]", 98, 98, 98, 10255, 10255], ["aten::fill_", "[[512], []]", 154, 92, 92, 7673, 7673], ["aten::fill_", "[[2048, 1024, 1, 1], []]", 7, 91, 91, 342, 342], ["aten::fill_", "[[1000, 2048], []]", 7, 91, 91, 347, 347], ["aten::add", "[[128, 128, 3, 3], [128, 128, 3, 3], []]", 32, 88, 88, 4532, 5894], ["aten::fill_", "[[1024, 256, 1, 1], []]", 42, 84, 84, 2141, 2141], ["aten::fill_", "[[128], []]", 112, 83, 83, 5627, 5627], ["aten::_log_softmax_backward_data", "[[32, 1000], [32, 1000], [], [32, 1000]]", 8, 83, 83, 1210, 2171], ["aten::_log_softmax", "[[32, 1000], [], []]", 8, 81, 81, 1877, 2731], ["aten::copy_", "[[256, 256, 3, 3], [256, 256, 3, 3], []]", 12, 78, 78, 1115, 1115], ["aten::add_", "[[256, 512, 1, 1], [256, 512, 1, 1], []]", 22, 75, 75, 2464, 2464], ["aten::add_", "[[64, 256, 1, 1], [64, 256, 1, 1], []]", 44, 74, 74, 4118, 4118], ["aten::add_", "[[512, 256, 1, 1], [512, 256, 1, 1], []]", 22, 73, 73, 2078, 2078], ["aten::add", "[[1024, 512, 1, 1], [1024, 512, 1, 1], []]", 8, 73, 73, 1083, 1412], ["aten::add", "[[512, 1024, 1, 1], [512, 1024, 1, 1], []]", 8, 72, 72, 1076, 1404], ["aten::fill_", "[[256, 1024, 1, 1], []]", 35, 70, 70, 1739, 1739], ["aten::copy_", "[[2048, 512, 1, 1], [2048, 512, 1, 1], []]", 6, 68, 68, 651, 651], ["aten::add", "[[512, 128, 1, 1], [512, 128, 1, 1], []]", 32, 66, 66, 4342, 5673], ["aten::add", "[[2048], [2048], []]", 64, 64, 64, 8494, 11650], ["aten::fill_", "[[1024], []]", 98, 63, 63, 4927, 4927], ["aten::copy_", "[[1024, 256, 1, 1], [1024, 256, 1, 1], []]", 12, 59, 59, 1191, 1191], ["aten::copy_", "[[512, 2048, 1, 1], [512, 2048, 1, 1], []]", 4, 57, 57, 364, 364], ["aten::mul_", "[[128, 128, 3, 3], []]", 28, 56, 56, 3027, 3027], ["aten::mul_", "[[2048], []]", 56, 56, 56, 5629, 5629], ["aten::fill_", "[[64], []]", 98, 50, 50, 4943, 4943], ["aten::add_", "[[64, 64, 1, 1], [64, 64, 1, 1], []]", 22, 48, 48, 2105, 2105], ["aten::add", "[[128, 512, 1, 1], [128, 512, 1, 1], []]", 24, 48, 48, 3286, 4267], ["aten::copy_", "[[2048, 1024, 1, 1], [2048, 1024, 1, 1], []]", 2, 48, 48, 238, 238], ["aten::copy_", "[[256, 1024, 1, 1], [256, 1024, 1, 1], []]", 10, 46, 46, 1447, 1447], ["aten::copy_", "[[1000, 2048], [1000, 2048], []]", 2, 46, 46, 223, 223], ["aten::add_", "[[128, 256, 1, 1], [128, 256, 1, 1], []]", 22, 45, 45, 2073, 2073], ["aten::add_", "[[64, 3, 7, 7], [64, 3, 7, 7], []]", 22, 42, 42, 2156, 2156], ["aten::mul_", "[[1024, 512, 1, 1], []]", 7, 39, 39, 735, 735], ["aten::mul_", "[[512, 1024, 1, 1], []]", 7, 36, 36, 721, 721], ["aten::add", "[[256, 64, 1, 1], [256, 64, 1, 1], []]", 32, 34, 34, 4418, 5787], ["aten::nll_loss_forward", "[[32, 1000], [32], [], [], []]", 8, 33, 33, 1977, 1977], ["aten::fill_", "[[256, 64, 1, 1], []]", 28, 28, 28, 1382, 1382], ["aten::fill_", "[[128, 128, 3, 3], []]", 28, 28, 28, 1382, 1382], ["aten::fill_", "[[512, 128, 1, 1], []]", 28, 28, 28, 1385, 1385], ["aten::fill_", "[[1024, 512, 1, 1], []]", 7, 28, 28, 343, 343], ["aten::fill_", "[[512, 1024, 1, 1], []]", 7, 28, 28, 395, 395], ["aten::mul_", "[[256, 64, 1, 1], []]", 28, 28, 28, 3052, 3052], ["aten::mul_", "[[512, 128, 1, 1], []]", 28, 28, 28, 3058, 3058], ["aten::add", "[[64, 64, 3, 3], [64, 64, 3, 3], []]", 24, 26, 26, 3238, 4263], ["aten::copy_", "[[32], [32], []]", 16, 25, 25, 1713, 1713], ["aten::add", "[[512, 256, 1, 1], [512, 256, 1, 1], []]", 8, 24, 24, 1147, 1490], ["aten::add", "[[256, 512, 1, 1], [256, 512, 1, 1], []]", 8, 24, 24, 1216, 1546], ["aten::nll_loss_backward", "[[], [32, 1000], [32], [], [], [], []]", 8, 24, 24, 1398, 1398], ["aten::add_", "[[1000], [1000], []]", 22, 22, 22, 2093, 2093], ["aten::fill_", "[[64, 64, 3, 3], []]", 21, 21, 21, 1134, 1134], ["aten::fill_", "[[128, 512, 1, 1], []]", 21, 21, 21, 1028, 1028], ["aten::mul_", "[[64, 64, 3, 3], []]", 21, 21, 21, 2246, 2246], ["aten::mul_", "[[128, 512, 1, 1], []]", 21, 21, 21, 2292, 2292], ["aten::copy_", "[[128, 128, 3, 3], [128, 128, 3, 3], []]", 8, 19, 19, 753, 753], ["aten::fill_", "[[2048], []]", 56, 19, 19, 3181, 3181], ["aten::add", "[[64, 256, 1, 1], [64, 256, 1, 1], []]", 16, 16, 16, 2166, 2835], ["aten::mul_", "[[512, 256, 1, 1], []]", 7, 16, 16, 741, 741], ["aten::mul_", "[[256, 512, 1, 1], []]", 7, 15, 15, 869, 869], ["aten::fill_", "[[64, 256, 1, 1], []]", 14, 14, 14, 686, 686], ["aten::mul_", "[[64, 256, 1, 1], []]", 14, 14, 14, 1501, 1501], ["aten::_local_scalar_dense", "[[]]", 1485, 12, 12, 32202, 32202], ["aten::copy_", "[[256, 64, 1, 1], [256, 64, 1, 1], []]", 8, 12, 12, 773, 773], ["aten::copy_", "[[512, 1024, 1, 1], [512, 1024, 1, 1], []]", 2, 11, 11, 200, 200], ["aten::copy_", "[[1024, 512, 1, 1], [1024, 512, 1, 1], []]", 2, 10, 10, 225, 225], ["aten::copy_", "[[512, 128, 1, 1], [512, 128, 1, 1], []]", 8, 9, 9, 740, 740], ["aten::copy_", "[[128, 512, 1, 1], [128, 512, 1, 1], []]", 6, 9, 9, 579, 579], ["aten::fill_", "[[], []]", 8, 8, 8, 479, 479], ["aten::add", "[[64, 3, 7, 7], [64, 3, 7, 7], []]", 8, 8, 8, 1228, 1592], ["aten::add", "[[64, 64, 1, 1], [64, 64, 1, 1], []]", 8, 8, 8, 1088, 1432], ["aten::add", "[[128, 256, 1, 1], [128, 256, 1, 1], []]", 8, 8, 8, 1135, 1473], ["aten::add", "[[1000], [1000], []]", 8, 8, 8, 1059, 1376], ["aten::fill_", "[[64, 3, 7, 7], []]", 7, 7, 7, 412, 412], ["aten::fill_", "[[128, 256, 1, 1], []]", 7, 7, 7, 355, 355], ["aten::fill_", "[[512, 256, 1, 1], []]", 7, 7, 7, 383, 383], ["aten::fill_", "[[256, 512, 1, 1], []]", 7, 7, 7, 343, 343], ["aten::fill_", "[[1000], []]", 7, 7, 7, 363, 363], ["aten::mul_", "[[64, 3, 7, 7], []]", 7, 7, 7, 824, 824], ["aten::mul_", "[[64, 64, 1, 1], []]", 7, 7, 7, 754, 754], ["aten::mul_", "[[128, 256, 1, 1], []]", 7, 7, 7, 747, 747], ["aten::mul_", "[[1000], []]", 7, 7, 7, 716, 716], ["aten::copy_", "[[64, 64, 3, 3], [64, 64, 3, 3], []]", 6, 6, 6, 546, 546], ["aten::copy_", "[[64, 256, 1, 1], [64, 256, 1, 1], []]", 4, 5, 5, 384, 384], ["aten::copy_", "[[128, 256, 1, 1], [128, 256, 1, 1], []]", 2, 5, 5, 186, 186], ["aten::copy_", "[[256, 512, 1, 1], [256, 512, 1, 1], []]", 2, 5, 5, 190, 190], ["aten::fill_", "[[64, 64, 1, 1], []]", 7, 4, 4, 357, 357], ["aten::copy_", "[[64, 64, 1, 1], [64, 64, 1, 1], []]", 2, 3, 3, 202, 202], ["aten::copy_", "[[512, 256, 1, 1], [512, 256, 1, 1], []]", 2, 3, 3, 187, 187], ["aten::copy_", "[[162], [162], []]", 2, 3, 3, 7810, 7810], ["aten::copy_", "[[5], [5], []]", 2, 3, 3, 238, 238], ["aten::copy_", "[[64, 3, 7, 7], [64, 3, 7, 7], []]", 2, 2, 2, 189, 189], ["aten::copy_", "[[1000], [1000], []]", 2, 2, 2, 198, 198], ["aten::empty", "[[], [], [], [], [], []]", 13220, 0, 0, 434482, 434482], ["aten::random_", "[[], []]", 1, 0, 0, 79, 79], ["aten::is_floating_point", "[[]]", 9, 0, 0, 125, 125], ["aten::item", "[[]]", 1485, 0, 12, 36456, 68658], ["aten::fill_", "[[1], []]", 280, 0, 0, 5104, 5104], ["aten::zero_", "[[1]]", 24, 0, 0, 754, 1119], ["aten::zeros", "[[], [], [], [], []]", 24, 0, 0, 1712, 3369], ["aten::uniform_", "[[1], [], [], []]", 964, 0, 0, 57045, 57045], ["aten::is_floating_point", "[[1]]", 1220, 0, 0, 14437, 14437], ["aten::_local_scalar_dense", "[[1]]", 1476, 0, 0, 45078, 45078], ["aten::item", "[[1]]", 1476, 0, 0, 31075, 76153], ["aten::to", "[[2], [], [], [], [], []]", 354, 0, 0, 5514, 5514], ["detach_", "[[2]]", 354, 0, 0, 4560, 4560], ["aten::detach_", "[[2]]", 354, 0, 0, 6662, 11222], ["aten::log", "[[2]]", 354, 0, 0, 34721, 41501], ["aten::as_strided", "[[2], [], [], []]", 708, 0, 0, 10481, 10481], ["aten::select", "[[2], [], []]", 708, 0, 0, 68648, 79129], ["aten::resize_", "[[0], [], []]", 1170, 0, 0, 25215, 25215], ["aten::exp", "[[0], [1]]", 354, 0, 0, 20475, 26496], ["aten::exp", "[[1]]", 354, 0, 0, 32076, 65339], ["aten::random_", "[[1], [], [], []]", 512, 0, 0, 16595, 16595], ["aten::randint", "[[], [], [], [], [], [], [], []]", 512, 0, 0, 33156, 61402], ["aten::rand", "[[], [], [], [], []]", 256, 0, 0, 18218, 33177], ["aten::empty_strided", "[[], [], [], [], [], []]", 1626, 0, 0, 58780, 58780], ["aten::to", "[[], [], [], [], []]", 768, 0, 0, 57406, 104270], ["aten::lt", "[[0], [1], []]", 256, 0, 0, 26388, 72723], ["aten::lt", "[[1], []]", 256, 0, 0, 28279, 105124], ["aten::is_nonzero", "[[1]]", 256, 0, 0, 5905, 19211], ["aten::set_", "[[], []]", 256, 0, 0, 18344, 18344], ["aten::view", "[[150528], []]", 256, 0, 0, 17872, 17872], ["aten::as_strided", "[[224, 224, 3], [], [], []]", 256, 0, 0, 4372, 4372], ["aten::permute", "[[224, 224, 3], []]", 256, 0, 0, 23020, 27392], ["aten::empty_like", "[[3, 224, 224], [], [], [], [], []]", 256, 0, 0, 11847, 17320], ["aten::copy_", "[[3, 224, 224], [3, 224, 224], []]", 768, 0, 0, 3853109, 3853109], ["aten::contiguous", "[[3, 224, 224], []]", 256, 0, 0, 13716, 1064623], ["aten::to", "[[3, 224, 224], [], [], [], []]", 256, 0, 0, 19366, 1939754], ["aten::div", "[[3, 224, 224], []]", 256, 0, 0, 951492, 992662], ["aten::clone", "[[3, 224, 224], []]", 256, 0, 0, 36176, 948948], ["aten::to", "[[3], [], [], [], [], []]", 512, 0, 0, 7877, 7877], ["aten::eq", "[[0], [3], []]", 256, 0, 0, 29130, 79545], ["aten::eq", "[[3], []]", 256, 0, 0, 26434, 110976], ["aten::as_strided", "[[], [], [], []]", 256, 0, 0, 4063, 4063], ["aten::any", "[[3]]", 256, 0, 0, 43695, 64036], ["aten::is_nonzero", "[[]]", 256, 0, 0, 6950, 20905], ["aten::view", "[[3], []]", 512, 0, 0, 34757, 34757], ["aten::sub_", "[[3, 224, 224], [3, 1, 1], []]", 256, 0, 0, 796119, 796119], ["aten::div_", "[[3, 224, 224], [3, 1, 1]]", 256, 0, 0, 966065, 966065], ["aten::as_strided", "[[3, 224, 224], [], [], []]", 256, 0, 0, 3232, 3232], ["aten::unsqueeze", "[[3, 224, 224], []]", 256, 0, 0, 9977, 13209], ["aten::as_strided", "[[32, 3, 224, 224], [], [], []]", 8, 0, 0, 116, 116], ["aten::slice", "[[32, 3, 224, 224], [], [], [], []]", 8, 0, 0, 279, 395], ["aten::narrow", "[[32, 3, 224, 224], [], [], []]", 8, 0, 0, 228, 623], ["aten::stride", "[[32, 3, 224, 224], []]", 72, 0, 0, 597, 597], ["aten::cat", "[[], []]", 24, 0, 392, 3294, 2889397], ["aten::stack", "[[], []]", 8, 0, 0, 4630, 804276], ["aten::to", "[[32], [], [], [], [], []]", 8, 0, 0, 201, 201], ["detach_", "[[32]]", 8, 0, 0, 169, 169], ["aten::detach_", "[[32]]", 8, 0, 0, 169, 338], ["aten::is_pinned", "[[32, 3, 224, 224]]", 8, 0, 0, 748, 748], ["aten::set_", "[[0], [], [], [], []]", 16, 0, 0, 957, 957], ["aten::pin_memory", "[[32, 3, 224, 224]]", 8, 0, 0, 18014, 116908], ["aten::is_pinned", "[[32]]", 8, 0, 0, 386, 386], ["aten::pin_memory", "[[32]]", 8, 0, 0, 1518, 3249], ["aten::to", "[[32, 3, 224, 224], [], [], [], [], [], [], []]", 16, 0, 13541, 898, 2830], ["aten::to", "[[32], [], [], [], [], [], [], []]", 8, 0, 25, 640, 2118], ["aten::contiguous", "[[64], []]", 336, 0, 0, 4268, 4268], ["aten::view", "[[64], []]", 336, 0, 0, 16542, 16542], ["aten::contiguous", "[[256], []]", 768, 0, 0, 10404, 10404], ["aten::view", "[[256], []]", 768, 0, 0, 38447, 38447], ["aten::contiguous", "[[128], []]", 384, 0, 0, 4862, 4862], ["aten::view", "[[128], []]", 384, 0, 0, 18412, 18412], ["aten::contiguous", "[[512], []]", 528, 0, 0, 6755, 6755], ["aten::view", "[[512], []]", 528, 0, 0, 26022, 26022], ["aten::contiguous", "[[1024], []]", 336, 0, 0, 4324, 4324], ["aten::view", "[[1024], []]", 336, 0, 0, 16592, 16592], ["aten::contiguous", "[[2048], []]", 192, 0, 0, 2352, 2352], ["aten::view", "[[2048], []]", 192, 0, 0, 9232, 9232], ["aten::stride", "[[64], []]", 112, 0, 0, 784, 784], ["aten::stride", "[[256], []]", 256, 0, 0, 1597, 1597], ["aten::stride", "[[128], []]", 128, 0, 0, 799, 799], ["aten::stride", "[[512], []]", 176, 0, 0, 1117, 1117], ["aten::stride", "[[1024], []]", 112, 0, 0, 705, 705], ["aten::stride", "[[2048], []]", 64, 0, 0, 399, 399], ["aten::stride", "[[53120], []]", 16, 0, 0, 107, 107], ["nccl:broadcast", "[]", 18, 0, 0, 547, 547], ["aten::contiguous", "[[], []]", 424, 0, 0, 6299, 6299], ["aten::view", "[[], []]", 424, 0, 0, 25005, 25005], ["aten::stride", "[[1], []]", 424, 0, 0, 2785, 2785], ["aten::stride", "[[53], []]", 16, 0, 0, 109, 109], ["aten::as_strided", "[[53120], [], [], []]", 848, 0, 0, 12277, 12277], ["aten::slice", "[[53120], [], [], [], []]", 848, 0, 0, 72913, 85190], ["aten::narrow", "[[53120], [], [], []]", 848, 0, 0, 23963, 109153], ["aten::as_strided", "[[53], [], [], []]", 424, 0, 0, 7601, 7601], ["aten::slice", "[[53], [], [], [], []]", 424, 0, 0, 30037, 37638], ["aten::narrow", "[[53], [], [], []]", 424, 0, 0, 12167, 49805], ["aten::view", "[[1], []]", 424, 0, 0, 24509, 24509], ["aten::contiguous", "[[32, 3, 224, 224], []]", 24, 0, 0, 311, 311], ["aten::contiguous", "[[64, 3, 7, 7], []]", 8, 0, 0, 134, 134], ["aten::resize_", "[[64, 3, 7, 7], [], []]", 8, 0, 0, 105, 105], ["aten::resize_", "[[32, 3, 224, 224], [], []]", 16, 0, 0, 166, 166], ["aten::_convolution", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 15106, 928, 1477506], ["aten::convolution", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], []]", 8, 0, 15106, 402, 1477908], ["aten::conv2d", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], []]", 8, 0, 15106, 463, 1478371], ["aten::contiguous", "[[32, 64, 112, 112], []]", 56, 0, 0, 752, 752], ["aten::empty_like", "[[32, 64, 112, 112], [], [], [], [], []]", 16, 0, 0, 801, 1560], ["aten::_batch_norm_impl_index", "[[32, 64, 112, 112], [64], [64], [64], [64], [], [], [], []]", 8, 0, 3412, 1273, 80235], ["aten::batch_norm", "[[32, 64, 112, 112], [64], [64], [64], [64], [], [], [], []]", 8, 0, 3412, 471, 80706], ["aten::relu_", "[[32, 64, 112, 112]]", 8, 0, 1993, 1130, 1720], ["aten::stride", "[[32, 64, 112, 112], []]", 64, 0, 0, 423, 423], ["aten::max_pool2d", "[[32, 64, 112, 112], [], [], [], [], []]", 8, 0, 1788, 488, 5260], ["aten::contiguous", "[[32, 64, 56, 56], []]", 488, 0, 0, 5998, 5998], ["aten::contiguous", "[[64, 64, 1, 1], []]", 16, 0, 0, 241, 241], ["aten::resize_", "[[64, 64, 1, 1], [], []]", 16, 0, 0, 211, 211], ["aten::resize_", "[[32, 64, 56, 56], [], []]", 224, 0, 0, 2402, 2402], ["aten::stride", "[[32, 64, 56, 56], []]", 792, 0, 0, 5698, 5698], ["aten::_convolution", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 3121, 827, 10116], ["aten::convolution", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], []]", 8, 0, 3121, 367, 10483], ["aten::conv2d", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], []]", 8, 0, 3121, 441, 10924], ["aten::empty_like", "[[32, 64, 56, 56], [], [], [], [], []]", 48, 0, 0, 2417, 4546], ["aten::_batch_norm_impl_index", "[[32, 64, 56, 56], [64], [64], [64], [64], [], [], [], []]", 48, 0, 5318, 6858, 46035], ["aten::batch_norm", "[[32, 64, 56, 56], [64], [64], [64], [64], [], [], [], []]", 48, 0, 5318, 2454, 48489], ["aten::relu_", "[[32, 64, 56, 56]]", 48, 0, 3031, 6449, 9393], ["aten::contiguous", "[[64, 64, 3, 3], []]", 48, 0, 0, 816, 816], ["aten::resize_", "[[64, 64, 3, 3], [], []]", 48, 0, 0, 595, 595], ["aten::_convolution", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 24, 0, 14848, 2489, 29087], ["aten::convolution", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], []]", 24, 0, 14848, 1136, 30223], ["aten::conv2d", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], []]", 24, 0, 14848, 1304, 31527], ["aten::contiguous", "[[256, 64, 1, 1], []]", 64, 0, 0, 956, 956], ["aten::resize_", "[[256, 64, 1, 1], [], []]", 64, 0, 0, 819, 819], ["aten::_convolution", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 32, 0, 15748, 3322, 35029], ["aten::convolution", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], []]", 32, 0, 15748, 1520, 36549], ["aten::conv2d", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], []]", 32, 0, 15748, 1719, 38268], ["aten::contiguous", "[[32, 256, 56, 56], []]", 288, 0, 0, 3528, 3528], ["aten::empty_like", "[[32, 256, 56, 56], [], [], [], [], []]", 32, 0, 0, 1616, 3022], ["aten::_batch_norm_impl_index", "[[32, 256, 56, 56], [256], [256], [256], [256], [], [], [], []]", 32, 0, 12813, 4515, 30421], ["aten::batch_norm", "[[32, 256, 56, 56], [256], [256], [256], [256], [], [], [], []]", 32, 0, 12813, 1698, 32119], ["aten::relu_", "[[32, 256, 56, 56]]", 24, 0, 6017, 3041, 4468], ["aten::contiguous", "[[64, 256, 1, 1], []]", 32, 0, 0, 512, 512], ["aten::resize_", "[[64, 256, 1, 1], [], []]", 32, 0, 0, 429, 429], ["aten::resize_", "[[32, 256, 56, 56], [], []]", 128, 0, 0, 1402, 1402], ["aten::stride", "[[32, 256, 56, 56], []]", 384, 0, 0, 2786, 2786], ["aten::_convolution", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 16, 0, 10361, 1643, 21522], ["aten::convolution", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], []]", 16, 0, 10361, 753, 22275], ["aten::conv2d", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], []]", 16, 0, 10361, 842, 23117], ["aten::contiguous", "[[128, 256, 1, 1], []]", 16, 0, 0, 242, 242], ["aten::resize_", "[[128, 256, 1, 1], [], []]", 16, 0, 0, 198, 198], ["aten::_convolution", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 15283, 831, 20179], ["aten::convolution", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], []]", 8, 0, 15283, 382, 20561], ["aten::conv2d", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], []]", 8, 0, 15283, 445, 21006], ["aten::contiguous", "[[32, 128, 56, 56], []]", 72, 0, 0, 893, 893], ["aten::empty_like", "[[32, 128, 56, 56], [], [], [], [], []]", 8, 0, 0, 411, 749], ["aten::_batch_norm_impl_index", "[[32, 128, 56, 56], [128], [128], [128], [128], [], [], [], []]", 8, 0, 1580, 1128, 7735], ["aten::batch_norm", "[[32, 128, 56, 56], [128], [128], [128], [128], [], [], [], []]", 8, 0, 1580, 407, 8142], ["aten::relu_", "[[32, 128, 56, 56]]", 8, 0, 1005, 1016, 1498], ["aten::contiguous", "[[128, 128, 3, 3], []]", 64, 0, 0, 973, 973], ["aten::resize_", "[[128, 128, 3, 3], [], []]", 64, 0, 0, 794, 794], ["aten::resize_", "[[32, 128, 56, 56], [], []]", 32, 0, 0, 369, 369], ["aten::stride", "[[32, 128, 56, 56], []]", 96, 0, 0, 691, 691], ["aten::_convolution", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 9524, 791, 18061], ["aten::convolution", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], [], [], []]", 8, 0, 9524, 374, 18435], ["aten::conv2d", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], []]", 8, 0, 9524, 433, 18868], ["aten::contiguous", "[[32, 128, 28, 28], []]", 504, 0, 0, 6245, 6245], ["aten::empty_like", "[[32, 128, 28, 28], [], [], [], [], []]", 56, 0, 0, 2896, 5464], ["aten::_batch_norm_impl_index", "[[32, 128, 28, 28], [128], [128], [128], [128], [], [], [], []]", 56, 0, 2922, 7976, 53230], ["aten::batch_norm", "[[32, 128, 28, 28], [128], [128], [128], [128], [], [], [], []]", 56, 0, 2922, 2801, 56031], ["aten::relu_", "[[32, 128, 28, 28]]", 56, 0, 1852, 7197, 10570], ["aten::contiguous", "[[512, 128, 1, 1], []]", 64, 0, 0, 995, 995], ["aten::resize_", "[[512, 128, 1, 1], [], []]", 64, 0, 0, 811, 811], ["aten::resize_", "[[32, 128, 28, 28], [], []]", 224, 0, 0, 2438, 2438], ["aten::stride", "[[32, 128, 28, 28], []]", 672, 0, 0, 4757, 4757], ["aten::_convolution", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 32, 0, 17626, 3190, 33015], ["aten::convolution", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], []]", 32, 0, 17626, 1543, 34558], ["aten::conv2d", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], []]", 32, 0, 17626, 1737, 36295], ["aten::contiguous", "[[32, 512, 28, 28], []]", 360, 0, 0, 4830, 4830], ["aten::empty_like", "[[32, 512, 28, 28], [], [], [], [], []]", 40, 0, 0, 2083, 4704], ["aten::_batch_norm_impl_index", "[[32, 512, 28, 28], [512], [512], [512], [512], [], [], [], []]", 40, 0, 8307, 5642, 38810], ["aten::batch_norm", "[[32, 512, 28, 28], [512], [512], [512], [512], [], [], [], []]", 40, 0, 8307, 1996, 40806], ["aten::contiguous", "[[512, 256, 1, 1], []]", 16, 0, 0, 240, 240], ["aten::resize_", "[[512, 256, 1, 1], [], []]", 16, 0, 0, 195, 195], ["aten::_convolution", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 7551, 790, 15553], ["aten::convolution", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], [], [], []]", 8, 0, 7551, 373, 15926], ["aten::conv2d", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], []]", 8, 0, 7551, 420, 16346], ["aten::relu_", "[[32, 512, 28, 28]]", 32, 0, 4061, 4019, 5890], ["aten::contiguous", "[[128, 512, 1, 1], []]", 48, 0, 0, 725, 725], ["aten::resize_", "[[128, 512, 1, 1], [], []]", 48, 0, 0, 754, 754], ["aten::resize_", "[[32, 512, 28, 28], [], []]", 160, 0, 0, 1743, 1743], ["aten::stride", "[[32, 512, 28, 28], []]", 480, 0, 0, 3484, 3484], ["aten::_convolution", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 24, 0, 13429, 2444, 26881], ["aten::convolution", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], []]", 24, 0, 13429, 1233, 28114], ["aten::conv2d", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], []]", 24, 0, 13429, 1298, 29412], ["aten::_convolution", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 24, 0, 11815, 2391, 30796], ["aten::convolution", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], []]", 24, 0, 11815, 1132, 31928], ["aten::conv2d", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], []]", 24, 0, 11815, 1307, 33235], ["aten::contiguous", "[[256, 512, 1, 1], []]", 16, 0, 0, 241, 241], ["aten::resize_", "[[256, 512, 1, 1], [], []]", 16, 0, 0, 198, 198], ["aten::_convolution", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 12689, 813, 18559], ["aten::convolution", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], []]", 8, 0, 12689, 443, 19002], ["aten::conv2d", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], []]", 8, 0, 12689, 416, 19418], ["aten::contiguous", "[[32, 256, 28, 28], []]", 72, 0, 0, 864, 864], ["aten::empty_like", "[[32, 256, 28, 28], [], [], [], [], []]", 8, 0, 0, 401, 739], ["aten::_batch_norm_impl_index", "[[32, 256, 28, 28], [256], [256], [256], [256], [], [], [], []]", 8, 0, 826, 1108, 7493], ["aten::batch_norm", "[[32, 256, 28, 28], [256], [256], [256], [256], [], [], [], []]", 8, 0, 826, 394, 7887], ["aten::relu_", "[[32, 256, 28, 28]]", 8, 0, 505, 1025, 1517], ["aten::contiguous", "[[256, 256, 3, 3], []]", 96, 0, 0, 1462, 1462], ["aten::resize_", "[[256, 256, 3, 3], [], []]", 96, 0, 0, 1217, 1217], ["aten::resize_", "[[32, 256, 28, 28], [], []]", 32, 0, 0, 340, 340], ["aten::stride", "[[32, 256, 28, 28], []]", 96, 0, 0, 677, 677], ["aten::_convolution", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 11264, 803, 12808], ["aten::convolution", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], [], [], []]", 8, 0, 11264, 397, 13205], ["aten::conv2d", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], []]", 8, 0, 11264, 416, 13621], ["aten::contiguous", "[[32, 256, 14, 14], []]", 792, 0, 0, 9864, 9864], ["aten::empty_like", "[[32, 256, 14, 14], [], [], [], [], []]", 88, 0, 0, 4677, 8589], ["aten::_batch_norm_impl_index", "[[32, 256, 14, 14], [256], [256], [256], [256], [], [], [], []]", 88, 0, 1995, 16996, 90332], ["aten::batch_norm", "[[32, 256, 14, 14], [256], [256], [256], [256], [], [], [], []]", 88, 0, 1995, 4935, 95267], ["aten::relu_", "[[32, 256, 14, 14]]", 88, 0, 1037, 11261, 16611], ["aten::contiguous", "[[1024, 256, 1, 1], []]", 96, 0, 0, 1464, 1464], ["aten::resize_", "[[1024, 256, 1, 1], [], []]", 96, 0, 0, 1209, 1209], ["aten::resize_", "[[32, 256, 14, 14], [], []]", 352, 0, 0, 3876, 3876], ["aten::stride", "[[32, 256, 14, 14], []]", 1056, 0, 0, 7810, 7810], ["aten::_convolution", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 48, 0, 23416, 5086, 43832], ["aten::convolution", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], []]", 48, 0, 23416, 2284, 46116], ["aten::conv2d", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], []]", 48, 0, 23416, 2570, 48686], ["aten::contiguous", "[[32, 1024, 14, 14], []]", 504, 0, 0, 6179, 6179], ["aten::empty_like", "[[32, 1024, 14, 14], [], [], [], [], []]", 56, 0, 0, 2823, 5926], ["aten::_batch_norm_impl_index", "[[32, 1024, 14, 14], [1024], [1024], [1024], [1024], [], [], [], []]", 56, 0, 4745, 7964, 54654], ["aten::batch_norm", "[[32, 1024, 14, 14], [1024], [1024], [1024], [1024], [], [], [], []]", 56, 0, 4745, 2794, 57448], ["aten::contiguous", "[[1024, 512, 1, 1], []]", 16, 0, 0, 245, 245], ["aten::resize_", "[[1024, 512, 1, 1], [], []]", 16, 0, 0, 199, 199], ["aten::_convolution", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 9034, 784, 11394], ["aten::convolution", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], [], [], []]", 8, 0, 9034, 389, 11783], ["aten::conv2d", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], []]", 8, 0, 9034, 423, 12206], ["aten::relu_", "[[32, 1024, 14, 14]]", 48, 0, 3034, 6122, 9032], ["aten::contiguous", "[[256, 1024, 1, 1], []]", 80, 0, 0, 1238, 1238], ["aten::resize_", "[[256, 1024, 1, 1], [], []]", 80, 0, 0, 1410, 1410], ["aten::resize_", "[[32, 1024, 14, 14], [], []]", 224, 0, 0, 2488, 2488], ["aten::stride", "[[32, 1024, 14, 14], []]", 672, 0, 0, 4863, 4863], ["aten::_convolution", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 40, 0, 20489, 4433, 40117], ["aten::convolution", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], []]", 40, 0, 20489, 1946, 42063], ["aten::conv2d", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], []]", 40, 0, 20489, 2156, 44219], ["aten::_convolution", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 40, 0, 17078, 4138, 42243], ["aten::convolution", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], []]", 40, 0, 17078, 1897, 44140], ["aten::conv2d", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], []]", 40, 0, 17078, 2218, 46358], ["aten::contiguous", "[[512, 1024, 1, 1], []]", 16, 0, 0, 241, 241], ["aten::resize_", "[[512, 1024, 1, 1], [], []]", 16, 0, 0, 200, 200], ["aten::_convolution", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 14809, 821, 19882], ["aten::convolution", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 0, 14809, 369, 20251], ["aten::conv2d", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], []]", 8, 0, 14809, 431, 20682], ["aten::contiguous", "[[32, 512, 14, 14], []]", 72, 0, 0, 886, 886], ["aten::empty_like", "[[32, 512, 14, 14], [], [], [], [], []]", 8, 0, 0, 398, 734], ["aten::_batch_norm_impl_index", "[[32, 512, 14, 14], [512], [512], [512], [512], [], [], [], []]", 8, 0, 371, 1101, 7869], ["aten::batch_norm", "[[32, 512, 14, 14], [512], [512], [512], [512], [], [], [], []]", 8, 0, 371, 407, 8276], ["aten::relu_", "[[32, 512, 14, 14]]", 8, 0, 242, 1005, 1480], ["aten::contiguous", "[[512, 512, 3, 3], []]", 48, 0, 0, 796, 796], ["aten::resize_", "[[512, 512, 3, 3], [], []]", 48, 0, 0, 601, 601], ["aten::resize_", "[[32, 512, 14, 14], [], []]", 32, 0, 0, 365, 365], ["aten::stride", "[[32, 512, 14, 14], []]", 96, 0, 0, 702, 702], ["aten::_convolution", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 15055, 787, 17067], ["aten::convolution", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], [], [], []]", 8, 0, 15055, 389, 17456], ["aten::conv2d", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], []]", 8, 0, 15055, 531, 17987], ["aten::contiguous", "[[32, 512, 7, 7], []]", 360, 0, 0, 4438, 4438], ["aten::empty_like", "[[32, 512, 7, 7], [], [], [], [], []]", 40, 0, 0, 2044, 3759], ["aten::_batch_norm_impl_index", "[[32, 512, 7, 7], [512], [512], [512], [512], [], [], [], []]", 40, 0, 631, 6001, 38788], ["aten::batch_norm", "[[32, 512, 7, 7], [512], [512], [512], [512], [], [], [], []]", 40, 0, 631, 2000, 40788], ["aten::relu_", "[[32, 512, 7, 7]]", 40, 0, 273, 5321, 7794], ["aten::contiguous", "[[2048, 512, 1, 1], []]", 48, 0, 0, 712, 712], ["aten::resize_", "[[2048, 512, 1, 1], [], []]", 48, 0, 0, 599, 599], ["aten::resize_", "[[32, 512, 7, 7], [], []]", 160, 0, 0, 1758, 1758], ["aten::stride", "[[32, 512, 7, 7], []]", 480, 0, 0, 3833, 3833], ["aten::_convolution", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 24, 0, 20407, 2394, 35292], ["aten::convolution", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], []]", 24, 0, 20407, 1156, 36448], ["aten::conv2d", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], []]", 24, 0, 20407, 1271, 37719], ["aten::contiguous", "[[32, 2048, 7, 7], []]", 240, 0, 0, 3014, 3014], ["aten::empty_like", "[[32, 2048, 7, 7], [], [], [], [], []]", 32, 0, 0, 1631, 3228], ["aten::_batch_norm_impl_index", "[[32, 2048, 7, 7], [2048], [2048], [2048], [2048], [], [], [], []]", 32, 0, 1797, 4493, 30347], ["aten::batch_norm", "[[32, 2048, 7, 7], [2048], [2048], [2048], [2048], [], [], [], []]", 32, 0, 1797, 1649, 31996], ["aten::contiguous", "[[2048, 1024, 1, 1], []]", 16, 0, 0, 236, 236], ["aten::resize_", "[[2048, 1024, 1, 1], [], []]", 16, 0, 0, 276, 276], ["aten::_convolution", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 8, 0, 9055, 798, 13486], ["aten::convolution", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], [], [], []]", 8, 0, 9055, 369, 13855], ["aten::conv2d", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], []]", 8, 0, 9055, 437, 14292], ["aten::relu_", "[[32, 2048, 7, 7]]", 24, 0, 797, 3066, 4469], ["aten::contiguous", "[[512, 2048, 1, 1], []]", 32, 0, 0, 484, 484], ["aten::resize_", "[[512, 2048, 1, 1], [], []]", 32, 0, 0, 396, 396], ["aten::resize_", "[[32, 2048, 7, 7], [], []]", 96, 0, 0, 1060, 1060], ["aten::stride", "[[32, 2048, 7, 7], []]", 192, 0, 0, 1352, 1352], ["aten::_convolution", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 16, 0, 18225, 1709, 30105], ["aten::convolution", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], []]", 16, 0, 18225, 735, 30840], ["aten::conv2d", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], []]", 16, 0, 18225, 911, 31751], ["aten::_convolution", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 16, 0, 15713, 1597, 27880], ["aten::convolution", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], []]", 16, 0, 15713, 738, 28618], ["aten::conv2d", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], []]", 16, 0, 15713, 837, 29455], ["aten::adaptive_avg_pool2d", "[[32, 2048, 7, 7], []]", 8, 0, 345, 413, 5932], ["aten::view", "[[32, 2048, 1, 1], []]", 8, 0, 0, 925, 925], ["aten::reshape", "[[32, 2048, 1, 1], []]", 8, 0, 0, 285, 1210], ["aten::flatten", "[[32, 2048, 1, 1], [], []]", 8, 0, 0, 427, 1637], ["aten::as_strided", "[[1000, 2048], [], [], []]", 16, 0, 0, 268, 268], ["aten::transpose", "[[1000, 2048], [], []]", 16, 0, 0, 574, 842], ["aten::t", "[[1000, 2048]]", 16, 0, 0, 1298, 2140], ["aten::as_strided", "[[1000], [], [], []]", 8, 0, 0, 140, 140], ["aten::expand", "[[1000], [], []]", 8, 0, 0, 409, 549], ["aten::stride", "[[2048, 1000], []]", 8, 0, 0, 111, 111], ["aten::stride", "[[32, 2048], []]", 24, 0, 0, 192, 192], ["aten::stride", "[[32, 1000], []]", 16, 0, 0, 98, 98], ["aten::contiguous", "[[32, 1000], []]", 24, 0, 0, 316, 316], ["aten::empty_like", "[[32, 1000], [], [], [], [], []]", 16, 0, 0, 801, 1499], ["aten::log_softmax", "[[32, 1000], [], []]", 8, 0, 81, 440, 3171], ["aten::nll_loss", "[[32, 1000], [32], [], [], []]", 8, 0, 33, 450, 2427], ["aten::empty_like", "[[], [], [], [], [], []]", 8, 0, 0, 449, 861], ["aten::ones_like", "[[], [], [], [], [], []]", 8, 0, 8, 572, 1912], ["aten::clone", "[[64, 3, 7, 7], []]", 1, 0, 1, 140, 282], ["detach", "[[64, 3, 7, 7]]", 1, 0, 0, 19, 19], ["aten::detach", "[[64, 3, 7, 7]]", 1, 0, 0, 29, 48], ["aten::clone", "[[64], []]", 14, 0, 14, 1932, 3797], ["detach", "[[64]]", 14, 0, 0, 262, 262], ["aten::detach", "[[64]]", 14, 0, 0, 382, 644], ["aten::clone", "[[64, 64, 1, 1], []]", 1, 0, 1, 135, 271], ["detach", "[[64, 64, 1, 1]]", 1, 0, 0, 18, 18], ["aten::detach", "[[64, 64, 1, 1]]", 1, 0, 0, 28, 46], ["aten::clone", "[[64, 64, 3, 3], []]", 3, 0, 3, 428, 837], ["detach", "[[64, 64, 3, 3]]", 3, 0, 0, 55, 55], ["aten::detach", "[[64, 64, 3, 3]]", 3, 0, 0, 86, 141], ["aten::clone", "[[256, 64, 1, 1], []]", 4, 0, 4, 563, 1136], ["detach", "[[256, 64, 1, 1]]", 4, 0, 0, 72, 72], ["aten::detach", "[[256, 64, 1, 1]]", 4, 0, 0, 116, 188], ["aten::clone", "[[256], []]", 32, 0, 32, 4405, 8735], ["detach", "[[256]]", 32, 0, 0, 584, 584], ["aten::detach", "[[256]]", 32, 0, 0, 940, 1524], ["aten::clone", "[[64, 256, 1, 1], []]", 2, 0, 2, 269, 560], ["detach", "[[64, 256, 1, 1]]", 2, 0, 0, 37, 37], ["aten::detach", "[[64, 256, 1, 1]]", 2, 0, 0, 54, 91], ["aten::clone", "[[128, 256, 1, 1], []]", 1, 0, 1, 143, 1049], ["detach", "[[128, 256, 1, 1]]", 1, 0, 0, 18, 18], ["aten::detach", "[[128, 256, 1, 1]]", 1, 0, 0, 29, 47], ["aten::clone", "[[128], []]", 16, 0, 16, 2180, 4424], ["detach", "[[128]]", 16, 0, 0, 288, 288], ["aten::detach", "[[128]]", 16, 0, 0, 463, 751], ["aten::clone", "[[128, 128, 3, 3], []]", 4, 0, 8, 546, 1333], ["detach", "[[128, 128, 3, 3]]", 4, 0, 0, 74, 74], ["aten::detach", "[[128, 128, 3, 3]]", 4, 0, 0, 109, 183], ["aten::clone", "[[512, 128, 1, 1], []]", 4, 0, 4, 544, 1106], ["detach", "[[512, 128, 1, 1]]", 4, 0, 0, 75, 75], ["aten::detach", "[[512, 128, 1, 1]]", 4, 0, 0, 106, 181], ["aten::clone", "[[512], []]", 22, 0, 22, 2987, 5951], ["detach", "[[512]]", 22, 0, 0, 393, 393], ["aten::detach", "[[512]]", 22, 0, 0, 611, 1004], ["aten::clone", "[[512, 256, 1, 1], []]", 1, 0, 1, 139, 519], ["detach", "[[512, 256, 1, 1]]", 1, 0, 0, 19, 19], ["aten::detach", "[[512, 256, 1, 1]]", 1, 0, 0, 28, 47], ["aten::clone", "[[128, 512, 1, 1], []]", 3, 0, 3, 439, 859], ["detach", "[[128, 512, 1, 1]]", 3, 0, 0, 57, 57], ["aten::detach", "[[128, 512, 1, 1]]", 3, 0, 0, 81, 138], ["aten::clone", "[[256, 512, 1, 1], []]", 1, 0, 2, 138, 503], ["detach", "[[256, 512, 1, 1]]", 1, 0, 0, 19, 19], ["aten::detach", "[[256, 512, 1, 1]]", 1, 0, 0, 27, 46], ["aten::clone", "[[256, 256, 3, 3], []]", 6, 0, 19, 835, 1663], ["detach", "[[256, 256, 3, 3]]", 6, 0, 0, 111, 111], ["aten::detach", "[[256, 256, 3, 3]]", 6, 0, 0, 158, 269], ["aten::clone", "[[1024, 256, 1, 1], []]", 6, 0, 13, 830, 3087], ["detach", "[[1024, 256, 1, 1]]", 6, 0, 0, 114, 114], ["aten::detach", "[[1024, 256, 1, 1]]", 6, 0, 0, 162, 276], ["aten::clone", "[[1024], []]", 14, 0, 14, 1906, 3826], ["detach", "[[1024]]", 14, 0, 0, 249, 249], ["aten::detach", "[[1024]]", 14, 0, 0, 388, 637], ["aten::clone", "[[1024, 512, 1, 1], []]", 1, 0, 3, 138, 269], ["detach", "[[1024, 512, 1, 1]]", 1, 0, 0, 19, 19], ["aten::detach", "[[1024, 512, 1, 1]]", 1, 0, 0, 27, 46], ["aten::clone", "[[256, 1024, 1, 1], []]", 5, 0, 10, 712, 1381], ["detach", "[[256, 1024, 1, 1]]", 5, 0, 0, 92, 92], ["aten::detach", "[[256, 1024, 1, 1]]", 5, 0, 0, 142, 234], ["aten::clone", "[[512, 1024, 1, 1], []]", 1, 0, 3, 135, 268], ["detach", "[[512, 1024, 1, 1]]", 1, 0, 0, 18, 18], ["aten::detach", "[[512, 1024, 1, 1]]", 1, 0, 0, 28, 46], ["aten::clone", "[[512, 512, 3, 3], []]", 3, 0, 78, 416, 833], ["detach", "[[512, 512, 3, 3]]", 3, 0, 0, 55, 55], ["aten::detach", "[[512, 512, 3, 3]]", 3, 0, 0, 81, 136], ["aten::clone", "[[2048, 512, 1, 1], []]", 3, 0, 30, 413, 826], ["detach", "[[2048, 512, 1, 1]]", 3, 0, 0, 55, 55], ["aten::detach", "[[2048, 512, 1, 1]]", 3, 0, 0, 80, 135], ["aten::clone", "[[2048], []]", 8, 0, 8, 1071, 2183], ["detach", "[[2048]]", 8, 0, 0, 143, 143], ["aten::detach", "[[2048]]", 8, 0, 0, 232, 375], ["aten::clone", "[[2048, 1024, 1, 1], []]", 1, 0, 23, 133, 268], ["detach", "[[2048, 1024, 1, 1]]", 1, 0, 0, 18, 18], ["aten::detach", "[[2048, 1024, 1, 1]]", 1, 0, 0, 27, 45], ["aten::clone", "[[512, 2048, 1, 1], []]", 2, 0, 20, 286, 555], ["detach", "[[512, 2048, 1, 1]]", 2, 0, 0, 36, 36], ["aten::detach", "[[512, 2048, 1, 1]]", 2, 0, 0, 54, 90], ["aten::clone", "[[1000, 2048], []]", 1, 0, 23, 132, 293], ["detach", "[[1000, 2048]]", 1, 0, 0, 18, 18], ["aten::detach", "[[1000, 2048]]", 1, 0, 0, 27, 45], ["aten::clone", "[[1000], []]", 1, 0, 1, 138, 271], ["detach", "[[1000]]", 1, 0, 0, 18, 18], ["aten::detach", "[[1000]]", 1, 0, 0, 27, 45], ["aten::as_strided", "[[2049000], [], [], []]", 2, 0, 0, 172, 172], ["aten::as_strided", "[[7875584], [], [], []]", 15, 0, 0, 1152, 1152], ["aten::as_strided", "[[6563840], [], [], []]", 12, 0, 0, 900, 900], ["aten::as_strided", "[[6637568], [], [], []]", 51, 0, 0, 3745, 3745], ["aten::as_strided", "[[2431040], [], [], []]", 81, 0, 0, 6089, 6089], ["aten::zero_", "[[64, 3, 7, 7]]", 7, 0, 7, 501, 913], ["aten::zero_", "[[64]]", 98, 0, 50, 6705, 11648], ["aten::zero_", "[[64, 64, 1, 1]]", 7, 0, 4, 462, 819], ["aten::zero_", "[[64, 64, 3, 3]]", 21, 0, 21, 1431, 2565], ["aten::zero_", "[[256, 64, 1, 1]]", 28, 0, 28, 1849, 3231], ["aten::zero_", "[[256]]", 224, 0, 106, 15115, 26459], ["aten::zero_", "[[64, 256, 1, 1]]", 14, 0, 14, 1137, 1823], ["aten::zero_", "[[128, 256, 1, 1]]", 7, 0, 7, 459, 814], ["aten::zero_", "[[128]]", 112, 0, 83, 7635, 13262], ["aten::zero_", "[[128, 128, 3, 3]]", 28, 0, 28, 1886, 3268], ["aten::zero_", "[[512, 128, 1, 1]]", 28, 0, 28, 1857, 3242], ["aten::zero_", "[[512]]", 154, 0, 92, 10435, 18108], ["aten::zero_", "[[512, 256, 1, 1]]", 7, 0, 7, 476, 859], ["aten::zero_", "[[128, 512, 1, 1]]", 21, 0, 21, 1434, 2462], ["aten::zero_", "[[256, 512, 1, 1]]", 7, 0, 7, 465, 808], ["aten::zero_", "[[256, 256, 3, 3]]", 42, 0, 168, 2877, 4973], ["aten::zero_", "[[1024, 256, 1, 1]]", 42, 0, 84, 2794, 4935], ["aten::zero_", "[[1024]]", 98, 0, 63, 6684, 11611], ["aten::zero_", "[[1024, 512, 1, 1]]", 7, 0, 28, 466, 809], ["aten::zero_", "[[256, 1024, 1, 1]]", 35, 0, 70, 2361, 4100], ["aten::zero_", "[[512, 1024, 1, 1]]", 7, 0, 28, 473, 868], ["aten::zero_", "[[512, 512, 3, 3]]", 21, 0, 315, 1542, 2604], ["aten::zero_", "[[2048, 512, 1, 1]]", 21, 0, 147, 1455, 2485], ["aten::zero_", "[[2048]]", 56, 0, 19, 3827, 7008], ["aten::zero_", "[[2048, 1024, 1, 1]]", 7, 0, 91, 463, 805], ["aten::zero_", "[[512, 2048, 1, 1]]", 14, 0, 98, 946, 1629], ["aten::zero_", "[[1000, 2048]]", 7, 0, 91, 502, 849], ["aten::zero_", "[[1000]]", 7, 0, 7, 465, 828], ["NllLossBackward", "[[]]", 8, 0, 24, 687, 2085], ["LogSoftmaxBackward", "[[32, 1000]]", 8, 0, 83, 518, 2689], ["aten::as_strided", "[[2048, 1000], [], [], []]", 16, 0, 0, 244, 244], ["aten::transpose", "[[2048, 1000], [], []]", 16, 0, 0, 590, 834], ["aten::t", "[[2048, 1000]]", 16, 0, 0, 887, 1721], ["aten::conj", "[[1000, 2048]]", 8, 0, 0, 161, 161], ["aten::stride", "[[1000, 2048], []]", 16, 0, 0, 134, 134], ["aten::as_strided", "[[32, 1000], [], [], []]", 8, 0, 0, 145, 145], ["aten::transpose", "[[32, 1000], [], []]", 8, 0, 0, 283, 428], ["aten::t", "[[32, 1000]]", 8, 0, 0, 489, 917], ["aten::conj", "[[32, 2048]]", 8, 0, 0, 156, 156], ["aten::stride", "[[1000, 32], []]", 8, 0, 0, 49, 49], ["AddmmBackward", "[[32, 1000]]", 8, 0, 386, 1410, 9196], ["torch::autograd::AccumulateGrad", "[[1000]]", 8, 0, 8, 378, 1240], ["TBackward", "[[2048, 1000]]", 8, 0, 0, 288, 1120], ["torch::autograd::AccumulateGrad", "[[1000, 2048]]", 8, 0, 237, 356, 1161], ["aten::view", "[[32, 2048], []]", 8, 0, 0, 538, 538], ["aten::reshape", "[[32, 2048], []]", 8, 0, 0, 253, 791], ["ViewBackward", "[[32, 2048]]", 8, 0, 0, 324, 1115], ["aten::as_strided", "[[32, 2048, 1, 1], [], [], []]", 8, 0, 0, 147, 147], ["aten::expand", "[[32, 2048, 1, 1], [], []]", 8, 0, 0, 712, 859], ["aten::to", "[[32, 2048, 7, 7], [], [], [], []]", 8, 0, 0, 130, 130], ["MeanBackward1", "[[32, 2048, 1, 1]]", 8, 0, 234, 703, 3646], ["ReluBackward1", "[[32, 2048, 7, 7]]", 24, 0, 1213, 1484, 5877], ["AddBackward0", "[[32, 2048, 7, 7]]", 24, 0, 0, 617, 617], ["CudnnBatchNormBackward", "[[32, 2048, 7, 7]]", 32, 0, 2351, 3683, 24504], ["torch::autograd::AccumulateGrad", "[[2048]]", 64, 0, 255, 3119, 9651], ["aten::cudnn_convolution_backward", "[[32, 512, 7, 7], [32, 2048, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], [], []]", 24, 0, 35776, 4302, 211255], ["CudnnConvolutionBackward", "[[32, 2048, 7, 7]]", 32, 0, 57174, 2745, 297745], ["torch::autograd::AccumulateGrad", "[[2048, 512, 1, 1]]", 24, 0, 397, 1265, 3835], ["ReluBackward1", "[[32, 512, 7, 7]]", 40, 0, 652, 2481, 9538], ["CudnnBatchNormBackward", "[[32, 512, 7, 7]]", 40, 0, 918, 4504, 26562], ["torch::autograd::AccumulateGrad", "[[512]]", 176, 0, 669, 8080, 25792], ["aten::cudnn_convolution_backward", "[[32, 512, 7, 7], [32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], [], []]", 16, 0, 24818, 2970, 124731], ["CudnnConvolutionBackward", "[[32, 512, 7, 7]]", 40, 0, 77576, 3326, 201046], ["torch::autograd::AccumulateGrad", "[[512, 512, 3, 3]]", 24, 0, 878, 1143, 3568], ["aten::cudnn_convolution_backward", "[[32, 2048, 7, 7], [32, 512, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], [], []]", 16, 0, 28497, 2845, 42792], ["torch::autograd::AccumulateGrad", "[[512, 2048, 1, 1]]", 16, 0, 306, 728, 2340], ["aten::cudnn_convolution_backward", "[[32, 1024, 14, 14], [32, 2048, 7, 7], [2048, 1024, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 21398, 1377, 83745], ["torch::autograd::AccumulateGrad", "[[2048, 1024, 1, 1]]", 8, 0, 262, 374, 1264], ["aten::cudnn_convolution_backward", "[[32, 512, 14, 14], [32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], [], []]", 8, 0, 24261, 1427, 30197], ["ReluBackward1", "[[32, 512, 14, 14]]", 8, 0, 407, 501, 1898], ["CudnnBatchNormBackward", "[[32, 512, 14, 14]]", 8, 0, 753, 893, 5261], ["aten::cudnn_convolution_backward", "[[32, 1024, 14, 14], [32, 512, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 23731, 1431, 28704], ["CudnnConvolutionBackward", "[[32, 512, 14, 14]]", 8, 0, 23731, 652, 29356], ["torch::autograd::AccumulateGrad", "[[512, 1024, 1, 1]]", 8, 0, 95, 376, 1196], ["ReluBackward1", "[[32, 1024, 14, 14]]", 48, 0, 4618, 2932, 11483], ["AddBackward0", "[[32, 1024, 14, 14]]", 48, 0, 0, 1264, 1264], ["CudnnBatchNormBackward", "[[32, 1024, 14, 14]]", 56, 0, 10163, 6229, 37508], ["torch::autograd::AccumulateGrad", "[[1024]]", 112, 0, 487, 5341, 16688], ["aten::cudnn_convolution_backward", "[[32, 256, 14, 14], [32, 1024, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], [], []]", 48, 0, 47750, 8415, 71778], ["CudnnConvolutionBackward", "[[32, 1024, 14, 14]]", 56, 0, 67147, 4762, 97383], ["torch::autograd::AccumulateGrad", "[[1024, 256, 1, 1]]", 48, 0, 343, 2214, 12515], ["ReluBackward1", "[[32, 256, 14, 14]]", 88, 0, 2461, 5415, 21323], ["CudnnBatchNormBackward", "[[32, 256, 14, 14]]", 88, 0, 4201, 10219, 59325], ["torch::autograd::AccumulateGrad", "[[256]]", 256, 0, 1105, 11916, 38425], ["aten::cudnn_convolution_backward", "[[32, 256, 14, 14], [32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], [], []]", 40, 0, 32574, 7027, 66043], ["CudnnConvolutionBackward", "[[32, 256, 14, 14]]", 88, 0, 91559, 7587, 154205], ["torch::autograd::AccumulateGrad", "[[256, 256, 3, 3]]", 48, 0, 482, 2218, 7072], ["aten::cudnn_convolution_backward", "[[32, 1024, 14, 14], [32, 256, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], [], []]", 40, 0, 39429, 6999, 59573], ["torch::autograd::AccumulateGrad", "[[256, 1024, 1, 1]]", 40, 0, 329, 1879, 6405], ["aten::cudnn_convolution_backward", "[[32, 512, 28, 28], [32, 1024, 14, 14], [1024, 512, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 19397, 1384, 20843], ["torch::autograd::AccumulateGrad", "[[1024, 512, 1, 1]]", 8, 0, 66, 365, 1302], ["aten::cudnn_convolution_backward", "[[32, 256, 28, 28], [32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], [], []]", 8, 0, 19556, 1400, 21002], ["ReluBackward1", "[[32, 256, 28, 28]]", 8, 0, 768, 495, 1960], ["CudnnBatchNormBackward", "[[32, 256, 28, 28]]", 8, 0, 1329, 895, 5327], ["aten::cudnn_convolution_backward", "[[32, 512, 28, 28], [32, 256, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 21787, 1465, 28148], ["CudnnConvolutionBackward", "[[32, 256, 28, 28]]", 8, 0, 21787, 733, 28881], ["torch::autograd::AccumulateGrad", "[[256, 512, 1, 1]]", 8, 0, 48, 363, 1169], ["ReluBackward1", "[[32, 512, 28, 28]]", 32, 0, 5947, 1967, 7630], ["AddBackward0", "[[32, 512, 28, 28]]", 32, 0, 0, 839, 839], ["CudnnBatchNormBackward", "[[32, 512, 28, 28]]", 40, 0, 13249, 4479, 27038], ["aten::cudnn_convolution_backward", "[[32, 128, 28, 28], [32, 512, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], [], []]", 32, 0, 31808, 5450, 50100], ["CudnnConvolutionBackward", "[[32, 512, 28, 28]]", 40, 0, 52822, 3400, 74258], ["torch::autograd::AccumulateGrad", "[[512, 128, 1, 1]]", 32, 0, 142, 1511, 4878], ["ReluBackward1", "[[32, 128, 28, 28]]", 56, 0, 2753, 3445, 13689], ["CudnnBatchNormBackward", "[[32, 128, 28, 28]]", 56, 0, 5143, 6338, 37791], ["torch::autograd::AccumulateGrad", "[[128]]", 128, 0, 515, 5905, 19038], ["aten::cudnn_convolution_backward", "[[32, 128, 28, 28], [32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], [], []]", 24, 0, 24231, 4162, 43545], ["CudnnConvolutionBackward", "[[32, 128, 28, 28]]", 56, 0, 71511, 4687, 114023], ["torch::autograd::AccumulateGrad", "[[128, 128, 3, 3]]", 32, 0, 181, 1443, 5841], ["aten::cudnn_convolution_backward", "[[32, 512, 28, 28], [32, 128, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], [], []]", 24, 0, 23922, 4209, 44077], ["torch::autograd::AccumulateGrad", "[[128, 512, 1, 1]]", 24, 0, 112, 1125, 3574], ["aten::cudnn_convolution_backward", "[[32, 256, 56, 56], [32, 512, 28, 28], [512, 256, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 21014, 1344, 20758], ["torch::autograd::AccumulateGrad", "[[512, 256, 1, 1]]", 8, 0, 45, 367, 1170], ["aten::cudnn_convolution_backward", "[[32, 128, 56, 56], [32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], [], []]", 8, 0, 23358, 1363, 21714], ["ReluBackward1", "[[32, 128, 56, 56]]", 8, 0, 1478, 481, 1903], ["CudnnBatchNormBackward", "[[32, 128, 56, 56]]", 8, 0, 2764, 899, 5208], ["aten::cudnn_convolution_backward", "[[32, 256, 56, 56], [32, 128, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 28851, 1394, 33618], ["CudnnConvolutionBackward", "[[32, 128, 56, 56]]", 8, 0, 28851, 706, 34324], ["torch::autograd::AccumulateGrad", "[[128, 256, 1, 1]]", 8, 0, 34, 364, 1142], ["ReluBackward1", "[[32, 256, 56, 56]]", 24, 0, 8808, 1573, 5811], ["AddBackward0", "[[32, 256, 56, 56]]", 24, 0, 0, 621, 621], ["CudnnBatchNormBackward", "[[32, 256, 56, 56]]", 32, 0, 20675, 3730, 22709], ["aten::cudnn_convolution_backward", "[[32, 64, 56, 56], [32, 256, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], [], []]", 32, 0, 36726, 5523, 53501], ["CudnnConvolutionBackward", "[[32, 256, 56, 56]]", 32, 0, 36726, 2645, 56146], ["torch::autograd::AccumulateGrad", "[[256, 64, 1, 1]]", 32, 0, 146, 1445, 5904], ["ReluBackward1", "[[32, 64, 56, 56]]", 48, 0, 4472, 3047, 11693], ["CudnnBatchNormBackward", "[[32, 64, 56, 56]]", 48, 0, 10151, 5463, 31655], ["torch::autograd::AccumulateGrad", "[[64]]", 112, 0, 439, 5081, 16217], ["aten::cudnn_convolution_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], [], []]", 24, 0, 42389, 4255, 59693], ["CudnnConvolutionBackward", "[[32, 64, 56, 56]]", 48, 0, 79457, 4088, 118305], ["torch::autograd::AccumulateGrad", "[[64, 64, 3, 3]]", 24, 0, 98, 1075, 3522], ["aten::cudnn_convolution_backward", "[[32, 256, 56, 56], [32, 64, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], [], []]", 16, 0, 29911, 2773, 34791], ["torch::autograd::AccumulateGrad", "[[64, 256, 1, 1]]", 16, 0, 47, 747, 2353], ["aten::cudnn_convolution_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], [], []]", 8, 0, 7157, 1398, 19733], ["torch::autograd::AccumulateGrad", "[[64, 64, 1, 1]]", 8, 0, 35, 363, 1192], ["aten::zero_", "[[32, 64, 112, 112]]", 8, 0, 1285, 344, 793], ["aten::zeros_like", "[[32, 64, 112, 112], [], [], [], [], []]", 8, 0, 1285, 382, 1975], ["aten::resize_", "[[32, 64, 112, 112], [], []]", 16, 0, 0, 172, 172], ["aten::resize_as_", "[[32, 64, 112, 112], [32, 64, 112, 112], []]", 8, 0, 0, 284, 359], ["MaxPool2DWithIndicesBackward", "[[32, 64, 56, 56]]", 8, 0, 6851, 655, 5800], ["ReluBackward1", "[[32, 64, 112, 112]]", 8, 0, 2963, 488, 1908], ["CudnnBatchNormBackward", "[[32, 64, 112, 112]]", 8, 0, 6523, 953, 5284], ["aten::cudnn_convolution_backward", "[[32, 3, 224, 224], [32, 64, 112, 112], [64, 3, 7, 7], [], [], [], [], [], [], [], []]", 8, 0, 12685, 1033, 12355], ["CudnnConvolutionBackward", "[[32, 64, 112, 112]]", 8, 0, 12685, 683, 13038], ["torch::autograd::AccumulateGrad", "[[64, 3, 7, 7]]", 8, 0, 28, 355, 1149]]}}, "kernel_op_table": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "string", "name": "Operator"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Total Duration (us)"}, {"type": "number", "name": "Mean Duration (us)"}, {"type": "number", "name": "Max Duration (us)"}, {"type": "number", "name": "Min Duration (us)"}], "rows": [["ncclAllReduceRingLLKernel_sum_f32(ncclColl)", "CallTreeRoot", 40, 1806797, 45169.925, 3880, 102092], ["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", "aten::cudnn_convolution_backward_input", 260, 143070, 550.2692307692307, 150, 1208], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 248, 124531, 502.14112903225805, 380, 1470], ["ncclBroadcastRingLLKernel_copy_i8(ncclColl)", "CallTreeRoot", 18, 123340, 6852.222222222223, 75, 106702], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", "aten::cudnn_batch_norm_backward", 352, 74951, 212.92897727272728, 43, 850], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 132, 61407, 465.20454545454544, 385, 879], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 94, 47410, 504.36170212765956, 363, 856], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", "aten::threshold_backward", 392, 36540, 93.21428571428571, 13, 394], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", "aten::cudnn_convolution_backward_weight", 76, 36447, 479.5657894736842, 331, 731], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", "aten::cudnn_batch_norm", 200, 35178, 175.89, 50, 444], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", "aten::add_", 3670, 33900, 9.237057220708447, 1, 394], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 30, 28896, 963.2, 889, 1392], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", "aten::threshold_", 392, 23847, 60.83418367346939, 6, 276], ["volta_gcgemm_32x32_nt", "aten::cudnn_convolution", 110, 21594, 196.3090909090909, 19, 2210], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", "CallTreeRoot", 128, 20766, 162.234375, 50, 396], ["volta_gcgemm_32x32_nt", "aten::cudnn_convolution_backward_input", 29, 19428, 669.9310344827586, 70, 2218], ["volta_sgemm_128x64_nt", "aten::cudnn_convolution_backward_weight", 84, 18456, 219.71428571428572, 173, 679], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", "aten::cudnn_convolution_backward_weight", 24, 16841, 701.7083333333334, 674, 884], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 28, 16418, 586.3571428571429, 405, 1015], ["volta_sgemm_128x64_nt", "aten::cudnn_convolution_backward_input", 84, 16328, 194.38095238095238, 158, 216], ["volta_cgemm_32x32_tn", "aten::cudnn_convolution_backward_input", 14, 16224, 1158.857142857143, 217, 3115], ["volta_cgemm_32x32_tn", "aten::cudnn_convolution", 14, 16186, 1156.142857142857, 216, 3118], ["volta_sgemm_128x64_nn", "aten::cudnn_convolution", 84, 16002, 190.5, 157, 208], ["volta_scudnn_128x64_stridedB_interior_nn_v1", "aten::cudnn_convolution_backward_input", 47, 15968, 339.74468085106383, 267, 547], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 22, 13622, 619.1818181818181, 213, 1005], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", "aten::cudnn_convolution", 19, 12215, 642.8947368421053, 137, 839], ["volta_scudnn_128x64_relu_interior_nn_v1", "aten::cudnn_convolution", 37, 11602, 313.56756756756755, 94, 674], ["volta_cgemm_32x32_tn", "aten::cudnn_convolution_backward_weight", 14, 11523, 823.0714285714286, 216, 1691], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", "aten::cudnn_convolution", 19, 11409, 600.4736842105264, 333, 728], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", "aten::cudnn_convolution_backward_weight", 17, 11037, 649.2352941176471, 361, 1118], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", "aten::cudnn_convolution_backward_input", 28, 10974, 391.92857142857144, 367, 769], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", "aten::cudnn_convolution", 28, 10733, 383.32142857142856, 363, 767], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", "aten::cudnn_convolution_backward_input", 266, 10563, 39.71052631578947, 6, 163], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", "aten::cudnn_batch_norm", 224, 9539, 42.58482142857143, 14, 88], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 12, 8677, 723.0833333333334, 658, 823], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 11, 8536, 776.0, 735, 805], ["volta_scudnn_128x64_relu_medium_nn_v1", "aten::cudnn_convolution", 12, 7419, 618.25, 384, 645], ["volta_scudnn_128x128_stridedB_interior_nn_v1", "aten::cudnn_convolution_backward_input", 25, 7296, 291.84, 271, 300], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", "aten::cudnn_convolution", 39, 6893, 176.74358974358975, 77, 445], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", "CallTreeRoot", 1288, 6654, 5.166149068322981, 1, 31], ["volta_cgemm_64x32_tn", "aten::cudnn_convolution_backward_weight", 2, 6346, 3173.0, 3172, 3174], ["void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution_backward_input", 13, 6138, 472.15384615384613, 52, 1646], ["void flip_filter<float, float>(float*, float const*, int, int, int, int)", "aten::cudnn_convolution", 16, 5990, 374.375, 8, 1637], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", "aten::cudnn_convolution", 10, 5956, 595.6, 571, 679], ["volta_scudnn_128x128_stridedB_small_nn_v1", "aten::cudnn_convolution_backward_input", 10, 5841, 584.1, 534, 883], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution_backward_input", 14, 5830, 416.42857142857144, 37, 1597], ["volta_scudnn_128x64_relu_small_nn_v1", "aten::cudnn_convolution", 19, 5611, 295.3157894736842, 270, 600], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution", 14, 5608, 400.57142857142856, 33, 1580], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", "aten::max_pool2d_with_indices_backward", 8, 5566, 695.75, 693, 700], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution_backward_weight", 7, 5500, 785.7142857142857, 129, 1675], ["volta_scudnn_128x128_stridedB_medium_nn_v1", "aten::cudnn_convolution_backward_input", 17, 5432, 319.52941176470586, 307, 330], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", "aten::cudnn_convolution_backward_weight", 15, 5076, 338.4, 101, 1350], ["volta_scudnn_128x128_relu_interior_nn_v1", "aten::cudnn_convolution", 9, 5025, 558.3333333333334, 550, 570], ["void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution", 8, 4496, 562.0, 14, 1751], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", "aten::cudnn_convolution_backward_input", 9, 4335, 481.6666666666667, 90, 1396], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", "aten::add", 1288, 4215, 3.2725155279503104, 1, 35], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", "aten::cudnn_convolution", 9, 4179, 464.3333333333333, 84, 1385], ["void flip_filter<float, float>(float*, float const*, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 16, 3960, 247.5, 28, 1129], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", "aten::cudnn_convolution_backward_input", 84, 3867, 46.035714285714285, 21, 117], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", "aten::cudnn_convolution_backward_weight", 84, 3829, 45.583333333333336, 21, 138], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", "aten::cudnn_convolution_backward_input", 84, 3681, 43.82142857142857, 20, 139], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", "aten::cudnn_convolution", 84, 3578, 42.595238095238095, 19, 111], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", "aten::cudnn_convolution_backward_weight", 84, 3576, 42.57142857142857, 17, 137], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 5, 6, 4, 3, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", "aten::cudnn_convolution_backward_input", 3, 3560, 1186.6666666666667, 1109, 1275], ["void fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)", "aten::cudnn_convolution_backward_input", 28, 3387, 120.96428571428571, 15, 290], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", "aten::cudnn_convolution", 84, 3373, 40.154761904761905, 17, 137], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", "aten::cudnn_batch_norm_backward", 72, 3264, 45.333333333333336, 19, 82], ["void cudnn::detail::dgrad_alg1_engine<float, 128, 6, 8, 3, 3, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)", "aten::cudnn_convolution_backward_input", 1, 3169, 3169.0, 3169, 3169], ["void fft2d_c2r_32x32<float, true, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution", 87, 3080, 35.40229885057471, 23, 122], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", "aten::fill_", 1143, 3005, 2.6290463692038495, 0, 162], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution", 10, 2932, 293.2, 88, 855], ["void fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)", "aten::cudnn_convolution", 16, 2919, 182.4375, 62, 293], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution_backward_input", 10, 2813, 281.3, 87, 876], ["volta_scudnn_128x64_stridedB_small_nn_v1", "aten::cudnn_convolution_backward_input", 12, 2811, 234.25, 95, 691], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", "aten::mul_", 1127, 2723, 2.4161490683229814, 1, 24], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution", 95, 2545, 26.789473684210527, 10, 206], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 12, 2434, 202.83333333333334, 134, 503], ["volta_scudnn_128x64_stridedB_splitK_interior_nn_v1", "aten::cudnn_convolution_backward_weight", 3, 2349, 783.0, 573, 893], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", "aten::cudnn_convolution_backward_input", 84, 2104, 25.047619047619047, 4, 71], ["void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution", 7, 2077, 296.7142857142857, 97, 743], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", "aten::cudnn_convolution_backward_weight", 84, 2066, 24.595238095238095, 3, 67], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1", "aten::cudnn_convolution", 3, 1950, 650.0, 580, 687], ["void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)", "aten::cudnn_convolution_backward_input", 16, 1941, 121.3125, 35, 237], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution_backward_weight", 5, 1857, 371.4, 131, 774], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 10, 1846, 184.6, 98, 363], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", "aten::cudnn_convolution", 84, 1838, 21.88095238095238, 4, 71], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", "aten::max_pool2d_with_indices", 8, 1788, 223.5, 223, 225], ["volta_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1", "aten::cudnn_convolution_backward_weight", 1, 1664, 1664.0, 1664, 1664], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution_backward_weight", 4, 1631, 407.75, 130, 700], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 4, 6, 3, 2, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", "aten::cudnn_convolution_backward_input", 1, 1618, 1618.0, 1618, 1618], ["void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)", "aten::cudnn_convolution", 16, 1529, 95.5625, 36, 224], ["void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution_backward_input", 14, 1472, 105.14285714285714, 48, 194], ["void fft1d_r2c_32<float, float, float2, true, false>(float2*, float const*, int, int3, int3, int2, int2)", "aten::cudnn_convolution", 12, 1467, 122.25, 19, 406], ["volta_scudnn_128x64_stridedB_splitK_small_nn_v1", "aten::cudnn_convolution_backward_weight", 2, 1289, 644.5, 643, 646], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution_backward_input", 5, 1226, 245.2, 120, 442], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 14, 1119, 79.92857142857143, 36, 163], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", "aten::cudnn_convolution_backward_input", 1, 1075, 1075.0, 1075, 1075], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution_backward_weight", 8, 1053, 131.625, 72, 230], ["void pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)", "aten::cudnn_convolution_backward_input", 2, 1032, 516.0, 501, 531], ["void pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)", "aten::cudnn_convolution", 2, 1000, 500.0, 491, 509], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution", 5, 985, 197.0, 121, 400], ["void explicit_convolve_sgemm<float, int, 512, 6, 8, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", "aten::cudnn_convolution", 1, 737, 737.0, 737, 737], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution_backward_input", 9, 735, 81.66666666666667, 38, 196], ["void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution", 9, 734, 81.55555555555556, 45, 198], ["volta_scudnn_128x128_relu_medium_nn_v1", "aten::cudnn_convolution", 2, 723, 361.5, 305, 418], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", "aten::cudnn_convolution_backward_input", 112, 715, 6.383928571428571, 2, 10], ["volta_scudnn_128x64_stridedB_medium_nn_v1", "aten::cudnn_convolution_backward_input", 1, 609, 609.0, 609, 609], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1", "aten::cudnn_convolution", 1, 581, 581.0, 581, 581], ["volta_scudnn_128x64_stridedB_splitK_medium_nn_v1", "aten::cudnn_convolution_backward_weight", 1, 540, 540.0, 540, 540], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution_backward_input", 7, 528, 75.42857142857143, 36, 141], ["void cudnn::cnn::wgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)", "aten::cudnn_convolution_backward_weight", 1, 526, 526.0, 526, 526], ["volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1", "aten::cudnn_convolution", 1, 517, 517.0, 517, 517], ["void fft2d_r2c_32x32<float, true, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", "aten::cudnn_convolution_backward_input", 6, 501, 83.5, 52, 144], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", "aten::cudnn_convolution_backward_weight", 124, 482, 3.8870967741935485, 1, 8], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", "aten::cudnn_convolution", 7, 460, 65.71428571428571, 34, 133], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", "aten::add", 424, 454, 1.070754716981132, 1, 3], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", "aten::cudnn_convolution_backward_input", 112, 449, 4.008928571428571, 1, 8], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", "aten::cudnn_convolution_backward_weight", 124, 418, 3.370967741935484, 1, 7], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution_backward_input", 3, 346, 115.33333333333333, 82, 143], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", "aten::mean", 8, 345, 43.125, 42, 47], ["void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", "aten::cudnn_convolution", 10, 320, 32.0, 9, 67], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1", "aten::cudnn_convolution", 1, 311, 311.0, 311, 311], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", "aten::cudnn_convolution", 95, 268, 2.8210526315789473, 2, 5], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<float, unsigned int, 1, 128, 1>(float*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<float, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", "aten::_cat", 8, 259, 32.375, 32, 35], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", "aten::cudnn_convolution_backward_input", 28, 237, 8.464285714285714, 3, 37], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", "aten::div", 8, 234, 29.25, 27, 30], ["volta_sgemm_64x32_sliced1x4_nn", "aten::mm", 8, 217, 27.125, 26, 28], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", "aten::cudnn_convolution", 2, 209, 104.5, 78, 131], ["volta_sgemm_64x32_sliced1x4_tn", "aten::addmm", 8, 200, 25.0, 24, 28], ["volta_sgemm_128x32_nt", "aten::mm", 8, 152, 19.0, 19, 19], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", "aten::cudnn_convolution", 28, 139, 4.964285714285714, 2, 46], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<long, unsigned int, 1, 128, 1>(long*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<long, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", "aten::_cat", 8, 133, 16.625, 16, 21], ["void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", "aten::cudnn_convolution", 6, 105, 17.5, 9, 36], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", "aten::_log_softmax_backward_data", 8, 83, 10.375, 10, 11], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", "aten::_log_softmax", 8, 81, 10.125, 10, 11], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", "CallTreeRoot", 8, 68, 8.5, 8, 9], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", "aten::addmm", 8, 43, 5.375, 5, 6], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", "aten::nll_loss_forward", 8, 33, 4.125, 4, 5], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", "aten::addmm", 8, 31, 3.875, 3, 4], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", "aten::nll_loss_backward", 8, 16, 2.0, 2, 2], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", "aten::mm", 8, 16, 2.0, 2, 2]]}}, "kernel_pie": {"total": {"columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["ncclAllReduceRingLLKernel_sum_f32(ncclColl)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1806797.0}], ["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 143070.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 124531.0}], ["ncclBroadcastRingLLKernel_copy_i8(ncclColl)", {"py/object": "numpy.float64", "dtype": "float64", "value": 123340.0}], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 74951.0}], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 61407.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 60387.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 58881.0}], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 47410.0}], ["volta_cgemm_32x32_tn", {"py/object": "numpy.float64", "dtype": "float64", "value": 43933.0}], ["volta_gcgemm_32x32_nt", {"py/object": "numpy.float64", "dtype": "float64", "value": 41022.0}], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 36447.0}], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 35178.0}], ["volta_sgemm_128x64_nt", {"py/object": "numpy.float64", "dtype": "float64", "value": 34784.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 28896.0}], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 21707.0}], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 16841.0}], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 16418.0}], ["volta_sgemm_128x64_nn", {"py/object": "numpy.float64", "dtype": "float64", "value": 16002.0}], ["volta_scudnn_128x64_stridedB_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 15968.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 13622.0}], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 13590.0}], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 12557.0}], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 12215.0}], ["volta_scudnn_128x64_relu_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 11602.0}], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 11409.0}], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 11037.0}], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 10563.0}], ["void flip_filter<float, float>(float*, float const*, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 9950.0}], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", {"py/object": "numpy.float64", "dtype": "float64", "value": 9539.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 9377.0}], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 8677.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 8536.0}], ["void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 8215.0}], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 7591.0}], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 7445.0}], ["volta_scudnn_128x64_relu_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 7419.0}], ["volta_scudnn_128x128_stridedB_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 7296.0}], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 7054.0}], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 6893.0}], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 6488.0}], ["volta_cgemm_64x32_tn", {"py/object": "numpy.float64", "dtype": "float64", "value": 6346.0}], ["void fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)", {"py/object": "numpy.float64", "dtype": "float64", "value": 6306.0}], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 5956.0}], ["volta_scudnn_128x128_stridedB_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 5841.0}], ["volta_scudnn_128x64_relu_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 5611.0}], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 5566.0}], ["volta_scudnn_128x128_stridedB_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 5432.0}], ["volta_scudnn_128x128_relu_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 5025.0}], ["void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 4496.0}], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 4333.0}], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 4068.0}], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3942.0}], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3829.0}], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3576.0}], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 5, 6, 4, 3, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3560.0}], ["void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3470.0}], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3264.0}], ["void cudnn::detail::dgrad_alg1_engine<float, 128, 6, 8, 3, 3, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3169.0}], ["void fft2d_c2r_32x32<float, true, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3080.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3005.0}], ["volta_scudnn_128x64_stridedB_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 2811.0}], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2434.0}], ["volta_scudnn_128x64_stridedB_splitK_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 2349.0}], ["void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2206.0}], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2186.0}], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2066.0}], ["void pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2032.0}], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 1950.0}], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1788.0}], ["volta_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 1664.0}], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 4, 6, 3, 2, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1618.0}], ["void fft1d_r2c_32<float, float, float2, true, false>(float2*, float const*, int, int3, int3, int2, int2)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1467.0}], ["volta_scudnn_128x64_stridedB_splitK_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 1289.0}], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1075.0}], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 983.0}], ["void explicit_convolve_sgemm<float, int, 512, 6, 8, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 737.0}], ["volta_scudnn_128x128_relu_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 723.0}], ["volta_scudnn_128x64_stridedB_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 609.0}], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 581.0}], ["volta_scudnn_128x64_stridedB_splitK_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 540.0}], ["void cudnn::cnn::wgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 526.0}], ["volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 517.0}], ["void fft2d_r2c_32x32<float, true, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 501.0}], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 482.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 454.0}], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 449.0}], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 418.0}], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 376.0}], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 345.0}], ["void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 320.0}], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 311.0}], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<float, unsigned int, 1, 128, 1>(float*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<float, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 259.0}], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", {"py/object": "numpy.float64", "dtype": "float64", "value": 234.0}], ["volta_sgemm_64x32_sliced1x4_nn", {"py/object": "numpy.float64", "dtype": "float64", "value": 217.0}], ["volta_sgemm_64x32_sliced1x4_tn", {"py/object": "numpy.float64", "dtype": "float64", "value": 200.0}], ["volta_sgemm_128x32_nt", {"py/object": "numpy.float64", "dtype": "float64", "value": 152.0}], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<long, unsigned int, 1, 128, 1>(long*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<long, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 133.0}], ["void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 105.0}], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 83.0}], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 81.0}], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 68.0}], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 47.0}], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", {"py/object": "numpy.float64", "dtype": "float64", "value": 43.0}], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", {"py/object": "numpy.float64", "dtype": "float64", "value": 33.0}], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", {"py/object": "numpy.float64", "dtype": "float64", "value": 16.0}]]}}, "kernel_table": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Total Duration (us)"}, {"type": "number", "name": "Mean Duration (us)"}, {"type": "number", "name": "Max Duration (us)"}, {"type": "number", "name": "Min Duration (us)"}], "rows": [["ncclAllReduceRingLLKernel_sum_f32(ncclColl)", 40, 1806797, 45170, 102092, 3880], ["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", 260, 143070, 550, 1208, 150], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 248, 124531, 502, 1470, 380], ["ncclBroadcastRingLLKernel_copy_i8(ncclColl)", 18, 123340, 6852, 106702, 75], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", 352, 74951, 213, 850, 43], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 132, 61407, 465, 879, 385], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", 784, 60387, 77, 394, 6], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", 5086, 58881, 12, 396, 1], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 94, 47410, 504, 856, 363], ["volta_cgemm_32x32_tn", 42, 43933, 1046, 3118, 216], ["volta_gcgemm_32x32_nt", 139, 41022, 295, 2218, 19], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", 76, 36447, 480, 731, 331], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", 200, 35178, 176, 444, 50], ["volta_sgemm_128x64_nt", 168, 34784, 207, 679, 158], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 30, 28896, 963, 1392, 889], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", 56, 21707, 388, 769, 363], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", 24, 16841, 702, 884, 674], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 28, 16418, 586, 1015, 405], ["volta_sgemm_128x64_nn", 84, 16002, 190, 208, 157], ["volta_scudnn_128x64_stridedB_interior_nn_v1", 47, 15968, 340, 547, 267], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 22, 13622, 619, 1005, 213], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", 33, 13590, 412, 1396, 84], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", 42, 12557, 299, 1597, 33], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 19, 12215, 643, 839, 137], ["volta_scudnn_128x64_relu_interior_nn_v1", 37, 11602, 314, 674, 94], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 19, 11409, 600, 728, 333], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", 17, 11037, 649, 1118, 361], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", 266, 10563, 40, 163, 6], ["void flip_filter<float, float>(float*, float const*, int, int, int, int)", 32, 9950, 311, 1637, 8], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", 224, 9539, 43, 88, 14], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", 2415, 9377, 4, 31, 1], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 12, 8677, 723, 823, 658], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 11, 8536, 776, 805, 735], ["void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 20, 8215, 411, 1646, 52], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", 30, 7591, 253, 876, 87], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", 168, 7445, 44, 117, 19], ["volta_scudnn_128x64_relu_medium_nn_v1", 12, 7419, 618, 645, 384], ["volta_scudnn_128x128_stridedB_interior_nn_v1", 25, 7296, 292, 300, 271], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 168, 7054, 42, 139, 17], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", 39, 6893, 177, 445, 77], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", 21, 6488, 309, 1675, 34], ["volta_cgemm_64x32_tn", 2, 6346, 3173, 3174, 3172], ["void fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)", 44, 6306, 143, 293, 15], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", 10, 5956, 596, 679, 571], ["volta_scudnn_128x128_stridedB_small_nn_v1", 10, 5841, 584, 883, 534], ["volta_scudnn_128x64_relu_small_nn_v1", 19, 5611, 295, 600, 270], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", 8, 5566, 696, 700, 693], ["volta_scudnn_128x128_stridedB_medium_nn_v1", 17, 5432, 320, 330, 307], ["volta_scudnn_128x128_relu_interior_nn_v1", 9, 5025, 558, 570, 550], ["void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 8, 4496, 562, 1751, 14], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 112, 4333, 39, 230, 10], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", 15, 4068, 271, 774, 120], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", 168, 3942, 23, 71, 4], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 84, 3829, 46, 138, 21], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", 84, 3576, 43, 137, 17], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 5, 6, 4, 3, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 3, 3560, 1187, 1275, 1109], ["void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)", 32, 3470, 108, 237, 35], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", 72, 3264, 45, 82, 19], ["void cudnn::detail::dgrad_alg1_engine<float, 128, 6, 8, 3, 3, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)", 1, 3169, 3169, 3169, 3169], ["void fft2d_c2r_32x32<float, true, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 87, 3080, 35, 122, 23], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", 1143, 3005, 3, 162, 0], ["volta_scudnn_128x64_stridedB_small_nn_v1", 12, 2811, 234, 691, 95], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 12, 2434, 203, 503, 134], ["volta_scudnn_128x64_stridedB_splitK_interior_nn_v1", 3, 2349, 783, 893, 573], ["void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 23, 2206, 96, 198, 45], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 9, 2186, 243, 700, 78], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", 84, 2066, 25, 67, 3], ["void pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)", 4, 2032, 508, 531, 491], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1", 3, 1950, 650, 687, 580], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", 8, 1788, 224, 225, 223], ["volta_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1", 1, 1664, 1664, 1664, 1664], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 4, 6, 3, 2, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 1, 1618, 1618, 1618, 1618], ["void fft1d_r2c_32<float, float, float2, true, false>(float2*, float const*, int, int3, int3, int2, int2)", 12, 1467, 122, 406, 19], ["volta_scudnn_128x64_stridedB_splitK_small_nn_v1", 2, 1289, 644, 646, 643], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 1, 1075, 1075, 1075, 1075], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", 207, 983, 5, 10, 2], ["void explicit_convolve_sgemm<float, int, 512, 6, 8, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 1, 737, 737, 737, 737], ["volta_scudnn_128x128_relu_medium_nn_v1", 2, 723, 362, 418, 305], ["volta_scudnn_128x64_stridedB_medium_nn_v1", 1, 609, 609, 609, 609], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1", 1, 581, 581, 581, 581], ["volta_scudnn_128x64_stridedB_splitK_medium_nn_v1", 1, 540, 540, 540, 540], ["void cudnn::cnn::wgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)", 1, 526, 526, 526, 526], ["volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1", 1, 517, 517, 517, 517], ["void fft2d_r2c_32x32<float, true, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 6, 501, 84, 144, 52], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", 124, 482, 4, 8, 1], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", 424, 454, 1, 3, 1], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", 112, 449, 4, 8, 1], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", 124, 418, 3, 7, 1], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", 56, 376, 7, 46, 2], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", 8, 345, 43, 47, 42], ["void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", 10, 320, 32, 67, 9], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1", 1, 311, 311, 311, 311], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<float, unsigned int, 1, 128, 1>(float*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<float, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", 8, 259, 32, 35, 32], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", 8, 234, 29, 30, 27], ["volta_sgemm_64x32_sliced1x4_nn", 8, 217, 27, 28, 26], ["volta_sgemm_64x32_sliced1x4_tn", 8, 200, 25, 28, 24], ["volta_sgemm_128x32_nt", 8, 152, 19, 19, 19], ["void at::native::(anonymous namespace)::CatArrayBatchedCopy<long, unsigned int, 1, 128, 1>(long*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<long, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)", 8, 133, 17, 21, 16], ["void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", 6, 105, 18, 36, 9], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", 8, 83, 10, 11, 10], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", 8, 81, 10, 11, 10], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", 8, 68, 8, 9, 8], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", 16, 47, 3, 4, 2], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", 8, 43, 5, 6, 5], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", 8, 33, 4, 5, 4], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", 8, 16, 2, 2, 2]]}}, "trace_file_path": "./data/tracing\\resnet50_autogradAPI_ddp\\worker1_span1.pt.trace.json.gz"}]}]}]}}