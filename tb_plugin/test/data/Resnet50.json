{"py/object": "tensorboard_plugin_torch_profiler.run.Run", "name": "test_profiler", "run_dir": "./data", "profiles": {"py/reduce": [{"py/type": "collections.OrderedDict"}, {"py/tuple": []}, null, null, {"py/tuple": [{"py/tuple": ["worker0", {"py/object": "tensorboard_plugin_torch_profiler.run.RunProfile", "worker": "worker0", "views": [{"py/object": "tensorboard_plugin_torch_profiler.consts.View", "py/newargs": {"py/tuple": [1, "overall", "Overview"]}, "py/seq": [1, "overall", "Overview"]}, {"py/object": "tensorboard_plugin_torch_profiler.consts.View", "py/newargs": {"py/tuple": [2, "operator", "Operator"]}, "py/seq": [2, "operator", "Operator"]}, {"py/object": "tensorboard_plugin_torch_profiler.consts.View", "py/newargs": {"py/tuple": [3, "kernel", "Kernel"]}, "py/seq": [3, "kernel", "Kernel"]}, {"py/object": "tensorboard_plugin_torch_profiler.consts.View", "py/newargs": {"py/tuple": [4, "trace", "Trace"]}, "py/seq": [4, "trace", "Trace"]}], "is_gpu_used": true, "overview": {"steps": {"columns": [{"type": "string", "name": "Step"}, {"type": "number", "name": "Kernel"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memcpy"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memset"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Runtime"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "DataLoader"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "CPU Exec"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Other"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}], "rows": [["5", 129520, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 159174us<br><b>Kernel: 129520us</b><br>Percentage: 81.37%</div>", 1948, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 159174us<br><b>Memcpy: 1948us</b><br>Percentage: 1.22%</div>", 90, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 159174us<br><b>Memset: 90us</b><br>Percentage: 0.06%</div>", 3346, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 159174us<br><b>Runtime: 3346us</b><br>Percentage: 2.1%</div>", 10482, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 159174us<br><b>DataLoader: 10482us</b><br>Percentage: 6.59%</div>", 12480, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 159174us<br><b>CPU Exec: 12480us</b><br>Percentage: 7.84%</div>", 1308, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 159174us<br><b>Other: 1308us</b><br>Percentage: 0.82%</div>"], ["6", 92970, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 150790us<br><b>Kernel: 92970us</b><br>Percentage: 61.66%</div>", 2436, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 150790us<br><b>Memcpy: 2436us</b><br>Percentage: 1.62%</div>", 63, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 150790us<br><b>Memset: 63us</b><br>Percentage: 0.04%</div>", 3144, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 150790us<br><b>Runtime: 3144us</b><br>Percentage: 2.09%</div>", 37456, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 150790us<br><b>DataLoader: 37456us</b><br>Percentage: 24.84%</div>", 13420, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 150790us<br><b>CPU Exec: 13420us</b><br>Percentage: 8.9%</div>", 1301, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 150790us<br><b>Other: 1301us</b><br>Percentage: 0.86%</div>"], ["7", 101813, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 141346us<br><b>Kernel: 101813us</b><br>Percentage: 72.03%</div>", 2111, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 141346us<br><b>Memcpy: 2111us</b><br>Percentage: 1.49%</div>", 70, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 141346us<br><b>Memset: 70us</b><br>Percentage: 0.05%</div>", 1756, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 141346us<br><b>Runtime: 1756us</b><br>Percentage: 1.24%</div>", 28987, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 141346us<br><b>DataLoader: 28987us</b><br>Percentage: 20.51%</div>", 5904, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 141346us<br><b>CPU Exec: 5904us</b><br>Percentage: 4.18%</div>", 705, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 141346us<br><b>Other: 705us</b><br>Percentage: 0.5%</div>"], ["8", 98964, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 160963us<br><b>Kernel: 98964us</b><br>Percentage: 61.48%</div>", 2078, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 160963us<br><b>Memcpy: 2078us</b><br>Percentage: 1.29%</div>", 68, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 160963us<br><b>Memset: 68us</b><br>Percentage: 0.04%</div>", 2040, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 160963us<br><b>Runtime: 2040us</b><br>Percentage: 1.27%</div>", 49981, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 160963us<br><b>DataLoader: 49981us</b><br>Percentage: 31.05%</div>", 7087, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 160963us<br><b>CPU Exec: 7087us</b><br>Percentage: 4.4%</div>", 745, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 160963us<br><b>Other: 745us</b><br>Percentage: 0.46%</div>"], ["9", 108112, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 148485us<br><b>Kernel: 108112us</b><br>Percentage: 72.81%</div>", 2072, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 148485us<br><b>Memcpy: 2072us</b><br>Percentage: 1.4%</div>", 74, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 148485us<br><b>Memset: 74us</b><br>Percentage: 0.05%</div>", 2926, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 148485us<br><b>Runtime: 2926us</b><br>Percentage: 1.97%</div>", 25411, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 148485us<br><b>DataLoader: 25411us</b><br>Percentage: 17.11%</div>", 9081, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 148485us<br><b>CPU Exec: 9081us</b><br>Percentage: 6.12%</div>", 809, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 148485us<br><b>Other: 809us</b><br>Percentage: 0.54%</div>"], ["10", 108661, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 167712us<br><b>Kernel: 108661us</b><br>Percentage: 64.79%</div>", 2089, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 167712us<br><b>Memcpy: 2089us</b><br>Percentage: 1.25%</div>", 74, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 167712us<br><b>Memset: 74us</b><br>Percentage: 0.04%</div>", 4174, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 167712us<br><b>Runtime: 4174us</b><br>Percentage: 2.49%</div>", 36220, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 167712us<br><b>DataLoader: 36220us</b><br>Percentage: 21.6%</div>", 14751, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 167712us<br><b>CPU Exec: 14751us</b><br>Percentage: 8.8%</div>", 1743, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 167712us<br><b>Other: 1743us</b><br>Percentage: 1.04%</div>"]]}, "performance": [{"name": "Average Step Time", "description": "", "value": 154745, "extra": 100, "children": [{"name": "Kernel", "description": "", "value": 106673, "extra": 68.93}, {"name": "Memcpy", "description": "", "value": 2122, "extra": 1.37}, {"name": "Memset", "description": "", "value": 73, "extra": 0.05}, {"name": "Runtime", "description": "", "value": 2898, "extra": 1.87}, {"name": "DataLoader", "description": "", "value": 31423, "extra": 20.31}, {"name": "CPU Exec", "description": "", "value": 10454, "extra": 6.76}, {"name": "Other", "description": "", "value": 1102, "extra": 0.71}]}], "recommendations": "<ul><li>This run has high time cost on input data loading. 20.3% of the step time is in DataLoader. You could try to set num_workers on DataLoader's construction and enable multi-processes on data loading. Reference: <a href =\"https://pytorch.org/docs/stable/data.html#single-and-multi-process-data-loading\" target=\"_blank\">Single- and Multi-process Data Loading</a></li></ul>"}, "operation_pie_by_name": {"device_total_time": {"title": "Device Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward", 285514], ["CudnnConvolutionBackward", 285514], ["aten::cudnn_convolution_backward_weight", 149670], ["aten::cudnn_convolution_backward_input", 135844], ["aten::cudnn_convolution", 135735], ["aten::_convolution", 135735], ["aten::convolution", 135735], ["aten::conv2d", 135735], ["aten::cudnn_batch_norm_backward", 56884], ["CudnnBatchNormBackward", 56884], ["aten::cudnn_batch_norm", 33292], ["aten::_batch_norm_impl_index", 33292], ["aten::batch_norm", 33292], ["aten::threshold_backward", 26258], ["ReluBackward1", 26258], ["aten::add_", 23357], ["aten::threshold_", 17759], ["aten::relu_", 17759], ["aten::copy_", 12734], ["aten::to", 12734], ["aten::max_pool2d_with_indices_backward", 5046], ["MaxPool2DWithIndicesBackward", 5046], ["torch::autograd::AccumulateGrad", 2915], ["aten::fill_", 2414], ["aten::zero_", 2408], ["aten::mul_", 2380], ["aten::max_pool2d_with_indices", 1341], ["aten::max_pool2d", 1341], ["aten::zeros_like", 948], ["aten::add", 325], ["aten::mm", 295], ["AddmmBackward", 295], ["aten::mean", 256], ["aten::adaptive_avg_pool2d", 256], ["aten::addmm", 201], ["aten::div", 162], ["MeanBackward1", 162], ["aten::_log_softmax_backward_data", 64], ["LogSoftmaxBackward", 64], ["aten::_log_softmax", 60], ["aten::log_softmax", 60], ["aten::nll_loss_forward", 20], ["aten::nll_loss", 20], ["aten::nll_loss_backward", 18], ["NllLossBackward", 18], ["aten::ones_like", 6]]}, "device_self_time": {"title": "Device Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward_weight", 149670], ["aten::cudnn_convolution_backward_input", 135844], ["aten::cudnn_convolution", 135735], ["aten::cudnn_batch_norm_backward", 56884], ["aten::cudnn_batch_norm", 33292], ["aten::threshold_backward", 26258], ["aten::add_", 23357], ["aten::threshold_", 17759], ["aten::copy_", 12734], ["aten::max_pool2d_with_indices_backward", 4098], ["aten::fill_", 2414], ["aten::mul_", 2380], ["aten::max_pool2d_with_indices", 1341], ["aten::add", 325], ["aten::mm", 295], ["aten::mean", 256], ["aten::addmm", 201], ["aten::div", 162], ["aten::_log_softmax_backward_data", 64], ["aten::_log_softmax", 60], ["aten::nll_loss_forward", 20], ["aten::nll_loss_backward", 18]]}, "host_total_time": {"title": "Host Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::add_", 96814], ["CudnnConvolutionBackward", 90857], ["aten::cudnn_convolution_backward", 87104], ["aten::conv2d", 61610], ["aten::copy_", 60140], ["aten::convolution", 57644], ["aten::batch_norm", 55154], ["aten::_convolution", 53789], ["aten::_batch_norm_impl_index", 51122], ["aten::cudnn_convolution", 49275], ["aten::cudnn_batch_norm", 47638], ["aten::to", 46057], ["aten::cudnn_convolution_backward_weight", 39006], ["aten::cudnn_convolution_backward_input", 38583], ["aten::mul_", 36843], ["aten::zero_", 36160], ["torch::autograd::AccumulateGrad", 34208], ["aten::empty", 33098], ["aten::stack", 33058], ["CudnnBatchNormBackward", 32186], ["aten::cat", 31169], ["aten::_cat", 30970], ["aten::div", 30671], ["aten::cudnn_batch_norm_backward", 27883], ["aten::contiguous", 24479], ["aten::fill_", 21081], ["aten::relu_", 16620], ["ReluBackward1", 15142], ["aten::add", 14945], ["aten::threshold_backward", 12601], ["aten::threshold_", 9128], ["aten::empty_like", 8255], ["aten::view", 4811], ["aten::resize_", 3415], ["aten::permute", 3161], ["aten::set_", 2994], ["aten::empty_strided", 1725], ["AddmmBackward", 1462], ["aten::unsqueeze", 1293], ["aten::addmm", 1274], ["aten::as_strided", 948], ["aten::mm", 847], ["MaxPool2DWithIndicesBackward", 763], ["aten::max_pool2d", 732], ["NllLossBackward", 719], ["aten::max_pool2d_with_indices_backward", 686], ["aten::t", 664], ["aten::zeros", 651], ["aten::max_pool2d_with_indices", 644], ["MeanBackward1", 606], ["aten::nll_loss_backward", 590], ["aten::adaptive_avg_pool2d", 566], ["aten::log_softmax", 527], ["aten::nll_loss", 500], ["aten::mean", 484], ["LogSoftmaxBackward", 451], ["aten::_log_softmax", 447], ["aten::nll_loss_forward", 425], ["aten::ones_like", 410], ["aten::_log_softmax_backward_data", 357], ["aten::zeros_like", 339], ["aten::transpose", 309], ["AddBackward0", 309], ["aten::reshape", 228], ["aten::flatten", 206], ["aten::expand", 141], ["TBackward", 140], ["ViewBackward", 121], ["aten::narrow", 87], ["aten::detach_", 64], ["aten::resize_as_", 54], ["aten::slice", 52], ["aten::conj", 46], ["detach_", 33]]}, "host_self_time": {"title": "Host Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::add_", 96814], ["aten::copy_", 60140], ["aten::cudnn_convolution", 43346], ["aten::mul_", 36843], ["aten::cudnn_convolution_backward_weight", 34576], ["aten::cudnn_convolution_backward_input", 34111], ["aten::cudnn_batch_norm", 33376], ["aten::empty", 33098], ["aten::_cat", 30756], ["aten::div", 26028], ["aten::fill_", 21081], ["aten::cudnn_batch_norm_backward", 20739], ["aten::zero_", 15259], ["aten::add", 14945], ["aten::threshold_backward", 10655], ["aten::cudnn_convolution_backward", 9515], ["aten::threshold_", 9128], ["aten::relu_", 7492], ["torch::autograd::AccumulateGrad", 6798], ["aten::view", 4811], ["aten::to", 4680], ["aten::_convolution", 4514], ["aten::empty_like", 4430], ["CudnnBatchNormBackward", 4303], ["aten::batch_norm", 4032], ["aten::conv2d", 3966], ["aten::convolution", 3855], ["CudnnConvolutionBackward", 3753], ["aten::_batch_norm_impl_index", 3484], ["aten::resize_", 3415], ["aten::set_", 2994], ["aten::permute", 2703], ["ReluBackward1", 2541], ["aten::contiguous", 2069], ["aten::empty_strided", 1725], ["aten::addmm", 1138], ["aten::as_strided", 948], ["aten::unsqueeze", 925], ["aten::mm", 771], ["aten::stack", 596], ["aten::nll_loss_backward", 590], ["aten::max_pool2d_with_indices", 497], ["aten::zeros", 463], ["aten::mean", 431], ["aten::nll_loss_forward", 425], ["aten::t", 355], ["aten::_log_softmax", 343], ["AddBackward0", 309], ["aten::max_pool2d_with_indices_backward", 293], ["aten::_log_softmax_backward_data", 246], ["aten::transpose", 226], ["aten::cat", 199], ["AddmmBackward", 195], ["NllLossBackward", 129], ["aten::expand", 113], ["MeanBackward1", 103], ["aten::ones_like", 100], ["LogSoftmaxBackward", 94], ["aten::max_pool2d", 88], ["aten::adaptive_avg_pool2d", 82], ["aten::log_softmax", 80], ["MaxPool2DWithIndicesBackward", 77], ["aten::nll_loss", 75], ["aten::reshape", 71], ["aten::flatten", 65], ["aten::zeros_like", 53], ["aten::conj", 46], ["aten::resize_as_", 44], ["aten::slice", 41], ["aten::narrow", 35], ["ViewBackward", 34], ["detach_", 33], ["aten::detach_", 31], ["TBackward", 29]]}}, "operation_table_by_name": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Device Self Duration (us)"}, {"type": "number", "name": "Device Total Duration (us)"}, {"type": "number", "name": "Host Self Duration (us)"}, {"type": "number", "name": "Host Total Duration (us)"}], "rows": [["aten::cudnn_convolution_backward_weight", 318, 149670, 149670, 34576, 39006], ["aten::cudnn_convolution_backward_input", 312, 135844, 135844, 34111, 38583], ["aten::cudnn_convolution", 318, 135735, 135735, 43346, 49275], ["aten::cudnn_batch_norm_backward", 318, 56884, 56884, 20739, 27883], ["aten::cudnn_batch_norm", 318, 33292, 33292, 33376, 47638], ["aten::threshold_backward", 294, 26258, 26258, 10655, 12601], ["aten::add_", 2994, 23357, 23357, 96814, 96814], ["aten::threshold_", 294, 17759, 17759, 9128, 9128], ["aten::copy_", 588, 12734, 12734, 60140, 60140], ["aten::max_pool2d_with_indices_backward", 6, 4098, 5046, 293, 686], ["aten::fill_", 978, 2414, 2414, 21081, 21081], ["aten::mul_", 966, 2380, 2380, 36843, 36843], ["aten::max_pool2d_with_indices", 6, 1341, 1341, 497, 644], ["aten::add", 318, 325, 325, 14945, 14945], ["aten::mm", 12, 295, 295, 771, 847], ["aten::mean", 6, 256, 256, 431, 484], ["aten::addmm", 6, 201, 201, 1138, 1274], ["aten::div", 198, 162, 162, 26028, 30671], ["aten::_log_softmax_backward_data", 6, 64, 64, 246, 357], ["aten::_log_softmax", 6, 60, 60, 343, 447], ["aten::nll_loss_forward", 6, 20, 20, 425, 425], ["aten::nll_loss_backward", 6, 18, 18, 590, 590], ["aten::empty", 5748, 0, 0, 33098, 33098], ["aten::zero_", 996, 0, 2408, 15259, 36160], ["aten::zeros", 24, 0, 0, 463, 651], ["aten::set_", 192, 0, 0, 2994, 2994], ["aten::view", 840, 0, 0, 4811, 4811], ["aten::as_strided", 432, 0, 0, 948, 948], ["aten::permute", 192, 0, 0, 2703, 3161], ["aten::empty_like", 534, 0, 0, 4430, 8255], ["aten::contiguous", 192, 0, 0, 2069, 24479], ["aten::empty_strided", 402, 0, 0, 1725, 1725], ["aten::to", 408, 0, 12734, 4680, 46057], ["aten::unsqueeze", 192, 0, 0, 925, 1293], ["aten::resize_", 1926, 0, 0, 3415, 3415], ["aten::slice", 6, 0, 0, 41, 52], ["aten::narrow", 6, 0, 0, 35, 87], ["aten::_cat", 6, 0, 0, 30756, 30970], ["aten::cat", 6, 0, 0, 199, 31169], ["aten::stack", 6, 0, 0, 596, 33058], ["detach_", 6, 0, 0, 33, 33], ["aten::detach_", 6, 0, 0, 31, 64], ["aten::_convolution", 318, 0, 135735, 4514, 53789], ["aten::convolution", 318, 0, 135735, 3855, 57644], ["aten::conv2d", 318, 0, 135735, 3966, 61610], ["aten::_batch_norm_impl_index", 318, 0, 33292, 3484, 51122], ["aten::batch_norm", 318, 0, 33292, 4032, 55154], ["aten::relu_", 294, 0, 17759, 7492, 16620], ["aten::max_pool2d", 6, 0, 1341, 88, 732], ["aten::adaptive_avg_pool2d", 6, 0, 256, 82, 566], ["aten::reshape", 12, 0, 0, 71, 228], ["aten::flatten", 6, 0, 0, 65, 206], ["aten::transpose", 30, 0, 0, 226, 309], ["aten::t", 30, 0, 0, 355, 664], ["aten::expand", 12, 0, 0, 113, 141], ["aten::log_softmax", 6, 0, 60, 80, 527], ["aten::nll_loss", 6, 0, 20, 75, 500], ["aten::ones_like", 6, 0, 6, 100, 410], ["NllLossBackward", 6, 0, 18, 129, 719], ["LogSoftmaxBackward", 6, 0, 64, 94, 451], ["aten::conj", 12, 0, 0, 46, 46], ["AddmmBackward", 6, 0, 295, 195, 1462], ["torch::autograd::AccumulateGrad", 966, 0, 2915, 6798, 34208], ["TBackward", 6, 0, 0, 29, 140], ["ViewBackward", 6, 0, 0, 34, 121], ["MeanBackward1", 6, 0, 162, 103, 606], ["ReluBackward1", 294, 0, 26258, 2541, 15142], ["AddBackward0", 96, 0, 0, 309, 309], ["CudnnBatchNormBackward", 318, 0, 56884, 4303, 32186], ["aten::cudnn_convolution_backward", 318, 0, 285514, 9515, 87104], ["CudnnConvolutionBackward", 318, 0, 285514, 3753, 90857], ["aten::zeros_like", 6, 0, 948, 53, 339], ["aten::resize_as_", 6, 0, 0, 44, 54], ["MaxPool2DWithIndicesBackward", 6, 0, 5046, 77, 763]]}}, "operation_pie_by_name_input": {"device_total_time": {"title": "Device Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["CudnnConvolutionBackward", 49785], ["CudnnConvolutionBackward", 38406], ["CudnnConvolutionBackward", 37188], ["CudnnConvolutionBackward", 33744], ["aten::cudnn_convolution_backward", 29069], ["CudnnConvolutionBackward", 27723], ["CudnnConvolutionBackward", 26158], ["CudnnConvolutionBackward", 24459], ["aten::cudnn_convolution_backward", 23387], ["aten::cudnn_convolution_backward", 22556], ["aten::cudnn_convolution_backward", 18456], ["CudnnConvolutionBackward", 18456], ["aten::cudnn_convolution_backward", 18214], ["aten::cudnn_convolution_backward", 17168], ["aten::cudnn_convolution_backward_weight", 17145], ["aten::cudnn_convolution_backward_input", 16034], ["aten::cudnn_batch_norm_backward", 15198], ["CudnnBatchNormBackward", 15198], ["aten::cudnn_convolution_backward", 14484], ["aten::cudnn_convolution", 14037], ["aten::_convolution", 14037], ["aten::convolution", 14037], ["aten::conv2d", 14037], ["aten::cudnn_convolution_backward_input", 13967], ["aten::cudnn_convolution_backward_weight", 13035], ["aten::cudnn_convolution_backward", 12791], ["aten::copy_", 12728], ["aten::to", 12728], ["aten::cudnn_convolution_backward_input", 12497], ["aten::cudnn_convolution_backward", 12198], ["aten::cudnn_convolution_backward_input", 12115], ["aten::cudnn_convolution", 11767], ["aten::_convolution", 11767], ["aten::convolution", 11767], ["aten::conv2d", 11767], ["aten::cudnn_convolution_backward_weight", 11694], ["aten::cudnn_convolution_backward", 11041], ["aten::cudnn_convolution_backward_weight", 10890], ["aten::cudnn_convolution_backward", 10505], ["aten::cudnn_convolution", 10192], ["aten::_convolution", 10192], ["aten::convolution", 10192], ["aten::conv2d", 10192], ["aten::cudnn_convolution_backward", 9975], ["aten::cudnn_batch_norm_backward", 9663], ["CudnnBatchNormBackward", 9663], ["aten::cudnn_batch_norm", 9555], ["aten::_batch_norm_impl_index", 9555], ["aten::batch_norm", 9555], ["aten::cudnn_convolution_backward_weight", 9541], ["aten::cudnn_convolution_backward", 9538], ["aten::cudnn_convolution_backward", 9509], ["aten::cudnn_convolution_backward", 9419], ["aten::cudnn_convolution_backward", 9337], ["aten::cudnn_convolution_backward", 9230], ["aten::cudnn_convolution_backward_input", 9193], ["aten::cudnn_convolution_backward_weight", 9039], ["aten::cudnn_convolution_backward_input", 8673], ["aten::cudnn_convolution", 8614], ["aten::_convolution", 8614], ["aten::convolution", 8614], ["aten::conv2d", 8614], ["aten::cudnn_convolution_backward_weight", 8558], ["aten::cudnn_convolution_backward_input", 8397], ["aten::cudnn_convolution_backward", 8147], ["CudnnConvolutionBackward", 8147], ["aten::cudnn_convolution_backward", 7974], ["CudnnConvolutionBackward", 7974], ["aten::cudnn_convolution_backward", 7558], ["CudnnConvolutionBackward", 7558], ["aten::cudnn_batch_norm_backward", 7463], ["CudnnBatchNormBackward", 7463], ["aten::cudnn_batch_norm_backward", 7412], ["CudnnBatchNormBackward", 7412], ["aten::cudnn_convolution", 7394], ["aten::_convolution", 7394], ["aten::convolution", 7394], ["aten::conv2d", 7394], ["aten::cudnn_convolution", 7261], ["aten::_convolution", 7261], ["aten::convolution", 7261], ["aten::conv2d", 7261], ["aten::cudnn_convolution_backward_weight", 7202], ["aten::cudnn_convolution_backward", 7201], ["aten::cudnn_convolution", 6824], ["aten::_convolution", 6824], ["aten::convolution", 6824], ["aten::conv2d", 6824], ["aten::cudnn_convolution_backward_input", 6762], ["aten::cudnn_convolution_backward_input", 6662], ["aten::cudnn_convolution", 6623], ["aten::_convolution", 6623], ["aten::convolution", 6623], ["aten::conv2d", 6623], ["aten::add_", 6538], ["aten::threshold_backward", 6534], ["ReluBackward1", 6534], ["aten::cudnn_batch_norm", 6189], ["aten::_batch_norm_impl_index", 6189], ["aten::batch_norm", 6189], ["aten::cudnn_convolution_backward_weight", 6087], ["aten::cudnn_convolution_backward_weight", 5916], ["aten::cudnn_convolution_backward", 5916], ["CudnnConvolutionBackward", 5916], ["aten::cudnn_convolution_backward_input", 5744], ["aten::cudnn_convolution", 5495], ["aten::_convolution", 5495], ["aten::convolution", 5495], ["aten::conv2d", 5495], ["aten::cudnn_convolution_backward_input", 5366], ["aten::cudnn_convolution_backward_input", 5345], ["aten::cudnn_convolution", 5341], ["aten::_convolution", 5341], ["aten::convolution", 5341], ["aten::conv2d", 5341], ["aten::cudnn_convolution_backward_weight", 5328], ["aten::cudnn_convolution", 5214], ["aten::_convolution", 5214], ["aten::convolution", 5214], ["aten::conv2d", 5214], ["aten::cudnn_convolution", 5093], ["aten::_convolution", 5093], ["aten::convolution", 5093], ["aten::conv2d", 5093], ["aten::max_pool2d_with_indices_backward", 5046], ["MaxPool2DWithIndicesBackward", 5046], ["aten::cudnn_convolution_backward_input", 4996], ["aten::cudnn_convolution_backward_input", 4950], ["aten::cudnn_batch_norm_backward", 4773], ["CudnnBatchNormBackward", 4773], ["aten::cudnn_convolution_backward_weight", 4769], ["aten::cudnn_convolution", 4640], ["aten::_convolution", 4640], ["aten::convolution", 4640], ["aten::conv2d", 4640], ["aten::cudnn_convolution", 4632], ["aten::_convolution", 4632], ["aten::convolution", 4632], ["aten::conv2d", 4632], ["aten::cudnn_convolution_backward_weight", 4559], ["aten::threshold_", 4491], ["aten::relu_", 4491], ["aten::cudnn_convolution", 4453], ["aten::_convolution", 4453], ["aten::convolution", 4453], ["aten::conv2d", 4453], ["aten::cudnn_convolution_backward_input", 4429], ["aten::add_", 4393], ["aten::cudnn_convolution_backward_weight", 4391], ["aten::cudnn_convolution", 4379], ["aten::_convolution", 4379], ["aten::convolution", 4379], ["aten::conv2d", 4379], ["aten::threshold_backward", 4377], ["ReluBackward1", 4377], ["aten::cudnn_convolution", 4265], ["aten::_convolution", 4265], ["aten::convolution", 4265], ["aten::conv2d", 4265], ["aten::cudnn_convolution_backward_weight", 4231], ["aten::cudnn_convolution", 4176], ["aten::_convolution", 4176], ["aten::convolution", 4176], ["aten::conv2d", 4176], ["aten::cudnn_convolution_backward_weight", 4103], ["aten::cudnn_convolution_backward_weight", 4053], ["aten::cudnn_convolution_backward_weight", 4032], ["aten::cudnn_convolution_backward_weight", 3992], ["aten::cudnn_batch_norm", 3985], ["aten::_batch_norm_impl_index", 3985], ["aten::batch_norm", 3985], ["aten::cudnn_convolution_backward_weight", 3873], ["aten::cudnn_convolution", 3841], ["aten::_convolution", 3841], ["aten::convolution", 3841], ["aten::conv2d", 3841], ["aten::cudnn_convolution_backward_input", 3752], ["aten::cudnn_convolution_backward_weight", 3718], ["aten::cudnn_convolution", 3683], ["aten::_convolution", 3683], ["aten::convolution", 3683], ["aten::conv2d", 3683], ["aten::cudnn_batch_norm_backward", 3660], ["CudnnBatchNormBackward", 3660], ["aten::cudnn_batch_norm", 3549], ["aten::_batch_norm_impl_index", 3549], ["aten::batch_norm", 3549], ["aten::cudnn_convolution", 3544], ["aten::_convolution", 3544], ["aten::convolution", 3544], ["aten::conv2d", 3544], ["aten::cudnn_convolution_backward_weight", 3514], ["aten::cudnn_convolution", 3419], ["aten::_convolution", 3419], ["aten::convolution", 3419], ["aten::conv2d", 3419], ["aten::add_", 3316], ["aten::threshold_backward", 3315], ["ReluBackward1", 3315], ["aten::threshold_backward", 3206], ["ReluBackward1", 3206], ["aten::cudnn_convolution_backward_input", 3205], ["aten::cudnn_convolution_backward_input", 3167], ["aten::threshold_", 3003], ["aten::relu_", 3003], ["aten::cudnn_batch_norm_backward", 2903], ["CudnnBatchNormBackward", 2903], ["aten::cudnn_batch_norm", 2546], ["aten::_batch_norm_impl_index", 2546], ["aten::batch_norm", 2546], ["aten::threshold_", 2291], ["aten::relu_", 2291], ["aten::threshold_", 2277], ["aten::relu_", 2277], ["aten::threshold_backward", 2180], ["ReluBackward1", 2180], ["aten::cudnn_batch_norm", 2143], ["aten::_batch_norm_impl_index", 2143], ["aten::batch_norm", 2143], ["aten::cudnn_batch_norm_backward", 2022], ["CudnnBatchNormBackward", 2022], ["aten::threshold_backward", 1909], ["ReluBackward1", 1909], ["aten::add_", 1893], ["aten::cudnn_convolution_backward", 1841], ["aten::cudnn_batch_norm_backward", 1695], ["CudnnBatchNormBackward", 1695], ["aten::threshold_backward", 1579], ["ReluBackward1", 1579], ["aten::threshold_", 1500], ["aten::relu_", 1500], ["aten::cudnn_batch_norm", 1477], ["aten::_batch_norm_impl_index", 1477], ["aten::batch_norm", 1477], ["aten::threshold_", 1347], ["aten::relu_", 1347], ["aten::max_pool2d_with_indices", 1341], ["aten::max_pool2d", 1341], ["aten::cudnn_batch_norm", 1314], ["aten::_batch_norm_impl_index", 1314], ["aten::batch_norm", 1314], ["aten::cudnn_batch_norm", 1199], ["aten::_batch_norm_impl_index", 1199], ["aten::batch_norm", 1199], ["aten::threshold_backward", 1083], ["ReluBackward1", 1083], ["aten::cudnn_batch_norm_backward", 961], ["CudnnBatchNormBackward", 961], ["aten::fill_", 948], ["aten::zero_", 948], ["aten::zeros_like", 948], ["aten::cudnn_convolution", 848], ["aten::_convolution", 848], ["aten::convolution", 848], ["aten::conv2d", 848], ["aten::threshold_backward", 846], ["ReluBackward1", 846], ["aten::add_", 829], ["aten::threshold_", 768], ["aten::relu_", 768], ["aten::threshold_", 755], ["aten::relu_", 755], ["aten::add_", 685], ["torch::autograd::AccumulateGrad", 631], ["aten::add_", 619], ["aten::cudnn_batch_norm", 617], ["aten::_batch_norm_impl_index", 617], ["aten::batch_norm", 617], ["aten::cudnn_convolution_backward_input", 590], ["aten::cudnn_batch_norm_backward", 588], ["CudnnBatchNormBackward", 588], ["aten::threshold_", 583], ["aten::relu_", 583], ["aten::add_", 576], ["aten::add_", 564], ["aten::threshold_backward", 556], ["ReluBackward1", 556], ["aten::add_", 555], ["aten::cudnn_batch_norm_backward", 546], ["CudnnBatchNormBackward", 546], ["aten::add_", 489], ["aten::cudnn_batch_norm", 442], ["aten::_batch_norm_impl_index", 442], ["aten::batch_norm", 442], ["aten::mul_", 431], ["aten::add_", 396], ["aten::threshold_backward", 390], ["ReluBackward1", 390], ["aten::threshold_", 378], ["aten::relu_", 378], ["aten::add_", 330], ["aten::add", 325], ["aten::add_", 325], ["AddmmBackward", 295], ["aten::add_", 288], ["aten::threshold_backward", 283], ["ReluBackward1", 283], ["aten::cudnn_batch_norm", 276], ["aten::_batch_norm_impl_index", 276], ["aten::batch_norm", 276], ["aten::fill_", 270], ["aten::zero_", 270], ["aten::mean", 256], ["aten::adaptive_avg_pool2d", 256], ["aten::add_", 252], ["aten::add_", 252], ["torch::autograd::AccumulateGrad", 243], ["aten::mul_", 230], ["torch::autograd::AccumulateGrad", 223], ["aten::addmm", 201], ["torch::autograd::AccumulateGrad", 196], ["aten::mul_", 192], ["aten::mul_", 192], ["torch::autograd::AccumulateGrad", 192], ["aten::threshold_", 186], ["aten::relu_", 186], ["torch::autograd::AccumulateGrad", 186], ["torch::autograd::AccumulateGrad", 184], ["aten::threshold_", 180], ["aten::relu_", 180], ["aten::mm", 178], ["aten::div", 162], ["MeanBackward1", 162], ["torch::autograd::AccumulateGrad", 150], ["aten::add_", 145], ["aten::fill_", 144], ["aten::zero_", 144], ["aten::add_", 144], ["aten::mul_", 132], ["torch::autograd::AccumulateGrad", 132], ["aten::mul_", 130], ["aten::fill_", 126], ["aten::zero_", 126], ["aten::mul_", 126], ["aten::add_", 125], ["aten::mul_", 125], ["aten::mm", 117], ["aten::add_", 116], ["aten::mul_", 113], ["torch::autograd::AccumulateGrad", 108], ["aten::add_", 102], ["aten::mul_", 96], ["torch::autograd::AccumulateGrad", 96], ["aten::fill_", 93], ["aten::zero_", 93], ["aten::add_", 91], ["aten::mul_", 90], ["aten::fill_", 84], ["aten::zero_", 84], ["aten::mul_", 84], ["aten::mul_", 84], ["torch::autograd::AccumulateGrad", 84], ["torch::autograd::AccumulateGrad", 84], ["aten::fill_", 78], ["aten::zero_", 78], ["aten::fill_", 78], ["aten::zero_", 78], ["aten::fill_", 76], ["aten::zero_", 76], ["aten::fill_", 72], ["aten::zero_", 72], ["aten::add_", 72], ["aten::fill_", 64], ["aten::zero_", 64], ["aten::_log_softmax_backward_data", 64], ["LogSoftmaxBackward", 64], ["aten::_log_softmax", 60], ["aten::log_softmax", 60], ["aten::fill_", 60], ["aten::zero_", 60], ["aten::add_", 57], ["torch::autograd::AccumulateGrad", 54], ["aten::fill_", 50], ["aten::zero_", 50], ["torch::autograd::AccumulateGrad", 49], ["aten::add_", 48], ["aten::mul_", 48], ["aten::mul_", 48], ["aten::mul_", 48], ["torch::autograd::AccumulateGrad", 48], ["torch::autograd::AccumulateGrad", 48], ["torch::autograd::AccumulateGrad", 47], ["aten::fill_", 45], ["aten::zero_", 45], ["aten::add_", 42], ["aten::add_", 36], ["aten::mul_", 36], ["aten::mul_", 36], ["aten::mul_", 36], ["torch::autograd::AccumulateGrad", 30], ["aten::fill_", 24], ["aten::zero_", 24], ["aten::fill_", 24], ["aten::zero_", 24], ["aten::fill_", 24], ["aten::zero_", 24], ["aten::fill_", 24], ["aten::zero_", 24], ["aten::fill_", 24], ["aten::zero_", 24], ["aten::mul_", 24], ["aten::add_", 24], ["torch::autograd::AccumulateGrad", 24], ["torch::autograd::AccumulateGrad", 24], ["torch::autograd::AccumulateGrad", 21], ["aten::nll_loss_forward", 20], ["aten::nll_loss", 20], ["aten::fill_", 20], ["aten::zero_", 20], ["aten::add_", 19], ["aten::fill_", 18], ["aten::zero_", 18], ["aten::fill_", 18], ["aten::zero_", 18], ["aten::add_", 18], ["aten::mul_", 18], ["aten::add_", 18], ["aten::nll_loss_backward", 18], ["NllLossBackward", 18], ["torch::autograd::AccumulateGrad", 18], ["aten::fill_", 12], ["aten::zero_", 12], ["aten::mul_", 12], ["aten::mul_", 12], ["aten::mul_", 12], ["torch::autograd::AccumulateGrad", 12], ["torch::autograd::AccumulateGrad", 12], ["aten::mul_", 7], ["torch::autograd::AccumulateGrad", 7], ["aten::copy_", 6], ["aten::to", 6], ["aten::fill_", 6], ["aten::zero_", 6], ["aten::fill_", 6], ["aten::zero_", 6], ["aten::fill_", 6], ["aten::zero_", 6], ["aten::fill_", 6], ["aten::zero_", 6], ["aten::fill_", 6], ["aten::zero_", 6], ["aten::fill_", 6], ["aten::ones_like", 6], ["aten::mul_", 6], ["aten::mul_", 6], ["aten::mul_", 6], ["torch::autograd::AccumulateGrad", 6], ["torch::autograd::AccumulateGrad", 6], ["aten::fill_", 2], ["aten::zero_", 2]]}, "device_self_time": {"title": "Device Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward_weight", 17145], ["aten::cudnn_convolution_backward_input", 16034], ["aten::cudnn_batch_norm_backward", 15198], ["aten::cudnn_convolution", 14037], ["aten::cudnn_convolution_backward_input", 13967], ["aten::cudnn_convolution_backward_weight", 13035], ["aten::copy_", 12728], ["aten::cudnn_convolution_backward_input", 12497], ["aten::cudnn_convolution_backward_input", 12115], ["aten::cudnn_convolution", 11767], ["aten::cudnn_convolution_backward_weight", 11694], ["aten::cudnn_convolution_backward_weight", 10890], ["aten::cudnn_convolution", 10192], ["aten::cudnn_batch_norm_backward", 9663], ["aten::cudnn_batch_norm", 9555], ["aten::cudnn_convolution_backward_weight", 9541], ["aten::cudnn_convolution_backward_input", 9193], ["aten::cudnn_convolution_backward_weight", 9039], ["aten::cudnn_convolution_backward_input", 8673], ["aten::cudnn_convolution", 8614], ["aten::cudnn_convolution_backward_weight", 8558], ["aten::cudnn_convolution_backward_input", 8397], ["aten::cudnn_batch_norm_backward", 7463], ["aten::cudnn_batch_norm_backward", 7412], ["aten::cudnn_convolution", 7394], ["aten::cudnn_convolution", 7261], ["aten::cudnn_convolution_backward_weight", 7202], ["aten::cudnn_convolution", 6824], ["aten::cudnn_convolution_backward_input", 6762], ["aten::cudnn_convolution_backward_input", 6662], ["aten::cudnn_convolution", 6623], ["aten::add_", 6538], ["aten::threshold_backward", 6534], ["aten::cudnn_batch_norm", 6189], ["aten::cudnn_convolution_backward_weight", 6087], ["aten::cudnn_convolution_backward_weight", 5916], ["aten::cudnn_convolution_backward_input", 5744], ["aten::cudnn_convolution", 5495], ["aten::cudnn_convolution_backward_input", 5366], ["aten::cudnn_convolution_backward_input", 5345], ["aten::cudnn_convolution", 5341], ["aten::cudnn_convolution_backward_weight", 5328], ["aten::cudnn_convolution", 5214], ["aten::cudnn_convolution", 5093], ["aten::cudnn_convolution_backward_input", 4996], ["aten::cudnn_convolution_backward_input", 4950], ["aten::cudnn_batch_norm_backward", 4773], ["aten::cudnn_convolution_backward_weight", 4769], ["aten::cudnn_convolution", 4640], ["aten::cudnn_convolution", 4632], ["aten::cudnn_convolution_backward_weight", 4559], ["aten::threshold_", 4491], ["aten::cudnn_convolution", 4453], ["aten::cudnn_convolution_backward_input", 4429], ["aten::add_", 4393], ["aten::cudnn_convolution_backward_weight", 4391], ["aten::cudnn_convolution", 4379], ["aten::threshold_backward", 4377], ["aten::cudnn_convolution", 4265], ["aten::cudnn_convolution_backward_weight", 4231], ["aten::cudnn_convolution", 4176], ["aten::cudnn_convolution_backward_weight", 4103], ["aten::max_pool2d_with_indices_backward", 4098], ["aten::cudnn_convolution_backward_weight", 4053], ["aten::cudnn_convolution_backward_weight", 4032], ["aten::cudnn_convolution_backward_weight", 3992], ["aten::cudnn_batch_norm", 3985], ["aten::cudnn_convolution_backward_weight", 3873], ["aten::cudnn_convolution", 3841], ["aten::cudnn_convolution_backward_input", 3752], ["aten::cudnn_convolution_backward_weight", 3718], ["aten::cudnn_convolution", 3683], ["aten::cudnn_batch_norm_backward", 3660], ["aten::cudnn_batch_norm", 3549], ["aten::cudnn_convolution", 3544], ["aten::cudnn_convolution_backward_weight", 3514], ["aten::cudnn_convolution", 3419], ["aten::add_", 3316], ["aten::threshold_backward", 3315], ["aten::threshold_backward", 3206], ["aten::cudnn_convolution_backward_input", 3205], ["aten::cudnn_convolution_backward_input", 3167], ["aten::threshold_", 3003], ["aten::cudnn_batch_norm_backward", 2903], ["aten::cudnn_batch_norm", 2546], ["aten::threshold_", 2291], ["aten::threshold_", 2277], ["aten::threshold_backward", 2180], ["aten::cudnn_batch_norm", 2143], ["aten::cudnn_batch_norm_backward", 2022], ["aten::threshold_backward", 1909], ["aten::add_", 1893], ["aten::cudnn_batch_norm_backward", 1695], ["aten::threshold_backward", 1579], ["aten::threshold_", 1500], ["aten::cudnn_batch_norm", 1477], ["aten::threshold_", 1347], ["aten::max_pool2d_with_indices", 1341], ["aten::cudnn_batch_norm", 1314], ["aten::cudnn_batch_norm", 1199], ["aten::threshold_backward", 1083], ["aten::cudnn_batch_norm_backward", 961], ["aten::fill_", 948], ["aten::cudnn_convolution", 848], ["aten::threshold_backward", 846], ["aten::add_", 829], ["aten::threshold_", 768], ["aten::threshold_", 755], ["aten::add_", 685], ["aten::add_", 619], ["aten::cudnn_batch_norm", 617], ["aten::cudnn_convolution_backward_input", 590], ["aten::cudnn_batch_norm_backward", 588], ["aten::threshold_", 583], ["aten::add_", 576], ["aten::add_", 564], ["aten::threshold_backward", 556], ["aten::add_", 555], ["aten::cudnn_batch_norm_backward", 546], ["aten::add_", 489], ["aten::cudnn_batch_norm", 442], ["aten::mul_", 431], ["aten::add_", 396], ["aten::threshold_backward", 390], ["aten::threshold_", 378], ["aten::add_", 330], ["aten::add", 325], ["aten::add_", 325], ["aten::add_", 288], ["aten::threshold_backward", 283], ["aten::cudnn_batch_norm", 276], ["aten::fill_", 270], ["aten::mean", 256], ["aten::add_", 252], ["aten::add_", 252], ["aten::mul_", 230], ["aten::addmm", 201], ["aten::mul_", 192], ["aten::mul_", 192], ["aten::threshold_", 186], ["aten::threshold_", 180], ["aten::mm", 178], ["aten::div", 162], ["aten::add_", 145], ["aten::fill_", 144], ["aten::add_", 144], ["aten::mul_", 132], ["aten::mul_", 130], ["aten::fill_", 126], ["aten::mul_", 126], ["aten::add_", 125], ["aten::mul_", 125], ["aten::mm", 117], ["aten::add_", 116], ["aten::mul_", 113], ["aten::add_", 102], ["aten::mul_", 96], ["aten::fill_", 93], ["aten::add_", 91], ["aten::mul_", 90], ["aten::fill_", 84], ["aten::mul_", 84], ["aten::mul_", 84], ["aten::fill_", 78], ["aten::fill_", 78], ["aten::fill_", 76], ["aten::fill_", 72], ["aten::add_", 72], ["aten::fill_", 64], ["aten::_log_softmax_backward_data", 64], ["aten::_log_softmax", 60], ["aten::fill_", 60], ["aten::add_", 57], ["aten::fill_", 50], ["aten::add_", 48], ["aten::mul_", 48], ["aten::mul_", 48], ["aten::mul_", 48], ["aten::fill_", 45], ["aten::add_", 42], ["aten::add_", 36], ["aten::mul_", 36], ["aten::mul_", 36], ["aten::mul_", 36], ["aten::fill_", 24], ["aten::fill_", 24], ["aten::fill_", 24], ["aten::fill_", 24], ["aten::fill_", 24], ["aten::mul_", 24], ["aten::add_", 24], ["aten::nll_loss_forward", 20], ["aten::fill_", 20], ["aten::add_", 19], ["aten::fill_", 18], ["aten::fill_", 18], ["aten::add_", 18], ["aten::mul_", 18], ["aten::add_", 18], ["aten::nll_loss_backward", 18], ["aten::fill_", 12], ["aten::mul_", 12], ["aten::mul_", 12], ["aten::mul_", 12], ["aten::mul_", 7], ["aten::copy_", 6], ["aten::fill_", 6], ["aten::fill_", 6], ["aten::fill_", 6], ["aten::fill_", 6], ["aten::fill_", 6], ["aten::fill_", 6], ["aten::mul_", 6], ["aten::mul_", 6], ["aten::mul_", 6], ["aten::fill_", 2]]}, "host_total_time": {"title": "Host Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 44477], ["aten::empty", 33098], ["aten::stack", 33058], ["aten::cat", 31169], ["aten::_cat", 30970], ["aten::div", 30262], ["aten::to", 27130], ["aten::contiguous", 24479], ["CudnnConvolutionBackward", 17775], ["aten::add_", 17673], ["aten::add_", 16697], ["aten::add", 14945], ["aten::to", 14882], ["aten::copy_", 14414], ["CudnnConvolutionBackward", 13711], ["CudnnConvolutionBackward", 11351], ["aten::batch_norm", 11347], ["aten::add_", 11049], ["CudnnConvolutionBackward", 10589], ["aten::_batch_norm_impl_index", 10512], ["aten::cudnn_batch_norm", 9764], ["aten::cudnn_convolution_backward", 9304], ["CudnnConvolutionBackward", 8355], ["aten::cudnn_convolution_backward", 7766], ["aten::cudnn_convolution_backward", 7679], ["aten::batch_norm", 7406], ["CudnnConvolutionBackward", 7370], ["CudnnConvolutionBackward", 7280], ["aten::cudnn_convolution_backward", 7091], ["aten::add_", 7055], ["aten::add_", 7010], ["aten::mul_", 6995], ["aten::batch_norm", 6919], ["aten::_batch_norm_impl_index", 6878], ["aten::zero_", 6626], ["CudnnBatchNormBackward", 6470], ["aten::cudnn_batch_norm", 6436], ["aten::_batch_norm_impl_index", 6396], ["CudnnConvolutionBackward", 6384], ["torch::autograd::AccumulateGrad", 6319], ["aten::conv2d", 6107], ["aten::cudnn_convolution_backward", 6103], ["aten::batch_norm", 6089], ["aten::cudnn_batch_norm", 5951], ["aten::conv2d", 5860], ["aten::convolution", 5737], ["aten::_batch_norm_impl_index", 5656], ["aten::cudnn_batch_norm_backward", 5606], ["aten::cudnn_convolution_backward", 5431], ["aten::mul_", 5430], ["aten::cudnn_convolution_backward", 5417], ["aten::convolution", 5407], ["aten::_convolution", 5398], ["aten::cudnn_batch_norm", 5262], ["aten::cudnn_convolution_backward", 5240], ["aten::batch_norm", 5136], ["aten::conv2d", 5084], ["aten::zero_", 5074], ["aten::batch_norm", 5026], ["aten::_convolution", 5001], ["aten::conv2d", 4993], ["aten::cudnn_convolution", 4989], ["aten::cudnn_convolution_backward_weight", 4853], ["aten::convolution", 4792], ["aten::_batch_norm_impl_index", 4770], ["aten::convolution", 4634], ["aten::cudnn_convolution_backward_input", 4615], ["aten::_batch_norm_impl_index", 4598], ["aten::mul_", 4528], ["aten::cudnn_convolution_backward", 4527], ["aten::cudnn_convolution", 4506], ["aten::_convolution", 4500], ["torch::autograd::AccumulateGrad", 4436], ["aten::cudnn_batch_norm", 4424], ["aten::batch_norm", 4322], ["aten::_convolution", 4303], ["CudnnBatchNormBackward", 4289], ["aten::cudnn_batch_norm", 4282], ["aten::zero_", 4268], ["CudnnBatchNormBackward", 4202], ["aten::cudnn_convolution", 4126], ["aten::cudnn_convolution_backward_input", 4078], ["aten::batch_norm", 4051], ["aten::_batch_norm_impl_index", 4007], ["aten::add_", 3991], ["aten::cudnn_convolution_backward_weight", 3987], ["aten::conv2d", 3930], ["aten::fill_", 3913], ["aten::cudnn_convolution", 3883], ["aten::conv2d", 3854], ["aten::relu_", 3796], ["aten::conv2d", 3785], ["aten::_batch_norm_impl_index", 3763], ["aten::cudnn_batch_norm", 3754], ["aten::cudnn_batch_norm_backward", 3705], ["aten::convolution", 3699], ["aten::cudnn_batch_norm_backward", 3652], ["CudnnBatchNormBackward", 3650], ["aten::convolution", 3569], ["aten::convolution", 3559], ["aten::cudnn_batch_norm", 3501], ["aten::to", 3487], ["ReluBackward1", 3452], ["aten::cudnn_convolution_backward_input", 3428], ["aten::cudnn_convolution_backward_weight", 3414], ["aten::mul_", 3412], ["aten::_convolution", 3375], ["torch::autograd::AccumulateGrad", 3366], ["aten::_convolution", 3307], ["aten::cudnn_convolution_backward", 3307], ["aten::zero_", 3294], ["aten::_convolution", 3283], ["aten::add_", 3264], ["aten::cudnn_convolution_backward", 3238], ["aten::fill_", 3235], ["aten::cudnn_convolution_backward_weight", 3196], ["aten::add_", 3193], ["aten::permute", 3161], ["aten::cudnn_batch_norm_backward", 3160], ["aten::cudnn_convolution_backward", 3155], ["aten::cudnn_convolution", 3130], ["aten::cudnn_convolution", 3065], ["CudnnBatchNormBackward", 3048], ["CudnnBatchNormBackward", 3015], ["aten::conv2d", 3010], ["aten::conv2d", 2998], ["aten::set_", 2994], ["aten::cudnn_convolution_backward_input", 2962], ["aten::cudnn_convolution", 2956], ["CudnnConvolutionBackward", 2947], ["aten::zero_", 2932], ["aten::mul_", 2932], ["aten::threshold_backward", 2901], ["aten::cudnn_convolution_backward_weight", 2891], ["aten::cudnn_convolution_backward", 2875], ["aten::cudnn_convolution_backward_input", 2845], ["torch::autograd::AccumulateGrad", 2833], ["aten::conv2d", 2816], ["aten::convolution", 2786], ["torch::autograd::AccumulateGrad", 2768], ["aten::convolution", 2754], ["aten::convolution", 2730], ["aten::conv2d", 2687], ["aten::_convolution", 2661], ["aten::cudnn_batch_norm_backward", 2648], ["aten::cudnn_convolution_backward_input", 2633], ["aten::cudnn_batch_norm_backward", 2616], ["aten::convolution", 2585], ["aten::cudnn_convolution", 2577], ["aten::_convolution", 2577], ["aten::_convolution", 2551], ["CudnnBatchNormBackward", 2548], ["CudnnBatchNormBackward", 2545], ["aten::_convolution", 2497], ["aten::conv2d", 2477], ["aten::add_", 2466], ["aten::cudnn_convolution_backward_weight", 2426], ["aten::cudnn_convolution_backward_weight", 2378], ["aten::cudnn_convolution", 2356], ["CudnnConvolutionBackward", 2355], ["aten::relu_", 2341], ["aten::cudnn_convolution_backward_input", 2339], ["aten::convolution", 2336], ["aten::conv2d", 2336], ["aten::cudnn_convolution", 2335], ["aten::cudnn_convolution", 2301], ["aten::cudnn_convolution_backward", 2282], ["aten::cudnn_batch_norm_backward", 2223], ["aten::_convolution", 2192], ["aten::convolution", 2191], ["aten::cudnn_batch_norm_backward", 2191], ["aten::add_", 2173], ["aten::add_", 2160], ["aten::add_", 2150], ["ReluBackward1", 2138], ["aten::cudnn_convolution_backward_input", 2132], ["aten::conv2d", 2131], ["aten::threshold_", 2107], ["aten::_convolution", 2056], ["aten::view", 2030], ["aten::cudnn_convolution", 2027], ["aten::cudnn_convolution_backward_input", 2024], ["aten::cudnn_convolution_backward_input", 1999], ["aten::empty_like", 1993], ["aten::convolution", 1987], ["aten::cudnn_convolution_backward_input", 1987], ["aten::relu_", 1973], ["aten::fill_", 1973], ["aten::cudnn_convolution_backward_weight", 1965], ["ReluBackward1", 1907], ["aten::relu_", 1903], ["aten::cudnn_convolution_backward_weight", 1903], ["aten::cudnn_convolution", 1887], ["ReluBackward1", 1833], ["aten::_convolution", 1830], ["aten::threshold_backward", 1785], ["aten::fill_", 1744], ["aten::batch_norm", 1740], ["aten::empty_strided", 1725], ["aten::fill_", 1713], ["aten::relu_", 1703], ["aten::cudnn_convolution_backward_input", 1692], ["aten::cudnn_convolution_backward_weight", 1684], ["aten::mul_", 1670], ["aten::cudnn_convolution_backward", 1656], ["aten::_batch_norm_impl_index", 1650], ["CudnnConvolutionBackward", 1634], ["aten::cudnn_convolution", 1631], ["aten::cudnn_convolution_backward", 1623], ["aten::zero_", 1614], ["aten::add_", 1611], ["aten::cudnn_convolution_backward", 1610], ["aten::add_", 1606], ["aten::cudnn_convolution_backward", 1600], ["torch::autograd::AccumulateGrad", 1597], ["aten::add_", 1581], ["aten::add_", 1580], ["aten::cudnn_convolution_backward", 1578], ["aten::cudnn_batch_norm", 1569], ["aten::cudnn_convolution_backward", 1566], ["aten::threshold_backward", 1563], ["aten::cudnn_convolution_backward", 1548], ["ReluBackward1", 1531], ["aten::threshold_backward", 1524], ["aten::add_", 1482], ["aten::cudnn_convolution_backward", 1481], ["AddmmBackward", 1462], ["aten::cudnn_convolution_backward_input", 1458], ["aten::cudnn_convolution_backward_weight", 1429], ["torch::autograd::AccumulateGrad", 1429], ["torch::autograd::AccumulateGrad", 1420], ["aten::relu_", 1375], ["aten::threshold_", 1296], ["aten::unsqueeze", 1293], ["aten::mul_", 1285], ["aten::conv2d", 1281], ["aten::threshold_backward", 1277], ["aten::addmm", 1274], ["aten::mul_", 1262], ["aten::empty_like", 1261], ["aten::zero_", 1257], ["aten::cudnn_convolution_backward_weight", 1251], ["aten::zero_", 1249], ["ReluBackward1", 1227], ["aten::convolution", 1208], ["aten::_convolution", 1140], ["aten::cudnn_convolution_backward_input", 1140], ["CudnnConvolutionBackward", 1106], ["aten::conv2d", 1105], ["aten::relu_", 1096], ["aten::zero_", 1084], ["aten::add_", 1083], ["aten::zero_", 1078], ["aten::threshold_", 1068], ["aten::conv2d", 1066], ["torch::autograd::AccumulateGrad", 1064], ["aten::cudnn_convolution", 1057], ["aten::batch_norm", 1056], ["aten::conv2d", 1056], ["aten::mul_", 1050], ["aten::add_", 1043], ["aten::batch_norm", 1041], ["aten::conv2d", 1039], ["torch::autograd::AccumulateGrad", 1035], ["aten::conv2d", 1032], ["aten::convolution", 1029], ["aten::cudnn_convolution_backward", 1027], ["aten::threshold_backward", 1025], ["aten::batch_norm", 1021], ["aten::add_", 1008], ["aten::conv2d", 992], ["aten::conv2d", 990], ["aten::convolution", 988], ["aten::_batch_norm_impl_index", 986], ["aten::conv2d", 981], ["aten::threshold_", 980], ["aten::convolution", 980], ["torch::autograd::AccumulateGrad", 977], ["torch::autograd::AccumulateGrad", 976], ["aten::_batch_norm_impl_index", 969], ["aten::convolution", 968], ["aten::_convolution", 966], ["aten::fill_", 961], ["aten::convolution", 958], ["aten::relu_", 939], ["aten::_batch_norm_impl_index", 937], ["ReluBackward1", 934], ["aten::cudnn_batch_norm", 921], ["aten::convolution", 919], ["aten::threshold_", 919], ["aten::convolution", 918], ["ReluBackward1", 917], ["aten::_convolution", 916], ["aten::copy_", 915], ["aten::convolution", 910], ["aten::cudnn_batch_norm", 905], ["aten::_convolution", 904], ["aten::_convolution", 892], ["aten::_convolution", 891], ["aten::cudnn_convolution_backward_weight", 879], ["aten::cudnn_convolution", 878], ["aten::mul_", 872], ["aten::cudnn_batch_norm", 869], ["aten::mul_", 855], ["aten::_convolution", 852], ["aten::_convolution", 851], ["aten::mul_", 851], ["aten::zero_", 849], ["aten::_convolution", 846], ["aten::cudnn_convolution_backward_weight", 845], ["aten::cudnn_convolution", 836], ["aten::cudnn_convolution_backward_weight", 834], ["aten::add_", 830], ["aten::zero_", 823], ["aten::cudnn_convolution", 822], ["aten::cudnn_convolution", 811], ["aten::cudnn_convolution", 811], ["aten::cudnn_convolution_backward_input", 810], ["aten::add_", 809], ["aten::cudnn_convolution_backward_weight", 808], ["aten::cudnn_convolution_backward_weight", 801], ["aten::cudnn_convolution_backward_weight", 799], ["aten::threshold_backward", 777], ["aten::view", 776], ["aten::cudnn_convolution", 771], ["aten::cudnn_convolution", 766], ["MaxPool2DWithIndicesBackward", 763], ["aten::threshold_backward", 756], ["aten::cudnn_convolution", 754], ["aten::threshold_", 751], ["aten::fill_", 748], ["aten::fill_", 748], ["aten::empty_like", 747], ["aten::empty_like", 740], ["torch::autograd::AccumulateGrad", 736], ["aten::max_pool2d", 732], ["torch::autograd::AccumulateGrad", 722], ["aten::fill_", 721], ["torch::autograd::AccumulateGrad", 720], ["NllLossBackward", 719], ["aten::empty_like", 713], ["aten::cudnn_convolution_backward_weight", 703], ["aten::cudnn_convolution_backward_weight", 698], ["aten::max_pool2d_with_indices_backward", 686], ["aten::cudnn_convolution_backward_input", 670], ["aten::threshold_", 668], ["aten::zero_", 667], ["aten::mul_", 661], ["aten::mul_", 652], ["aten::zeros", 651], ["aten::cudnn_convolution_backward_input", 648], ["aten::zero_", 647], ["aten::max_pool2d_with_indices", 644], ["CudnnBatchNormBackward", 641], ["aten::cudnn_convolution_backward_weight", 637], ["torch::autograd::AccumulateGrad", 636], ["aten::mul_", 633], ["aten::mul_", 631], ["aten::zero_", 630], ["aten::cudnn_convolution_backward_weight", 625], ["aten::fill_", 617], ["aten::zero_", 613], ["MeanBackward1", 606], ["CudnnBatchNormBackward", 602], ["CudnnBatchNormBackward", 596], ["aten::add_", 593], ["aten::nll_loss_backward", 590], ["aten::add_", 589], ["CudnnBatchNormBackward", 580], ["aten::view", 575], ["aten::adaptive_avg_pool2d", 566], ["aten::cudnn_convolution_backward_input", 566], ["aten::cudnn_convolution_backward_input", 557], ["aten::add_", 553], ["aten::empty_like", 548], ["aten::mm", 547], ["aten::add_", 543], ["aten::cudnn_batch_norm_backward", 530], ["aten::to", 527], ["aten::log_softmax", 527], ["aten::add_", 527], ["aten::cudnn_batch_norm_backward", 527], ["aten::add_", 520], ["aten::cudnn_batch_norm_backward", 519], ["aten::empty_like", 516], ["torch::autograd::AccumulateGrad", 510], ["aten::cudnn_batch_norm_backward", 506], ["aten::add_", 503], ["aten::nll_loss", 500], ["aten::fill_", 494], ["aten::add_", 492], ["aten::add_", 490], ["aten::add_", 490], ["aten::mean", 484], ["aten::threshold_", 482], ["aten::fill_", 476], ["aten::as_strided", 458], ["aten::relu_", 453], ["LogSoftmaxBackward", 451], ["aten::_log_softmax", 447], ["aten::empty_like", 433], ["aten::empty_like", 433], ["aten::mul_", 430], ["aten::nll_loss_forward", 425], ["aten::mul_", 415], ["aten::zero_", 414], ["aten::zero_", 413], ["aten::ones_like", 410], ["torch::autograd::AccumulateGrad", 410], ["aten::div", 409], ["aten::zero_", 394], ["aten::view", 383], ["aten::relu_", 377], ["aten::fill_", 374], ["aten::resize_", 371], ["aten::as_strided", 368], ["aten::mul_", 368], ["aten::fill_", 364], ["aten::fill_", 363], ["aten::fill_", 360], ["aten::_log_softmax_backward_data", 357], ["aten::view", 356], ["aten::view", 342], ["aten::relu_", 340], ["aten::zeros_like", 339], ["aten::copy_", 334], ["aten::relu_", 324], ["ReluBackward1", 304], ["aten::zero_", 303], ["aten::t", 302], ["ReluBackward1", 301], ["aten::mm", 300], ["ReluBackward1", 300], ["ReluBackward1", 298], ["aten::fill_", 265], ["aten::threshold_", 260], ["aten::resize_", 257], ["torch::autograd::AccumulateGrad", 255], ["torch::autograd::AccumulateGrad", 254], ["aten::threshold_backward", 254], ["aten::threshold_backward", 250], ["aten::resize_", 249], ["aten::mul_", 249], ["aten::threshold_backward", 249], ["aten::fill_", 248], ["aten::t", 244], ["aten::fill_", 242], ["torch::autograd::AccumulateGrad", 242], ["aten::zero_", 241], ["torch::autograd::AccumulateGrad", 240], ["aten::threshold_backward", 240], ["torch::autograd::AccumulateGrad", 237], ["aten::resize_", 233], ["aten::threshold_", 226], ["aten::resize_", 221], ["aten::fill_", 217], ["aten::mul_", 216], ["aten::empty_like", 215], ["aten::zero_", 213], ["torch::autograd::AccumulateGrad", 213], ["aten::mul_", 212], ["torch::autograd::AccumulateGrad", 212], ["aten::mul_", 211], ["aten::mul_", 210], ["aten::zero_", 208], ["aten::mul_", 208], ["torch::autograd::AccumulateGrad", 208], ["aten::empty_like", 207], ["aten::flatten", 206], ["aten::mul_", 205], ["torch::autograd::AccumulateGrad", 205], ["aten::zero_", 204], ["aten::zero_", 204], ["aten::zero_", 202], ["aten::zero_", 202], ["aten::mul_", 202], ["aten::zero_", 201], ["aten::mul_", 198], ["aten::threshold_", 193], ["aten::view", 192], ["aten::zero_", 192], ["torch::autograd::AccumulateGrad", 188], ["aten::fill_", 180], ["aten::threshold_", 178], ["aten::resize_", 166], ["aten::resize_", 161], ["aten::resize_", 145], ["aten::resize_", 143], ["aten::reshape", 141], ["TBackward", 140], ["aten::fill_", 140], ["aten::transpose", 137], ["aten::resize_", 135], ["aten::fill_", 133], ["aten::resize_", 130], ["aten::empty_like", 130], ["aten::fill_", 127], ["aten::fill_", 123], ["aten::empty_like", 122], ["aten::fill_", 121], ["aten::fill_", 121], ["ViewBackward", 121], ["aten::resize_", 120], ["aten::fill_", 120], ["aten::fill_", 120], ["aten::fill_", 120], ["aten::transpose", 118], ["aten::t", 118], ["AddBackward0", 114], ["aten::resize_", 103], ["aten::view", 103], ["aten::resize_", 101], ["aten::empty_like", 99], ["aten::empty_like", 98], ["aten::resize_", 98], ["aten::resize_", 93], ["aten::narrow", 87], ["aten::reshape", 87], ["aten::expand", 81], ["aten::resize_", 78], ["AddBackward0", 77], ["aten::resize_", 74], ["aten::resize_", 74], ["aten::resize_", 73], ["aten::zero_", 64], ["aten::detach_", 64], ["aten::expand", 60], ["AddBackward0", 59], ["AddBackward0", 59], ["aten::transpose", 54], ["aten::view", 54], ["aten::resize_as_", 54], ["aten::slice", 52], ["aten::resize_", 49], ["aten::resize_", 49], ["aten::as_strided", 39], ["aten::resize_", 34], ["detach_", 33], ["aten::resize_", 33], ["aten::as_strided", 29], ["aten::resize_", 27], ["aten::resize_", 26], ["aten::resize_", 25], ["aten::conj", 25], ["aten::resize_", 24], ["aten::resize_", 23], ["aten::resize_", 23], ["aten::resize_", 22], ["aten::resize_", 22], ["aten::conj", 21], ["aten::resize_", 19], ["aten::to", 18], ["aten::as_strided", 15], ["aten::resize_", 14], ["aten::as_strided", 14], ["aten::as_strided", 14], ["aten::to", 13], ["aten::as_strided", 11]]}, "host_self_time": {"title": "Host Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 44477], ["aten::empty", 33098], ["aten::_cat", 30756], ["aten::div", 25659], ["aten::add_", 17673], ["aten::add_", 16697], ["aten::add", 14945], ["aten::copy_", 14414], ["aten::add_", 11049], ["aten::add_", 7055], ["aten::add_", 7010], ["aten::mul_", 6995], ["aten::cudnn_batch_norm", 6974], ["aten::mul_", 5430], ["aten::mul_", 4528], ["aten::cudnn_convolution", 4406], ["aten::cudnn_convolution_backward_weight", 4351], ["aten::cudnn_convolution_backward_input", 4341], ["aten::cudnn_batch_norm", 4316], ["aten::cudnn_batch_norm", 4204], ["aten::cudnn_batch_norm_backward", 4137], ["aten::add_", 3991], ["aten::fill_", 3913], ["aten::cudnn_convolution", 3905], ["aten::cudnn_batch_norm", 3723], ["aten::cudnn_convolution", 3632], ["aten::cudnn_convolution_backward_input", 3574], ["aten::cudnn_convolution_backward_weight", 3567], ["aten::mul_", 3412], ["aten::cudnn_convolution", 3290], ["aten::add_", 3264], ["aten::fill_", 3235], ["aten::add_", 3193], ["aten::cudnn_batch_norm", 3129], ["aten::cudnn_batch_norm", 3020], ["aten::set_", 2994], ["aten::cudnn_convolution_backward_weight", 2987], ["aten::cudnn_convolution_backward_input", 2965], ["aten::mul_", 2932], ["aten::cudnn_convolution_backward_weight", 2863], ["aten::cudnn_convolution", 2799], ["aten::cudnn_batch_norm_backward", 2764], ["aten::cudnn_batch_norm", 2755], ["aten::cudnn_batch_norm_backward", 2717], ["aten::zero_", 2713], ["aten::permute", 2703], ["aten::cudnn_convolution", 2693], ["aten::cudnn_convolution_backward_weight", 2641], ["aten::cudnn_convolution_backward_input", 2596], ["aten::cudnn_convolution", 2557], ["aten::zero_", 2555], ["aten::cudnn_batch_norm", 2478], ["aten::threshold_backward", 2467], ["aten::add_", 2466], ["aten::cudnn_convolution", 2444], ["aten::cudnn_convolution_backward_input", 2435], ["aten::cudnn_batch_norm_backward", 2318], ["aten::cudnn_convolution_backward_input", 2297], ["aten::to", 2295], ["aten::cudnn_convolution", 2215], ["aten::add_", 2173], ["aten::add_", 2160], ["aten::add_", 2150], ["aten::to", 2111], ["aten::threshold_", 2107], ["aten::cudnn_convolution_backward_weight", 2105], ["aten::contiguous", 2069], ["aten::cudnn_convolution_backward_weight", 2057], ["aten::view", 2030], ["aten::cudnn_convolution_backward_input", 2018], ["aten::cudnn_convolution", 1994], ["aten::cudnn_convolution", 1975], ["aten::fill_", 1973], ["aten::cudnn_batch_norm_backward", 1951], ["aten::cudnn_batch_norm_backward", 1950], ["aten::cudnn_convolution_backward_input", 1898], ["aten::cudnn_convolution_backward_input", 1849], ["aten::zero_", 1839], ["aten::cudnn_convolution", 1806], ["aten::cudnn_convolution_backward_input", 1777], ["aten::cudnn_convolution_backward_input", 1760], ["aten::fill_", 1744], ["aten::empty_strided", 1725], ["aten::fill_", 1713], ["aten::cudnn_convolution_backward_weight", 1710], ["aten::cudnn_batch_norm_backward", 1695], ["aten::relu_", 1689], ["aten::mul_", 1670], ["aten::cudnn_convolution", 1660], ["aten::cudnn_batch_norm_backward", 1650], ["aten::cudnn_convolution_backward_weight", 1644], ["aten::add_", 1611], ["aten::add_", 1606], ["aten::add_", 1581], ["aten::add_", 1580], ["aten::cudnn_convolution_backward_weight", 1522], ["aten::cudnn_convolution_backward_input", 1514], ["aten::threshold_backward", 1500], ["aten::add_", 1482], ["aten::cudnn_convolution", 1435], ["aten::cudnn_convolution_backward_input", 1368], ["aten::zero_", 1321], ["aten::threshold_backward", 1309], ["aten::threshold_backward", 1304], ["aten::threshold_", 1296], ["aten::empty_like", 1288], ["aten::mul_", 1285], ["aten::cudnn_convolution_backward_weight", 1269], ["aten::mul_", 1262], ["torch::autograd::AccumulateGrad", 1203], ["aten::zero_", 1188], ["aten::addmm", 1138], ["aten::cudnn_convolution_backward_weight", 1089], ["aten::add_", 1083], ["aten::threshold_backward", 1072], ["aten::threshold_", 1068], ["aten::mul_", 1050], ["aten::relu_", 1045], ["aten::add_", 1043], ["aten::cudnn_convolution_backward", 1023], ["aten::add_", 1008], ["aten::cudnn_convolution_backward_input", 986], ["aten::threshold_", 980], ["aten::fill_", 961], ["aten::cudnn_convolution", 929], ["aten::unsqueeze", 925], ["aten::relu_", 923], ["aten::threshold_", 919], ["aten::copy_", 915], ["aten::relu_", 905], ["aten::cudnn_convolution_backward", 881], ["aten::mul_", 872], ["CudnnBatchNormBackward", 864], ["aten::mul_", 855], ["torch::autograd::AccumulateGrad", 854], ["aten::threshold_backward", 854], ["aten::mul_", 851], ["aten::cudnn_convolution_backward", 847], ["aten::batch_norm", 835], ["aten::add_", 830], ["aten::cudnn_batch_norm", 829], ["aten::add_", 809], ["aten::cudnn_convolution_backward_weight", 787], ["aten::relu_", 784], ["aten::view", 776], ["aten::cudnn_convolution", 773], ["aten::cudnn_convolution_backward_weight", 757], ["CudnnConvolutionBackward", 752], ["aten::threshold_", 751], ["aten::_batch_norm_impl_index", 748], ["aten::fill_", 748], ["aten::fill_", 748], ["aten::cudnn_convolution_backward_weight", 746], ["aten::cudnn_convolution", 724], ["aten::cudnn_convolution_backward_weight", 722], ["aten::fill_", 721], ["aten::cudnn_convolution_backward", 715], ["aten::cudnn_convolution_backward_weight", 714], ["aten::cudnn_convolution_backward", 714], ["aten::cudnn_convolution_backward_weight", 713], ["aten::cudnn_convolution", 708], ["aten::cudnn_convolution", 707], ["aten::cudnn_convolution_backward_input", 693], ["aten::cudnn_convolution", 684], ["aten::cudnn_convolution", 676], ["aten::cudnn_convolution", 675], ["aten::threshold_", 668], ["aten::threshold_backward", 666], ["aten::mul_", 661], ["aten::cudnn_convolution", 659], ["aten::cudnn_batch_norm", 655], ["aten::cudnn_batch_norm", 654], ["aten::zero_", 653], ["aten::empty_like", 652], ["aten::mul_", 652], ["aten::threshold_backward", 645], ["aten::cudnn_batch_norm", 639], ["aten::mul_", 633], ["aten::mul_", 631], ["aten::relu_", 624], ["torch::autograd::AccumulateGrad", 620], ["aten::cudnn_convolution_backward_weight", 618], ["aten::fill_", 617], ["aten::cudnn_convolution_backward_weight", 617], ["aten::stack", 596], ["aten::add_", 593], ["aten::nll_loss_backward", 590], ["aten::add_", 589], ["CudnnBatchNormBackward", 584], ["aten::view", 575], ["aten::cudnn_convolution_backward", 573], ["torch::autograd::AccumulateGrad", 564], ["aten::add_", 553], ["ReluBackward1", 551], ["aten::cudnn_convolution_backward_weight", 551], ["CudnnBatchNormBackward", 550], ["aten::cudnn_convolution_backward_weight", 546], ["aten::add_", 543], ["aten::cudnn_convolution_backward_input", 538], ["torch::autograd::AccumulateGrad", 538], ["aten::zero_", 536], ["aten::cudnn_convolution_backward_input", 535], ["aten::cudnn_convolution_backward", 533], ["aten::batch_norm", 528], ["aten::add_", 527], ["aten::cudnn_convolution_backward", 527], ["aten::batch_norm", 523], ["aten::add_", 520], ["aten::mm", 512], ["aten::cudnn_convolution_backward", 512], ["aten::add_", 503], ["aten::zero_", 501], ["CudnnConvolutionBackward", 499], ["aten::max_pool2d_with_indices", 497], ["aten::_convolution", 495], ["aten::fill_", 494], ["CudnnConvolutionBackward", 493], ["aten::add_", 492], ["aten::add_", 490], ["aten::add_", 490], ["CudnnBatchNormBackward", 490], ["aten::cudnn_convolution_backward_input", 488], ["aten::threshold_", 482], ["aten::cudnn_convolution_backward_input", 479], ["aten::fill_", 476], ["aten::zeros", 463], ["aten::zero_", 461], ["aten::as_strided", 458], ["aten::relu_", 457], ["aten::conv2d", 453], ["aten::_batch_norm_impl_index", 445], ["aten::_batch_norm_impl_index", 442], ["aten::batch_norm", 433], ["CudnnConvolutionBackward", 432], ["aten::mean", 431], ["aten::mul_", 430], ["aten::relu_", 428], ["aten::batch_norm", 428], ["aten::nll_loss_forward", 425], ["aten::_convolution", 420], ["aten::mul_", 415], ["aten::_convolution", 409], ["aten::convolution", 406], ["aten::cudnn_batch_norm_backward", 401], ["CudnnBatchNormBackward", 400], ["CudnnBatchNormBackward", 399], ["aten::_batch_norm_impl_index", 394], ["aten::cudnn_batch_norm_backward", 393], ["aten::convolution", 392], ["aten::cudnn_batch_norm_backward", 390], ["aten::view", 383], ["aten::empty_like", 378], ["aten::_convolution", 374], ["aten::fill_", 374], ["aten::cudnn_batch_norm_backward", 373], ["aten::resize_", 371], ["aten::conv2d", 370], ["aten::div", 369], ["aten::as_strided", 368], ["aten::empty_like", 368], ["aten::mul_", 368], ["CudnnConvolutionBackward", 368], ["aten::batch_norm", 366], ["aten::fill_", 364], ["aten::cudnn_convolution_backward", 364], ["aten::fill_", 363], ["aten::fill_", 360], ["aten::conv2d", 359], ["aten::cudnn_convolution_backward", 357], ["CudnnBatchNormBackward", 357], ["aten::view", 356], ["aten::zero_", 355], ["ReluBackward1", 353], ["aten::zero_", 347], ["aten::_batch_norm_impl_index", 346], ["ReluBackward1", 344], ["aten::_log_softmax", 343], ["aten::empty_like", 342], ["aten::view", 342], ["aten::convolution", 339], ["CudnnConvolutionBackward", 339], ["aten::zero_", 336], ["aten::copy_", 334], ["aten::convolution", 331], ["aten::cudnn_convolution_backward", 331], ["aten::cudnn_convolution_backward", 329], ["aten::_convolution", 327], ["CudnnBatchNormBackward", 322], ["aten::_batch_norm_impl_index", 316], ["aten::batch_norm", 315], ["ReluBackward1", 309], ["torch::autograd::AccumulateGrad", 305], ["aten::zero_", 303], ["CudnnConvolutionBackward", 297], ["aten::conv2d", 295], ["aten::max_pool2d_with_indices_backward", 293], ["aten::convolution", 292], ["aten::conv2d", 292], ["aten::batch_norm", 288], ["aten::zero_", 287], ["CudnnConvolutionBackward", 281], ["torch::autograd::AccumulateGrad", 279], ["torch::autograd::AccumulateGrad", 277], ["aten::convolution", 276], ["torch::autograd::AccumulateGrad", 269], ["aten::fill_", 265], ["aten::empty_like", 263], ["aten::_batch_norm_impl_index", 262], ["aten::threshold_", 260], ["aten::mm", 259], ["aten::resize_", 257], ["aten::zero_", 256], ["aten::empty_like", 255], ["ReluBackward1", 254], ["aten::_batch_norm_impl_index", 253], ["aten::_convolution", 250], ["aten::zero_", 250], ["aten::resize_", 249], ["aten::mul_", 249], ["aten::fill_", 248], ["aten::_log_softmax_backward_data", 246], ["aten::_convolution", 245], ["aten::conv2d", 244], ["aten::_convolution", 242], ["aten::_convolution", 242], ["aten::fill_", 242], ["aten::resize_", 233], ["aten::conv2d", 231], ["aten::threshold_", 226], ["aten::conv2d", 224], ["aten::resize_", 221], ["torch::autograd::AccumulateGrad", 221], ["aten::fill_", 217], ["aten::conv2d", 216], ["aten::mul_", 216], ["aten::threshold_backward", 214], ["aten::empty_like", 212], ["aten::mul_", 212], ["aten::empty_like", 211], ["aten::mul_", 211], ["aten::threshold_backward", 211], ["aten::mul_", 210], ["aten::threshold_backward", 210], ["aten::convolution", 209], ["aten::mul_", 208], ["aten::cudnn_convolution_backward", 207], ["torch::autograd::AccumulateGrad", 206], ["aten::mul_", 205], ["aten::convolution", 203], ["aten::threshold_backward", 203], ["aten::mul_", 202], ["ReluBackward1", 202], ["aten::cat", 199], ["aten::_convolution", 199], ["aten::mul_", 198], ["AddmmBackward", 195], ["torch::autograd::AccumulateGrad", 195], ["aten::convolution", 194], ["aten::relu_", 193], ["aten::threshold_", 193], ["aten::view", 192], ["aten::cudnn_convolution_backward", 187], ["aten::cudnn_convolution_backward", 186], ["aten::cudnn_convolution_backward", 185], ["aten::fill_", 180], ["aten::cudnn_convolution_backward", 179], ["aten::threshold_", 178], ["aten::cudnn_convolution_backward", 175], ["aten::cudnn_convolution_backward", 174], ["aten::cudnn_convolution_backward", 172], ["aten::cudnn_convolution_backward", 172], ["aten::cudnn_convolution_backward", 172], ["aten::zero_", 171], ["aten::_convolution", 169], ["aten::resize_", 166], ["aten::zero_", 166], ["aten::_convolution", 165], ["aten::t", 165], ["torch::autograd::AccumulateGrad", 162], ["aten::resize_", 161], ["ReluBackward1", 161], ["aten::convolution", 157], ["ReluBackward1", 157], ["aten::to", 154], ["aten::relu_", 151], ["torch::autograd::AccumulateGrad", 150], ["aten::relu_", 147], ["aten::relu_", 146], ["aten::resize_", 145], ["aten::conv2d", 145], ["aten::convolution", 144], ["aten::conv2d", 144], ["aten::resize_", 143], ["torch::autograd::AccumulateGrad", 142], ["aten::_convolution", 141], ["aten::conv2d", 141], ["aten::fill_", 140], ["aten::resize_", 135], ["aten::convolution", 135], ["torch::autograd::AccumulateGrad", 135], ["aten::fill_", 133], ["aten::resize_", 130], ["aten::zero_", 129], ["NllLossBackward", 129], ["aten::fill_", 127], ["aten::t", 126], ["aten::fill_", 123], ["aten::empty_like", 122], ["aten::fill_", 121], ["aten::fill_", 121], ["aten::resize_", 120], ["aten::fill_", 120], ["aten::fill_", 120], ["aten::fill_", 120], ["AddBackward0", 114], ["aten::empty_like", 111], ["CudnnBatchNormBackward", 111], ["aten::zero_", 108], ["aten::resize_", 103], ["aten::view", 103], ["MeanBackward1", 103], ["torch::autograd::AccumulateGrad", 103], ["aten::conv2d", 102], ["aten::resize_", 101], ["aten::ones_like", 100], ["aten::resize_", 98], ["aten::_convolution", 98], ["aten::transpose", 98], ["aten::convolution", 97], ["torch::autograd::AccumulateGrad", 96], ["LogSoftmaxBackward", 94], ["aten::resize_", 93], ["aten::batch_norm", 90], ["aten::zero_", 90], ["aten::to", 89], ["aten::transpose", 89], ["aten::convolution", 88], ["aten::max_pool2d", 88], ["aten::_convolution", 88], ["aten::conv2d", 86], ["aten::zero_", 86], ["aten::batch_norm", 84], ["aten::_convolution", 84], ["aten::zero_", 84], ["aten::_convolution", 83], ["aten::zero_", 83], ["aten::_convolution", 82], ["aten::adaptive_avg_pool2d", 82], ["aten::zero_", 82], ["aten::_batch_norm_impl_index", 81], ["aten::_convolution", 81], ["aten::zero_", 81], ["aten::zero_", 81], ["aten::zero_", 81], ["aten::_convolution", 80], ["aten::_convolution", 80], ["aten::_convolution", 80], ["aten::_convolution", 80], ["aten::log_softmax", 80], ["CudnnConvolutionBackward", 79], ["aten::resize_", 78], ["aten::conv2d", 78], ["CudnnBatchNormBackward", 77], ["AddBackward0", 77], ["MaxPool2DWithIndicesBackward", 77], ["aten::conv2d", 76], ["aten::conv2d", 76], ["aten::nll_loss", 75], ["CudnnBatchNormBackward", 75], ["aten::conv2d", 74], ["aten::resize_", 74], ["aten::resize_", 74], ["CudnnBatchNormBackward", 74], ["aten::resize_", 73], ["aten::conv2d", 73], ["aten::conv2d", 73], ["CudnnConvolutionBackward", 73], ["aten::conv2d", 72], ["aten::batch_norm", 72], ["CudnnConvolutionBackward", 72], ["aten::conv2d", 71], ["aten::conv2d", 71], ["aten::batch_norm", 70], ["aten::convolution", 69], ["aten::empty_like", 69], ["aten::_batch_norm_impl_index", 68], ["aten::convolution", 68], ["aten::convolution", 68], ["CudnnConvolutionBackward", 68], ["aten::expand", 67], ["aten::convolution", 66], ["aten::convolution", 66], ["aten::_batch_norm_impl_index", 65], ["aten::flatten", 65], ["aten::zero_", 64], ["aten::convolution", 64], ["aten::_batch_norm_impl_index", 64], ["aten::convolution", 64], ["aten::convolution", 64], ["aten::t", 64], ["aten::convolution", 63], ["torch::autograd::AccumulateGrad", 60], ["aten::empty_like", 59], ["AddBackward0", 59], ["AddBackward0", 59], ["ReluBackward1", 58], ["aten::view", 54], ["aten::zeros_like", 53], ["torch::autograd::AccumulateGrad", 52], ["aten::zero_", 52], ["aten::empty_like", 51], ["ReluBackward1", 51], ["ReluBackward1", 51], ["torch::autograd::AccumulateGrad", 50], ["ReluBackward1", 50], ["aten::resize_", 49], ["aten::empty_like", 49], ["aten::resize_", 49], ["torch::autograd::AccumulateGrad", 49], ["torch::autograd::AccumulateGrad", 49], ["torch::autograd::AccumulateGrad", 47], ["torch::autograd::AccumulateGrad", 47], ["aten::expand", 46], ["torch::autograd::AccumulateGrad", 46], ["torch::autograd::AccumulateGrad", 45], ["aten::resize_as_", 44], ["aten::slice", 41], ["aten::as_strided", 39], ["aten::transpose", 39], ["aten::reshape", 38], ["aten::narrow", 35], ["aten::resize_", 34], ["torch::autograd::AccumulateGrad", 34], ["ViewBackward", 34], ["detach_", 33], ["aten::resize_", 33], ["aten::reshape", 33], ["aten::detach_", 31], ["aten::as_strided", 29], ["TBackward", 29], ["aten::resize_", 27], ["aten::resize_", 26], ["aten::resize_", 25], ["aten::conj", 25], ["aten::resize_", 24], ["aten::resize_", 23], ["aten::resize_", 23], ["aten::resize_", 22], ["aten::resize_", 22], ["aten::conj", 21], ["aten::resize_", 19], ["aten::to", 18], ["aten::as_strided", 15], ["aten::resize_", 14], ["aten::as_strided", 14], ["aten::as_strided", 14], ["aten::to", 13], ["aten::as_strided", 11]]}}, "operation_table_by_name_input": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "string", "name": "Input Shape"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Device Self Duration (us)"}, {"type": "number", "name": "Device Total Duration (us)"}, {"type": "number", "name": "Host Self Duration (us)"}, {"type": "number", "name": "Host Total Duration (us)"}], "rows": [["aten::cudnn_convolution_backward_weight", "[[], [32, 64, 56, 56], [32, 64, 56, 56], [], [], [], [], [], [], []]", 24, 17145, 17145, 2863, 3196], ["aten::cudnn_convolution_backward_input", "[[], [32, 1024, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], []]", 36, 16034, 16034, 2965, 3428], ["aten::cudnn_batch_norm_backward", "[[32, 256, 56, 56], [32, 256, 56, 56], [256], [256], [256], [256], [256], [], [0]]", 24, 15198, 15198, 1650, 2191], ["aten::cudnn_convolution", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], []]", 36, 14037, 14037, 3905, 4506], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], []]", 36, 13967, 13967, 3574, 4078], ["aten::cudnn_convolution_backward_weight", "[[], [32, 1024, 14, 14], [32, 256, 14, 14], [], [], [], [], [], [], []]", 36, 13035, 13035, 4351, 4853], ["aten::copy_", "[[32, 3, 224, 224], [32, 3, 224, 224], []]", 6, 12728, 12728, 14414, 14414], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], []]", 30, 12497, 12497, 2435, 2845], ["aten::cudnn_convolution_backward_input", "[[], [32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], []]", 24, 12115, 12115, 2297, 2633], ["aten::cudnn_convolution", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], []]", 30, 11767, 11767, 3290, 3883], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 56, 56], [32, 64, 56, 56], [], [], [], [], [], [], []]", 24, 11694, 11694, 2105, 2426], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 14, 14], [32, 1024, 14, 14], [], [], [], [], [], [], []]", 30, 10890, 10890, 3567, 3987], ["aten::cudnn_convolution", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], []]", 24, 10192, 10192, 2557, 2956], ["aten::cudnn_batch_norm_backward", "[[32, 512, 28, 28], [32, 512, 28, 28], [512], [512], [512], [512], [512], [], [0]]", 30, 9663, 9663, 1950, 2616], ["aten::cudnn_batch_norm", "[[32, 256, 56, 56], [256], [256], [256], [256], [], [], []]", 24, 9555, 9555, 2478, 3501], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 28, 28], [32, 128, 28, 28], [], [], [], [], [], [], []]", 24, 9541, 9541, 2057, 2378], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], []]", 18, 9193, 9193, 1777, 2024], ["aten::cudnn_convolution_backward_weight", "[[], [32, 64, 56, 56], [32, 256, 56, 56], [], [], [], [], [], [], []]", 12, 9039, 9039, 1089, 1251], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], []]", 24, 8673, 8673, 2018, 2339], ["aten::cudnn_convolution", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], []]", 30, 8614, 8614, 4406, 4989], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 14, 14], [32, 256, 14, 14], [], [], [], [], [], [], []]", 30, 8558, 8558, 2987, 3414], ["aten::cudnn_convolution_backward_input", "[[], [32, 2048, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], []]", 18, 8397, 8397, 1760, 1999], ["aten::cudnn_batch_norm_backward", "[[32, 1024, 14, 14], [32, 1024, 14, 14], [1024], [1024], [1024], [1024], [1024], [], [0]]", 42, 7463, 7463, 2717, 3652], ["aten::cudnn_batch_norm_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], [64], [64], [64], [64], [64], [], [0]]", 36, 7412, 7412, 2318, 3160], ["aten::cudnn_convolution", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], []]", 18, 7394, 7394, 1994, 2335], ["aten::cudnn_convolution", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], []]", 24, 7261, 7261, 3632, 4126], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 28, 28], [32, 512, 28, 28], [], [], [], [], [], [], []]", 18, 7202, 7202, 1644, 1903], ["aten::cudnn_convolution", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], []]", 18, 6824, 6824, 1975, 2301], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], []]", 24, 6762, 6762, 2596, 2962], ["aten::cudnn_convolution_backward_input", "[[], [32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], []]", 18, 6662, 6662, 1849, 2132], ["aten::cudnn_convolution", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], []]", 18, 6623, 6623, 2693, 3065], ["aten::add_", "[[32, 256, 56, 56], [32, 256, 56, 56], []]", 18, 6538, 6538, 830, 830], ["aten::threshold_backward", "[[32, 256, 56, 56], [32, 256, 56, 56], []]", 18, 6534, 6534, 645, 756], ["aten::cudnn_batch_norm", "[[32, 512, 28, 28], [512], [512], [512], [512], [], [], []]", 30, 6189, 6189, 3020, 4282], ["aten::cudnn_convolution_backward_weight", "[[], [32, 2048, 7, 7], [32, 512, 7, 7], [], [], [], [], [], [], []]", 18, 6087, 6087, 2641, 2891], ["aten::cudnn_convolution_backward_weight", "[[], [32, 64, 112, 112], [32, 3, 224, 224], [], [], [], [], [], [], []]", 6, 5916, 5916, 617, 698], ["aten::cudnn_convolution_backward_input", "[[], [32, 2048, 7, 7], [2048, 1024, 1, 1], [], [], [], [], [], [], []]", 6, 5744, 5744, 538, 648], ["aten::cudnn_convolution", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], [], [], []]", 6, 5495, 5495, 724, 836], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], []]", 12, 5366, 5366, 986, 1140], ["aten::cudnn_convolution_backward_input", "[[], [32, 1024, 14, 14], [1024, 512, 1, 1], [], [], [], [], [], [], []]", 6, 5345, 5345, 488, 566], ["aten::cudnn_convolution", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], []]", 12, 5341, 5341, 1435, 1631], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 28, 28], [32, 128, 28, 28], [], [], [], [], [], [], []]", 18, 5328, 5328, 1710, 1965], ["aten::cudnn_convolution", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], []]", 18, 5214, 5214, 2799, 3130], ["aten::cudnn_convolution", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], [], [], []]", 6, 5093, 5093, 684, 822], ["aten::cudnn_convolution_backward_input", "[[], [32, 128, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], []]", 18, 4996, 4996, 4341, 4615], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 28, 28], [512, 256, 1, 1], [], [], [], [], [], [], []]", 6, 4950, 4950, 535, 670], ["aten::cudnn_batch_norm_backward", "[[32, 64, 112, 112], [32, 64, 112, 112], [64], [64], [64], [64], [64], [], [0]]", 6, 4773, 4773, 393, 530], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 56, 56], [32, 256, 56, 56], [], [], [], [], [], [], []]", 6, 4769, 4769, 551, 637], ["aten::cudnn_convolution", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], [], [], []]", 6, 4640, 4640, 675, 771], ["aten::cudnn_convolution", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], []]", 6, 4632, 4632, 929, 1057], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 28, 28], [32, 256, 56, 56], [], [], [], [], [], [], []]", 6, 4559, 4559, 546, 625], ["aten::threshold_", "[[32, 256, 56, 56], [], []]", 18, 4491, 4491, 668, 668], ["aten::cudnn_convolution", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], [], [], []]", 6, 4453, 4453, 659, 754], ["aten::cudnn_convolution_backward_input", "[[], [32, 512, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], []]", 6, 4429, 4429, 479, 557], ["aten::add_", "[[32, 512, 28, 28], [32, 512, 28, 28], []]", 24, 4393, 4393, 1043, 1043], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 28, 28], [32, 512, 28, 28], [], [], [], [], [], [], []]", 6, 4391, 4391, 618, 703], ["aten::cudnn_convolution", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], [], [], []]", 6, 4379, 4379, 676, 766], ["aten::threshold_backward", "[[32, 512, 28, 28], [32, 512, 28, 28], []]", 24, 4377, 4377, 854, 1025], ["aten::cudnn_convolution", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], []]", 6, 4265, 4265, 707, 811], ["aten::cudnn_convolution_backward_weight", "[[], [32, 2048, 7, 7], [32, 1024, 14, 14], [], [], [], [], [], [], []]", 6, 4231, 4231, 713, 801], ["aten::cudnn_convolution", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], []]", 6, 4176, 4176, 708, 811], ["aten::cudnn_convolution_backward_weight", "[[], [32, 128, 28, 28], [32, 128, 56, 56], [], [], [], [], [], [], []]", 6, 4103, 4103, 757, 845], ["aten::max_pool2d_with_indices_backward", "[[32, 64, 56, 56], [32, 64, 112, 112], [], [], [], [], [], [32, 64, 56, 56]]", 6, 4098, 5046, 293, 686], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 7, 7], [32, 2048, 7, 7], [], [], [], [], [], [], []]", 12, 4053, 4053, 1522, 1684], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 7, 7], [32, 512, 14, 14], [], [], [], [], [], [], []]", 6, 4032, 4032, 787, 879], ["aten::cudnn_convolution_backward_weight", "[[], [32, 1024, 14, 14], [32, 512, 28, 28], [], [], [], [], [], [], []]", 6, 3992, 3992, 722, 808], ["aten::cudnn_batch_norm", "[[32, 64, 56, 56], [64], [64], [64], [64], [], [], []]", 36, 3985, 3985, 3723, 5262], ["aten::cudnn_convolution_backward_weight", "[[], [32, 256, 14, 14], [32, 256, 28, 28], [], [], [], [], [], [], []]", 6, 3873, 3873, 714, 799], ["aten::cudnn_convolution", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], []]", 6, 3841, 3841, 2215, 2356], ["aten::cudnn_convolution_backward_input", "[[], [32, 64, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], []]", 12, 3752, 3752, 1514, 1692], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 14, 14], [32, 1024, 14, 14], [], [], [], [], [], [], []]", 6, 3718, 3718, 746, 834], ["aten::cudnn_convolution", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], []]", 12, 3683, 3683, 1660, 1887], ["aten::cudnn_batch_norm_backward", "[[32, 128, 28, 28], [32, 128, 28, 28], [128], [128], [128], [128], [128], [], [0]]", 42, 3660, 3660, 2764, 3705], ["aten::cudnn_batch_norm", "[[32, 1024, 14, 14], [1024], [1024], [1024], [1024], [], [], []]", 42, 3549, 3549, 4316, 6436], ["aten::cudnn_convolution", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], [], [], []]", 6, 3544, 3544, 2444, 2577], ["aten::cudnn_convolution_backward_weight", "[[], [32, 512, 7, 7], [32, 512, 7, 7], [], [], [], [], [], [], []]", 12, 3514, 3514, 1269, 1429], ["aten::cudnn_convolution", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], []]", 12, 3419, 3419, 1806, 2027], ["aten::add_", "[[32, 1024, 14, 14], [32, 1024, 14, 14], []]", 36, 3316, 3316, 1606, 1606], ["aten::threshold_backward", "[[32, 1024, 14, 14], [32, 1024, 14, 14], []]", 36, 3315, 3315, 1304, 1524], ["aten::threshold_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], []]", 36, 3206, 3206, 1309, 1563], ["aten::cudnn_convolution_backward_input", "[[], [32, 128, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], []]", 6, 3205, 3205, 1368, 1458], ["aten::cudnn_convolution_backward_input", "[[], [32, 256, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], []]", 6, 3167, 3167, 1898, 1987], ["aten::threshold_", "[[32, 512, 28, 28], [], []]", 24, 3003, 3003, 751, 751], ["aten::cudnn_batch_norm_backward", "[[32, 256, 14, 14], [32, 256, 14, 14], [256], [256], [256], [256], [256], [], [0]]", 66, 2903, 2903, 4137, 5606], ["aten::cudnn_batch_norm", "[[32, 64, 112, 112], [64], [64], [64], [64], [], [], []]", 6, 2546, 2546, 829, 1569], ["aten::threshold_", "[[32, 64, 56, 56], [], []]", 36, 2291, 2291, 1068, 1068], ["aten::threshold_", "[[32, 1024, 14, 14], [], []]", 36, 2277, 2277, 980, 980], ["aten::threshold_backward", "[[32, 64, 112, 112], [32, 64, 112, 112], []]", 6, 2180, 2180, 203, 240], ["aten::cudnn_batch_norm", "[[32, 128, 28, 28], [128], [128], [128], [128], [], [], []]", 42, 2143, 2143, 4204, 5951], ["aten::cudnn_batch_norm_backward", "[[32, 128, 56, 56], [32, 128, 56, 56], [128], [128], [128], [128], [128], [], [0]]", 6, 2022, 2022, 373, 506], ["aten::threshold_backward", "[[32, 128, 28, 28], [32, 128, 28, 28], []]", 42, 1909, 1909, 1500, 1785], ["aten::add_", "[[512, 512, 3, 3], [512, 512, 3, 3], []]", 54, 1893, 1893, 1611, 1611], ["aten::cudnn_batch_norm_backward", "[[32, 2048, 7, 7], [32, 2048, 7, 7], [2048], [2048], [2048], [2048], [2048], [], [0]]", 24, 1695, 1695, 1695, 2223], ["aten::threshold_backward", "[[32, 256, 14, 14], [32, 256, 14, 14], []]", 66, 1579, 1579, 2467, 2901], ["aten::threshold_", "[[32, 64, 112, 112], [], []]", 6, 1500, 1500, 260, 260], ["aten::cudnn_batch_norm", "[[32, 256, 14, 14], [256], [256], [256], [256], [], [], []]", 66, 1477, 1477, 6974, 9764], ["aten::threshold_", "[[32, 128, 28, 28], [], []]", 42, 1347, 1347, 1296, 1296], ["aten::max_pool2d_with_indices", "[[32, 64, 112, 112], [], [], [], [], []]", 6, 1341, 1341, 497, 644], ["aten::cudnn_batch_norm", "[[32, 2048, 7, 7], [2048], [2048], [2048], [2048], [], [], []]", 24, 1314, 1314, 2755, 3754], ["aten::cudnn_batch_norm", "[[32, 128, 56, 56], [128], [128], [128], [128], [], [], []]", 6, 1199, 1199, 639, 869], ["aten::threshold_backward", "[[32, 128, 56, 56], [32, 128, 56, 56], []]", 6, 1083, 1083, 211, 250], ["aten::cudnn_batch_norm_backward", "[[32, 256, 28, 28], [32, 256, 28, 28], [256], [256], [256], [256], [256], [], [0]]", 6, 961, 961, 390, 519], ["aten::fill_", "[[32, 64, 112, 112], []]", 6, 948, 948, 140, 140], ["aten::cudnn_convolution", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], []]", 6, 848, 848, 773, 878], ["aten::threshold_backward", "[[32, 2048, 7, 7], [32, 2048, 7, 7], []]", 18, 846, 846, 666, 777], ["aten::add_", "[[32, 2048, 7, 7], [32, 2048, 7, 7], []]", 18, 829, 829, 809, 809], ["aten::threshold_", "[[32, 256, 14, 14], [], []]", 66, 768, 768, 2107, 2107], ["aten::threshold_", "[[32, 128, 56, 56], [], []]", 6, 755, 755, 178, 178], ["aten::add_", "[[2048, 512, 1, 1], [2048, 512, 1, 1], []]", 54, 685, 685, 1580, 1580], ["aten::add_", "[[256, 256, 3, 3], [256, 256, 3, 3], []]", 108, 619, 619, 3264, 3264], ["aten::cudnn_batch_norm", "[[32, 256, 28, 28], [256], [256], [256], [256], [], [], []]", 6, 617, 617, 655, 921], ["aten::cudnn_convolution_backward_input", "[[], [32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], []]", 6, 590, 590, 693, 810], ["aten::cudnn_batch_norm_backward", "[[32, 512, 7, 7], [32, 512, 7, 7], [512], [512], [512], [512], [512], [], [0]]", 30, 588, 588, 1951, 2648], ["aten::threshold_", "[[32, 2048, 7, 7], [], []]", 18, 583, 583, 482, 482], ["aten::add_", "[[256], [256], []]", 576, 576, 576, 16697, 16697], ["aten::add_", "[[2048, 1024, 1, 1], [2048, 1024, 1, 1], []]", 18, 564, 564, 553, 553], ["aten::threshold_backward", "[[32, 256, 28, 28], [32, 256, 28, 28], []]", 6, 556, 556, 214, 254], ["aten::add_", "[[1000, 2048], [1000, 2048], []]", 18, 555, 555, 490, 490], ["aten::cudnn_batch_norm_backward", "[[32, 512, 14, 14], [32, 512, 14, 14], [512], [512], [512], [512], [512], [], [0]]", 6, 546, 546, 401, 527], ["aten::add_", "[[512, 2048, 1, 1], [512, 2048, 1, 1], []]", 36, 489, 489, 1008, 1008], ["aten::cudnn_batch_norm", "[[32, 512, 7, 7], [512], [512], [512], [512], [], [], []]", 30, 442, 442, 3129, 4424], ["aten::mul_", "[[512, 512, 3, 3], []]", 18, 431, 431, 631, 631], ["aten::add_", "[[512], [512], []]", 396, 396, 396, 11049, 11049], ["aten::threshold_backward", "[[32, 512, 7, 7], [32, 512, 7, 7], []]", 30, 390, 390, 1072, 1277], ["aten::threshold_", "[[32, 256, 28, 28], [], []]", 6, 378, 378, 193, 193], ["aten::add_", "[[256, 1024, 1, 1], [256, 1024, 1, 1], []]", 90, 330, 330, 2466, 2466], ["aten::add", "[[], [], []]", 318, 325, 325, 14945, 14945], ["aten::add_", "[[1024, 256, 1, 1], [1024, 256, 1, 1], []]", 108, 325, 325, 3193, 3193], ["aten::add_", "[[128], [128], []]", 288, 288, 288, 17673, 17673], ["aten::threshold_backward", "[[32, 512, 14, 14], [32, 512, 14, 14], []]", 6, 283, 283, 210, 249], ["aten::cudnn_batch_norm", "[[32, 512, 14, 14], [512], [512], [512], [512], [], [], []]", 6, 276, 276, 654, 905], ["aten::fill_", "[[512, 512, 3, 3], []]", 18, 270, 270, 363, 363], ["aten::mean", "[[32, 2048, 7, 7], [], [], []]", 6, 256, 256, 431, 484], ["aten::add_", "[[64], [64], []]", 252, 252, 252, 7010, 7010], ["aten::add_", "[[1024], [1024], []]", 252, 252, 252, 7055, 7055], ["aten::mul_", "[[256, 256, 3, 3], []]", 36, 230, 230, 1285, 1285], ["aten::addmm", "[[1000], [32, 2048], [2048, 1000], [], []]", 6, 201, 201, 1138, 1274], ["aten::mul_", "[[256], []]", 192, 192, 192, 6995, 6995], ["aten::mul_", "[[2048, 512, 1, 1], []]", 18, 192, 192, 633, 633], ["aten::threshold_", "[[32, 512, 14, 14], [], []]", 6, 186, 186, 226, 226], ["aten::threshold_", "[[32, 512, 7, 7], [], []]", 30, 180, 180, 919, 919], ["aten::mm", "[[32, 1000], [1000, 2048]]", 6, 178, 178, 512, 547], ["aten::div", "[[32, 2048, 7, 7], []]", 6, 162, 162, 369, 409], ["aten::add_", "[[128, 128, 3, 3], [128, 128, 3, 3], []]", 72, 145, 145, 2160, 2160], ["aten::fill_", "[[256, 256, 3, 3], []]", 36, 144, 144, 748, 748], ["aten::add_", "[[2048], [2048], []]", 144, 144, 144, 3991, 3991], ["aten::mul_", "[[512], []]", 132, 132, 132, 4528, 4528], ["aten::mul_", "[[512, 2048, 1, 1], []]", 12, 130, 130, 430, 430], ["aten::fill_", "[[2048, 512, 1, 1], []]", 18, 126, 126, 360, 360], ["aten::mul_", "[[2048, 1024, 1, 1], []]", 6, 126, 126, 249, 249], ["aten::add_", "[[512, 128, 1, 1], [512, 128, 1, 1], []]", 72, 125, 125, 2173, 2173], ["aten::mul_", "[[1000, 2048], []]", 6, 125, 125, 208, 208], ["aten::mm", "[[1000, 32], [32, 2048]]", 6, 117, 117, 259, 300], ["aten::add_", "[[512, 1024, 1, 1], [512, 1024, 1, 1], []]", 18, 116, 116, 503, 503], ["aten::mul_", "[[1024, 256, 1, 1], []]", 36, 113, 113, 1262, 1262], ["aten::add_", "[[128, 512, 1, 1], [128, 512, 1, 1], []]", 54, 102, 102, 1482, 1482], ["aten::mul_", "[[128], []]", 96, 96, 96, 3412, 3412], ["aten::fill_", "[[256], []]", 192, 93, 93, 3913, 3913], ["aten::add_", "[[1024, 512, 1, 1], [1024, 512, 1, 1], []]", 18, 91, 91, 543, 543], ["aten::mul_", "[[256, 1024, 1, 1], []]", 30, 90, 90, 1050, 1050], ["aten::fill_", "[[512, 2048, 1, 1], []]", 12, 84, 84, 248, 248], ["aten::mul_", "[[64], []]", 84, 84, 84, 2932, 2932], ["aten::mul_", "[[1024], []]", 84, 84, 84, 5430, 5430], ["aten::fill_", "[[2048, 1024, 1, 1], []]", 6, 78, 78, 120, 120], ["aten::fill_", "[[1000, 2048], []]", 6, 78, 78, 120, 120], ["aten::fill_", "[[512], []]", 132, 76, 76, 3235, 3235], ["aten::fill_", "[[1024, 256, 1, 1], []]", 36, 72, 72, 721, 721], ["aten::add_", "[[256, 64, 1, 1], [256, 64, 1, 1], []]", 72, 72, 72, 2150, 2150], ["aten::fill_", "[[128], []]", 96, 64, 64, 1973, 1973], ["aten::_log_softmax_backward_data", "[[32, 1000], [32, 1000], [], [32, 1000]]", 6, 64, 64, 246, 357], ["aten::_log_softmax", "[[32, 1000], [], []]", 6, 60, 60, 343, 447], ["aten::fill_", "[[256, 1024, 1, 1], []]", 30, 60, 60, 617, 617], ["aten::add_", "[[64, 64, 3, 3], [64, 64, 3, 3], []]", 54, 57, 57, 1581, 1581], ["aten::fill_", "[[1024], []]", 84, 50, 50, 1713, 1713], ["aten::add_", "[[64, 256, 1, 1], [64, 256, 1, 1], []]", 36, 48, 48, 1083, 1083], ["aten::mul_", "[[128, 128, 3, 3], []]", 24, 48, 48, 872, 872], ["aten::mul_", "[[512, 128, 1, 1], []]", 24, 48, 48, 855, 855], ["aten::mul_", "[[2048], []]", 48, 48, 48, 1670, 1670], ["aten::fill_", "[[64], []]", 84, 45, 45, 1744, 1744], ["aten::add_", "[[256, 512, 1, 1], [256, 512, 1, 1], []]", 18, 42, 42, 492, 492], ["aten::add_", "[[512, 256, 1, 1], [512, 256, 1, 1], []]", 18, 36, 36, 593, 593], ["aten::mul_", "[[128, 512, 1, 1], []]", 18, 36, 36, 652, 652], ["aten::mul_", "[[1024, 512, 1, 1], []]", 6, 36, 36, 212, 212], ["aten::mul_", "[[512, 1024, 1, 1], []]", 6, 36, 36, 202, 202], ["aten::fill_", "[[256, 64, 1, 1], []]", 24, 24, 24, 476, 476], ["aten::fill_", "[[128, 128, 3, 3], []]", 24, 24, 24, 494, 494], ["aten::fill_", "[[512, 128, 1, 1], []]", 24, 24, 24, 748, 748], ["aten::fill_", "[[1024, 512, 1, 1], []]", 6, 24, 24, 121, 121], ["aten::fill_", "[[512, 1024, 1, 1], []]", 6, 24, 24, 127, 127], ["aten::mul_", "[[256, 64, 1, 1], []]", 24, 24, 24, 851, 851], ["aten::add_", "[[128, 256, 1, 1], [128, 256, 1, 1], []]", 18, 24, 24, 527, 527], ["aten::nll_loss_forward", "[[32, 1000], [32], [], [], []]", 6, 20, 20, 425, 425], ["aten::fill_", "[[2048], []]", 48, 20, 20, 961, 961], ["aten::add_", "[[64, 64, 1, 1], [64, 64, 1, 1], []]", 18, 19, 19, 490, 490], ["aten::fill_", "[[64, 64, 3, 3], []]", 18, 18, 18, 364, 364], ["aten::fill_", "[[128, 512, 1, 1], []]", 18, 18, 18, 374, 374], ["aten::add_", "[[64, 3, 7, 7], [64, 3, 7, 7], []]", 18, 18, 18, 589, 589], ["aten::mul_", "[[64, 64, 3, 3], []]", 18, 18, 18, 661, 661], ["aten::add_", "[[1000], [1000], []]", 18, 18, 18, 520, 520], ["aten::nll_loss_backward", "[[], [32, 1000], [32], [], [], [], []]", 6, 18, 18, 590, 590], ["aten::fill_", "[[64, 256, 1, 1], []]", 12, 12, 12, 242, 242], ["aten::mul_", "[[64, 256, 1, 1], []]", 12, 12, 12, 415, 415], ["aten::mul_", "[[512, 256, 1, 1], []]", 6, 12, 12, 216, 216], ["aten::mul_", "[[256, 512, 1, 1], []]", 6, 12, 12, 205, 205], ["aten::mul_", "[[64, 3, 7, 7], []]", 6, 7, 7, 368, 368], ["aten::copy_", "[[32], [32], []]", 6, 6, 6, 334, 334], ["aten::fill_", "[[64, 3, 7, 7], []]", 6, 6, 6, 265, 265], ["aten::fill_", "[[128, 256, 1, 1], []]", 6, 6, 6, 120, 120], ["aten::fill_", "[[512, 256, 1, 1], []]", 6, 6, 6, 217, 217], ["aten::fill_", "[[256, 512, 1, 1], []]", 6, 6, 6, 133, 133], ["aten::fill_", "[[1000], []]", 6, 6, 6, 121, 121], ["aten::fill_", "[[], []]", 6, 6, 6, 180, 180], ["aten::mul_", "[[64, 64, 1, 1], []]", 6, 6, 6, 211, 211], ["aten::mul_", "[[128, 256, 1, 1], []]", 6, 6, 6, 210, 210], ["aten::mul_", "[[1000], []]", 6, 6, 6, 198, 198], ["aten::fill_", "[[64, 64, 1, 1], []]", 6, 2, 2, 123, 123], ["aten::empty", "[[], [], [], [], [], []]", 5748, 0, 0, 33098, 33098], ["aten::zero_", "[[1]]", 24, 0, 0, 64, 64], ["aten::zeros", "[[], [], [], [], []]", 24, 0, 0, 463, 651], ["aten::set_", "[[], []]", 192, 0, 0, 2994, 2994], ["aten::view", "[[150528], []]", 192, 0, 0, 2030, 2030], ["aten::as_strided", "[[224, 224, 3], [], [], []]", 192, 0, 0, 458, 458], ["aten::permute", "[[224, 224, 3], []]", 192, 0, 0, 2703, 3161], ["aten::empty_like", "[[3, 224, 224], [], [], [], [], []]", 192, 0, 0, 1288, 1993], ["aten::copy_", "[[3, 224, 224], [3, 224, 224], []]", 384, 0, 0, 44477, 44477], ["aten::contiguous", "[[3, 224, 224], []]", 192, 0, 0, 2069, 24479], ["aten::empty_strided", "[[], [], [], [], [], []]", 402, 0, 0, 1725, 1725], ["aten::to", "[[3, 224, 224], [], [], [], []]", 192, 0, 0, 2295, 27130], ["aten::copy_", "[[], [], []]", 192, 0, 0, 915, 915], ["aten::to", "[[], [], [], [], []]", 192, 0, 0, 2111, 3487], ["aten::div", "[[3, 224, 224], []]", 192, 0, 0, 25659, 30262], ["aten::as_strided", "[[3, 224, 224], [], [], []]", 192, 0, 0, 368, 368], ["aten::unsqueeze", "[[3, 224, 224], []]", 192, 0, 0, 925, 1293], ["aten::resize_", "[[0], [], []]", 24, 0, 0, 257, 257], ["aten::as_strided", "[[32, 3, 224, 224], [], [], []]", 6, 0, 0, 11, 11], ["aten::slice", "[[32, 3, 224, 224], [], [], [], []]", 6, 0, 0, 41, 52], ["aten::narrow", "[[32, 3, 224, 224], [], [], []]", 6, 0, 0, 35, 87], ["aten::_cat", "[[], []]", 6, 0, 0, 30756, 30970], ["aten::cat", "[[], []]", 6, 0, 0, 199, 31169], ["aten::stack", "[[], []]", 6, 0, 0, 596, 33058], ["aten::to", "[[32], [], [], [], [], []]", 6, 0, 0, 18, 18], ["detach_", "[[32]]", 6, 0, 0, 33, 33], ["aten::detach_", "[[32]]", 6, 0, 0, 31, 64], ["aten::to", "[[32, 3, 224, 224], [], [], [], [], [], [], []]", 6, 0, 12728, 154, 14882], ["aten::to", "[[32], [], [], [], [], [], [], []]", 6, 0, 6, 89, 527], ["aten::resize_", "[[64, 3, 7, 7], [], []]", 6, 0, 0, 19, 19], ["aten::resize_", "[[32, 3, 224, 224], [], []]", 12, 0, 0, 14, 14], ["aten::_convolution", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], [], [], [], [], []]", 6, 0, 3841, 141, 2497], ["aten::convolution", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], []]", 6, 0, 3841, 88, 2585], ["aten::conv2d", "[[32, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], []]", 6, 0, 3841, 102, 2687], ["aten::empty_like", "[[32, 64, 112, 112], [], [], [], [], []]", 12, 0, 0, 111, 207], ["aten::view", "[[64], []]", 84, 0, 0, 356, 356], ["aten::_batch_norm_impl_index", "[[32, 64, 112, 112], [64], [64], [64], [64], [], [], [], []]", 6, 0, 2546, 81, 1650], ["aten::batch_norm", "[[32, 64, 112, 112], [64], [64], [64], [64], [], [], [], []]", 6, 0, 2546, 90, 1740], ["aten::relu_", "[[32, 64, 112, 112]]", 6, 0, 1500, 193, 453], ["aten::max_pool2d", "[[32, 64, 112, 112], [], [], [], [], []]", 6, 0, 1341, 88, 732], ["aten::resize_", "[[64, 64, 1, 1], [], []]", 12, 0, 0, 23, 23], ["aten::resize_", "[[32, 64, 56, 56], [], []]", 168, 0, 0, 233, 233], ["aten::_convolution", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 6, 0, 848, 88, 966], ["aten::convolution", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], []]", 6, 0, 848, 63, 1029], ["aten::conv2d", "[[32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], []]", 6, 0, 848, 76, 1105], ["aten::empty_like", "[[32, 64, 56, 56], [], [], [], [], []]", 36, 0, 0, 342, 713], ["aten::_batch_norm_impl_index", "[[32, 64, 56, 56], [64], [64], [64], [64], [], [], [], []]", 36, 0, 3985, 394, 5656], ["aten::batch_norm", "[[32, 64, 56, 56], [64], [64], [64], [64], [], [], [], []]", 36, 0, 3985, 433, 6089], ["aten::relu_", "[[32, 64, 56, 56]]", 36, 0, 2291, 905, 1973], ["aten::resize_", "[[64, 64, 3, 3], [], []]", 36, 0, 0, 73, 73], ["aten::_convolution", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 18, 0, 6623, 242, 3307], ["aten::convolution", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], []]", 18, 0, 6623, 392, 3699], ["aten::conv2d", "[[32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], []]", 18, 0, 6623, 231, 3930], ["aten::resize_", "[[256, 64, 1, 1], [], []]", 48, 0, 0, 103, 103], ["aten::_convolution", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 24, 0, 7261, 374, 4500], ["aten::convolution", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], []]", 24, 0, 7261, 292, 4792], ["aten::conv2d", "[[32, 64, 56, 56], [256, 64, 1, 1], [], [], [], [], []]", 24, 0, 7261, 292, 5084], ["aten::empty_like", "[[32, 256, 56, 56], [], [], [], [], []]", 24, 0, 0, 211, 433], ["aten::view", "[[256], []]", 192, 0, 0, 776, 776], ["aten::_batch_norm_impl_index", "[[32, 256, 56, 56], [256], [256], [256], [256], [], [], [], []]", 24, 0, 9555, 262, 3763], ["aten::batch_norm", "[[32, 256, 56, 56], [256], [256], [256], [256], [], [], [], []]", 24, 0, 9555, 288, 4051], ["aten::relu_", "[[32, 256, 56, 56]]", 18, 0, 4491, 428, 1096], ["aten::resize_", "[[64, 256, 1, 1], [], []]", 24, 0, 0, 49, 49], ["aten::resize_", "[[32, 256, 56, 56], [], []]", 96, 0, 0, 135, 135], ["aten::_convolution", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 12, 0, 3419, 165, 2192], ["aten::convolution", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], []]", 12, 0, 3419, 144, 2336], ["aten::conv2d", "[[32, 256, 56, 56], [64, 256, 1, 1], [], [], [], [], []]", 12, 0, 3419, 141, 2477], ["aten::resize_", "[[128, 256, 1, 1], [], []]", 12, 0, 0, 27, 27], ["aten::_convolution", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 6, 0, 4265, 81, 892], ["aten::convolution", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], []]", 6, 0, 4265, 66, 958], ["aten::conv2d", "[[32, 256, 56, 56], [128, 256, 1, 1], [], [], [], [], []]", 6, 0, 4265, 74, 1032], ["aten::empty_like", "[[32, 128, 56, 56], [], [], [], [], []]", 6, 0, 0, 49, 98], ["aten::view", "[[128], []]", 96, 0, 0, 383, 383], ["aten::_batch_norm_impl_index", "[[32, 128, 56, 56], [128], [128], [128], [128], [], [], [], []]", 6, 0, 1199, 68, 937], ["aten::batch_norm", "[[32, 128, 56, 56], [128], [128], [128], [128], [], [], [], []]", 6, 0, 1199, 84, 1021], ["aten::relu_", "[[32, 128, 56, 56]]", 6, 0, 755, 146, 324], ["aten::resize_", "[[128, 128, 3, 3], [], []]", 48, 0, 0, 93, 93], ["aten::resize_", "[[32, 128, 56, 56], [], []]", 24, 0, 0, 34, 34], ["aten::_convolution", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 6, 0, 3544, 84, 2661], ["aten::convolution", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], [], [], []]", 6, 0, 3544, 69, 2730], ["aten::conv2d", "[[32, 128, 56, 56], [128, 128, 3, 3], [], [], [], [], []]", 6, 0, 3544, 86, 2816], ["aten::empty_like", "[[32, 128, 28, 28], [], [], [], [], []]", 42, 0, 0, 378, 747], ["aten::_batch_norm_impl_index", "[[32, 128, 28, 28], [128], [128], [128], [128], [], [], [], []]", 42, 0, 2143, 445, 6396], ["aten::batch_norm", "[[32, 128, 28, 28], [128], [128], [128], [128], [], [], [], []]", 42, 0, 2143, 523, 6919], ["aten::relu_", "[[32, 128, 28, 28]]", 42, 0, 1347, 1045, 2341], ["aten::resize_", "[[512, 128, 1, 1], [], []]", 48, 0, 0, 98, 98], ["aten::resize_", "[[32, 128, 28, 28], [], []]", 168, 0, 0, 249, 249], ["aten::_convolution", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 24, 0, 10192, 327, 3283], ["aten::convolution", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], []]", 24, 0, 10192, 276, 3559], ["aten::conv2d", "[[32, 128, 28, 28], [512, 128, 1, 1], [], [], [], [], []]", 24, 0, 10192, 295, 3854], ["aten::empty_like", "[[32, 512, 28, 28], [], [], [], [], []]", 30, 0, 0, 255, 516], ["aten::view", "[[512], []]", 132, 0, 0, 575, 575], ["aten::_batch_norm_impl_index", "[[32, 512, 28, 28], [512], [512], [512], [512], [], [], [], []]", 30, 0, 6189, 316, 4598], ["aten::batch_norm", "[[32, 512, 28, 28], [512], [512], [512], [512], [], [], [], []]", 30, 0, 6189, 428, 5026], ["aten::resize_", "[[512, 256, 1, 1], [], []]", 12, 0, 0, 25, 25], ["aten::_convolution", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 6, 0, 4640, 80, 851], ["aten::convolution", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], [], [], []]", 6, 0, 4640, 68, 919], ["aten::conv2d", "[[32, 256, 56, 56], [512, 256, 1, 1], [], [], [], [], []]", 6, 0, 4640, 73, 992], ["aten::relu_", "[[32, 512, 28, 28]]", 24, 0, 3003, 624, 1375], ["aten::resize_", "[[128, 512, 1, 1], [], []]", 36, 0, 0, 78, 78], ["aten::resize_", "[[32, 512, 28, 28], [], []]", 120, 0, 0, 166, 166], ["aten::_convolution", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 18, 0, 6824, 250, 2551], ["aten::convolution", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], []]", 18, 0, 6824, 203, 2754], ["aten::conv2d", "[[32, 512, 28, 28], [128, 512, 1, 1], [], [], [], [], []]", 18, 0, 6824, 244, 2998], ["aten::_convolution", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 18, 0, 5214, 245, 3375], ["aten::convolution", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], []]", 18, 0, 5214, 194, 3569], ["aten::conv2d", "[[32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], []]", 18, 0, 5214, 216, 3785], ["aten::resize_", "[[256, 512, 1, 1], [], []]", 12, 0, 0, 22, 22], ["aten::_convolution", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 6, 0, 4176, 80, 891], ["aten::convolution", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], []]", 6, 0, 4176, 97, 988], ["aten::conv2d", "[[32, 512, 28, 28], [256, 512, 1, 1], [], [], [], [], []]", 6, 0, 4176, 78, 1066], ["aten::empty_like", "[[32, 256, 28, 28], [], [], [], [], []]", 6, 0, 0, 69, 122], ["aten::_batch_norm_impl_index", "[[32, 256, 28, 28], [256], [256], [256], [256], [], [], [], []]", 6, 0, 617, 65, 986], ["aten::batch_norm", "[[32, 256, 28, 28], [256], [256], [256], [256], [], [], [], []]", 6, 0, 617, 70, 1056], ["aten::relu_", "[[32, 256, 28, 28]]", 6, 0, 378, 147, 340], ["aten::resize_", "[[256, 256, 3, 3], [], []]", 72, 0, 0, 145, 145], ["aten::resize_", "[[32, 256, 28, 28], [], []]", 24, 0, 0, 74, 74], ["aten::_convolution", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 6, 0, 5093, 82, 904], ["aten::convolution", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], [], [], []]", 6, 0, 5093, 64, 968], ["aten::conv2d", "[[32, 256, 28, 28], [256, 256, 3, 3], [], [], [], [], []]", 6, 0, 5093, 71, 1039], ["aten::empty_like", "[[32, 256, 14, 14], [], [], [], [], []]", 66, 0, 0, 652, 1261], ["aten::_batch_norm_impl_index", "[[32, 256, 14, 14], [256], [256], [256], [256], [], [], [], []]", 66, 0, 1477, 748, 10512], ["aten::batch_norm", "[[32, 256, 14, 14], [256], [256], [256], [256], [], [], [], []]", 66, 0, 1477, 835, 11347], ["aten::relu_", "[[32, 256, 14, 14]]", 66, 0, 768, 1689, 3796], ["aten::resize_", "[[1024, 256, 1, 1], [], []]", 72, 0, 0, 143, 143], ["aten::resize_", "[[32, 256, 14, 14], [], []]", 264, 0, 0, 371, 371], ["aten::_convolution", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 36, 0, 14037, 495, 5001], ["aten::convolution", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], []]", 36, 0, 14037, 406, 5407], ["aten::conv2d", "[[32, 256, 14, 14], [1024, 256, 1, 1], [], [], [], [], []]", 36, 0, 14037, 453, 5860], ["aten::empty_like", "[[32, 1024, 14, 14], [], [], [], [], []]", 42, 0, 0, 368, 740], ["aten::view", "[[1024], []]", 84, 0, 0, 342, 342], ["aten::_batch_norm_impl_index", "[[32, 1024, 14, 14], [1024], [1024], [1024], [1024], [], [], [], []]", 42, 0, 3549, 442, 6878], ["aten::batch_norm", "[[32, 1024, 14, 14], [1024], [1024], [1024], [1024], [], [], [], []]", 42, 0, 3549, 528, 7406], ["aten::resize_", "[[1024, 512, 1, 1], [], []]", 12, 0, 0, 24, 24], ["aten::_convolution", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 6, 0, 4453, 98, 852], ["aten::convolution", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], [], [], []]", 6, 0, 4453, 66, 918], ["aten::conv2d", "[[32, 512, 28, 28], [1024, 512, 1, 1], [], [], [], [], []]", 6, 0, 4453, 72, 990], ["aten::relu_", "[[32, 1024, 14, 14]]", 36, 0, 2277, 923, 1903], ["aten::resize_", "[[256, 1024, 1, 1], [], []]", 60, 0, 0, 130, 130], ["aten::resize_", "[[32, 1024, 14, 14], [], []]", 168, 0, 0, 221, 221], ["aten::_convolution", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 30, 0, 11767, 420, 4303], ["aten::convolution", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], []]", 30, 0, 11767, 331, 4634], ["aten::conv2d", "[[32, 1024, 14, 14], [256, 1024, 1, 1], [], [], [], [], []]", 30, 0, 11767, 359, 4993], ["aten::_convolution", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 30, 0, 8614, 409, 5398], ["aten::convolution", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], []]", 30, 0, 8614, 339, 5737], ["aten::conv2d", "[[32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], []]", 30, 0, 8614, 370, 6107], ["aten::resize_", "[[512, 1024, 1, 1], [], []]", 12, 0, 0, 26, 26], ["aten::_convolution", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 6, 0, 4632, 83, 1140], ["aten::convolution", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], []]", 6, 0, 4632, 68, 1208], ["aten::conv2d", "[[32, 1024, 14, 14], [512, 1024, 1, 1], [], [], [], [], []]", 6, 0, 4632, 73, 1281], ["aten::empty_like", "[[32, 512, 14, 14], [], [], [], [], []]", 6, 0, 0, 51, 99], ["aten::_batch_norm_impl_index", "[[32, 512, 14, 14], [512], [512], [512], [512], [], [], [], []]", 6, 0, 276, 64, 969], ["aten::batch_norm", "[[32, 512, 14, 14], [512], [512], [512], [512], [], [], [], []]", 6, 0, 276, 72, 1041], ["aten::relu_", "[[32, 512, 14, 14]]", 6, 0, 186, 151, 377], ["aten::resize_", "[[512, 512, 3, 3], [], []]", 36, 0, 0, 74, 74], ["aten::resize_", "[[32, 512, 14, 14], [], []]", 24, 0, 0, 33, 33], ["aten::_convolution", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 6, 0, 5495, 80, 916], ["aten::convolution", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], [], [], []]", 6, 0, 5495, 64, 980], ["aten::conv2d", "[[32, 512, 14, 14], [512, 512, 3, 3], [], [], [], [], []]", 6, 0, 5495, 76, 1056], ["aten::empty_like", "[[32, 512, 7, 7], [], [], [], [], []]", 30, 0, 0, 263, 548], ["aten::_batch_norm_impl_index", "[[32, 512, 7, 7], [512], [512], [512], [512], [], [], [], []]", 30, 0, 442, 346, 4770], ["aten::batch_norm", "[[32, 512, 7, 7], [512], [512], [512], [512], [], [], [], []]", 30, 0, 442, 366, 5136], ["aten::relu_", "[[32, 512, 7, 7]]", 30, 0, 180, 784, 1703], ["aten::resize_", "[[2048, 512, 1, 1], [], []]", 36, 0, 0, 120, 120], ["aten::resize_", "[[32, 512, 7, 7], [], []]", 120, 0, 0, 161, 161], ["aten::_convolution", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 18, 0, 7394, 242, 2577], ["aten::convolution", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], []]", 18, 0, 7394, 209, 2786], ["aten::conv2d", "[[32, 512, 7, 7], [2048, 512, 1, 1], [], [], [], [], []]", 18, 0, 7394, 224, 3010], ["aten::empty_like", "[[32, 2048, 7, 7], [], [], [], [], []]", 24, 0, 0, 212, 433], ["aten::view", "[[2048], []]", 48, 0, 0, 192, 192], ["aten::_batch_norm_impl_index", "[[32, 2048, 7, 7], [2048], [2048], [2048], [2048], [], [], [], []]", 24, 0, 1314, 253, 4007], ["aten::batch_norm", "[[32, 2048, 7, 7], [2048], [2048], [2048], [2048], [], [], [], []]", 24, 0, 1314, 315, 4322], ["aten::resize_", "[[2048, 1024, 1, 1], [], []]", 12, 0, 0, 23, 23], ["aten::_convolution", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 6, 0, 4379, 80, 846], ["aten::convolution", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], [], [], []]", 6, 0, 4379, 64, 910], ["aten::conv2d", "[[32, 1024, 14, 14], [2048, 1024, 1, 1], [], [], [], [], []]", 6, 0, 4379, 71, 981], ["aten::relu_", "[[32, 2048, 7, 7]]", 18, 0, 583, 457, 939], ["aten::resize_", "[[512, 2048, 1, 1], [], []]", 24, 0, 0, 49, 49], ["aten::resize_", "[[32, 2048, 7, 7], [], []]", 72, 0, 0, 101, 101], ["aten::_convolution", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], [], [], [], [], []]", 12, 0, 5341, 199, 1830], ["aten::convolution", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], []]", 12, 0, 5341, 157, 1987], ["aten::conv2d", "[[32, 2048, 7, 7], [512, 2048, 1, 1], [], [], [], [], []]", 12, 0, 5341, 144, 2131], ["aten::_convolution", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], [], [], [], [], []]", 12, 0, 3683, 169, 2056], ["aten::convolution", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], []]", 12, 0, 3683, 135, 2191], ["aten::conv2d", "[[32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], []]", 12, 0, 3683, 145, 2336], ["aten::adaptive_avg_pool2d", "[[32, 2048, 7, 7], []]", 6, 0, 256, 82, 566], ["aten::view", "[[32, 2048, 1, 1], []]", 6, 0, 0, 103, 103], ["aten::reshape", "[[32, 2048, 1, 1], []]", 6, 0, 0, 38, 141], ["aten::flatten", "[[32, 2048, 1, 1], [], []]", 6, 0, 0, 65, 206], ["aten::as_strided", "[[1000, 2048], [], [], []]", 12, 0, 0, 39, 39], ["aten::transpose", "[[1000, 2048], [], []]", 12, 0, 0, 98, 137], ["aten::t", "[[1000, 2048]]", 12, 0, 0, 165, 302], ["aten::as_strided", "[[1000], [], [], []]", 6, 0, 0, 14, 14], ["aten::expand", "[[1000], [], []]", 6, 0, 0, 46, 60], ["aten::empty_like", "[[32, 1000], [], [], [], [], []]", 12, 0, 0, 122, 215], ["aten::log_softmax", "[[32, 1000], [], []]", 6, 0, 60, 80, 527], ["aten::nll_loss", "[[32, 1000], [32], [], [], []]", 6, 0, 20, 75, 500], ["aten::zero_", "[[64, 3, 7, 7]]", 6, 0, 6, 129, 394], ["aten::zero_", "[[64]]", 84, 0, 45, 1188, 2932], ["aten::zero_", "[[64, 64, 1, 1]]", 6, 0, 2, 90, 213], ["aten::zero_", "[[64, 64, 3, 3]]", 18, 0, 18, 303, 667], ["aten::zero_", "[[256, 64, 1, 1]]", 24, 0, 24, 347, 823], ["aten::zero_", "[[256]]", 192, 0, 93, 2713, 6626], ["aten::zero_", "[[64, 256, 1, 1]]", 12, 0, 12, 171, 413], ["aten::zero_", "[[128, 256, 1, 1]]", 6, 0, 6, 82, 202], ["aten::zero_", "[[128]]", 96, 0, 64, 1321, 3294], ["aten::zero_", "[[128, 128, 3, 3]]", 24, 0, 24, 355, 849], ["aten::zero_", "[[512, 128, 1, 1]]", 24, 0, 24, 336, 1084], ["aten::zero_", "[[512]]", 132, 0, 76, 1839, 5074], ["aten::zero_", "[[512, 256, 1, 1]]", 6, 0, 6, 86, 303], ["aten::zero_", "[[128, 512, 1, 1]]", 18, 0, 18, 256, 630], ["aten::zero_", "[[256, 512, 1, 1]]", 6, 0, 6, 108, 241], ["aten::zero_", "[[256, 256, 3, 3]]", 36, 0, 144, 501, 1249], ["aten::zero_", "[[1024, 256, 1, 1]]", 36, 0, 72, 536, 1257], ["aten::zero_", "[[1024]]", 84, 0, 50, 2555, 4268], ["aten::zero_", "[[1024, 512, 1, 1]]", 6, 0, 24, 81, 202], ["aten::zero_", "[[256, 1024, 1, 1]]", 30, 0, 60, 461, 1078], ["aten::zero_", "[[512, 1024, 1, 1]]", 6, 0, 24, 81, 208], ["aten::zero_", "[[512, 512, 3, 3]]", 18, 0, 270, 250, 613], ["aten::zero_", "[[2048, 512, 1, 1]]", 18, 0, 126, 287, 647], ["aten::zero_", "[[2048]]", 48, 0, 20, 653, 1614], ["aten::zero_", "[[2048, 1024, 1, 1]]", 6, 0, 78, 84, 204], ["aten::zero_", "[[512, 2048, 1, 1]]", 12, 0, 84, 166, 414], ["aten::zero_", "[[1000, 2048]]", 6, 0, 78, 81, 201], ["aten::zero_", "[[1000]]", 6, 0, 6, 83, 204], ["aten::empty_like", "[[], [], [], [], [], []]", 6, 0, 0, 59, 130], ["aten::ones_like", "[[], [], [], [], [], []]", 6, 0, 6, 100, 410], ["NllLossBackward", "[[]]", 6, 0, 18, 129, 719], ["LogSoftmaxBackward", "[[32, 1000]]", 6, 0, 64, 94, 451], ["aten::as_strided", "[[2048, 1000], [], [], []]", 12, 0, 0, 29, 29], ["aten::transpose", "[[2048, 1000], [], []]", 12, 0, 0, 89, 118], ["aten::t", "[[2048, 1000]]", 12, 0, 0, 126, 244], ["aten::conj", "[[1000, 2048]]", 6, 0, 0, 25, 25], ["aten::as_strided", "[[32, 1000], [], [], []]", 6, 0, 0, 15, 15], ["aten::transpose", "[[32, 1000], [], []]", 6, 0, 0, 39, 54], ["aten::t", "[[32, 1000]]", 6, 0, 0, 64, 118], ["aten::conj", "[[32, 2048]]", 6, 0, 0, 21, 21], ["AddmmBackward", "[[32, 1000]]", 6, 0, 295, 195, 1462], ["torch::autograd::AccumulateGrad", "[[1000]]", 6, 0, 6, 60, 254], ["TBackward", "[[2048, 1000]]", 6, 0, 0, 29, 140], ["torch::autograd::AccumulateGrad", "[[1000, 2048]]", 6, 0, 184, 34, 188], ["aten::view", "[[32, 2048], []]", 6, 0, 0, 54, 54], ["aten::reshape", "[[32, 2048], []]", 6, 0, 0, 33, 87], ["ViewBackward", "[[32, 2048]]", 6, 0, 0, 34, 121], ["aten::as_strided", "[[32, 2048, 1, 1], [], [], []]", 6, 0, 0, 14, 14], ["aten::expand", "[[32, 2048, 1, 1], [], []]", 6, 0, 0, 67, 81], ["aten::to", "[[32, 2048, 7, 7], [], [], [], []]", 6, 0, 0, 13, 13], ["MeanBackward1", "[[32, 2048, 1, 1]]", 6, 0, 162, 103, 606], ["ReluBackward1", "[[32, 2048, 7, 7]]", 18, 0, 846, 157, 934], ["AddBackward0", "[[32, 2048, 7, 7]]", 18, 0, 0, 59, 59], ["CudnnBatchNormBackward", "[[32, 2048, 7, 7]]", 24, 0, 1695, 322, 2545], ["torch::autograd::AccumulateGrad", "[[2048]]", 48, 0, 48, 305, 1597], ["aten::cudnn_convolution_backward", "[[32, 512, 7, 7], [32, 2048, 7, 7], [2048, 512, 1, 1], [], [], [], [], [], [], [], []]", 18, 0, 14484, 527, 5417], ["CudnnConvolutionBackward", "[[32, 2048, 7, 7]]", 24, 0, 24459, 297, 7370], ["torch::autograd::AccumulateGrad", "[[2048, 512, 1, 1]]", 18, 0, 243, 142, 722], ["ReluBackward1", "[[32, 512, 7, 7]]", 30, 0, 390, 254, 1531], ["CudnnBatchNormBackward", "[[32, 512, 7, 7]]", 30, 0, 588, 400, 3048], ["torch::autograd::AccumulateGrad", "[[512]]", 132, 0, 132, 854, 4436], ["aten::cudnn_convolution_backward", "[[32, 512, 7, 7], [32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], [], []]", 12, 0, 7201, 357, 3238], ["CudnnConvolutionBackward", "[[32, 512, 7, 7]]", 30, 0, 26158, 339, 8355], ["torch::autograd::AccumulateGrad", "[[512, 512, 3, 3]]", 18, 0, 631, 162, 736], ["aten::cudnn_convolution_backward", "[[32, 2048, 7, 7], [32, 512, 7, 7], [512, 2048, 1, 1], [], [], [], [], [], [], [], []]", 12, 0, 9419, 331, 3155], ["torch::autograd::AccumulateGrad", "[[512, 2048, 1, 1]]", 12, 0, 196, 96, 410], ["aten::cudnn_convolution_backward", "[[32, 1024, 14, 14], [32, 2048, 7, 7], [2048, 1024, 1, 1], [], [], [], [], [], [], [], []]", 6, 0, 9975, 207, 1656], ["torch::autograd::AccumulateGrad", "[[2048, 1024, 1, 1]]", 6, 0, 186, 45, 237], ["aten::cudnn_convolution_backward", "[[32, 512, 14, 14], [32, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], [], []]", 6, 0, 9538, 172, 1623], ["ReluBackward1", "[[32, 512, 14, 14]]", 6, 0, 283, 51, 300], ["CudnnBatchNormBackward", "[[32, 512, 14, 14]]", 6, 0, 546, 75, 602], ["aten::cudnn_convolution_backward", "[[32, 1024, 14, 14], [32, 512, 14, 14], [512, 1024, 1, 1], [], [], [], [], [], [], [], []]", 6, 0, 8147, 175, 1566], ["CudnnConvolutionBackward", "[[32, 512, 14, 14]]", 6, 0, 8147, 68, 1634], ["torch::autograd::AccumulateGrad", "[[512, 1024, 1, 1]]", 6, 0, 54, 50, 213], ["ReluBackward1", "[[32, 1024, 14, 14]]", 36, 0, 3315, 309, 1833], ["AddBackward0", "[[32, 1024, 14, 14]]", 36, 0, 0, 114, 114], ["CudnnBatchNormBackward", "[[32, 1024, 14, 14]]", 42, 0, 7463, 550, 4202], ["torch::autograd::AccumulateGrad", "[[1024]]", 84, 0, 84, 564, 2833], ["aten::cudnn_convolution_backward", "[[32, 256, 14, 14], [32, 1024, 14, 14], [1024, 256, 1, 1], [], [], [], [], [], [], [], []]", 36, 0, 29069, 1023, 9304], ["CudnnConvolutionBackward", "[[32, 1024, 14, 14]]", 42, 0, 38406, 499, 11351], ["torch::autograd::AccumulateGrad", "[[1024, 256, 1, 1]]", 36, 0, 108, 279, 1429], ["ReluBackward1", "[[32, 256, 14, 14]]", 66, 0, 1579, 551, 3452], ["CudnnBatchNormBackward", "[[32, 256, 14, 14]]", 66, 0, 2903, 864, 6470], ["torch::autograd::AccumulateGrad", "[[256]]", 192, 0, 192, 1203, 6319], ["aten::cudnn_convolution_backward", "[[32, 256, 14, 14], [32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], [], []]", 30, 0, 17168, 881, 7766], ["CudnnConvolutionBackward", "[[32, 256, 14, 14]]", 66, 0, 49785, 752, 17775], ["torch::autograd::AccumulateGrad", "[[256, 256, 3, 3]]", 36, 0, 223, 277, 1420], ["aten::cudnn_convolution_backward", "[[32, 1024, 14, 14], [32, 256, 14, 14], [256, 1024, 1, 1], [], [], [], [], [], [], [], []]", 30, 0, 23387, 847, 7679], ["torch::autograd::AccumulateGrad", "[[256, 1024, 1, 1]]", 30, 0, 150, 269, 1064], ["aten::cudnn_convolution_backward", "[[32, 512, 28, 28], [32, 1024, 14, 14], [1024, 512, 1, 1], [], [], [], [], [], [], [], []]", 6, 0, 9337, 174, 1548], ["torch::autograd::AccumulateGrad", "[[1024, 512, 1, 1]]", 6, 0, 30, 47, 242], ["aten::cudnn_convolution_backward", "[[32, 256, 28, 28], [32, 256, 14, 14], [256, 256, 3, 3], [], [], [], [], [], [], [], []]", 6, 0, 9230, 172, 1578], ["ReluBackward1", "[[32, 256, 28, 28]]", 6, 0, 556, 50, 304], ["CudnnBatchNormBackward", "[[32, 256, 28, 28]]", 6, 0, 961, 77, 596], ["aten::cudnn_convolution_backward", "[[32, 512, 28, 28], [32, 256, 28, 28], [256, 512, 1, 1], [], [], [], [], [], [], [], []]", 6, 0, 7558, 185, 2875], ["CudnnConvolutionBackward", "[[32, 256, 28, 28]]", 6, 0, 7558, 72, 2947], ["torch::autograd::AccumulateGrad", "[[256, 512, 1, 1]]", 6, 0, 18, 52, 212], ["ReluBackward1", "[[32, 512, 28, 28]]", 24, 0, 4377, 202, 1227], ["AddBackward0", "[[32, 512, 28, 28]]", 24, 0, 0, 77, 77], ["CudnnBatchNormBackward", "[[32, 512, 28, 28]]", 30, 0, 9663, 399, 3015], ["aten::cudnn_convolution_backward", "[[32, 128, 28, 28], [32, 512, 28, 28], [512, 128, 1, 1], [], [], [], [], [], [], [], []]", 24, 0, 18214, 714, 5431], ["CudnnConvolutionBackward", "[[32, 512, 28, 28]]", 30, 0, 27723, 368, 7280], ["torch::autograd::AccumulateGrad", "[[512, 128, 1, 1]]", 24, 0, 48, 221, 1035], ["ReluBackward1", "[[32, 128, 28, 28]]", 42, 0, 1909, 353, 2138], ["CudnnBatchNormBackward", "[[32, 128, 28, 28]]", 42, 0, 3660, 584, 4289], ["torch::autograd::AccumulateGrad", "[[128]]", 96, 0, 96, 620, 3366], ["aten::cudnn_convolution_backward", "[[32, 128, 28, 28], [32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], [], []]", 18, 0, 10505, 512, 4527], ["CudnnConvolutionBackward", "[[32, 128, 28, 28]]", 42, 0, 33744, 493, 13711], ["torch::autograd::AccumulateGrad", "[[128, 128, 3, 3]]", 24, 0, 49, 206, 977], ["aten::cudnn_convolution_backward", "[[32, 512, 28, 28], [32, 128, 28, 28], [128, 512, 1, 1], [], [], [], [], [], [], [], []]", 18, 0, 12198, 573, 7091], ["torch::autograd::AccumulateGrad", "[[128, 512, 1, 1]]", 18, 0, 47, 150, 636], ["aten::cudnn_convolution_backward", "[[32, 256, 56, 56], [32, 512, 28, 28], [512, 256, 1, 1], [], [], [], [], [], [], [], []]", 6, 0, 9509, 186, 1481], ["torch::autograd::AccumulateGrad", "[[512, 256, 1, 1]]", 6, 0, 12, 46, 240], ["aten::cudnn_convolution_backward", "[[32, 128, 56, 56], [32, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], [], [], [], []]", 6, 0, 11041, 172, 1600], ["ReluBackward1", "[[32, 128, 56, 56]]", 6, 0, 1083, 51, 301], ["CudnnBatchNormBackward", "[[32, 128, 56, 56]]", 6, 0, 2022, 74, 580], ["aten::cudnn_convolution_backward", "[[32, 256, 56, 56], [32, 128, 56, 56], [128, 256, 1, 1], [], [], [], [], [], [], [], []]", 6, 0, 7974, 187, 2282], ["CudnnConvolutionBackward", "[[32, 128, 56, 56]]", 6, 0, 7974, 73, 2355], ["torch::autograd::AccumulateGrad", "[[128, 256, 1, 1]]", 6, 0, 12, 49, 208], ["ReluBackward1", "[[32, 256, 56, 56]]", 18, 0, 6534, 161, 917], ["AddBackward0", "[[32, 256, 56, 56]]", 18, 0, 0, 59, 59], ["CudnnBatchNormBackward", "[[32, 256, 56, 56]]", 24, 0, 15198, 357, 2548], ["aten::cudnn_convolution_backward", "[[32, 64, 56, 56], [32, 256, 56, 56], [256, 64, 1, 1], [], [], [], [], [], [], [], []]", 24, 0, 18456, 715, 6103], ["CudnnConvolutionBackward", "[[32, 256, 56, 56]]", 24, 0, 18456, 281, 6384], ["torch::autograd::AccumulateGrad", "[[256, 64, 1, 1]]", 24, 0, 24, 195, 976], ["ReluBackward1", "[[32, 64, 56, 56]]", 36, 0, 3206, 344, 1907], ["CudnnBatchNormBackward", "[[32, 64, 56, 56]]", 36, 0, 7412, 490, 3650], ["torch::autograd::AccumulateGrad", "[[64]]", 84, 0, 84, 538, 2768], ["aten::cudnn_convolution_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], [], []]", 18, 0, 22556, 533, 5240], ["CudnnConvolutionBackward", "[[32, 64, 56, 56]]", 36, 0, 37188, 432, 10589], ["torch::autograd::AccumulateGrad", "[[64, 64, 3, 3]]", 18, 0, 21, 135, 720], ["aten::cudnn_convolution_backward", "[[32, 256, 56, 56], [32, 64, 56, 56], [64, 256, 1, 1], [], [], [], [], [], [], [], []]", 12, 0, 12791, 364, 3307], ["torch::autograd::AccumulateGrad", "[[64, 256, 1, 1]]", 12, 0, 24, 103, 510], ["aten::cudnn_convolution_backward", "[[32, 64, 56, 56], [32, 64, 56, 56], [64, 64, 1, 1], [], [], [], [], [], [], [], []]", 6, 0, 1841, 179, 1610], ["torch::autograd::AccumulateGrad", "[[64, 64, 1, 1]]", 6, 0, 7, 47, 205], ["aten::zero_", "[[32, 64, 112, 112]]", 6, 0, 948, 52, 192], ["aten::zeros_like", "[[32, 64, 112, 112], [], [], [], [], []]", 6, 0, 948, 53, 339], ["aten::resize_", "[[32, 64, 112, 112], [], []]", 12, 0, 0, 22, 22], ["aten::resize_as_", "[[32, 64, 112, 112], [32, 64, 112, 112], []]", 6, 0, 0, 44, 54], ["MaxPool2DWithIndicesBackward", "[[32, 64, 56, 56]]", 6, 0, 5046, 77, 763], ["ReluBackward1", "[[32, 64, 112, 112]]", 6, 0, 2180, 58, 298], ["CudnnBatchNormBackward", "[[32, 64, 112, 112]]", 6, 0, 4773, 111, 641], ["aten::cudnn_convolution_backward", "[[32, 3, 224, 224], [32, 64, 112, 112], [64, 3, 7, 7], [], [], [], [], [], [], [], []]", 6, 0, 5916, 329, 1027], ["CudnnConvolutionBackward", "[[32, 64, 112, 112]]", 6, 0, 5916, 79, 1106], ["torch::autograd::AccumulateGrad", "[[64, 3, 7, 7]]", 6, 0, 6, 49, 255]]}}, "kernel_op_table": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "string", "name": "Operator"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Total Duration (us)"}, {"type": "number", "name": "Mean Duration (us)"}, {"type": "number", "name": "Max Duration (us)"}, {"type": "number", "name": "Min Duration (us)"}], "rows": [["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", "aten::cudnn_convolution_backward_input", 162, 84053, 518.8456790123457, 330, 1084], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", "aten::cudnn_batch_norm_backward", 264, 54601, 206.8219696969697, 43, 799], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 90, 46546, 517.1777777777778, 393, 815], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 90, 40341, 448.23333333333335, 381, 753], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 60, 28063, 467.71666666666664, 361, 851], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", "aten::cudnn_convolution_backward_weight", 72, 27624, 383.6666666666667, 354, 667], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", "aten::threshold_backward", 294, 26258, 89.31292517006803, 13, 364], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", "aten::cudnn_batch_norm", 150, 26234, 174.89333333333335, 50, 426], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", "aten::cudnn_convolution_backward_weight", 30, 23873, 795.7666666666667, 664, 885], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", "aten::add_", 2994, 23357, 7.80126920507682, 1, 364], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", "aten::cudnn_convolution_backward_weight", 48, 21753, 453.1875, 328, 705], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", "aten::threshold_", 294, 17759, 60.404761904761905, 6, 250], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", "CallTreeRoot", 96, 15142, 157.72916666666666, 47, 361], ["volta_sgemm_128x64_nt", "aten::cudnn_convolution_backward_weight", 60, 11415, 190.25, 172, 202], ["volta_sgemm_128x64_nn", "aten::cudnn_convolution", 60, 11407, 190.11666666666667, 156, 207], ["volta_sgemm_128x64_nt", "aten::cudnn_convolution_backward_input", 60, 11336, 188.93333333333334, 156, 206], ["volta_scudnn_128x64_stridedB_interior_nn_v1", "aten::cudnn_convolution_backward_input", 30, 9825, 327.5, 263, 525], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 12, 8816, 734.6666666666666, 660, 784], ["volta_scudnn_128x64_relu_interior_nn_v1", "aten::cudnn_convolution", 24, 7210, 300.4166666666667, 295, 311], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 12, 7155, 596.25, 207, 990], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", "aten::cudnn_batch_norm", 168, 7058, 42.01190476190476, 14, 87], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", "aten::cudnn_convolution_backward_input", 18, 6600, 366.6666666666667, 364, 370], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", "aten::cudnn_convolution", 18, 6561, 364.5, 361, 369], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 12, 5341, 445.0833333333333, 442, 449], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", "aten::cudnn_convolution_backward_input", 162, 5183, 31.993827160493826, 6, 158], ["volta_scudnn_128x128_stridedB_interior_nn_v1", "aten::cudnn_convolution_backward_input", 18, 4902, 272.3333333333333, 269, 275], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", "aten::cudnn_convolution", 6, 4895, 815.8333333333334, 809, 822], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", "aten::cudnn_convolution_backward_weight", 6, 4553, 758.8333333333334, 732, 780], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", "aten::max_pool2d_with_indices_backward", 6, 4098, 683.0, 682, 684], ["volta_scudnn_128x64_relu_medium_nn_v1", "aten::cudnn_convolution", 6, 3829, 638.1666666666666, 637, 641], ["volta_scudnn_128x128_stridedB_medium_nn_v1", "aten::cudnn_convolution_backward_input", 12, 3714, 309.5, 301, 325], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", "aten::cudnn_convolution", 6, 3533, 588.8333333333334, 573, 659], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", "aten::cudnn_convolution", 6, 3532, 588.6666666666666, 569, 672], ["volta_scudnn_128x64_relu_small_nn_v1", "aten::cudnn_convolution", 12, 3395, 282.9166666666667, 270, 296], ["volta_scudnn_128x128_stridedB_small_nn_v1", "aten::cudnn_convolution_backward_input", 6, 3180, 530.0, 527, 533], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", "aten::cudnn_convolution_backward_input", 60, 2562, 42.7, 21, 68], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", "aten::cudnn_convolution", 60, 2492, 41.53333333333333, 19, 66], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", "aten::cudnn_convolution_backward_weight", 60, 2424, 40.4, 21, 60], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", "aten::fill_", 978, 2414, 2.4683026584867074, 0, 158], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", "aten::mul_", 966, 2380, 2.463768115942029, 1, 24], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", "aten::cudnn_convolution", 60, 2306, 38.43333333333333, 17, 63], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", "aten::cudnn_batch_norm_backward", 54, 2283, 42.27777777777778, 19, 74], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", "aten::cudnn_convolution_backward_input", 60, 2280, 38.0, 20, 61], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", "aten::cudnn_convolution_backward_weight", 60, 2269, 37.81666666666667, 16, 61], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", "aten::cudnn_convolution", 12, 1699, 141.58333333333334, 98, 184], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", "aten::max_pool2d_with_indices", 6, 1341, 223.5, 223, 224], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", "aten::cudnn_convolution", 60, 1306, 21.766666666666666, 4, 66], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", "aten::cudnn_convolution_backward_input", 60, 1296, 21.6, 5, 64], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", "aten::cudnn_convolution_backward_weight", 60, 1292, 21.533333333333335, 4, 63], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", "aten::cudnn_convolution", 6, 848, 141.33333333333334, 140, 142], ["volta_scudnn_128x64_stridedB_small_nn_v1", "aten::cudnn_convolution_backward_input", 6, 572, 95.33333333333333, 94, 96], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", "aten::add", 318, 325, 1.0220125786163523, 1, 2], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", "aten::mean", 6, 256, 42.666666666666664, 42, 43], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", "aten::cudnn_convolution_backward_input", 72, 201, 2.7916666666666665, 2, 4], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", "aten::cudnn_convolution_backward_weight", 150, 190, 1.2666666666666666, 1, 2], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", "aten::cudnn_convolution_backward_weight", 150, 168, 1.12, 1, 2], ["volta_sgemm_64x32_sliced1x4_nn", "aten::mm", 6, 166, 27.666666666666668, 27, 28], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", "aten::div", 6, 162, 27.0, 27, 27], ["volta_sgemm_64x32_sliced1x4_tn", "aten::addmm", 6, 145, 24.166666666666668, 24, 25], ["volta_sgemm_128x32_nt", "aten::mm", 6, 117, 19.5, 19, 20], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", "aten::cudnn_convolution", 48, 99, 2.0625, 2, 3], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", "aten::cudnn_convolution_backward_input", 72, 78, 1.0833333333333333, 1, 2], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", "aten::_log_softmax_backward_data", 6, 64, 10.666666666666666, 10, 11], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", "aten::cudnn_convolution", 18, 62, 3.4444444444444446, 3, 5], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", "aten::cudnn_convolution_backward_input", 18, 62, 3.4444444444444446, 3, 5], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", "aten::_log_softmax", 6, 60, 10.0, 10, 10], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", "CallTreeRoot", 6, 48, 8.0, 8, 8], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", "aten::addmm", 6, 33, 5.5, 5, 6], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", "aten::addmm", 6, 23, 3.8333333333333335, 3, 4], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", "aten::nll_loss_forward", 6, 20, 3.3333333333333335, 3, 4], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", "aten::nll_loss_backward", 6, 12, 2.0, 2, 2], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", "aten::mm", 6, 12, 2.0, 2, 2]]}}, "kernel_pie": {"total": {"columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 86835.0}], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 61395.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 53577.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 47050.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 41190.0}], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 40341.0}], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 28063.0}], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 27624.0}], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 27184.0}], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 26234.0}], ["volta_sgemm_128x64_nt", {"py/object": "numpy.float64", "dtype": "float64", "value": 23737.0}], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 21753.0}], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 14259.0}], ["volta_sgemm_128x64_nn", {"py/object": "numpy.float64", "dtype": "float64", "value": 11407.0}], ["volta_scudnn_128x64_stridedB_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 10904.0}], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 8816.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 8346.0}], ["volta_scudnn_128x64_relu_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 7210.0}], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", {"py/object": "numpy.float64", "dtype": "float64", "value": 7058.0}], ["volta_scudnn_128x128_stridedB_interior_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 5717.0}], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", {"py/object": "numpy.float64", "dtype": "float64", "value": 5482.0}], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 5341.0}], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 5298.0}], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 5250.0}], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 4895.0}], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 4781.0}], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 4765.0}], ["volta_scudnn_128x128_stridedB_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 4312.0}], ["volta_scudnn_128x64_relu_medium_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 3829.0}], ["volta_scudnn_128x128_stridedB_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 3709.0}], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 3533.0}], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 3532.0}], ["volta_scudnn_128x64_relu_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 3395.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2779.0}], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2617.0}], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2602.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2572.0}], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2449.0}], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", {"py/object": "numpy.float64", "dtype": "float64", "value": 2283.0}], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1699.0}], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1341.0}], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 1306.0}], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 848.0}], ["volta_scudnn_128x64_stridedB_small_nn_v1", {"py/object": "numpy.float64", "dtype": "float64", "value": 666.0}], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 330.0}], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 325.0}], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 256.0}], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 198.0}], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 174.0}], ["volta_sgemm_64x32_sliced1x4_nn", {"py/object": "numpy.float64", "dtype": "float64", "value": 166.0}], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", {"py/object": "numpy.float64", "dtype": "float64", "value": 162.0}], ["volta_sgemm_64x32_sliced1x4_tn", {"py/object": "numpy.float64", "dtype": "float64", "value": 145.0}], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 135.0}], ["volta_sgemm_128x32_nt", {"py/object": "numpy.float64", "dtype": "float64", "value": 117.0}], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", {"py/object": "numpy.float64", "dtype": "float64", "value": 90.0}], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 64.0}], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", {"py/object": "numpy.float64", "dtype": "float64", "value": 60.0}], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", {"py/object": "numpy.float64", "dtype": "float64", "value": 48.0}], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", {"py/object": "numpy.float64", "dtype": "float64", "value": 35.0}], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", {"py/object": "numpy.float64", "dtype": "float64", "value": 33.0}], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", {"py/object": "numpy.float64", "dtype": "float64", "value": 20.0}], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", {"py/object": "numpy.float64", "dtype": "float64", "value": 12.0}]]}}, "kernel_table": {"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Total Duration (us)"}, {"type": "number", "name": "Mean Duration (us)"}, {"type": "number", "name": "Max Duration (us)"}, {"type": "number", "name": "Min Duration (us)"}], "rows": [["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", 167, 86835, 520, 1084, 330], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", 287, 61395, 214, 799, 43], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 104, 53577, 515, 815, 393], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", 609, 47050, 77, 364, 6], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", 3489, 41190, 12, 364, 1], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 90, 40341, 448, 753, 381], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 60, 28063, 468, 851, 361], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", 72, 27624, 384, 667, 354], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", 34, 27184, 800, 885, 664], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", 150, 26234, 175, 426, 50], ["volta_sgemm_128x64_nt", 126, 23737, 188, 206, 155], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", 48, 21753, 453, 705, 328], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", 39, 14259, 366, 370, 361], ["volta_sgemm_128x64_nn", 60, 11407, 190, 207, 156], ["volta_scudnn_128x64_stridedB_interior_nn_v1", 34, 10904, 321, 525, 263], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 12, 8816, 735, 784, 660], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 14, 8346, 596, 990, 207], ["volta_scudnn_128x64_relu_interior_nn_v1", 24, 7210, 300, 311, 295], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", 168, 7058, 42, 87, 14], ["volta_scudnn_128x128_stridedB_interior_nn_v1", 21, 5717, 272, 275, 269], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", 167, 5482, 33, 158, 6], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 12, 5341, 445, 449, 442], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 7, 5298, 757, 780, 732], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", 123, 5250, 43, 68, 19], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 6, 4895, 816, 822, 809], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", 7, 4781, 683, 684, 682], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 123, 4765, 39, 63, 17], ["volta_scudnn_128x128_stridedB_medium_nn_v1", 14, 4312, 308, 325, 299], ["volta_scudnn_128x64_relu_medium_nn_v1", 6, 3829, 638, 641, 637], ["volta_scudnn_128x128_stridedB_small_nn_v1", 7, 3709, 530, 533, 527], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 6, 3533, 589, 659, 573], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", 6, 3532, 589, 672, 569], ["volta_scudnn_128x64_relu_small_nn_v1", 12, 3395, 283, 296, 270], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", 1127, 2779, 2, 24, 1], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", 123, 2617, 21, 66, 4], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 63, 2602, 41, 60, 21], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", 979, 2572, 3, 158, 0], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", 63, 2449, 39, 61, 16], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", 54, 2283, 42, 74, 19], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", 12, 1699, 142, 184, 98], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", 6, 1341, 224, 224, 223], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", 63, 1306, 21, 63, 4], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 6, 848, 141, 142, 140], ["volta_scudnn_128x64_stridedB_small_nn_v1", 7, 666, 95, 96, 94], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", 131, 330, 3, 4, 2], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", 318, 325, 1, 2, 1], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", 6, 256, 43, 43, 42], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", 154, 198, 1, 2, 1], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", 154, 174, 1, 2, 1], ["volta_sgemm_64x32_sliced1x4_nn", 6, 166, 28, 28, 27], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", 6, 162, 27, 27, 27], ["volta_sgemm_64x32_sliced1x4_tn", 6, 145, 24, 25, 24], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", 39, 135, 3, 5, 3], ["volta_sgemm_128x32_nt", 6, 117, 20, 20, 19], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", 83, 90, 1, 2, 1], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", 6, 64, 11, 11, 10], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", 6, 60, 10, 10, 10], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", 6, 48, 8, 8, 8], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", 12, 35, 3, 4, 2], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", 6, 33, 6, 6, 5], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", 6, 20, 3, 4, 3], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", 6, 12, 2, 2, 2]]}}, "trace_file_path": "./data\\worker0.pt.trace.json.gz"}]}]}]}}